[ Tue Jun 20 04:34:12 2023 ] using warm up, epoch: 5
[ Tue Jun 20 04:34:14 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 20 04:34:14 2023 ] # Parameters: 1538958
[ Tue Jun 20 04:34:14 2023 ] Training epoch: 1
[ Tue Jun 20 04:34:18 2023 ] 	Training loss: 88.5274.  Training acc: 33.82%.
[ Tue Jun 20 04:34:18 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Jun 20 04:34:18 2023 ] Eval epoch: 1
[ Tue Jun 20 04:34:19 2023 ] 	Mean test loss of 625 batches: 1219.693628.
[ Tue Jun 20 04:34:19 2023 ] 	Top1: 38.60%
[ Tue Jun 20 04:34:19 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:34:19 2023 ] Training epoch: 2
[ Tue Jun 20 04:34:21 2023 ] 	Training loss: 8.4884.  Training acc: 35.85%.
[ Tue Jun 20 04:34:21 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 04:34:21 2023 ] Eval epoch: 2
[ Tue Jun 20 04:34:22 2023 ] 	Mean test loss of 625 batches: 21.500105.
[ Tue Jun 20 04:34:22 2023 ] 	Top1: 38.60%
[ Tue Jun 20 04:34:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:34:22 2023 ] Training epoch: 3
[ Tue Jun 20 04:34:23 2023 ] 	Training loss: 5.2676.  Training acc: 49.36%.
[ Tue Jun 20 04:34:23 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 04:34:23 2023 ] Eval epoch: 3
[ Tue Jun 20 04:34:24 2023 ] 	Mean test loss of 625 batches: 19.204166.
[ Tue Jun 20 04:34:24 2023 ] 	Top1: 38.60%
[ Tue Jun 20 04:34:24 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:34:24 2023 ] Training epoch: 4
[ Tue Jun 20 04:34:26 2023 ] 	Training loss: 2.5894.  Training acc: 72.79%.
[ Tue Jun 20 04:34:26 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 04:34:26 2023 ] Eval epoch: 4
[ Tue Jun 20 04:34:26 2023 ] 	Mean test loss of 625 batches: 5.958696.
[ Tue Jun 20 04:34:26 2023 ] 	Top1: 61.40%
[ Tue Jun 20 04:34:26 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:34:26 2023 ] Training epoch: 5
[ Tue Jun 20 04:34:28 2023 ] 	Training loss: 3.7895.  Training acc: 57.72%.
[ Tue Jun 20 04:34:28 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 04:34:28 2023 ] Eval epoch: 5
[ Tue Jun 20 04:34:29 2023 ] 	Mean test loss of 625 batches: 71.419635.
[ Tue Jun 20 04:34:29 2023 ] 	Top1: 29.82%
[ Tue Jun 20 04:34:29 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:34:29 2023 ] Training epoch: 6
[ Tue Jun 20 04:34:31 2023 ] 	Training loss: 5.8226.  Training acc: 60.48%.
[ Tue Jun 20 04:34:31 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 04:34:31 2023 ] Eval epoch: 6
[ Tue Jun 20 04:34:31 2023 ] 	Mean test loss of 625 batches: 39.918753.
[ Tue Jun 20 04:34:31 2023 ] 	Top1: 38.60%
[ Tue Jun 20 04:34:31 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:34:31 2023 ] Training epoch: 7
[ Tue Jun 20 04:34:33 2023 ] 	Training loss: 3.9803.  Training acc: 52.67%.
[ Tue Jun 20 04:34:33 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 04:34:33 2023 ] Eval epoch: 7
[ Tue Jun 20 04:34:34 2023 ] 	Mean test loss of 625 batches: 15.128516.
[ Tue Jun 20 04:34:34 2023 ] 	Top1: 54.39%
[ Tue Jun 20 04:34:34 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:34:34 2023 ] Training epoch: 8
[ Tue Jun 20 04:34:36 2023 ] 	Training loss: 3.0962.  Training acc: 31.62%.
[ Tue Jun 20 04:34:36 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 20 04:34:36 2023 ] Eval epoch: 8
[ Tue Jun 2[ Sun Jun 25 15:58:51 2023 ] using warm up, epoch: 5
[ Sun Jun 25 15:58:53 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 60, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Sun Jun 25 15:58:53 2023 ] # Parameters Predictor: 1553607
[ Sun Jun 25 15:58:53 2023 ] Start training Predictor
[ Sun Jun 25 15:58:53 2023 ] Training epoch: 1
[ Sun Jun 25 16:02:06 2023 ] using warm up, epoch: 5
[ Sun Jun 25 16:02:07 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 60, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Sun Jun 25 16:02:07 2023 ] # Parameters Predictor: 1553607
[ Sun Jun 25 16:02:07 2023 ] Start training Predictor
[ Sun Jun 25 16:02:07 2023 ] Training epoch: 1
[ Sun Jun 25 16:02:39 2023 ] using warm up, epoch: 5
[ Sun Jun 25 16:02:40 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 60, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Sun Jun 25 16:02:40 2023 ] # Parameters Predictor: 1553607
[ Sun Jun 25 16:02:40 2023 ] Start training Predictor
[ Sun Jun 25 16:02:40 2023 ] Training epoch: 1
[ Tue Jun 27 13:49:27 2023 ] using warm up, epoch: 5
[ Tue Jun 27 13:50:53 2023 ] using warm up, epoch: 5
[ Tue Jun 27 13:52:07 2023 ] using warm up, epoch: 5
[ Tue Jun 27 13:52:33 2023 ] using warm up, epoch: 5
[ Tue Jun 27 13:52:51 2023 ] using warm up, epoch: 5
[ Tue Jun 27 13:52:53 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 13:52:53 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 13:52:53 2023 ] Start training Predictor
[ Tue Jun 27 13:52:53 2023 ] Training epoch: 1
[ Tue Jun 27 13:52:59 2023 ] 	Training loss: 109.5587.  Training acc: 36.40%.
[ Tue Jun 27 13:52:59 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 13:52:59 2023 ] Eval epoch: 1
[ Tue Jun 27 13:55:41 2023 ] using warm up, epoch: 5
[ Tue Jun 27 13:55:43 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 13:55:43 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 13:55:43 2023 ] Start training Predictor
[ Tue Jun 27 13:55:43 2023 ] Training epoch: 1
[ Tue Jun 27 13:56:50 2023 ] using warm up, epoch: 5
[ Tue Jun 27 13:56:52 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 13:56:52 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 13:56:52 2023 ] Start training Predictor
[ Tue Jun 27 13:56:52 2023 ] Training epoch: 1
[ Tue Jun 27 13:56:57 2023 ] 	Training loss: 115.7417.  Training acc: 33.73%.
[ Tue Jun 27 13:56:57 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jun 27 13:56:57 2023 ] Eval epoch: 1
[ Tue Jun 27 13:56:58 2023 ] 	Mean test loss of 625 batches: 1658.780640.
[ Tue Jun 27 13:56:58 2023 ] 	Top1: 38.60%
[ Tue Jun 27 13:56:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:56:58 2023 ] Training epoch: 2
[ Tue Jun 27 13:57:00 2023 ] 	Training loss: 11.2867.  Training acc: 34.93%.
[ Tue Jun 27 13:57:00 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 13:57:00 2023 ] Eval epoch: 2
[ Tue Jun 27 13:57:01 2023 ] 	Mean test loss of 625 batches: 1.575934.
[ Tue Jun 27 13:57:01 2023 ] 	Top1: 31.58%
[ Tue Jun 27 13:57:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:57:01 2023 ] Training epoch: 3
[ Tue Jun 27 13:57:03 2023 ] 	Training loss: 7.5996.  Training acc: 34.65%.
[ Tue Jun 27 13:57:03 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 13:57:03 2023 ] Eval epoch: 3
[ Tue Jun 27 13:57:04 2023 ] 	Mean test loss of 625 batches: 3.893192.
[ Tue Jun 27 13:57:04 2023 ] 	Top1: 31.58%
[ Tue Jun 27 13:57:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:57:04 2023 ] Training epoch: 4
[ Tue Jun 27 13:58:24 2023 ] using warm up, epoch: 5
[ Tue Jun 27 13:58:25 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 13:58:25 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 13:58:25 2023 ] Start training Predictor
[ Tue Jun 27 13:58:25 2023 ] Training epoch: 1
[ Tue Jun 27 13:58:30 2023 ] 	Training loss: 100.1440.  Training acc: 34.83%.
[ Tue Jun 27 13:58:30 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Jun 27 13:58:30 2023 ] Eval epoch: 1
[ Tue Jun 27 13:58:30 2023 ] 	Mean test loss of 625 batches: 10469.936914.
[ Tue Jun 27 13:58:30 2023 ] 	Top1: 29.82%
[ Tue Jun 27 13:58:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:30 2023 ] Training epoch: 2
[ Tue Jun 27 13:58:32 2023 ] 	Training loss: 24.3064.  Training acc: 39.15%.
[ Tue Jun 27 13:58:32 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:58:33 2023 ] Eval epoch: 2
[ Tue Jun 27 13:58:33 2023 ] 	Mean test loss of 625 batches: 73.783802.
[ Tue Jun 27 13:58:33 2023 ] 	Top1: 40.35%
[ Tue Jun 27 13:58:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:33 2023 ] Training epoch: 3
[ Tue Jun 27 13:58:35 2023 ] 	Training loss: 11.3042.  Training acc: 35.57%.
[ Tue Jun 27 13:58:35 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:58:35 2023 ] Eval epoch: 3
[ Tue Jun 27 13:58:36 2023 ] 	Mean test loss of 625 batches: 2.362692.
[ Tue Jun 27 13:58:36 2023 ] 	Top1: 42.11%
[ Tue Jun 27 13:58:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:36 2023 ] Training epoch: 4
[ Tue Jun 27 13:58:38 2023 ] 	Training loss: 5.8534.  Training acc: 38.88%.
[ Tue Jun 27 13:58:38 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:58:38 2023 ] Eval epoch: 4
[ Tue Jun 27 13:58:38 2023 ] 	Mean test loss of 625 batches: 2.814429.
[ Tue Jun 27 13:58:38 2023 ] 	Top1: 40.35%
[ Tue Jun 27 13:58:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:38 2023 ] Training epoch: 5
[ Tue Jun 27 13:58:41 2023 ] 	Training loss: 4.9206.  Training acc: 44.21%.
[ Tue Jun 27 13:58:41 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:58:41 2023 ] Eval epoch: 5
[ Tue Jun 27 13:58:41 2023 ] 	Mean test loss of 625 batches: 11.311417.
[ Tue Jun 27 13:58:41 2023 ] 	Top1: 43.86%
[ Tue Jun 27 13:58:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:41 2023 ] Training epoch: 6
[ Tue Jun 27 13:58:43 2023 ] 	Training loss: 3.4599.  Training acc: 51.93%.
[ Tue Jun 27 13:58:43 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 13:58:43 2023 ] Eval epoch: 6
[ Tue Jun 27 13:58:44 2023 ] 	Mean test loss of 625 batches: 1.189034.
[ Tue Jun 27 13:58:44 2023 ] 	Top1: 45.61%
[ Tue Jun 27 13:58:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:44 2023 ] Training epoch: 7
[ Tue Jun 27 13:58:46 2023 ] 	Training loss: 1.9195.  Training acc: 51.84%.
[ Tue Jun 27 13:58:46 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:58:46 2023 ] Eval epoch: 7
[ Tue Jun 27 13:58:46 2023 ] 	Mean test loss of 625 batches: 2.385581.
[ Tue Jun 27 13:58:46 2023 ] 	Top1: 31.58%
[ Tue Jun 27 13:58:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:46 2023 ] Training epoch: 8
[ Tue Jun 27 13:58:49 2023 ] 	Training loss: 3.0066.  Training acc: 55.70%.
[ Tue Jun 27 13:58:49 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 13:58:49 2023 ] Eval epoch: 8
[ Tue Jun 27 13:58:49 2023 ] 	Mean test loss of 625 batches: 1.072437.
[ Tue Jun 27 13:58:49 2023 ] 	Top1: 42.11%
[ Tue Jun 27 13:58:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:49 2023 ] Training epoch: 9
[ Tue Jun 27 13:58:51 2023 ] 	Training loss: 1.9910.  Training acc: 60.11%.
[ Tue Jun 27 13:58:51 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 13:58:51 2023 ] Eval epoch: 9
[ Tue Jun 27 13:58:52 2023 ] 	Mean test loss of 625 batches: 2.403122.
[ Tue Jun 27 13:58:52 2023 ] 	Top1: 31.58%
[ Tue Jun 27 13:58:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:52 2023 ] Training epoch: 10
[ Tue Jun 27 13:58:54 2023 ] 	Training loss: 1.6636.  Training acc: 56.99%.
[ Tue Jun 27 13:58:54 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:58:54 2023 ] Eval epoch: 10
[ Tue Jun 27 13:58:54 2023 ] 	Mean test loss of 625 batches: 1.856842.
[ Tue Jun 27 13:58:54 2023 ] 	Top1: 31.58%
[ Tue Jun 27 13:58:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:54 2023 ] Training epoch: 11
[ Tue Jun 27 13:58:56 2023 ] 	Training loss: 1.4464.  Training acc: 59.28%.
[ Tue Jun 27 13:58:56 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:58:56 2023 ] Eval epoch: 11
[ Tue Jun 27 13:58:57 2023 ] 	Mean test loss of 625 batches: 0.830895.
[ Tue Jun 27 13:58:57 2023 ] 	Top1: 59.65%
[ Tue Jun 27 13:58:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:57 2023 ] Training epoch: 12
[ Tue Jun 27 13:58:59 2023 ] 	Training loss: 1.3609.  Training acc: 60.75%.
[ Tue Jun 27 13:58:59 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:58:59 2023 ] Eval epoch: 12
[ Tue Jun 27 13:59:00 2023 ] 	Mean test loss of 625 batches: 0.737848.
[ Tue Jun 27 13:59:00 2023 ] 	Top1: 70.18%
[ Tue Jun 27 13:59:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:00 2023 ] Training epoch: 13
[ Tue Jun 27 13:59:02 2023 ] 	Training loss: 1.2263.  Training acc: 62.41%.
[ Tue Jun 27 13:59:02 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 13:59:02 2023 ] Eval epoch: 13
[ Tue Jun 27 13:59:03 2023 ] 	Mean test loss of 625 batches: 0.771405.
[ Tue Jun 27 13:59:03 2023 ] 	Top1: 68.42%
[ Tue Jun 27 13:59:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:03 2023 ] Training epoch: 14
[ Tue Jun 27 13:59:05 2023 ] 	Training loss: 1.2264.  Training acc: 64.61%.
[ Tue Jun 27 13:59:05 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 13:59:05 2023 ] Eval epoch: 14
[ Tue Jun 27 13:59:06 2023 ] 	Mean test loss of 625 batches: 0.695661.
[ Tue Jun 27 13:59:06 2023 ] 	Top1: 70.18%
[ Tue Jun 27 13:59:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:06 2023 ] Training epoch: 15
[ Tue Jun 27 13:59:08 2023 ] 	Training loss: 1.2571.  Training acc: 62.04%.
[ Tue Jun 27 13:59:08 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 13:59:08 2023 ] Eval epoch: 15
[ Tue Jun 27 13:59:09 2023 ] 	Mean test loss of 625 batches: 0.698380.
[ Tue Jun 27 13:59:09 2023 ] 	Top1: 70.18%
[ Tue Jun 27 13:59:09 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:09 2023 ] Training epoch: 16
[ Tue Jun 27 13:59:11 2023 ] 	Training loss: 1.1829.  Training acc: 63.88%.
[ Tue Jun 27 13:59:11 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:59:11 2023 ] Eval epoch: 16
[ Tue Jun 27 13:59:11 2023 ] 	Mean test loss of 625 batches: 0.688894.
[ Tue Jun 27 13:59:11 2023 ] 	Top1: 70.18%
[ Tue Jun 27 13:59:11 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:11 2023 ] Training epoch: 17
[ Tue Jun 27 13:59:14 2023 ] 	Training loss: 1.1544.  Training acc: 62.59%.
[ Tue Jun 27 13:59:14 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:59:14 2023 ] Eval epoch: 17
[ Tue Jun 27 13:59:14 2023 ] 	Mean test loss of 625 batches: 0.686606.
[ Tue Jun 27 13:59:14 2023 ] 	Top1: 73.68%
[ Tue Jun 27 13:59:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:14 2023 ] Training epoch: 18
[ Tue Jun 27 13:59:16 2023 ] 	Training loss: 1.1340.  Training acc: 63.05%.
[ Tue Jun 27 13:59:16 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:59:17 2023 ] Eval epoch: 18
[ Tue Jun 27 13:59:17 2023 ] 	Mean test loss of 625 batches: 0.662801.
[ Tue Jun 27 13:59:17 2023 ] 	Top1: 82.46%
[ Tue Jun 27 13:59:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:17 2023 ] Training epoch: 19
[ Tue Jun 27 13:59:19 2023 ] 	Training loss: 1.0827.  Training acc: 65.53%.
[ Tue Jun 27 13:59:19 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 13:59:19 2023 ] Eval epoch: 19
[ Tue Jun 27 13:59:20 2023 ] 	Mean test loss of 625 batches: 0.721548.
[ Tue Jun 27 13:59:20 2023 ] 	Top1: 75.44%
[ Tue Jun 27 13:59:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:20 2023 ] Training epoch: 20
[ Tue Jun 27 13:59:22 2023 ] 	Training loss: 0.9813.  Training acc: 69.21%.
[ Tue Jun 27 13:59:22 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 13:59:22 2023 ] Eval epoch: 20
[ Tue Jun 27 13:59:23 2023 ] 	Mean test loss of 625 batches: 0.668444.
[ Tue Jun 27 13:59:23 2023 ] 	Top1: 78.95%
[ Tue Jun 27 13:59:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:23 2023 ] Training epoch: 21
[ Tue Jun 27 13:59:25 2023 ] 	Training loss: 1.0096.  Training acc: 67.74%.
[ Tue Jun 27 13:59:25 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:59:25 2023 ] Eval epoch: 21
[ Tue Jun 27 13:59:26 2023 ] 	Mean test loss of 625 batches: 0.663707.
[ Tue Jun 27 13:59:26 2023 ] 	Top1: 80.70%
[ Tue Jun 27 13:59:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:26 2023 ] Training epoch: 22
[ Tue Jun 27 13:59:28 2023 ] 	Training loss: 0.9417.  Training acc: 70.22%.
[ Tue Jun 27 13:59:28 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Tue Jun 27 13:59:28 2023 ] Eval epoch: 22
[ Tue Jun 27 13:59:29 2023 ] 	Mean test loss of 625 batches: 0.643037.
[ Tue Jun 27 13:59:29 2023 ] 	Top1: 78.95%
[ Tue Jun 27 13:59:29 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:29 2023 ] Training epoch: 23
[ Tue Jun 27 13:59:31 2023 ] 	Training loss: 0.9777.  Training acc: 68.66%.
[ Tue Jun 27 13:59:31 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 13:59:31 2023 ] Eval epoch: 23
[ Tue Jun 27 13:59:32 2023 ] 	Mean test loss of 625 batches: 0.636263.
[ Tue Jun 27 13:59:32 2023 ] 	Top1: 80.70%
[ Tue Jun 27 13:59:32 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:32 2023 ] Training epoch: 24
[ Tue Jun 27 13:59:34 2023 ] 	Training loss: 0.9415.  Training acc: 70.40%.
[ Tue Jun 27 13:59:34 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 13:59:34 2023 ] Eval epoch: 24
[ Tue Jun 27 13:59:35 2023 ] 	Mean test loss of 625 batches: 0.636494.
[ Tue Jun 27 13:59:35 2023 ] 	Top1: 80.70%
[ Tue Jun 27 13:59:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:35 2023 ] Training epoch: 25
[ Tue Jun 27 13:59:37 2023 ] 	Training loss: 0.9646.  Training acc: 69.58%.
[ Tue Jun 27 13:59:37 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 13:59:37 2023 ] Eval epoch: 25
[ Tue Jun 27 13:59:38 2023 ] 	Mean test loss of 625 batches: 0.642202.
[ Tue Jun 27 13:59:38 2023 ] 	Top1: 80.70%
[ Tue Jun 27 13:59:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:38 2023 ] Training epoch: 26
[ Tue Jun 27 13:59:40 2023 ] 	Training loss: 0.9328.  Training acc: 71.23%.
[ Tue Jun 27 13:59:40 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 13:59:40 2023 ] Eval epoch: 26
[ Tue Jun 27 13:59:41 2023 ] 	Mean test loss of 625 batches: 0.632260.
[ Tue Jun 27 13:59:41 2023 ] 	Top1: 80.70%
[ Tue Jun 27 13:59:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:41 2023 ] Training epoch: 27
[ Tue Jun 27 13:59:43 2023 ] 	Training loss: 0.9577.  Training acc: 69.85%.
[ Tue Jun 27 13:59:43 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 13:59:43 2023 ] Eval epoch: 27
[ Tue Jun 27 13:59:44 2023 ] 	Mean test loss of 625 batches: 0.631299.
[ Tue Jun 27 13:59:44 2023 ] 	Top1: 78.95%
[ Tue Jun 27 13:59:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:44 2023 ] Training epoch: 28
[ Tue Jun 27 13:59:46 2023 ] 	Training loss: 0.9518.  Training acc: 71.23%.
[ Tue Jun 27 13:59:46 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:59:46 2023 ] Eval epoch: 28
[ Tue Jun 27 13:59:47 2023 ] 	Mean test loss of 625 batches: 0.631414.
[ Tue Jun 27 13:59:47 2023 ] 	Top1: 80.70%
[ Tue Jun 27 13:59:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:47 2023 ] Training epoch: 29
[ Tue Jun 27 13:59:49 2023 ] 	Training loss: 0.9196.  Training acc: 72.79%.
[ Tue Jun 27 13:59:49 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 13:59:49 2023 ] Eval epoch: 29
[ Tue Jun 27 13:59:50 2023 ] 	Mean test loss of 625 batches: 0.635160.
[ Tue Jun 27 13:59:50 2023 ] 	Top1: 82.46%
[ Tue Jun 27 13:59:50 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:50 2023 ] Training epoch: 30
[ Tue Jun 27 13:59:52 2023 ] 	Training loss: 0.8911.  Training acc: 72.06%.
[ Tue Jun 27 13:59:52 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:59:52 2023 ] Eval epoch: 30
[ Tue Jun 27 13:59:53 2023 ] 	Mean test loss of 625 batches: 0.625212.
[ Tue Jun 27 13:59:53 2023 ] 	Top1: 80.70%
[ Tue Jun 27 13:59:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:53 2023 ] Best accuracy: 0.8245614035087719
[ Tue Jun 27 13:59:53 2023 ] Epoch number: 18
[ Tue Jun 27 13:59:53 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 13:59:53 2023 ] Weight decay: 0.0005
[ Tue Jun 27 13:59:53 2023 ] Base LR: 0.1
[ Tue Jun 27 13:59:53 2023 ] Batch Size: 64
[ Tue Jun 27 13:59:53 2023 ] Test Batch Size: 64
[ Tue Jun 27 13:59:53 2023 ] seed: 1
[ Tue Jun 27 14:01:00 2023 ] using warm up, epoch: 5
[ Tue Jun 27 14:01:02 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 14:01:02 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 14:01:02 2023 ] Start training Predictor
[ Tue Jun 27 14:01:02 2023 ] Training epoch: 1
[ Tue Jun 27 14:01:07 2023 ] 	Training loss: 105.0571.  Training acc: 35.57%.
[ Tue Jun 27 14:01:07 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jun 27 14:01:07 2023 ] Eval epoch: 1
[ Tue Jun 27 14:01:08 2023 ] 	Mean test loss of 625 batches: 9916.885303.
[ Tue Jun 27 14:01:08 2023 ] 	Top1: 29.82%
[ Tue Jun 27 14:01:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:08 2023 ] Training epoch: 2
[ Tue Jun 27 14:01:10 2023 ] 	Training loss: 17.9997.  Training acc: 38.97%.
[ Tue Jun 27 14:01:10 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 14:01:10 2023 ] Eval epoch: 2
[ Tue Jun 27 14:01:11 2023 ] 	Mean test loss of 625 batches: 2172.547998.
[ Tue Jun 27 14:01:11 2023 ] 	Top1: 29.82%
[ Tue Jun 27 14:01:11 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:11 2023 ] Training epoch: 3
[ Tue Jun 27 14:01:13 2023 ] 	Training loss: 6.4831.  Training acc: 40.99%.
[ Tue Jun 27 14:01:13 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:01:13 2023 ] Eval epoch: 3
[ Tue Jun 27 14:01:13 2023 ] 	Mean test loss of 625 batches: 23.002123.
[ Tue Jun 27 14:01:13 2023 ] 	Top1: 29.82%
[ Tue Jun 27 14:01:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:13 2023 ] Training epoch: 4
[ Tue Jun 27 14:01:16 2023 ] 	Training loss: 5.8920.  Training acc: 38.69%.
[ Tue Jun 27 14:01:16 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:01:16 2023 ] Eval epoch: 4
[ Tue Jun 27 14:01:16 2023 ] 	Mean test loss of 625 batches: 6.472894.
[ Tue Jun 27 14:01:16 2023 ] 	Top1: 29.82%
[ Tue Jun 27 14:01:16 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:16 2023 ] Training epoch: 5
[ Tue Jun 27 14:01:18 2023 ] 	Training loss: 3.5655.  Training acc: 56.07%.
[ Tue Jun 27 14:01:18 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:01:18 2023 ] Eval epoch: 5
[ Tue Jun 27 14:01:19 2023 ] 	Mean test loss of 625 batches: 1.394858.
[ Tue Jun 27 14:01:19 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:01:19 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:19 2023 ] Training epoch: 6
[ Tue Jun 27 14:01:21 2023 ] 	Training loss: 2.5142.  Training acc: 57.63%.
[ Tue Jun 27 14:01:21 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:01:21 2023 ] Eval epoch: 6
[ Tue Jun 27 14:01:22 2023 ] 	Mean test loss of 625 batches: 26.309593.
[ Tue Jun 27 14:01:22 2023 ] 	Top1: 29.82%
[ Tue Jun 27 14:01:22 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:22 2023 ] Training epoch: 7
[ Tue Jun 27 14:01:24 2023 ] 	Training loss: 2.3178.  Training acc: 60.29%.
[ Tue Jun 27 14:01:24 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 14:01:24 2023 ] Eval epoch: 7
[ Tue Jun 27 14:01:25 2023 ] 	Mean test loss of 625 batches: 5.277068.
[ Tue Jun 27 14:01:25 2023 ] 	Top1: 50.88%
[ Tue Jun 27 14:01:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:25 2023 ] Training epoch: 8
[ Tue Jun 27 14:01:27 2023 ] 	Training loss: 1.8893.  Training acc: 61.67%.
[ Tue Jun 27 14:01:27 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 14:01:27 2023 ] Eval epoch: 8
[ Tue Jun 27 14:01:28 2023 ] 	Mean test loss of 625 batches: 1.625292.
[ Tue Jun 27 14:01:28 2023 ] 	Top1: 68.42%
[ Tue Jun 27 14:01:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:28 2023 ] Training epoch: 9
[ Tue Jun 27 14:01:30 2023 ] 	Training loss: 1.4047.  Training acc: 61.31%.
[ Tue Jun 27 14:01:30 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:01:30 2023 ] Eval epoch: 9
[ Tue Jun 27 14:01:31 2023 ] 	Mean test loss of 625 batches: 0.877045.
[ Tue Jun 27 14:01:31 2023 ] 	Top1: 64.91%
[ Tue Jun 27 14:01:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:31 2023 ] Training epoch: 10
[ Tue Jun 27 14:01:33 2023 ] 	Training loss: 1.2627.  Training acc: 60.48%.
[ Tue Jun 27 14:01:33 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:01:33 2023 ] Eval epoch: 10
[ Tue Jun 27 14:01:34 2023 ] 	Mean test loss of 625 batches: 1.109237.
[ Tue Jun 27 14:01:34 2023 ] 	Top1: 66.67%
[ Tue Jun 27 14:01:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:34 2023 ] Training epoch: 11
[ Tue Jun 27 14:01:36 2023 ] 	Training loss: 1.2074.  Training acc: 63.14%.
[ Tue Jun 27 14:01:36 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:01:36 2023 ] Eval epoch: 11
[ Tue Jun 27 14:01:36 2023 ] 	Mean test loss of 625 batches: 0.816517.
[ Tue Jun 27 14:01:36 2023 ] 	Top1: 64.91%
[ Tue Jun 27 14:01:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:36 2023 ] Training epoch: 12
[ Tue Jun 27 14:01:39 2023 ] 	Training loss: 1.0294.  Training acc: 64.25%.
[ Tue Jun 27 14:01:39 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:01:39 2023 ] Eval epoch: 12
[ Tue Jun 27 14:01:39 2023 ] 	Mean test loss of 625 batches: 0.739190.
[ Tue Jun 27 14:01:39 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:01:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:39 2023 ] Training epoch: 13
[ Tue Jun 27 14:01:42 2023 ] 	Training loss: 0.8958.  Training acc: 67.19%.
[ Tue Jun 27 14:01:42 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:01:42 2023 ] Eval epoch: 13
[ Tue Jun 27 14:01:42 2023 ] 	Mean test loss of 625 batches: 0.727985.
[ Tue Jun 27 14:01:42 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:01:42 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:42 2023 ] Training epoch: 14
[ Tue Jun 27 14:01:44 2023 ] 	Training loss: 0.8683.  Training acc: 65.44%.
[ Tue Jun 27 14:01:44 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:01:44 2023 ] Eval epoch: 14
[ Tue Jun 27 14:01:45 2023 ] 	Mean test loss of 625 batches: 0.717627.
[ Tue Jun 27 14:01:45 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:01:45 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:45 2023 ] Training epoch: 15
[ Tue Jun 27 14:01:47 2023 ] 	Training loss: 0.8822.  Training acc: 66.08%.
[ Tue Jun 27 14:01:47 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:01:47 2023 ] Eval epoch: 15
[ Tue Jun 27 14:01:48 2023 ] 	Mean test loss of 625 batches: 0.737741.
[ Tue Jun 27 14:01:48 2023 ] 	Top1: 68.42%
[ Tue Jun 27 14:01:48 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:48 2023 ] Training epoch: 16
[ Tue Jun 27 14:01:50 2023 ] 	Training loss: 0.8656.  Training acc: 69.21%.
[ Tue Jun 27 14:01:50 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 14:01:50 2023 ] Eval epoch: 16
[ Tue Jun 27 14:01:51 2023 ] 	Mean test loss of 625 batches: 0.725928.
[ Tue Jun 27 14:01:51 2023 ] 	Top1: 71.93%
[ Tue Jun 27 14:01:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:51 2023 ] Training epoch: 17
[ Tue Jun 27 14:01:53 2023 ] 	Training loss: 0.7935.  Training acc: 70.77%.
[ Tue Jun 27 14:01:53 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:01:53 2023 ] Eval epoch: 17
[ Tue Jun 27 14:01:54 2023 ] 	Mean test loss of 625 batches: 0.668416.
[ Tue Jun 27 14:01:54 2023 ] 	Top1: 78.95%
[ Tue Jun 27 14:01:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:54 2023 ] Training epoch: 18
[ Tue Jun 27 14:01:56 2023 ] 	Training loss: 0.7862.  Training acc: 72.52%.
[ Tue Jun 27 14:01:56 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:01:56 2023 ] Eval epoch: 18
[ Tue Jun 27 14:01:57 2023 ] 	Mean test loss of 625 batches: 0.686954.
[ Tue Jun 27 14:01:57 2023 ] 	Top1: 71.93%
[ Tue Jun 27 14:01:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:57 2023 ] Training epoch: 19
[ Tue Jun 27 14:01:59 2023 ] 	Training loss: 0.7992.  Training acc: 72.98%.
[ Tue Jun 27 14:01:59 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:01:59 2023 ] Eval epoch: 19
[ Tue Jun 27 14:02:00 2023 ] 	Mean test loss of 625 batches: 0.795414.
[ Tue Jun 27 14:02:00 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:02:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:00 2023 ] Training epoch: 20
[ Tue Jun 27 14:02:02 2023 ] 	Training loss: 0.7594.  Training acc: 75.83%.
[ Tue Jun 27 14:02:02 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:02:02 2023 ] Eval epoch: 20
[ Tue Jun 27 14:02:03 2023 ] 	Mean test loss of 625 batches: 0.715280.
[ Tue Jun 27 14:02:03 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:02:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:03 2023 ] Training epoch: 21
[ Tue Jun 27 14:02:05 2023 ] 	Training loss: 0.7306.  Training acc: 78.03%.
[ Tue Jun 27 14:02:05 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:02:05 2023 ] Eval epoch: 21
[ Tue Jun 27 14:02:06 2023 ] 	Mean test loss of 625 batches: 0.620975.
[ Tue Jun 27 14:02:06 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:06 2023 ] Training epoch: 22
[ Tue Jun 27 14:02:08 2023 ] 	Training loss: 0.6931.  Training acc: 80.42%.
[ Tue Jun 27 14:02:08 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 14:02:08 2023 ] Eval epoch: 22
[ Tue Jun 27 14:02:08 2023 ] 	Mean test loss of 625 batches: 0.629052.
[ Tue Jun 27 14:02:08 2023 ] 	Top1: 80.70%
[ Tue Jun 27 14:02:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:09 2023 ] Training epoch: 23
[ Tue Jun 27 14:02:11 2023 ] 	Training loss: 0.6946.  Training acc: 79.69%.
[ Tue Jun 27 14:02:11 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:02:11 2023 ] Eval epoch: 23
[ Tue Jun 27 14:02:11 2023 ] 	Mean test loss of 625 batches: 0.641322.
[ Tue Jun 27 14:02:11 2023 ] 	Top1: 80.70%
[ Tue Jun 27 14:02:11 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:11 2023 ] Training epoch: 24
[ Tue Jun 27 14:02:14 2023 ] 	Training loss: 0.6952.  Training acc: 80.42%.
[ Tue Jun 27 14:02:14 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:02:14 2023 ] Eval epoch: 24
[ Tue Jun 27 14:02:14 2023 ] 	Mean test loss of 625 batches: 0.617999.
[ Tue Jun 27 14:02:14 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:02:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:14 2023 ] Training epoch: 25
[ Tue Jun 27 14:02:17 2023 ] 	Training loss: 0.7056.  Training acc: 78.68%.
[ Tue Jun 27 14:02:17 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:02:17 2023 ] Eval epoch: 25
[ Tue Jun 27 14:02:18 2023 ] 	Mean test loss of 625 batches: 0.628484.
[ Tue Jun 27 14:02:18 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:18 2023 ] Training epoch: 26
[ Tue Jun 27 14:02:20 2023 ] 	Training loss: 0.6817.  Training acc: 81.34%.
[ Tue Jun 27 14:02:20 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:02:20 2023 ] Eval epoch: 26
[ Tue Jun 27 14:02:21 2023 ] 	Mean test loss of 625 batches: 0.626601.
[ Tue Jun 27 14:02:21 2023 ] 	Top1: 80.70%
[ Tue Jun 27 14:02:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:21 2023 ] Training epoch: 27
[ Tue Jun 27 14:02:24 2023 ] 	Training loss: 0.6971.  Training acc: 81.07%.
[ Tue Jun 27 14:02:24 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:02:24 2023 ] Eval epoch: 27
[ Tue Jun 27 14:02:24 2023 ] 	Mean test loss of 625 batches: 0.608106.
[ Tue Jun 27 14:02:24 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:24 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:24 2023 ] Training epoch: 28
[ Tue Jun 27 14:02:27 2023 ] 	Training loss: 0.6735.  Training acc: 83.00%.
[ Tue Jun 27 14:02:27 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:02:27 2023 ] Eval epoch: 28
[ Tue Jun 27 14:02:27 2023 ] 	Mean test loss of 625 batches: 0.601313.
[ Tue Jun 27 14:02:27 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:02:27 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:27 2023 ] Training epoch: 29
[ Tue Jun 27 14:02:30 2023 ] 	Training loss: 0.6642.  Training acc: 82.44%.
[ Tue Jun 27 14:02:30 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 14:02:30 2023 ] Eval epoch: 29
[ Tue Jun 27 14:02:30 2023 ] 	Mean test loss of 625 batches: 0.607080.
[ Tue Jun 27 14:02:30 2023 ] 	Top1: 82.46%
[ Tue Jun 27 14:02:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:30 2023 ] Training epoch: 30
[ Tue Jun 27 14:02:33 2023 ] 	Training loss: 0.6505.  Training acc: 84.93%.
[ Tue Jun 27 14:02:33 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:02:33 2023 ] Eval epoch: 30
[ Tue Jun 27 14:02:33 2023 ] 	Mean test loss of 625 batches: 0.594197.
[ Tue Jun 27 14:02:33 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:33 2023 ] Training epoch: 31
[ Tue Jun 27 14:02:36 2023 ] 	Training loss: 0.6622.  Training acc: 82.08%.
[ Tue Jun 27 14:02:36 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:02:36 2023 ] Eval epoch: 31
[ Tue Jun 27 14:02:36 2023 ] 	Mean test loss of 625 batches: 0.616825.
[ Tue Jun 27 14:02:36 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:02:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:36 2023 ] Training epoch: 32
[ Tue Jun 27 14:02:38 2023 ] 	Training loss: 0.6796.  Training acc: 82.81%.
[ Tue Jun 27 14:02:38 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 14:02:38 2023 ] Eval epoch: 32
[ Tue Jun 27 14:02:39 2023 ] 	Mean test loss of 625 batches: 0.605950.
[ Tue Jun 27 14:02:39 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:39 2023 ] Training epoch: 33
[ Tue Jun 27 14:02:42 2023 ] 	Training loss: 0.6491.  Training acc: 83.92%.
[ Tue Jun 27 14:02:42 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:02:42 2023 ] Eval epoch: 33
[ Tue Jun 27 14:02:42 2023 ] 	Mean test loss of 625 batches: 0.595160.
[ Tue Jun 27 14:02:42 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:42 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:42 2023 ] Training epoch: 34
[ Tue Jun 27 14:02:44 2023 ] 	Training loss: 0.6583.  Training acc: 84.19%.
[ Tue Jun 27 14:02:44 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:02:44 2023 ] Eval epoch: 34
[ Tue Jun 27 14:02:45 2023 ] 	Mean test loss of 625 batches: 0.602782.
[ Tue Jun 27 14:02:45 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:45 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:45 2023 ] Training epoch: 35
[ Tue Jun 27 14:02:47 2023 ] 	Training loss: 0.6396.  Training acc: 86.03%.
[ Tue Jun 27 14:02:47 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:02:47 2023 ] Eval epoch: 35
[ Tue Jun 27 14:02:48 2023 ] 	Mean test loss of 625 batches: 0.573930.
[ Tue Jun 27 14:02:48 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:48 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:48 2023 ] Training epoch: 36
[ Tue Jun 27 14:02:50 2023 ] 	Training loss: 0.6379.  Training acc: 85.66%.
[ Tue Jun 27 14:02:50 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:02:50 2023 ] Eval epoch: 36
[ Tue Jun 27 14:02:51 2023 ] 	Mean test loss of 625 batches: 0.586560.
[ Tue Jun 27 14:02:51 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:51 2023 ] Training epoch: 37
[ Tue Jun 27 14:02:53 2023 ] 	Training loss: 0.6431.  Training acc: 85.57%.
[ Tue Jun 27 14:02:53 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:02:53 2023 ] Eval epoch: 37
[ Tue Jun 27 14:02:54 2023 ] 	Mean test loss of 625 batches: 0.591507.
[ Tue Jun 27 14:02:54 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:54 2023 ] Training epoch: 38
[ Tue Jun 27 14:02:56 2023 ] 	Training loss: 0.6363.  Training acc: 84.83%.
[ Tue Jun 27 14:02:56 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:02:56 2023 ] Eval epoch: 38
[ Tue Jun 27 14:02:57 2023 ] 	Mean test loss of 625 batches: 0.603585.
[ Tue Jun 27 14:02:57 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:57 2023 ] Training epoch: 39
[ Tue Jun 27 14:02:59 2023 ] 	Training loss: 0.6232.  Training acc: 86.67%.
[ Tue Jun 27 14:02:59 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:02:59 2023 ] Eval epoch: 39
[ Tue Jun 27 14:02:59 2023 ] 	Mean test loss of 625 batches: 0.572214.
[ Tue Jun 27 14:02:59 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:02:59 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:59 2023 ] Training epoch: 40
[ Tue Jun 27 14:03:02 2023 ] 	Training loss: 0.6520.  Training acc: 84.83%.
[ Tue Jun 27 14:03:02 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 14:03:02 2023 ] Eval epoch: 40
[ Tue Jun 27 14:03:02 2023 ] 	Mean test loss of 625 batches: 0.574481.
[ Tue Jun 27 14:03:02 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:03:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:03:03 2023 ] Best accuracy: 0.8771929824561403
[ Tue Jun 27 14:03:03 2023 ] Epoch number: 39
[ Tue Jun 27 14:03:03 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 14:03:03 2023 ] Weight decay: 0.0005
[ Tue Jun 27 14:03:03 2023 ] Base LR: 0.1
[ Tue Jun 27 14:03:03 2023 ] Batch Size: 64
[ Tue Jun 27 14:03:03 2023 ] Test Batch Size: 64
[ Tue Jun 27 14:03:03 2023 ] seed: 1
[ Tue Jun 27 14:04:36 2023 ] using warm up, epoch: 5
[ Tue Jun 27 14:04:37 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 14:04:37 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 14:04:37 2023 ] Start training Predictor
[ Tue Jun 27 14:04:37 2023 ] Training epoch: 1
[ Tue Jun 27 14:04:43 2023 ] 	Training loss: 110.7125.  Training acc: 34.56%.
[ Tue Jun 27 14:04:43 2023 ] 	Time consumption: [Data]05%, [Network]94%
[ Tue Jun 27 14:04:43 2023 ] Eval epoch: 1
[ Tue Jun 27 14:04:44 2023 ] 	Mean test loss of 625 batches: 266.382657.
[ Tue Jun 27 14:04:44 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:04:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:04:44 2023 ] Training epoch: 2
[ Tue Jun 27 14:04:46 2023 ] 	Training loss: 11.0199.  Training acc: 34.65%.
[ Tue Jun 27 14:04:46 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:04:46 2023 ] Eval epoch: 2
[ Tue Jun 27 14:04:47 2023 ] 	Mean test loss of 625 batches: 3.910967.
[ Tue Jun 27 14:04:47 2023 ] 	Top1: 35.09%
[ Tue Jun 27 14:04:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:04:47 2023 ] Training epoch: 3
[ Tue Jun 27 14:04:49 2023 ] 	Training loss: 7.3739.  Training acc: 35.20%.
[ Tue Jun 27 14:04:49 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:04:49 2023 ] Eval epoch: 3
[ Tue Jun 27 14:04:50 2023 ] 	Mean test loss of 625 batches: 1.591804.
[ Tue Jun 27 14:04:50 2023 ] 	Top1: 36.84%
[ Tue Jun 27 14:04:50 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:04:50 2023 ] Training epoch: 4
[ Tue Jun 27 14:04:52 2023 ] 	Training loss: 6.7339.  Training acc: 39.06%.
[ Tue Jun 27 14:04:52 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:04:52 2023 ] Eval epoch: 4
[ Tue Jun 27 14:04:52 2023 ] 	Mean test loss of 625 batches: 7.395569.
[ Tue Jun 27 14:04:52 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:04:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:04:52 2023 ] Training epoch: 5
[ Tue Jun 27 14:04:55 2023 ] 	Training loss: 4.6160.  Training acc: 52.67%.
[ Tue Jun 27 14:04:55 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:04:55 2023 ] Eval epoch: 5
[ Tue Jun 27 14:04:55 2023 ] 	Mean test loss of 625 batches: 3.790101.
[ Tue Jun 27 14:04:55 2023 ] 	Top1: 63.16%
[ Tue Jun 27 14:04:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:04:56 2023 ] Training epoch: 6
[ Tue Jun 27 14:04:58 2023 ] 	Training loss: 3.6742.  Training acc: 54.78%.
[ Tue Jun 27 14:04:58 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:04:58 2023 ] Eval epoch: 6
[ Tue Jun 27 14:04:58 2023 ] 	Mean test loss of 625 batches: 2.917603.
[ Tue Jun 27 14:04:58 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:04:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:04:58 2023 ] Training epoch: 7
[ Tue Jun 27 14:05:01 2023 ] 	Training loss: 1.9858.  Training acc: 56.25%.
[ Tue Jun 27 14:05:01 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:05:01 2023 ] Eval epoch: 7
[ Tue Jun 27 14:05:01 2023 ] 	Mean test loss of 625 batches: 1.217876.
[ Tue Jun 27 14:05:01 2023 ] 	Top1: 63.16%
[ Tue Jun 27 14:05:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:01 2023 ] Training epoch: 8
[ Tue Jun 27 14:05:04 2023 ] 	Training loss: 1.9460.  Training acc: 51.84%.
[ Tue Jun 27 14:05:04 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:05:04 2023 ] Eval epoch: 8
[ Tue Jun 27 14:05:04 2023 ] 	Mean test loss of 625 batches: 0.799216.
[ Tue Jun 27 14:05:04 2023 ] 	Top1: 68.42%
[ Tue Jun 27 14:05:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:04 2023 ] Training epoch: 9
[ Tue Jun 27 14:05:07 2023 ] 	Training loss: 2.4020.  Training acc: 47.33%.
[ Tue Jun 27 14:05:07 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:05:07 2023 ] Eval epoch: 9
[ Tue Jun 27 14:05:07 2023 ] 	Mean test loss of 625 batches: 29.632864.
[ Tue Jun 27 14:05:07 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:05:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:07 2023 ] Training epoch: 10
[ Tue Jun 27 14:05:10 2023 ] 	Training loss: 1.7838.  Training acc: 47.70%.
[ Tue Jun 27 14:05:10 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:05:10 2023 ] Eval epoch: 10
[ Tue Jun 27 14:05:10 2023 ] 	Mean test loss of 625 batches: 22.565140.
[ Tue Jun 27 14:05:10 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:05:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:10 2023 ] Training epoch: 11
[ Tue Jun 27 14:05:12 2023 ] 	Training loss: 1.1539.  Training acc: 56.89%.
[ Tue Jun 27 14:05:12 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:05:12 2023 ] Eval epoch: 11
[ Tue Jun 27 14:05:13 2023 ] 	Mean test loss of 625 batches: 1.152249.
[ Tue Jun 27 14:05:13 2023 ] 	Top1: 54.39%
[ Tue Jun 27 14:05:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:13 2023 ] Training epoch: 12
[ Tue Jun 27 14:05:15 2023 ] 	Training loss: 0.9925.  Training acc: 58.55%.
[ Tue Jun 27 14:05:15 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:05:15 2023 ] Eval epoch: 12
[ Tue Jun 27 14:05:16 2023 ] 	Mean test loss of 625 batches: 0.882661.
[ Tue Jun 27 14:05:16 2023 ] 	Top1: 56.14%
[ Tue Jun 27 14:05:16 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:16 2023 ] Training epoch: 13
[ Tue Jun 27 14:05:19 2023 ] 	Training loss: 0.8824.  Training acc: 61.86%.
[ Tue Jun 27 14:05:19 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:05:19 2023 ] Eval epoch: 13
[ Tue Jun 27 14:05:19 2023 ] 	Mean test loss of 625 batches: 0.767506.
[ Tue Jun 27 14:05:19 2023 ] 	Top1: 59.65%
[ Tue Jun 27 14:05:19 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:19 2023 ] Training epoch: 14
[ Tue Jun 27 14:05:22 2023 ] 	Training loss: 0.8448.  Training acc: 60.94%.
[ Tue Jun 27 14:05:22 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:05:22 2023 ] Eval epoch: 14
[ Tue Jun 27 14:05:22 2023 ] 	Mean test loss of 625 batches: 0.753298.
[ Tue Jun 27 14:05:22 2023 ] 	Top1: 64.91%
[ Tue Jun 27 14:05:22 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:22 2023 ] Training epoch: 15
[ Tue Jun 27 14:05:25 2023 ] 	Training loss: 0.8359.  Training acc: 65.17%.
[ Tue Jun 27 14:05:25 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:05:25 2023 ] Eval epoch: 15
[ Tue Jun 27 14:05:26 2023 ] 	Mean test loss of 625 batches: 0.765828.
[ Tue Jun 27 14:05:26 2023 ] 	Top1: 66.67%
[ Tue Jun 27 14:05:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:26 2023 ] Training epoch: 16
[ Tue Jun 27 14:05:28 2023 ] 	Training loss: 0.8220.  Training acc: 65.17%.
[ Tue Jun 27 14:05:28 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:05:28 2023 ] Eval epoch: 16
[ Tue Jun 27 14:05:29 2023 ] 	Mean test loss of 625 batches: 0.661623.
[ Tue Jun 27 14:05:29 2023 ] 	Top1: 73.68%
[ Tue Jun 27 14:05:29 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:29 2023 ] Training epoch: 17
[ Tue Jun 27 14:05:31 2023 ] 	Training loss: 0.8053.  Training acc: 67.46%.
[ Tue Jun 27 14:05:31 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:05:31 2023 ] Eval epoch: 17
[ Tue Jun 27 14:05:32 2023 ] 	Mean test loss of 625 batches: 0.749622.
[ Tue Jun 27 14:05:32 2023 ] 	Top1: 66.67%
[ Tue Jun 27 14:05:32 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:32 2023 ] Training epoch: 18
[ Tue Jun 27 14:05:34 2023 ] 	Training loss: 0.7793.  Training acc: 68.38%.
[ Tue Jun 27 14:05:34 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:05:34 2023 ] Eval epoch: 18
[ Tue Jun 27 14:05:35 2023 ] 	Mean test loss of 625 batches: 0.702248.
[ Tue Jun 27 14:05:35 2023 ] 	Top1: 68.42%
[ Tue Jun 27 14:05:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:35 2023 ] Training epoch: 19
[ Tue Jun 27 14:05:37 2023 ] 	Training loss: 0.7899.  Training acc: 69.49%.
[ Tue Jun 27 14:05:37 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:05:37 2023 ] Eval epoch: 19
[ Tue Jun 27 14:05:38 2023 ] 	Mean test loss of 625 batches: 0.671686.
[ Tue Jun 27 14:05:38 2023 ] 	Top1: 77.19%
[ Tue Jun 27 14:05:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:38 2023 ] Training epoch: 20
[ Tue Jun 27 14:05:41 2023 ] 	Training loss: 0.7247.  Training acc: 71.78%.
[ Tue Jun 27 14:05:41 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:05:41 2023 ] Eval epoch: 20
[ Tue Jun 27 14:05:41 2023 ] 	Mean test loss of 625 batches: 0.729764.
[ Tue Jun 27 14:05:41 2023 ] 	Top1: 68.42%
[ Tue Jun 27 14:05:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:41 2023 ] Training epoch: 21
[ Tue Jun 27 14:05:43 2023 ] 	Training loss: 0.7490.  Training acc: 72.15%.
[ Tue Jun 27 14:05:43 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:05:43 2023 ] Eval epoch: 21
[ Tue Jun 27 14:05:44 2023 ] 	Mean test loss of 625 batches: 0.653507.
[ Tue Jun 27 14:05:44 2023 ] 	Top1: 77.19%
[ Tue Jun 27 14:05:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:44 2023 ] Training epoch: 22
[ Tue Jun 27 14:05:46 2023 ] 	Training loss: 0.6938.  Training acc: 74.72%.
[ Tue Jun 27 14:05:46 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:05:46 2023 ] Eval epoch: 22
[ Tue Jun 27 14:05:47 2023 ] 	Mean test loss of 625 batches: 0.631672.
[ Tue Jun 27 14:05:47 2023 ] 	Top1: 78.95%
[ Tue Jun 27 14:05:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:47 2023 ] Training epoch: 23
[ Tue Jun 27 14:05:49 2023 ] 	Training loss: 0.6922.  Training acc: 75.83%.
[ Tue Jun 27 14:05:49 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:05:49 2023 ] Eval epoch: 23
[ Tue Jun 27 14:05:50 2023 ] 	Mean test loss of 625 batches: 0.648096.
[ Tue Jun 27 14:05:50 2023 ] 	Top1: 77.19%
[ Tue Jun 27 14:05:50 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:50 2023 ] Training epoch: 24
[ Tue Jun 27 14:05:52 2023 ] 	Training loss: 0.7033.  Training acc: 74.63%.
[ Tue Jun 27 14:05:52 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:05:52 2023 ] Eval epoch: 24
[ Tue Jun 27 14:05:53 2023 ] 	Mean test loss of 625 batches: 0.636311.
[ Tue Jun 27 14:05:53 2023 ] 	Top1: 78.95%
[ Tue Jun 27 14:05:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:53 2023 ] Training epoch: 25
[ Tue Jun 27 14:05:55 2023 ] 	Training loss: 0.7126.  Training acc: 73.71%.
[ Tue Jun 27 14:05:55 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:05:55 2023 ] Eval epoch: 25
[ Tue Jun 27 14:05:56 2023 ] 	Mean test loss of 625 batches: 0.632899.
[ Tue Jun 27 14:05:56 2023 ] 	Top1: 78.95%
[ Tue Jun 27 14:05:56 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:56 2023 ] Training epoch: 26
[ Tue Jun 27 14:05:58 2023 ] 	Training loss: 0.6944.  Training acc: 75.64%.
[ Tue Jun 27 14:05:58 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:05:58 2023 ] Eval epoch: 26
[ Tue Jun 27 14:05:59 2023 ] 	Mean test loss of 625 batches: 0.620750.
[ Tue Jun 27 14:05:59 2023 ] 	Top1: 80.70%
[ Tue Jun 27 14:05:59 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:59 2023 ] Training epoch: 27
[ Tue Jun 27 14:06:01 2023 ] 	Training loss: 0.7054.  Training acc: 75.37%.
[ Tue Jun 27 14:06:01 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:06:01 2023 ] Eval epoch: 27
[ Tue Jun 27 14:06:02 2023 ] 	Mean test loss of 625 batches: 0.656544.
[ Tue Jun 27 14:06:02 2023 ] 	Top1: 78.95%
[ Tue Jun 27 14:06:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:02 2023 ] Training epoch: 28
[ Tue Jun 27 14:06:04 2023 ] 	Training loss: 0.6833.  Training acc: 77.02%.
[ Tue Jun 27 14:06:04 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:06:04 2023 ] Eval epoch: 28
[ Tue Jun 27 14:06:05 2023 ] 	Mean test loss of 625 batches: 0.632121.
[ Tue Jun 27 14:06:05 2023 ] 	Top1: 78.95%
[ Tue Jun 27 14:06:05 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:05 2023 ] Training epoch: 29
[ Tue Jun 27 14:06:07 2023 ] 	Training loss: 0.6827.  Training acc: 77.67%.
[ Tue Jun 27 14:06:07 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:06:07 2023 ] Eval epoch: 29
[ Tue Jun 27 14:06:08 2023 ] 	Mean test loss of 625 batches: 0.622878.
[ Tue Jun 27 14:06:08 2023 ] 	Top1: 78.95%
[ Tue Jun 27 14:06:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:08 2023 ] Training epoch: 30
[ Tue Jun 27 14:06:10 2023 ] 	Training loss: 0.6623.  Training acc: 79.69%.
[ Tue Jun 27 14:06:10 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:06:10 2023 ] Eval epoch: 30
[ Tue Jun 27 14:06:11 2023 ] 	Mean test loss of 625 batches: 0.639096.
[ Tue Jun 27 14:06:11 2023 ] 	Top1: 80.70%
[ Tue Jun 27 14:06:11 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:11 2023 ] Training epoch: 31
[ Tue Jun 27 14:06:13 2023 ] 	Training loss: 0.6752.  Training acc: 75.83%.
[ Tue Jun 27 14:06:13 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:06:13 2023 ] Eval epoch: 31
[ Tue Jun 27 14:06:14 2023 ] 	Mean test loss of 625 batches: 0.622081.
[ Tue Jun 27 14:06:14 2023 ] 	Top1: 82.46%
[ Tue Jun 27 14:06:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:14 2023 ] Training epoch: 32
[ Tue Jun 27 14:06:16 2023 ] 	Training loss: 0.6783.  Training acc: 77.39%.
[ Tue Jun 27 14:06:16 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:06:16 2023 ] Eval epoch: 32
[ Tue Jun 27 14:06:17 2023 ] 	Mean test loss of 625 batches: 0.648448.
[ Tue Jun 27 14:06:17 2023 ] 	Top1: 80.70%
[ Tue Jun 27 14:06:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:17 2023 ] Training epoch: 33
[ Tue Jun 27 14:06:19 2023 ] 	Training loss: 0.6633.  Training acc: 78.86%.
[ Tue Jun 27 14:06:19 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:06:19 2023 ] Eval epoch: 33
[ Tue Jun 27 14:06:20 2023 ] 	Mean test loss of 625 batches: 0.606030.
[ Tue Jun 27 14:06:20 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:06:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:20 2023 ] Training epoch: 34
[ Tue Jun 27 14:06:22 2023 ] 	Training loss: 0.6659.  Training acc: 77.57%.
[ Tue Jun 27 14:06:22 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:06:22 2023 ] Eval epoch: 34
[ Tue Jun 27 14:06:23 2023 ] 	Mean test loss of 625 batches: 0.603441.
[ Tue Jun 27 14:06:23 2023 ] 	Top1: 82.46%
[ Tue Jun 27 14:06:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:23 2023 ] Training epoch: 35
[ Tue Jun 27 14:06:25 2023 ] 	Training loss: 0.6594.  Training acc: 79.50%.
[ Tue Jun 27 14:06:25 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:06:25 2023 ] Eval epoch: 35
[ Tue Jun 27 14:06:26 2023 ] 	Mean test loss of 625 batches: 0.606393.
[ Tue Jun 27 14:06:26 2023 ] 	Top1: 82.46%
[ Tue Jun 27 14:06:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:26 2023 ] Training epoch: 36
[ Tue Jun 27 14:06:28 2023 ] 	Training loss: 0.6546.  Training acc: 80.24%.
[ Tue Jun 27 14:06:28 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:06:28 2023 ] Eval epoch: 36
[ Tue Jun 27 14:06:29 2023 ] 	Mean test loss of 625 batches: 0.602908.
[ Tue Jun 27 14:06:29 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:06:29 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:29 2023 ] Training epoch: 37
[ Tue Jun 27 14:06:31 2023 ] 	Training loss: 0.6595.  Training acc: 80.24%.
[ Tue Jun 27 14:06:31 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:06:31 2023 ] Eval epoch: 37
[ Tue Jun 27 14:06:32 2023 ] 	Mean test loss of 625 batches: 0.610469.
[ Tue Jun 27 14:06:32 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:06:32 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:32 2023 ] Training epoch: 38
[ Tue Jun 27 14:06:34 2023 ] 	Training loss: 0.6516.  Training acc: 81.25%.
[ Tue Jun 27 14:06:34 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:06:34 2023 ] Eval epoch: 38
[ Tue Jun 27 14:06:35 2023 ] 	Mean test loss of 625 batches: 0.628408.
[ Tue Jun 27 14:06:35 2023 ] 	Top1: 82.46%
[ Tue Jun 27 14:06:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:35 2023 ] Training epoch: 39
[ Tue Jun 27 14:06:37 2023 ] 	Training loss: 0.6461.  Training acc: 80.70%.
[ Tue Jun 27 14:06:37 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:06:37 2023 ] Eval epoch: 39
[ Tue Jun 27 14:06:38 2023 ] 	Mean test loss of 625 batches: 0.594244.
[ Tue Jun 27 14:06:38 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:06:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:38 2023 ] Training epoch: 40
[ Tue Jun 27 14:06:40 2023 ] 	Training loss: 0.6699.  Training acc: 77.85%.
[ Tue Jun 27 14:06:40 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:06:40 2023 ] Eval epoch: 40
[ Tue Jun 27 14:06:41 2023 ] 	Mean test loss of 625 batches: 0.612546.
[ Tue Jun 27 14:06:41 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:06:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:42 2023 ] Best accuracy: 0.8596491228070176
[ Tue Jun 27 14:06:42 2023 ] Epoch number: 37
[ Tue Jun 27 14:06:42 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 14:06:42 2023 ] Weight decay: 0.0005
[ Tue Jun 27 14:06:42 2023 ] Base LR: 0.1
[ Tue Jun 27 14:06:42 2023 ] Batch Size: 64
[ Tue Jun 27 14:06:42 2023 ] Test Batch Size: 64
[ Tue Jun 27 14:06:42 2023 ] seed: 1
[ Tue Jun 27 14:06:42 2023 ] Start training Corrector
[ Tue Jun 27 14:07:45 2023 ] using warm up, epoch: 5
[ Tue Jun 27 14:07:46 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 14:07:46 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 14:07:46 2023 ] Start training Predictor
[ Tue Jun 27 14:07:46 2023 ] Training epoch: 1
[ Tue Jun 27 14:07:51 2023 ] 	Training loss: 109.9660.  Training acc: 35.39%.
[ Tue Jun 27 14:07:51 2023 ] 	Time consumption: [Data]05%, [Network]94%
[ Tue Jun 27 14:07:51 2023 ] Eval epoch: 1
[ Tue Jun 27 14:07:52 2023 ] 	Mean test loss of 625 batches: 2254.578003.
[ Tue Jun 27 14:07:52 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:07:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:07:52 2023 ] Training epoch: 2
[ Tue Jun 27 14:07:55 2023 ] 	Training loss: 20.3376.  Training acc: 35.75%.
[ Tue Jun 27 14:07:55 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:07:55 2023 ] Eval epoch: 2
[ Tue Jun 27 14:07:55 2023 ] 	Mean test loss of 625 batches: 2.269802.
[ Tue Jun 27 14:07:55 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:07:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:07:55 2023 ] Training epoch: 3
[ Tue Jun 27 14:07:58 2023 ] 	Training loss: 7.6806.  Training acc: 33.92%.
[ Tue Jun 27 14:07:58 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:07:58 2023 ] Eval epoch: 3
[ Tue Jun 27 14:07:58 2023 ] 	Mean test loss of 625 batches: 3.884099.
[ Tue Jun 27 14:07:58 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:07:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:07:58 2023 ] Training epoch: 4
[ Tue Jun 27 14:08:00 2023 ] 	Training loss: 6.5402.  Training acc: 32.90%.
[ Tue Jun 27 14:08:00 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:08:00 2023 ] Eval epoch: 4
[ Tue Jun 27 14:08:01 2023 ] 	Mean test loss of 625 batches: 5.640648.
[ Tue Jun 27 14:08:01 2023 ] 	Top1: 17.54%
[ Tue Jun 27 14:08:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:01 2023 ] Training epoch: 5
[ Tue Jun 27 14:08:03 2023 ] 	Training loss: 5.5490.  Training acc: 40.26%.
[ Tue Jun 27 14:08:03 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 14:08:03 2023 ] Eval epoch: 5
[ Tue Jun 27 14:08:04 2023 ] 	Mean test loss of 625 batches: 2.062758.
[ Tue Jun 27 14:08:04 2023 ] 	Top1: 49.12%
[ Tue Jun 27 14:08:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:04 2023 ] Training epoch: 6
[ Tue Jun 27 14:08:06 2023 ] 	Training loss: 3.8087.  Training acc: 47.70%.
[ Tue Jun 27 14:08:06 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:08:06 2023 ] Eval epoch: 6
[ Tue Jun 27 14:08:07 2023 ] 	Mean test loss of 625 batches: 1.191411.
[ Tue Jun 27 14:08:07 2023 ] 	Top1: 54.39%
[ Tue Jun 27 14:08:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:07 2023 ] Training epoch: 7
[ Tue Jun 27 14:08:09 2023 ] 	Training loss: 2.0877.  Training acc: 57.35%.
[ Tue Jun 27 14:08:09 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:08:09 2023 ] Eval epoch: 7
[ Tue Jun 27 14:08:10 2023 ] 	Mean test loss of 625 batches: 8.773708.
[ Tue Jun 27 14:08:10 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:08:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:10 2023 ] Training epoch: 8
[ Tue Jun 27 14:08:12 2023 ] 	Training loss: 1.8185.  Training acc: 61.31%.
[ Tue Jun 27 14:08:12 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:08:12 2023 ] Eval epoch: 8
[ Tue Jun 27 14:08:13 2023 ] 	Mean test loss of 625 batches: 1.019631.
[ Tue Jun 27 14:08:13 2023 ] 	Top1: 68.42%
[ Tue Jun 27 14:08:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:13 2023 ] Training epoch: 9
[ Tue Jun 27 14:08:15 2023 ] 	Training loss: 1.2117.  Training acc: 65.44%.
[ Tue Jun 27 14:08:15 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:08:15 2023 ] Eval epoch: 9
[ Tue Jun 27 14:08:16 2023 ] 	Mean test loss of 625 batches: 0.912477.
[ Tue Jun 27 14:08:16 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:08:16 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:16 2023 ] Training epoch: 10
[ Tue Jun 27 14:08:19 2023 ] 	Training loss: 1.0563.  Training acc: 65.99%.
[ Tue Jun 27 14:08:19 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:08:19 2023 ] Eval epoch: 10
[ Tue Jun 27 14:08:19 2023 ] 	Mean test loss of 625 batches: 0.700711.
[ Tue Jun 27 14:08:19 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:08:19 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:19 2023 ] Training epoch: 11
[ Tue Jun 27 14:08:21 2023 ] 	Training loss: 0.9343.  Training acc: 62.96%.
[ Tue Jun 27 14:08:21 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:08:21 2023 ] Eval epoch: 11
[ Tue Jun 27 14:08:22 2023 ] 	Mean test loss of 625 batches: 0.726508.
[ Tue Jun 27 14:08:22 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:08:22 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:22 2023 ] Training epoch: 12
[ Tue Jun 27 14:08:24 2023 ] 	Training loss: 0.9108.  Training acc: 65.35%.
[ Tue Jun 27 14:08:24 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:08:24 2023 ] Eval epoch: 12
[ Tue Jun 27 14:08:25 2023 ] 	Mean test loss of 625 batches: 0.809410.
[ Tue Jun 27 14:08:25 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:08:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:25 2023 ] Training epoch: 13
[ Tue Jun 27 14:08:27 2023 ] 	Training loss: 0.8500.  Training acc: 67.19%.
[ Tue Jun 27 14:08:27 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:08:27 2023 ] Eval epoch: 13
[ Tue Jun 27 14:08:28 2023 ] 	Mean test loss of 625 batches: 0.705907.
[ Tue Jun 27 14:08:28 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:08:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:28 2023 ] Training epoch: 14
[ Tue Jun 27 14:08:31 2023 ] 	Training loss: 0.8007.  Training acc: 71.60%.
[ Tue Jun 27 14:08:31 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:08:31 2023 ] Eval epoch: 14
[ Tue Jun 27 14:08:31 2023 ] 	Mean test loss of 625 batches: 0.802759.
[ Tue Jun 27 14:08:31 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:08:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:31 2023 ] Training epoch: 15
[ Tue Jun 27 14:08:33 2023 ] 	Training loss: 0.7955.  Training acc: 70.86%.
[ Tue Jun 27 14:08:33 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:08:33 2023 ] Eval epoch: 15
[ Tue Jun 27 14:08:34 2023 ] 	Mean test loss of 625 batches: 0.704653.
[ Tue Jun 27 14:08:34 2023 ] 	Top1: 68.42%
[ Tue Jun 27 14:08:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:34 2023 ] Training epoch: 16
[ Tue Jun 27 14:08:36 2023 ] 	Training loss: 0.8022.  Training acc: 70.31%.
[ Tue Jun 27 14:08:36 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:08:36 2023 ] Eval epoch: 16
[ Tue Jun 27 14:08:37 2023 ] 	Mean test loss of 625 batches: 0.698325.
[ Tue Jun 27 14:08:37 2023 ] 	Top1: 71.93%
[ Tue Jun 27 14:08:37 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:37 2023 ] Training epoch: 17
[ Tue Jun 27 14:08:39 2023 ] 	Training loss: 0.7421.  Training acc: 72.24%.
[ Tue Jun 27 14:08:39 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:08:39 2023 ] Eval epoch: 17
[ Tue Jun 27 14:08:40 2023 ] 	Mean test loss of 625 batches: 0.654636.
[ Tue Jun 27 14:08:40 2023 ] 	Top1: 71.93%
[ Tue Jun 27 14:08:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:40 2023 ] Training epoch: 18
[ Tue Jun 27 14:08:42 2023 ] 	Training loss: 0.6912.  Training acc: 76.29%.
[ Tue Jun 27 14:08:42 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:08:42 2023 ] Eval epoch: 18
[ Tue Jun 27 14:08:43 2023 ] 	Mean test loss of 625 batches: 0.854641.
[ Tue Jun 27 14:08:43 2023 ] 	Top1: 71.93%
[ Tue Jun 27 14:08:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:43 2023 ] Training epoch: 19
[ Tue Jun 27 14:08:45 2023 ] 	Training loss: 0.7112.  Training acc: 76.29%.
[ Tue Jun 27 14:08:45 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:08:45 2023 ] Eval epoch: 19
[ Tue Jun 27 14:08:46 2023 ] 	Mean test loss of 625 batches: 0.690104.
[ Tue Jun 27 14:08:46 2023 ] 	Top1: 71.93%
[ Tue Jun 27 14:08:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:46 2023 ] Training epoch: 20
[ Tue Jun 27 14:08:48 2023 ] 	Training loss: 0.6451.  Training acc: 80.51%.
[ Tue Jun 27 14:08:48 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:08:48 2023 ] Eval epoch: 20
[ Tue Jun 27 14:08:49 2023 ] 	Mean test loss of 625 batches: 0.755450.
[ Tue Jun 27 14:08:49 2023 ] 	Top1: 71.93%
[ Tue Jun 27 14:08:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:49 2023 ] Training epoch: 21
[ Tue Jun 27 14:08:51 2023 ] 	Training loss: 0.6341.  Training acc: 79.78%.
[ Tue Jun 27 14:08:51 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:08:51 2023 ] Eval epoch: 21
[ Tue Jun 27 14:08:52 2023 ] 	Mean test loss of 625 batches: 0.645700.
[ Tue Jun 27 14:08:52 2023 ] 	Top1: 73.68%
[ Tue Jun 27 14:08:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:52 2023 ] Training epoch: 22
[ Tue Jun 27 14:08:54 2023 ] 	Training loss: 0.6161.  Training acc: 81.89%.
[ Tue Jun 27 14:08:54 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:08:54 2023 ] Eval epoch: 22
[ Tue Jun 27 14:08:55 2023 ] 	Mean test loss of 625 batches: 0.679143.
[ Tue Jun 27 14:08:55 2023 ] 	Top1: 71.93%
[ Tue Jun 27 14:08:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:55 2023 ] Training epoch: 23
[ Tue Jun 27 14:08:57 2023 ] 	Training loss: 0.5944.  Training acc: 82.26%.
[ Tue Jun 27 14:08:57 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:08:57 2023 ] Eval epoch: 23
[ Tue Jun 27 14:08:58 2023 ] 	Mean test loss of 625 batches: 0.661898.
[ Tue Jun 27 14:08:58 2023 ] 	Top1: 73.68%
[ Tue Jun 27 14:08:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:58 2023 ] Training epoch: 24
[ Tue Jun 27 14:09:01 2023 ] 	Training loss: 0.6028.  Training acc: 82.08%.
[ Tue Jun 27 14:09:01 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:09:01 2023 ] Eval epoch: 24
[ Tue Jun 27 14:09:01 2023 ] 	Mean test loss of 625 batches: 0.640602.
[ Tue Jun 27 14:09:01 2023 ] 	Top1: 73.68%
[ Tue Jun 27 14:09:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:01 2023 ] Training epoch: 25
[ Tue Jun 27 14:09:03 2023 ] 	Training loss: 0.5865.  Training acc: 84.19%.
[ Tue Jun 27 14:09:03 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:09:03 2023 ] Eval epoch: 25
[ Tue Jun 27 14:09:04 2023 ] 	Mean test loss of 625 batches: 0.640815.
[ Tue Jun 27 14:09:04 2023 ] 	Top1: 73.68%
[ Tue Jun 27 14:09:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:04 2023 ] Training epoch: 26
[ Tue Jun 27 14:09:06 2023 ] 	Training loss: 0.5699.  Training acc: 85.29%.
[ Tue Jun 27 14:09:06 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:09:06 2023 ] Eval epoch: 26
[ Tue Jun 27 14:09:07 2023 ] 	Mean test loss of 625 batches: 0.646702.
[ Tue Jun 27 14:09:07 2023 ] 	Top1: 73.68%
[ Tue Jun 27 14:09:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:07 2023 ] Training epoch: 27
[ Tue Jun 27 14:09:09 2023 ] 	Training loss: 0.5588.  Training acc: 85.39%.
[ Tue Jun 27 14:09:09 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:09:09 2023 ] Eval epoch: 27
[ Tue Jun 27 14:09:10 2023 ] 	Mean test loss of 625 batches: 0.599764.
[ Tue Jun 27 14:09:10 2023 ] 	Top1: 73.68%
[ Tue Jun 27 14:09:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:10 2023 ] Training epoch: 28
[ Tue Jun 27 14:09:12 2023 ] 	Training loss: 0.5337.  Training acc: 87.13%.
[ Tue Jun 27 14:09:12 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:09:12 2023 ] Eval epoch: 28
[ Tue Jun 27 14:09:13 2023 ] 	Mean test loss of 625 batches: 0.598869.
[ Tue Jun 27 14:09:13 2023 ] 	Top1: 75.44%
[ Tue Jun 27 14:09:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:13 2023 ] Training epoch: 29
[ Tue Jun 27 14:09:16 2023 ] 	Training loss: 0.5379.  Training acc: 87.96%.
[ Tue Jun 27 14:09:16 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:09:16 2023 ] Eval epoch: 29
[ Tue Jun 27 14:09:16 2023 ] 	Mean test loss of 625 batches: 0.569207.
[ Tue Jun 27 14:09:16 2023 ] 	Top1: 77.19%
[ Tue Jun 27 14:09:16 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:16 2023 ] Training epoch: 30
[ Tue Jun 27 14:09:19 2023 ] 	Training loss: 0.5046.  Training acc: 89.06%.
[ Tue Jun 27 14:09:19 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:09:19 2023 ] Eval epoch: 30
[ Tue Jun 27 14:09:20 2023 ] 	Mean test loss of 625 batches: 0.524050.
[ Tue Jun 27 14:09:20 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:09:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:20 2023 ] Training epoch: 31
[ Tue Jun 27 14:09:22 2023 ] 	Training loss: 0.4900.  Training acc: 91.18%.
[ Tue Jun 27 14:09:22 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:09:22 2023 ] Eval epoch: 31
[ Tue Jun 27 14:09:23 2023 ] 	Mean test loss of 625 batches: 0.502170.
[ Tue Jun 27 14:09:23 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:09:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:23 2023 ] Training epoch: 32
[ Tue Jun 27 14:09:25 2023 ] 	Training loss: 0.4946.  Training acc: 89.34%.
[ Tue Jun 27 14:09:25 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:09:25 2023 ] Eval epoch: 32
[ Tue Jun 27 14:09:26 2023 ] 	Mean test loss of 625 batches: 0.481832.
[ Tue Jun 27 14:09:26 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:09:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:26 2023 ] Training epoch: 33
[ Tue Jun 27 14:09:28 2023 ] 	Training loss: 0.4502.  Training acc: 93.47%.
[ Tue Jun 27 14:09:28 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:09:28 2023 ] Eval epoch: 33
[ Tue Jun 27 14:09:29 2023 ] 	Mean test loss of 625 batches: 0.455646.
[ Tue Jun 27 14:09:29 2023 ] 	Top1: 89.47%
[ Tue Jun 27 14:09:29 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:29 2023 ] Training epoch: 34
[ Tue Jun 27 14:09:32 2023 ] 	Training loss: 0.4426.  Training acc: 94.39%.
[ Tue Jun 27 14:09:32 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:09:32 2023 ] Eval epoch: 34
[ Tue Jun 27 14:09:32 2023 ] 	Mean test loss of 625 batches: 0.426795.
[ Tue Jun 27 14:09:32 2023 ] 	Top1: 94.74%
[ Tue Jun 27 14:09:32 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:32 2023 ] Training epoch: 35
[ Tue Jun 27 14:09:35 2023 ] 	Training loss: 0.4150.  Training acc: 95.13%.
[ Tue Jun 27 14:09:35 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:09:35 2023 ] Eval epoch: 35
[ Tue Jun 27 14:09:36 2023 ] 	Mean test loss of 625 batches: 0.393742.
[ Tue Jun 27 14:09:36 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:09:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:36 2023 ] Training epoch: 36
[ Tue Jun 27 14:09:38 2023 ] 	Training loss: 0.4201.  Training acc: 95.96%.
[ Tue Jun 27 14:09:38 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:09:38 2023 ] Eval epoch: 36
[ Tue Jun 27 14:09:38 2023 ] 	Mean test loss of 625 batches: 0.385004.
[ Tue Jun 27 14:09:38 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:09:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:38 2023 ] Training epoch: 37
[ Tue Jun 27 14:09:41 2023 ] 	Training loss: 0.4183.  Training acc: 95.40%.
[ Tue Jun 27 14:09:41 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:09:41 2023 ] Eval epoch: 37
[ Tue Jun 27 14:09:42 2023 ] 	Mean test loss of 625 batches: 0.378871.
[ Tue Jun 27 14:09:42 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:09:42 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:42 2023 ] Training epoch: 38
[ Tue Jun 27 14:09:44 2023 ] 	Training loss: 0.4171.  Training acc: 95.86%.
[ Tue Jun 27 14:09:44 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:09:44 2023 ] Eval epoch: 38
[ Tue Jun 27 14:09:45 2023 ] 	Mean test loss of 625 batches: 0.381249.
[ Tue Jun 27 14:09:45 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:09:45 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:45 2023 ] Training epoch: 39
[ Tue Jun 27 14:09:47 2023 ] 	Training loss: 0.4010.  Training acc: 96.88%.
[ Tue Jun 27 14:09:47 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:09:47 2023 ] Eval epoch: 39
[ Tue Jun 27 14:09:47 2023 ] 	Mean test loss of 625 batches: 0.351291.
[ Tue Jun 27 14:09:47 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:09:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:48 2023 ] Training epoch: 40
[ Tue Jun 27 14:09:50 2023 ] 	Training loss: 0.4102.  Training acc: 95.96%.
[ Tue Jun 27 14:09:50 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:09:50 2023 ] Eval epoch: 40
[ Tue Jun 27 14:09:51 2023 ] 	Mean test loss of 625 batches: 0.356684.
[ Tue Jun 27 14:09:51 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:09:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:51 2023 ] Best accuracy: 1.0
[ Tue Jun 27 14:09:51 2023 ] Epoch number: 35
[ Tue Jun 27 14:09:51 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 14:09:51 2023 ] Weight decay: 0.0005
[ Tue Jun 27 14:09:51 2023 ] Base LR: 0.1
[ Tue Jun 27 14:09:51 2023 ] Batch Size: 64
[ Tue Jun 27 14:09:51 2023 ] Test Batch Size: 64
[ Tue Jun 27 14:09:51 2023 ] seed: 1
[ Tue Jun 27 14:09:51 2023 ] Start training Corrector
[ Tue Jun 27 14:09:51 2023 ] Training epoch: 1
[ Tue Jun 27 14:12:56 2023 ] using warm up, epoch: 5
[ Tue Jun 27 14:12:58 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 14:12:58 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 14:12:58 2023 ] Start training Predictor
[ Tue Jun 27 14:12:58 2023 ] Training epoch: 1
[ Tue Jun 27 14:13:03 2023 ] 	Training loss: 106.5895.  Training acc: 35.57%.
[ Tue Jun 27 14:13:03 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Jun 27 14:13:03 2023 ] Eval epoch: 1
[ Tue Jun 27 14:13:04 2023 ] 	Mean test loss of 625 batches: 1375.783521.
[ Tue Jun 27 14:13:04 2023 ] 	Top1: 29.82%
[ Tue Jun 27 14:13:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:04 2023 ] Training epoch: 2
[ Tue Jun 27 14:13:07 2023 ] 	Training loss: 12.5282.  Training acc: 35.85%.
[ Tue Jun 27 14:13:07 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:13:07 2023 ] Eval epoch: 2
[ Tue Jun 27 14:13:07 2023 ] 	Mean test loss of 625 batches: 2.967765.
[ Tue Jun 27 14:13:07 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:13:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:07 2023 ] Training epoch: 3
[ Tue Jun 27 14:13:09 2023 ] 	Training loss: 7.4831.  Training acc: 34.19%.
[ Tue Jun 27 14:13:09 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:13:09 2023 ] Eval epoch: 3
[ Tue Jun 27 14:13:10 2023 ] 	Mean test loss of 625 batches: 2.617230.
[ Tue Jun 27 14:13:10 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:13:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:10 2023 ] Training epoch: 4
[ Tue Jun 27 14:13:12 2023 ] 	Training loss: 6.1471.  Training acc: 31.34%.
[ Tue Jun 27 14:13:12 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:13:12 2023 ] Eval epoch: 4
[ Tue Jun 27 14:13:13 2023 ] 	Mean test loss of 625 batches: 1.712681.
[ Tue Jun 27 14:13:13 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:13:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:13 2023 ] Training epoch: 5
[ Tue Jun 27 14:13:15 2023 ] 	Training loss: 5.2338.  Training acc: 36.40%.
[ Tue Jun 27 14:13:15 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:13:15 2023 ] Eval epoch: 5
[ Tue Jun 27 14:13:16 2023 ] 	Mean test loss of 625 batches: 1.717953.
[ Tue Jun 27 14:13:16 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:13:16 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:16 2023 ] Training epoch: 6
[ Tue Jun 27 14:13:18 2023 ] 	Training loss: 3.7186.  Training acc: 34.74%.
[ Tue Jun 27 14:13:18 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:13:18 2023 ] Eval epoch: 6
[ Tue Jun 27 14:13:19 2023 ] 	Mean test loss of 625 batches: 1.074450.
[ Tue Jun 27 14:13:19 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:13:19 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:19 2023 ] Training epoch: 7
[ Tue Jun 27 14:13:22 2023 ] 	Training loss: 2.7821.  Training acc: 37.41%.
[ Tue Jun 27 14:13:22 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:13:22 2023 ] Eval epoch: 7
[ Tue Jun 27 14:13:22 2023 ] 	Mean test loss of 625 batches: 1.343509.
[ Tue Jun 27 14:13:22 2023 ] 	Top1: 47.37%
[ Tue Jun 27 14:13:22 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:22 2023 ] Training epoch: 8
[ Tue Jun 27 14:13:25 2023 ] 	Training loss: 1.8633.  Training acc: 51.47%.
[ Tue Jun 27 14:13:25 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:13:25 2023 ] Eval epoch: 8
[ Tue Jun 27 14:13:25 2023 ] 	Mean test loss of 625 batches: 1.694526.
[ Tue Jun 27 14:13:25 2023 ] 	Top1: 35.09%
[ Tue Jun 27 14:13:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:25 2023 ] Training epoch: 9
[ Tue Jun 27 14:13:28 2023 ] 	Training loss: 1.4690.  Training acc: 65.53%.
[ Tue Jun 27 14:13:28 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 14:13:28 2023 ] Eval epoch: 9
[ Tue Jun 27 14:13:29 2023 ] 	Mean test loss of 625 batches: 4.727582.
[ Tue Jun 27 14:13:29 2023 ] 	Top1: 29.82%
[ Tue Jun 27 14:13:29 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:29 2023 ] Training epoch: 10
[ Tue Jun 27 14:13:31 2023 ] 	Training loss: 1.4260.  Training acc: 58.82%.
[ Tue Jun 27 14:13:31 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:13:31 2023 ] Eval epoch: 10
[ Tue Jun 27 14:13:32 2023 ] 	Mean test loss of 625 batches: 2.922850.
[ Tue Jun 27 14:13:32 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:13:32 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:32 2023 ] Training epoch: 11
[ Tue Jun 27 14:13:34 2023 ] 	Training loss: 1.1036.  Training acc: 69.03%.
[ Tue Jun 27 14:13:34 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:13:34 2023 ] Eval epoch: 11
[ Tue Jun 27 14:13:35 2023 ] 	Mean test loss of 625 batches: 0.638423.
[ Tue Jun 27 14:13:35 2023 ] 	Top1: 77.19%
[ Tue Jun 27 14:13:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:35 2023 ] Training epoch: 12
[ Tue Jun 27 14:13:37 2023 ] 	Training loss: 0.9600.  Training acc: 70.04%.
[ Tue Jun 27 14:13:37 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:13:37 2023 ] Eval epoch: 12
[ Tue Jun 27 14:13:38 2023 ] 	Mean test loss of 625 batches: 0.599555.
[ Tue Jun 27 14:13:38 2023 ] 	Top1: 89.47%
[ Tue Jun 27 14:13:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:38 2023 ] Training epoch: 13
[ Tue Jun 27 14:13:40 2023 ] 	Training loss: 0.8563.  Training acc: 74.17%.
[ Tue Jun 27 14:13:40 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:13:40 2023 ] Eval epoch: 13
[ Tue Jun 27 14:13:41 2023 ] 	Mean test loss of 625 batches: 0.648085.
[ Tue Jun 27 14:13:41 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:13:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:41 2023 ] Training epoch: 14
[ Tue Jun 27 14:13:43 2023 ] 	Training loss: 0.8341.  Training acc: 75.55%.
[ Tue Jun 27 14:13:43 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:13:43 2023 ] Eval epoch: 14
[ Tue Jun 27 14:13:44 2023 ] 	Mean test loss of 625 batches: 0.640134.
[ Tue Jun 27 14:13:44 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:13:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:44 2023 ] Training epoch: 15
[ Tue Jun 27 14:13:46 2023 ] 	Training loss: 0.8253.  Training acc: 77.02%.
[ Tue Jun 27 14:13:46 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:13:46 2023 ] Eval epoch: 15
[ Tue Jun 27 14:13:47 2023 ] 	Mean test loss of 625 batches: 0.611834.
[ Tue Jun 27 14:13:47 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:13:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:47 2023 ] Training epoch: 16
[ Tue Jun 27 14:13:50 2023 ] 	Training loss: 0.8057.  Training acc: 77.67%.
[ Tue Jun 27 14:13:50 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:13:50 2023 ] Eval epoch: 16
[ Tue Jun 27 14:13:51 2023 ] 	Mean test loss of 625 batches: 0.669350.
[ Tue Jun 27 14:13:51 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:13:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:51 2023 ] Training epoch: 17
[ Tue Jun 27 14:13:53 2023 ] 	Training loss: 0.7664.  Training acc: 80.15%.
[ Tue Jun 27 14:13:53 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:13:53 2023 ] Eval epoch: 17
[ Tue Jun 27 14:13:54 2023 ] 	Mean test loss of 625 batches: 0.570769.
[ Tue Jun 27 14:13:54 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:13:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:54 2023 ] Training epoch: 18
[ Tue Jun 27 14:13:56 2023 ] 	Training loss: 0.7574.  Training acc: 80.79%.
[ Tue Jun 27 14:13:56 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:13:56 2023 ] Eval epoch: 18
[ Tue Jun 27 14:13:57 2023 ] 	Mean test loss of 625 batches: 0.570245.
[ Tue Jun 27 14:13:57 2023 ] 	Top1: 91.23%
[ Tue Jun 27 14:13:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:57 2023 ] Training epoch: 19
[ Tue Jun 27 14:13:59 2023 ] 	Training loss: 0.7505.  Training acc: 83.27%.
[ Tue Jun 27 14:13:59 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:13:59 2023 ] Eval epoch: 19
[ Tue Jun 27 14:14:00 2023 ] 	Mean test loss of 625 batches: 0.530231.
[ Tue Jun 27 14:14:00 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:14:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:00 2023 ] Training epoch: 20
[ Tue Jun 27 14:14:02 2023 ] 	Training loss: 0.6959.  Training acc: 84.47%.
[ Tue Jun 27 14:14:02 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:14:02 2023 ] Eval epoch: 20
[ Tue Jun 27 14:14:03 2023 ] 	Mean test loss of 625 batches: 0.531663.
[ Tue Jun 27 14:14:03 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:14:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:03 2023 ] Training epoch: 21
[ Tue Jun 27 14:14:06 2023 ] 	Training loss: 0.6638.  Training acc: 85.20%.
[ Tue Jun 27 14:14:06 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:14:06 2023 ] Eval epoch: 21
[ Tue Jun 27 14:14:06 2023 ] 	Mean test loss of 625 batches: 0.506425.
[ Tue Jun 27 14:14:06 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:14:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:06 2023 ] Training epoch: 22
[ Tue Jun 27 14:14:09 2023 ] 	Training loss: 0.6656.  Training acc: 87.41%.
[ Tue Jun 27 14:14:09 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:14:09 2023 ] Eval epoch: 22
[ Tue Jun 27 14:14:09 2023 ] 	Mean test loss of 625 batches: 0.518641.
[ Tue Jun 27 14:14:09 2023 ] 	Top1: 94.74%
[ Tue Jun 27 14:14:09 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:09 2023 ] Training epoch: 23
[ Tue Jun 27 14:14:12 2023 ] 	Training loss: 0.6569.  Training acc: 87.78%.
[ Tue Jun 27 14:14:12 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:14:12 2023 ] Eval epoch: 23
[ Tue Jun 27 14:14:12 2023 ] 	Mean test loss of 625 batches: 0.512817.
[ Tue Jun 27 14:14:12 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:14:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:12 2023 ] Training epoch: 24
[ Tue Jun 27 14:14:15 2023 ] 	Training loss: 0.6655.  Training acc: 85.85%.
[ Tue Jun 27 14:14:15 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:14:15 2023 ] Eval epoch: 24
[ Tue Jun 27 14:14:15 2023 ] 	Mean test loss of 625 batches: 0.522225.
[ Tue Jun 27 14:14:15 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:14:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:15 2023 ] Training epoch: 25
[ Tue Jun 27 14:14:18 2023 ] 	Training loss: 0.6457.  Training acc: 86.67%.
[ Tue Jun 27 14:14:18 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:14:18 2023 ] Eval epoch: 25
[ Tue Jun 27 14:14:18 2023 ] 	Mean test loss of 625 batches: 0.531138.
[ Tue Jun 27 14:14:18 2023 ] 	Top1: 92.98%
[ Tue Jun 27 14:14:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:18 2023 ] Training epoch: 26
[ Tue Jun 27 14:14:21 2023 ] 	Training loss: 0.6412.  Training acc: 88.42%.
[ Tue Jun 27 14:14:21 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:14:21 2023 ] Eval epoch: 26
[ Tue Jun 27 14:14:21 2023 ] 	Mean test loss of 625 batches: 0.532836.
[ Tue Jun 27 14:14:21 2023 ] 	Top1: 92.98%
[ Tue Jun 27 14:14:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:21 2023 ] Training epoch: 27
[ Tue Jun 27 14:14:24 2023 ] 	Training loss: 0.6482.  Training acc: 87.41%.
[ Tue Jun 27 14:14:24 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:14:24 2023 ] Eval epoch: 27
[ Tue Jun 27 14:14:25 2023 ] 	Mean test loss of 625 batches: 0.538444.
[ Tue Jun 27 14:14:25 2023 ] 	Top1: 92.98%
[ Tue Jun 27 14:14:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:25 2023 ] Training epoch: 28
[ Tue Jun 27 14:14:27 2023 ] 	Training loss: 0.6327.  Training acc: 88.60%.
[ Tue Jun 27 14:14:27 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:14:27 2023 ] Eval epoch: 28
[ Tue Jun 27 14:14:28 2023 ] 	Mean test loss of 625 batches: 0.524777.
[ Tue Jun 27 14:14:28 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:14:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:28 2023 ] Training epoch: 29
[ Tue Jun 27 14:14:30 2023 ] 	Training loss: 0.6246.  Training acc: 89.80%.
[ Tue Jun 27 14:14:30 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:14:30 2023 ] Eval epoch: 29
[ Tue Jun 27 14:14:31 2023 ] 	Mean test loss of 625 batches: 0.503484.
[ Tue Jun 27 14:14:31 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:14:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:31 2023 ] Training epoch: 30
[ Tue Jun 27 14:14:34 2023 ] 	Training loss: 0.6199.  Training acc: 90.44%.
[ Tue Jun 27 14:14:34 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:14:34 2023 ] Eval epoch: 30
[ Tue Jun 27 14:14:34 2023 ] 	Mean test loss of 625 batches: 0.505487.
[ Tue Jun 27 14:14:34 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:14:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:34 2023 ] Training epoch: 31
[ Tue Jun 27 14:14:37 2023 ] 	Training loss: 0.6108.  Training acc: 90.26%.
[ Tue Jun 27 14:14:37 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:14:37 2023 ] Eval epoch: 31
[ Tue Jun 27 14:14:37 2023 ] 	Mean test loss of 625 batches: 0.517283.
[ Tue Jun 27 14:14:37 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:14:37 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:37 2023 ] Training epoch: 32
[ Tue Jun 27 14:14:40 2023 ] 	Training loss: 0.6266.  Training acc: 89.06%.
[ Tue Jun 27 14:14:40 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:14:40 2023 ] Eval epoch: 32
[ Tue Jun 27 14:14:40 2023 ] 	Mean test loss of 625 batches: 0.519752.
[ Tue Jun 27 14:14:40 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:14:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:40 2023 ] Training epoch: 33
[ Tue Jun 27 14:14:42 2023 ] 	Training loss: 0.6169.  Training acc: 90.62%.
[ Tue Jun 27 14:14:42 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:14:42 2023 ] Eval epoch: 33
[ Tue Jun 27 14:14:43 2023 ] 	Mean test loss of 625 batches: 0.489517.
[ Tue Jun 27 14:14:43 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:14:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:43 2023 ] Training epoch: 34
[ Tue Jun 27 14:14:45 2023 ] 	Training loss: 0.6243.  Training acc: 89.06%.
[ Tue Jun 27 14:14:45 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:14:45 2023 ] Eval epoch: 34
[ Tue Jun 27 14:14:46 2023 ] 	Mean test loss of 625 batches: 0.501129.
[ Tue Jun 27 14:14:46 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:14:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:46 2023 ] Training epoch: 35
[ Tue Jun 27 14:14:49 2023 ] 	Training loss: 0.5946.  Training acc: 91.08%.
[ Tue Jun 27 14:14:49 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:14:49 2023 ] Eval epoch: 35
[ Tue Jun 27 14:14:49 2023 ] 	Mean test loss of 625 batches: 0.512617.
[ Tue Jun 27 14:14:49 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:14:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:49 2023 ] Training epoch: 36
[ Tue Jun 27 14:14:52 2023 ] 	Training loss: 0.6096.  Training acc: 90.53%.
[ Tue Jun 27 14:14:52 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:14:52 2023 ] Eval epoch: 36
[ Tue Jun 27 14:14:52 2023 ] 	Mean test loss of 625 batches: 0.495757.
[ Tue Jun 27 14:14:52 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:14:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:52 2023 ] Training epoch: 37
[ Tue Jun 27 14:14:55 2023 ] 	Training loss: 0.6198.  Training acc: 89.71%.
[ Tue Jun 27 14:14:55 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:14:55 2023 ] Eval epoch: 37
[ Tue Jun 27 14:14:56 2023 ] 	Mean test loss of 625 batches: 0.495695.
[ Tue Jun 27 14:14:56 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:14:56 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:56 2023 ] Training epoch: 38
[ Tue Jun 27 14:14:58 2023 ] 	Training loss: 0.6041.  Training acc: 89.89%.
[ Tue Jun 27 14:14:58 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:14:58 2023 ] Eval epoch: 38
[ Tue Jun 27 14:14:58 2023 ] 	Mean test loss of 625 batches: 0.478477.
[ Tue Jun 27 14:14:58 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:14:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:58 2023 ] Training epoch: 39
[ Tue Jun 27 14:15:01 2023 ] 	Training loss: 0.6059.  Training acc: 91.18%.
[ Tue Jun 27 14:15:01 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:15:01 2023 ] Eval epoch: 39
[ Tue Jun 27 14:15:02 2023 ] 	Mean test loss of 625 batches: 0.501927.
[ Tue Jun 27 14:15:02 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:15:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:15:02 2023 ] Training epoch: 40
[ Tue Jun 27 14:15:04 2023 ] 	Training loss: 0.6244.  Training acc: 89.06%.
[ Tue Jun 27 14:15:04 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:15:04 2023 ] Eval epoch: 40
[ Tue Jun 27 14:15:05 2023 ] 	Mean test loss of 625 batches: 0.497709.
[ Tue Jun 27 14:15:05 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:15:05 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:15:06 2023 ] Best accuracy: 1.0
[ Tue Jun 27 14:15:06 2023 ] Epoch number: 19
[ Tue Jun 27 14:15:06 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 14:15:06 2023 ] Weight decay: 0.0005
[ Tue Jun 27 14:15:06 2023 ] Base LR: 0.1
[ Tue Jun 27 14:15:06 2023 ] Batch Size: 64
[ Tue Jun 27 14:15:06 2023 ] Test Batch Size: 64
[ Tue Jun 27 14:15:06 2023 ] seed: 1
[ Tue Jun 27 14:15:06 2023 ] Start training Corrector
[ Tue Jun 27 14:15:06 2023 ] Training epoch: 1
[ Tue Jun 27 14:16:38 2023 ] using warm up, epoch: 5
[ Tue Jun 27 14:16:39 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 14:16:39 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 14:16:39 2023 ] Start training Predictor
[ Tue Jun 27 14:16:39 2023 ] Training epoch: 1
[ Tue Jun 27 14:16:45 2023 ] 	Training loss: 102.3355.  Training acc: 34.93%.
[ Tue Jun 27 14:16:45 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jun 27 14:16:45 2023 ] Eval epoch: 1
[ Tue Jun 27 14:16:46 2023 ] 	Mean test loss of 625 batches: 5985.130371.
[ Tue Jun 27 14:16:46 2023 ] 	Top1: 29.82%
[ Tue Jun 27 14:16:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:16:46 2023 ] Training epoch: 2
[ Tue Jun 27 14:16:48 2023 ] 	Training loss: 17.1171.  Training acc: 35.02%.
[ Tue Jun 27 14:16:48 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:16:48 2023 ] Eval epoch: 2
[ Tue Jun 27 14:16:49 2023 ] 	Mean test loss of 625 batches: 1.762706.
[ Tue Jun 27 14:16:49 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:16:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:16:49 2023 ] Training epoch: 3
[ Tue Jun 27 14:16:51 2023 ] 	Training loss: 5.8446.  Training acc: 44.76%.
[ Tue Jun 27 14:16:51 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:16:51 2023 ] Eval epoch: 3
[ Tue Jun 27 14:16:52 2023 ] 	Mean test loss of 625 batches: 2.601907.
[ Tue Jun 27 14:16:52 2023 ] 	Top1: 59.65%
[ Tue Jun 27 14:16:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:16:52 2023 ] Training epoch: 4
[ Tue Jun 27 14:16:54 2023 ] 	Training loss: 5.6151.  Training acc: 55.79%.
[ Tue Jun 27 14:16:54 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:16:54 2023 ] Eval epoch: 4
[ Tue Jun 27 14:16:55 2023 ] 	Mean test loss of 625 batches: 5.038555.
[ Tue Jun 27 14:16:55 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:16:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:16:55 2023 ] Training epoch: 5
[ Tue Jun 27 14:16:57 2023 ] 	Training loss: 3.5563.  Training acc: 55.79%.
[ Tue Jun 27 14:16:57 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:16:57 2023 ] Eval epoch: 5
[ Tue Jun 27 14:16:57 2023 ] 	Mean test loss of 625 batches: 8.399402.
[ Tue Jun 27 14:16:57 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:16:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:16:57 2023 ] Training epoch: 6
[ Tue Jun 27 14:17:00 2023 ] 	Training loss: 5.0115.  Training acc: 55.51%.
[ Tue Jun 27 14:17:00 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:00 2023 ] Eval epoch: 6
[ Tue Jun 27 14:17:00 2023 ] 	Mean test loss of 625 batches: 5.735251.
[ Tue Jun 27 14:17:00 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:17:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:00 2023 ] Training epoch: 7
[ Tue Jun 27 14:17:03 2023 ] 	Training loss: 2.3901.  Training acc: 59.65%.
[ Tue Jun 27 14:17:03 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:03 2023 ] Eval epoch: 7
[ Tue Jun 27 14:17:03 2023 ] 	Mean test loss of 625 batches: 1.936157.
[ Tue Jun 27 14:17:03 2023 ] 	Top1: 68.42%
[ Tue Jun 27 14:17:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:03 2023 ] Training epoch: 8
[ Tue Jun 27 14:17:06 2023 ] 	Training loss: 1.7598.  Training acc: 59.56%.
[ Tue Jun 27 14:17:06 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:06 2023 ] Eval epoch: 8
[ Tue Jun 27 14:17:06 2023 ] 	Mean test loss of 625 batches: 0.710838.
[ Tue Jun 27 14:17:06 2023 ] 	Top1: 68.42%
[ Tue Jun 27 14:17:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:06 2023 ] Training epoch: 9
[ Tue Jun 27 14:17:09 2023 ] 	Training loss: 1.3426.  Training acc: 65.17%.
[ Tue Jun 27 14:17:09 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:17:09 2023 ] Eval epoch: 9
[ Tue Jun 27 14:17:09 2023 ] 	Mean test loss of 625 batches: 1.474418.
[ Tue Jun 27 14:17:09 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:17:09 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:09 2023 ] Training epoch: 10
[ Tue Jun 27 14:17:11 2023 ] 	Training loss: 1.0030.  Training acc: 75.28%.
[ Tue Jun 27 14:17:11 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:17:11 2023 ] Eval epoch: 10
[ Tue Jun 27 14:17:12 2023 ] 	Mean test loss of 625 batches: 0.797948.
[ Tue Jun 27 14:17:12 2023 ] 	Top1: 82.46%
[ Tue Jun 27 14:17:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:12 2023 ] Training epoch: 11
[ Tue Jun 27 14:17:14 2023 ] 	Training loss: 0.7000.  Training acc: 87.22%.
[ Tue Jun 27 14:17:14 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:14 2023 ] Eval epoch: 11
[ Tue Jun 27 14:17:15 2023 ] 	Mean test loss of 625 batches: 0.581801.
[ Tue Jun 27 14:17:15 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:17:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:15 2023 ] Training epoch: 12
[ Tue Jun 27 14:17:17 2023 ] 	Training loss: 0.6068.  Training acc: 89.34%.
[ Tue Jun 27 14:17:17 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:17 2023 ] Eval epoch: 12
[ Tue Jun 27 14:17:18 2023 ] 	Mean test loss of 625 batches: 0.590783.
[ Tue Jun 27 14:17:18 2023 ] 	Top1: 89.47%
[ Tue Jun 27 14:17:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:18 2023 ] Training epoch: 13
[ Tue Jun 27 14:17:20 2023 ] 	Training loss: 0.5529.  Training acc: 90.17%.
[ Tue Jun 27 14:17:21 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:21 2023 ] Eval epoch: 13
[ Tue Jun 27 14:17:21 2023 ] 	Mean test loss of 625 batches: 0.523088.
[ Tue Jun 27 14:17:21 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:17:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:21 2023 ] Training epoch: 14
[ Tue Jun 27 14:17:24 2023 ] 	Training loss: 0.5269.  Training acc: 90.81%.
[ Tue Jun 27 14:17:24 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:24 2023 ] Eval epoch: 14
[ Tue Jun 27 14:17:24 2023 ] 	Mean test loss of 625 batches: 0.416696.
[ Tue Jun 27 14:17:24 2023 ] 	Top1: 94.74%
[ Tue Jun 27 14:17:24 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:24 2023 ] Training epoch: 15
[ Tue Jun 27 14:17:27 2023 ] 	Training loss: 0.5758.  Training acc: 88.69%.
[ Tue Jun 27 14:17:27 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:27 2023 ] Eval epoch: 15
[ Tue Jun 27 14:17:27 2023 ] 	Mean test loss of 625 batches: 0.446513.
[ Tue Jun 27 14:17:27 2023 ] 	Top1: 94.74%
[ Tue Jun 27 14:17:27 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:27 2023 ] Training epoch: 16
[ Tue Jun 27 14:17:30 2023 ] 	Training loss: 0.5201.  Training acc: 92.10%.
[ Tue Jun 27 14:17:30 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:17:30 2023 ] Eval epoch: 16
[ Tue Jun 27 14:17:30 2023 ] 	Mean test loss of 625 batches: 0.500284.
[ Tue Jun 27 14:17:30 2023 ] 	Top1: 91.23%
[ Tue Jun 27 14:17:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:30 2023 ] Training epoch: 17
[ Tue Jun 27 14:17:33 2023 ] 	Training loss: 0.4914.  Training acc: 93.47%.
[ Tue Jun 27 14:17:33 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:17:33 2023 ] Eval epoch: 17
[ Tue Jun 27 14:17:33 2023 ] 	Mean test loss of 625 batches: 0.469586.
[ Tue Jun 27 14:17:33 2023 ] 	Top1: 92.98%
[ Tue Jun 27 14:17:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:33 2023 ] Training epoch: 18
[ Tue Jun 27 14:17:36 2023 ] 	Training loss: 0.5324.  Training acc: 90.81%.
[ Tue Jun 27 14:17:36 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:17:36 2023 ] Eval epoch: 18
[ Tue Jun 27 14:17:36 2023 ] 	Mean test loss of 625 batches: 0.465171.
[ Tue Jun 27 14:17:36 2023 ] 	Top1: 91.23%
[ Tue Jun 27 14:17:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:36 2023 ] Training epoch: 19
[ Tue Jun 27 14:17:38 2023 ] 	Training loss: 0.5182.  Training acc: 92.37%.
[ Tue Jun 27 14:17:38 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:38 2023 ] Eval epoch: 19
[ Tue Jun 27 14:17:39 2023 ] 	Mean test loss of 625 batches: 0.542538.
[ Tue Jun 27 14:17:39 2023 ] 	Top1: 89.47%
[ Tue Jun 27 14:17:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:39 2023 ] Training epoch: 20
[ Tue Jun 27 14:17:41 2023 ] 	Training loss: 0.4657.  Training acc: 93.57%.
[ Tue Jun 27 14:17:41 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:17:41 2023 ] Eval epoch: 20
[ Tue Jun 27 14:17:42 2023 ] 	Mean test loss of 625 batches: 0.438097.
[ Tue Jun 27 14:17:42 2023 ] 	Top1: 94.74%
[ Tue Jun 27 14:17:42 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:42 2023 ] Training epoch: 21
[ Tue Jun 27 14:17:44 2023 ] 	Training loss: 0.4645.  Training acc: 94.30%.
[ Tue Jun 27 14:17:44 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:44 2023 ] Eval epoch: 21
[ Tue Jun 27 14:17:45 2023 ] 	Mean test loss of 625 batches: 0.388977.
[ Tue Jun 27 14:17:45 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:17:45 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:45 2023 ] Training epoch: 22
[ Tue Jun 27 14:17:47 2023 ] 	Training loss: 0.4423.  Training acc: 94.49%.
[ Tue Jun 27 14:17:47 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:17:47 2023 ] Eval epoch: 22
[ Tue Jun 27 14:17:48 2023 ] 	Mean test loss of 625 batches: 0.377652.
[ Tue Jun 27 14:17:48 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:17:48 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:48 2023 ] Training epoch: 23
[ Tue Jun 27 14:17:50 2023 ] 	Training loss: 0.4358.  Training acc: 95.50%.
[ Tue Jun 27 14:17:50 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:17:50 2023 ] Eval epoch: 23
[ Tue Jun 27 14:17:51 2023 ] 	Mean test loss of 625 batches: 0.394345.
[ Tue Jun 27 14:17:51 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:17:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:51 2023 ] Training epoch: 24
[ Tue Jun 27 14:17:53 2023 ] 	Training loss: 0.4332.  Training acc: 96.14%.
[ Tue Jun 27 14:17:53 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 14:17:53 2023 ] Eval epoch: 24
[ Tue Jun 27 14:17:54 2023 ] 	Mean test loss of 625 batches: 0.378246.
[ Tue Jun 27 14:17:54 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:17:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:54 2023 ] Training epoch: 25
[ Tue Jun 27 14:17:57 2023 ] 	Training loss: 0.4368.  Training acc: 95.86%.
[ Tue Jun 27 14:17:57 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:57 2023 ] Eval epoch: 25
[ Tue Jun 27 14:17:57 2023 ] 	Mean test loss of 625 batches: 0.400809.
[ Tue Jun 27 14:17:57 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:17:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:57 2023 ] Training epoch: 26
[ Tue Jun 27 14:18:00 2023 ] 	Training loss: 0.4326.  Training acc: 95.77%.
[ Tue Jun 27 14:18:00 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:18:00 2023 ] Eval epoch: 26
[ Tue Jun 27 14:18:00 2023 ] 	Mean test loss of 625 batches: 0.363933.
[ Tue Jun 27 14:18:00 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:18:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:00 2023 ] Training epoch: 27
[ Tue Jun 27 14:18:03 2023 ] 	Training loss: 0.4270.  Training acc: 96.32%.
[ Tue Jun 27 14:18:03 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:18:03 2023 ] Eval epoch: 27
[ Tue Jun 27 14:18:03 2023 ] 	Mean test loss of 625 batches: 0.381944.
[ Tue Jun 27 14:18:03 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:18:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:03 2023 ] Training epoch: 28
[ Tue Jun 27 14:18:06 2023 ] 	Training loss: 0.4150.  Training acc: 96.69%.
[ Tue Jun 27 14:18:06 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:18:06 2023 ] Eval epoch: 28
[ Tue Jun 27 14:18:06 2023 ] 	Mean test loss of 625 batches: 0.371516.
[ Tue Jun 27 14:18:06 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:18:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:06 2023 ] Training epoch: 29
[ Tue Jun 27 14:18:09 2023 ] 	Training loss: 0.4351.  Training acc: 95.40%.
[ Tue Jun 27 14:18:09 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:18:09 2023 ] Eval epoch: 29
[ Tue Jun 27 14:18:09 2023 ] 	Mean test loss of 625 batches: 0.364708.
[ Tue Jun 27 14:18:09 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:18:09 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:09 2023 ] Training epoch: 30
[ Tue Jun 27 14:18:12 2023 ] 	Training loss: 0.4229.  Training acc: 96.14%.
[ Tue Jun 27 14:18:12 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:18:12 2023 ] Eval epoch: 30
[ Tue Jun 27 14:18:12 2023 ] 	Mean test loss of 625 batches: 0.381269.
[ Tue Jun 27 14:18:12 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:18:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:12 2023 ] Training epoch: 31
[ Tue Jun 27 14:18:15 2023 ] 	Training loss: 0.4328.  Training acc: 95.96%.
[ Tue Jun 27 14:18:15 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:18:15 2023 ] Eval epoch: 31
[ Tue Jun 27 14:18:15 2023 ] 	Mean test loss of 625 batches: 0.378118.
[ Tue Jun 27 14:18:15 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:18:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:15 2023 ] Training epoch: 32
[ Tue Jun 27 14:18:18 2023 ] 	Training loss: 0.4193.  Training acc: 95.86%.
[ Tue Jun 27 14:18:18 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:18:18 2023 ] Eval epoch: 32
[ Tue Jun 27 14:18:18 2023 ] 	Mean test loss of 625 batches: 0.370340.
[ Tue Jun 27 14:18:18 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:18:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:18 2023 ] Training epoch: 33
[ Tue Jun 27 14:18:21 2023 ] 	Training loss: 0.4153.  Training acc: 96.69%.
[ Tue Jun 27 14:18:21 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:18:21 2023 ] Eval epoch: 33
[ Tue Jun 27 14:18:21 2023 ] 	Mean test loss of 625 batches: 0.355677.
[ Tue Jun 27 14:18:21 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:18:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:21 2023 ] Training epoch: 34
[ Tue Jun 27 14:18:24 2023 ] 	Training loss: 0.4101.  Training acc: 96.97%.
[ Tue Jun 27 14:18:24 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:18:24 2023 ] Eval epoch: 34
[ Tue Jun 27 14:18:24 2023 ] 	Mean test loss of 625 batches: 0.355379.
[ Tue Jun 27 14:18:24 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:18:24 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:24 2023 ] Training epoch: 35
[ Tue Jun 27 14:18:27 2023 ] 	Training loss: 0.4184.  Training acc: 96.78%.
[ Tue Jun 27 14:18:27 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:18:27 2023 ] Eval epoch: 35
[ Tue Jun 27 14:18:27 2023 ] 	Mean test loss of 625 batches: 0.354597.
[ Tue Jun 27 14:18:27 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:18:27 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:27 2023 ] Training epoch: 36
[ Tue Jun 27 14:18:30 2023 ] 	Training loss: 0.4095.  Training acc: 96.78%.
[ Tue Jun 27 14:18:30 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:18:30 2023 ] Eval epoch: 36
[ Tue Jun 27 14:18:30 2023 ] 	Mean test loss of 625 batches: 0.372976.
[ Tue Jun 27 14:18:30 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:18:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:30 2023 ] Training epoch: 37
[ Tue Jun 27 14:18:33 2023 ] 	Training loss: 0.4173.  Training acc: 96.69%.
[ Tue Jun 27 14:18:33 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:18:33 2023 ] Eval epoch: 37
[ Tue Jun 27 14:18:33 2023 ] 	Mean test loss of 625 batches: 0.352693.
[ Tue Jun 27 14:18:33 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:18:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:33 2023 ] Training epoch: 38
[ Tue Jun 27 14:18:36 2023 ] 	Training loss: 0.4090.  Training acc: 96.97%.
[ Tue Jun 27 14:18:36 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:18:36 2023 ] Eval epoch: 38
[ Tue Jun 27 14:18:36 2023 ] 	Mean test loss of 625 batches: 0.358210.
[ Tue Jun 27 14:18:36 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:18:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:36 2023 ] Training epoch: 39
[ Tue Jun 27 14:18:39 2023 ] 	Training loss: 0.4009.  Training acc: 96.97%.
[ Tue Jun 27 14:18:39 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:18:39 2023 ] Eval epoch: 39
[ Tue Jun 27 14:18:39 2023 ] 	Mean test loss of 625 batches: 0.341408.
[ Tue Jun 27 14:18:39 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:18:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:39 2023 ] Training epoch: 40
[ Tue Jun 27 14:18:42 2023 ] 	Training loss: 0.4146.  Training acc: 96.42%.
[ Tue Jun 27 14:18:42 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:18:42 2023 ] Eval epoch: 40
[ Tue Jun 27 14:18:42 2023 ] 	Mean test loss of 625 batches: 0.360832.
[ Tue Jun 27 14:18:42 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:18:42 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:43 2023 ] Best accuracy: 0.9824561403508771
[ Tue Jun 27 14:18:43 2023 ] Epoch number: 26
[ Tue Jun 27 14:18:43 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 14:18:43 2023 ] Weight decay: 0.0005
[ Tue Jun 27 14:18:43 2023 ] Base LR: 0.1
[ Tue Jun 27 14:18:43 2023 ] Batch Size: 64
[ Tue Jun 27 14:18:43 2023 ] Test Batch Size: 64
[ Tue Jun 27 14:18:43 2023 ] seed: 1
[ Tue Jun 27 14:18:43 2023 ] Start training Corrector
[ Tue Jun 27 14:18:43 2023 ] Training epoch: 1
[ Tue Jun 27 14:23:58 2023 ] using warm up, epoch: 5
[ Tue Jun 27 14:23:58 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 14:23:58 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 14:23:58 2023 ] Start training Predictor
[ Tue Jun 27 14:23:58 2023 ] Training epoch: 1
[ Tue Jun 27 14:24:04 2023 ] 	Training loss: 105.0491.  Training acc: 35.48%.
[ Tue Jun 27 14:24:04 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Jun 27 14:24:04 2023 ] Eval epoch: 1
[ Tue Jun 27 14:24:04 2023 ] 	Mean test loss of 625 batches: 72.175684.
[ Tue Jun 27 14:24:04 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:24:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:05 2023 ] Training epoch: 2
[ Tue Jun 27 14:24:07 2023 ] 	Training loss: 8.2283.  Training acc: 39.25%.
[ Tue Jun 27 14:24:07 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:24:07 2023 ] Eval epoch: 2
[ Tue Jun 27 14:24:07 2023 ] 	Mean test loss of 625 batches: 17.031623.
[ Tue Jun 27 14:24:07 2023 ] 	Top1: 56.14%
[ Tue Jun 27 14:24:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:07 2023 ] Training epoch: 3
[ Tue Jun 27 14:24:10 2023 ] 	Training loss: 6.3609.  Training acc: 47.61%.
[ Tue Jun 27 14:24:10 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:24:10 2023 ] Eval epoch: 3
[ Tue Jun 27 14:24:10 2023 ] 	Mean test loss of 625 batches: 15.792705.
[ Tue Jun 27 14:24:10 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:24:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:10 2023 ] Training epoch: 4
[ Tue Jun 27 14:24:13 2023 ] 	Training loss: 7.2384.  Training acc: 64.25%.
[ Tue Jun 27 14:24:13 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:24:13 2023 ] Eval epoch: 4
[ Tue Jun 27 14:24:13 2023 ] 	Mean test loss of 625 batches: 7.427565.
[ Tue Jun 27 14:24:13 2023 ] 	Top1: 43.86%
[ Tue Jun 27 14:24:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:13 2023 ] Training epoch: 5
[ Tue Jun 27 14:24:16 2023 ] 	Training loss: 9.0349.  Training acc: 56.62%.
[ Tue Jun 27 14:24:16 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:24:16 2023 ] Eval epoch: 5
[ Tue Jun 27 14:24:16 2023 ] 	Mean test loss of 625 batches: 16.257784.
[ Tue Jun 27 14:24:16 2023 ] 	Top1: 43.86%
[ Tue Jun 27 14:24:16 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:16 2023 ] Training epoch: 6
[ Tue Jun 27 14:24:19 2023 ] 	Training loss: 2.3363.  Training acc: 55.24%.
[ Tue Jun 27 14:24:19 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:24:19 2023 ] Eval epoch: 6
[ Tue Jun 27 14:24:19 2023 ] 	Mean test loss of 625 batches: 29.427145.
[ Tue Jun 27 14:24:19 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:24:19 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:19 2023 ] Training epoch: 7
[ Tue Jun 27 14:24:21 2023 ] 	Training loss: 1.6169.  Training acc: 57.08%.
[ Tue Jun 27 14:24:21 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:24:21 2023 ] Eval epoch: 7
[ Tue Jun 27 14:24:22 2023 ] 	Mean test loss of 625 batches: 6.851389.
[ Tue Jun 27 14:24:22 2023 ] 	Top1: 33.33%
[ Tue Jun 27 14:24:22 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:22 2023 ] Training epoch: 8
[ Tue Jun 27 14:24:24 2023 ] 	Training loss: 1.6804.  Training acc: 48.71%.
[ Tue Jun 27 14:24:24 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:24:24 2023 ] Eval epoch: 8
[ Tue Jun 27 14:24:25 2023 ] 	Mean test loss of 625 batches: 1.310456.
[ Tue Jun 27 14:24:25 2023 ] 	Top1: 50.88%
[ Tue Jun 27 14:24:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:25 2023 ] Training epoch: 9
[ Tue Jun 27 14:24:27 2023 ] 	Training loss: 2.1178.  Training acc: 48.44%.
[ Tue Jun 27 14:24:27 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:24:27 2023 ] Eval epoch: 9
[ Tue Jun 27 14:24:28 2023 ] 	Mean test loss of 625 batches: 1.372901.
[ Tue Jun 27 14:24:28 2023 ] 	Top1: 40.35%
[ Tue Jun 27 14:24:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:28 2023 ] Training epoch: 10
[ Tue Jun 27 14:24:30 2023 ] 	Training loss: 1.4009.  Training acc: 54.78%.
[ Tue Jun 27 14:24:30 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:24:30 2023 ] Eval epoch: 10
[ Tue Jun 27 14:24:31 2023 ] 	Mean test loss of 625 batches: 4.652955.
[ Tue Jun 27 14:24:31 2023 ] 	Top1: 8.77%
[ Tue Jun 27 14:24:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:31 2023 ] Training epoch: 11
[ Tue Jun 27 14:24:33 2023 ] 	Training loss: 1.1025.  Training acc: 58.73%.
[ Tue Jun 27 14:24:33 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:24:33 2023 ] Eval epoch: 11
[ Tue Jun 27 14:24:34 2023 ] 	Mean test loss of 625 batches: 1.032710.
[ Tue Jun 27 14:24:34 2023 ] 	Top1: 36.84%
[ Tue Jun 27 14:24:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:34 2023 ] Training epoch: 12
[ Tue Jun 27 14:24:36 2023 ] 	Training loss: 1.0127.  Training acc: 57.72%.
[ Tue Jun 27 14:24:36 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:24:36 2023 ] Eval epoch: 12
[ Tue Jun 27 14:24:37 2023 ] 	Mean test loss of 625 batches: 0.769107.
[ Tue Jun 27 14:24:37 2023 ] 	Top1: 64.91%
[ Tue Jun 27 14:24:37 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:37 2023 ] Training epoch: 13
[ Tue Jun 27 14:24:39 2023 ] 	Training loss: 0.8962.  Training acc: 62.96%.
[ Tue Jun 27 14:24:39 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:24:39 2023 ] Eval epoch: 13
[ Tue Jun 27 14:24:40 2023 ] 	Mean test loss of 625 batches: 0.673707.
[ Tue Jun 27 14:24:40 2023 ] 	Top1: 82.46%
[ Tue Jun 27 14:24:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:40 2023 ] Training epoch: 14
[ Tue Jun 27 14:24:43 2023 ] 	Training loss: 0.8380.  Training acc: 65.99%.
[ Tue Jun 27 14:24:43 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:24:43 2023 ] Eval epoch: 14
[ Tue Jun 27 14:24:43 2023 ] 	Mean test loss of 625 batches: 0.739172.
[ Tue Jun 27 14:24:43 2023 ] 	Top1: 77.19%
[ Tue Jun 27 14:24:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:43 2023 ] Training epoch: 15
[ Tue Jun 27 14:24:46 2023 ] 	Training loss: 0.8518.  Training acc: 64.98%.
[ Tue Jun 27 14:24:46 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:24:46 2023 ] Eval epoch: 15
[ Tue Jun 27 14:24:46 2023 ] 	Mean test loss of 625 batches: 0.680898.
[ Tue Jun 27 14:24:46 2023 ] 	Top1: 68.42%
[ Tue Jun 27 14:24:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:46 2023 ] Training epoch: 16
[ Tue Jun 27 14:24:48 2023 ] 	Training loss: 0.7959.  Training acc: 68.29%.
[ Tue Jun 27 14:24:48 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:24:48 2023 ] Eval epoch: 16
[ Tue Jun 27 14:24:49 2023 ] 	Mean test loss of 625 batches: 0.697690.
[ Tue Jun 27 14:24:49 2023 ] 	Top1: 66.67%
[ Tue Jun 27 14:24:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:49 2023 ] Training epoch: 17
[ Tue Jun 27 14:24:52 2023 ] 	Training loss: 0.7379.  Training acc: 73.35%.
[ Tue Jun 27 14:24:52 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:24:52 2023 ] Eval epoch: 17
[ Tue Jun 27 14:24:52 2023 ] 	Mean test loss of 625 batches: 0.681639.
[ Tue Jun 27 14:24:52 2023 ] 	Top1: 71.93%
[ Tue Jun 27 14:24:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:52 2023 ] Training epoch: 18
[ Tue Jun 27 14:24:55 2023 ] 	Training loss: 0.7285.  Training acc: 72.70%.
[ Tue Jun 27 14:24:55 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:24:55 2023 ] Eval epoch: 18
[ Tue Jun 27 14:24:55 2023 ] 	Mean test loss of 625 batches: 0.662989.
[ Tue Jun 27 14:24:55 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:24:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:55 2023 ] Training epoch: 19
[ Tue Jun 27 14:24:58 2023 ] 	Training loss: 0.7085.  Training acc: 76.93%.
[ Tue Jun 27 14:24:58 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:24:58 2023 ] Eval epoch: 19
[ Tue Jun 27 14:24:58 2023 ] 	Mean test loss of 625 batches: 0.704919.
[ Tue Jun 27 14:24:58 2023 ] 	Top1: 82.46%
[ Tue Jun 27 14:24:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:58 2023 ] Training epoch: 20
[ Tue Jun 27 14:25:01 2023 ] 	Training loss: 0.6789.  Training acc: 79.41%.
[ Tue Jun 27 14:25:01 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:01 2023 ] Eval epoch: 20
[ Tue Jun 27 14:25:01 2023 ] 	Mean test loss of 625 batches: 0.726280.
[ Tue Jun 27 14:25:01 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:25:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:01 2023 ] Training epoch: 21
[ Tue Jun 27 14:25:03 2023 ] 	Training loss: 0.6578.  Training acc: 81.71%.
[ Tue Jun 27 14:25:03 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:03 2023 ] Eval epoch: 21
[ Tue Jun 27 14:25:04 2023 ] 	Mean test loss of 625 batches: 0.612851.
[ Tue Jun 27 14:25:04 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:25:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:04 2023 ] Training epoch: 22
[ Tue Jun 27 14:25:07 2023 ] 	Training loss: 0.6395.  Training acc: 83.09%.
[ Tue Jun 27 14:25:07 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:07 2023 ] Eval epoch: 22
[ Tue Jun 27 14:25:07 2023 ] 	Mean test loss of 625 batches: 0.622487.
[ Tue Jun 27 14:25:07 2023 ] 	Top1: 89.47%
[ Tue Jun 27 14:25:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:07 2023 ] Training epoch: 23
[ Tue Jun 27 14:25:10 2023 ] 	Training loss: 0.6231.  Training acc: 85.02%.
[ Tue Jun 27 14:25:10 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:25:10 2023 ] Eval epoch: 23
[ Tue Jun 27 14:25:10 2023 ] 	Mean test loss of 625 batches: 0.641874.
[ Tue Jun 27 14:25:10 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:25:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:10 2023 ] Training epoch: 24
[ Tue Jun 27 14:25:13 2023 ] 	Training loss: 0.6457.  Training acc: 81.53%.
[ Tue Jun 27 14:25:13 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:13 2023 ] Eval epoch: 24
[ Tue Jun 27 14:25:13 2023 ] 	Mean test loss of 625 batches: 0.626704.
[ Tue Jun 27 14:25:13 2023 ] 	Top1: 89.47%
[ Tue Jun 27 14:25:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:13 2023 ] Training epoch: 25
[ Tue Jun 27 14:25:16 2023 ] 	Training loss: 0.6422.  Training acc: 83.27%.
[ Tue Jun 27 14:25:16 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:16 2023 ] Eval epoch: 25
[ Tue Jun 27 14:25:16 2023 ] 	Mean test loss of 625 batches: 0.621373.
[ Tue Jun 27 14:25:16 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:25:16 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:16 2023 ] Training epoch: 26
[ Tue Jun 27 14:25:19 2023 ] 	Training loss: 0.6322.  Training acc: 83.64%.
[ Tue Jun 27 14:25:19 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:19 2023 ] Eval epoch: 26
[ Tue Jun 27 14:25:19 2023 ] 	Mean test loss of 625 batches: 0.590198.
[ Tue Jun 27 14:25:19 2023 ] 	Top1: 91.23%
[ Tue Jun 27 14:25:19 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:19 2023 ] Training epoch: 27
[ Tue Jun 27 14:25:22 2023 ] 	Training loss: 0.6352.  Training acc: 83.64%.
[ Tue Jun 27 14:25:22 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:22 2023 ] Eval epoch: 27
[ Tue Jun 27 14:25:22 2023 ] 	Mean test loss of 625 batches: 0.607043.
[ Tue Jun 27 14:25:22 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:25:22 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:22 2023 ] Training epoch: 28
[ Tue Jun 27 14:25:25 2023 ] 	Training loss: 0.6073.  Training acc: 86.86%.
[ Tue Jun 27 14:25:25 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:25 2023 ] Eval epoch: 28
[ Tue Jun 27 14:25:25 2023 ] 	Mean test loss of 625 batches: 0.638436.
[ Tue Jun 27 14:25:25 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:25:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:25 2023 ] Training epoch: 29
[ Tue Jun 27 14:25:28 2023 ] 	Training loss: 0.6081.  Training acc: 86.67%.
[ Tue Jun 27 14:25:28 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:28 2023 ] Eval epoch: 29
[ Tue Jun 27 14:25:28 2023 ] 	Mean test loss of 625 batches: 0.611331.
[ Tue Jun 27 14:25:28 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:25:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:28 2023 ] Training epoch: 30
[ Tue Jun 27 14:25:31 2023 ] 	Training loss: 0.6096.  Training acc: 85.75%.
[ Tue Jun 27 14:25:31 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:25:31 2023 ] Eval epoch: 30
[ Tue Jun 27 14:25:31 2023 ] 	Mean test loss of 625 batches: 0.591933.
[ Tue Jun 27 14:25:31 2023 ] 	Top1: 89.47%
[ Tue Jun 27 14:25:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:31 2023 ] Training epoch: 31
[ Tue Jun 27 14:25:34 2023 ] 	Training loss: 0.6095.  Training acc: 85.75%.
[ Tue Jun 27 14:25:34 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:34 2023 ] Eval epoch: 31
[ Tue Jun 27 14:25:34 2023 ] 	Mean test loss of 625 batches: 0.597013.
[ Tue Jun 27 14:25:34 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:25:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:34 2023 ] Training epoch: 32
[ Tue Jun 27 14:25:37 2023 ] 	Training loss: 0.6107.  Training acc: 85.66%.
[ Tue Jun 27 14:25:37 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:37 2023 ] Eval epoch: 32
[ Tue Jun 27 14:25:37 2023 ] 	Mean test loss of 625 batches: 0.586705.
[ Tue Jun 27 14:25:37 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:25:37 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:37 2023 ] Training epoch: 33
[ Tue Jun 27 14:25:39 2023 ] 	Training loss: 0.5932.  Training acc: 87.13%.
[ Tue Jun 27 14:25:39 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:39 2023 ] Eval epoch: 33
[ Tue Jun 27 14:25:40 2023 ] 	Mean test loss of 625 batches: 0.593860.
[ Tue Jun 27 14:25:40 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:25:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:40 2023 ] Training epoch: 34
[ Tue Jun 27 14:25:42 2023 ] 	Training loss: 0.5984.  Training acc: 86.76%.
[ Tue Jun 27 14:25:42 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:42 2023 ] Eval epoch: 34
[ Tue Jun 27 14:25:43 2023 ] 	Mean test loss of 625 batches: 0.592506.
[ Tue Jun 27 14:25:43 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:25:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:43 2023 ] Training epoch: 35
[ Tue Jun 27 14:25:45 2023 ] 	Training loss: 0.5891.  Training acc: 88.88%.
[ Tue Jun 27 14:25:45 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:25:45 2023 ] Eval epoch: 35
[ Tue Jun 27 14:25:46 2023 ] 	Mean test loss of 625 batches: 0.569726.
[ Tue Jun 27 14:25:46 2023 ] 	Top1: 91.23%
[ Tue Jun 27 14:25:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:46 2023 ] Training epoch: 36
[ Tue Jun 27 14:25:48 2023 ] 	Training loss: 0.5962.  Training acc: 87.50%.
[ Tue Jun 27 14:25:48 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:25:48 2023 ] Eval epoch: 36
[ Tue Jun 27 14:25:49 2023 ] 	Mean test loss of 625 batches: 0.561325.
[ Tue Jun 27 14:25:49 2023 ] 	Top1: 91.23%
[ Tue Jun 27 14:25:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:49 2023 ] Training epoch: 37
[ Tue Jun 27 14:25:51 2023 ] 	Training loss: 0.5899.  Training acc: 88.24%.
[ Tue Jun 27 14:25:51 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:51 2023 ] Eval epoch: 37
[ Tue Jun 27 14:25:52 2023 ] 	Mean test loss of 625 batches: 0.602103.
[ Tue Jun 27 14:25:52 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:25:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:52 2023 ] Training epoch: 38
[ Tue Jun 27 14:25:54 2023 ] 	Training loss: 0.5893.  Training acc: 87.87%.
[ Tue Jun 27 14:25:54 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:54 2023 ] Eval epoch: 38
[ Tue Jun 27 14:25:55 2023 ] 	Mean test loss of 625 batches: 0.585777.
[ Tue Jun 27 14:25:55 2023 ] 	Top1: 89.47%
[ Tue Jun 27 14:25:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:55 2023 ] Training epoch: 39
[ Tue Jun 27 14:25:57 2023 ] 	Training loss: 0.5803.  Training acc: 89.43%.
[ Tue Jun 27 14:25:57 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:57 2023 ] Eval epoch: 39
[ Tue Jun 27 14:25:58 2023 ] 	Mean test loss of 625 batches: 0.575629.
[ Tue Jun 27 14:25:58 2023 ] 	Top1: 89.47%
[ Tue Jun 27 14:25:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:58 2023 ] Training epoch: 40
[ Tue Jun 27 14:26:00 2023 ] 	Training loss: 0.6015.  Training acc: 87.13%.
[ Tue Jun 27 14:26:00 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 14:26:00 2023 ] Eval epoch: 40
[ Tue Jun 27 14:26:01 2023 ] 	Mean test loss of 625 batches: 0.569328.
[ Tue Jun 27 14:26:01 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:26:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:26:01 2023 ] Best accuracy: 0.9122807017543859
[ Tue Jun 27 14:26:01 2023 ] Epoch number: 26
[ Tue Jun 27 14:26:01 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 14:26:01 2023 ] Weight decay: 0.0005
[ Tue Jun 27 14:26:01 2023 ] Base LR: 0.1
[ Tue Jun 27 14:26:01 2023 ] Batch Size: 64
[ Tue Jun 27 14:26:01 2023 ] Test Batch Size: 64
[ Tue Jun 27 14:26:01 2023 ] seed: 1
[ Tue Jun 27 14:26:01 2023 ] Start training Corrector
[ Tue Jun 27 14:26:01 2023 ] Training epoch: 1
[ Tue Jun 27 14:27:44 2023 ] using warm up, epoch: 5
[ Tue Jun 27 14:27:44 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 14:27:44 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 14:27:44 2023 ] Start training Predictor
[ Tue Jun 27 14:27:44 2023 ] Training epoch: 1
[ Tue Jun 27 14:27:50 2023 ] 	Training loss: 115.6280.  Training acc: 35.11%.
[ Tue Jun 27 14:27:50 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jun 27 14:27:50 2023 ] Eval epoch: 1
[ Tue Jun 27 14:27:51 2023 ] 	Mean test loss of 625 batches: 5561.882812.
[ Tue Jun 27 14:27:51 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:27:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:27:51 2023 ] Training epoch: 2
[ Tue Jun 27 14:27:53 2023 ] 	Training loss: 10.0636.  Training acc: 34.47%.
[ Tue Jun 27 14:27:53 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 14:27:53 2023 ] Eval epoch: 2
[ Tue Jun 27 14:27:54 2023 ] 	Mean test loss of 625 batches: 4.427555.
[ Tue Jun 27 14:27:54 2023 ] 	Top1: 33.33%
[ Tue Jun 27 14:27:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:27:54 2023 ] Training epoch: 3
[ Tue Jun 27 14:27:57 2023 ] 	Training loss: 6.1542.  Training acc: 34.93%.
[ Tue Jun 27 14:27:57 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:27:57 2023 ] Eval epoch: 3
[ Tue Jun 27 14:27:57 2023 ] 	Mean test loss of 625 batches: 1.007667.
[ Tue Jun 27 14:27:57 2023 ] 	Top1: 52.63%
[ Tue Jun 27 14:27:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:27:57 2023 ] Training epoch: 4
[ Tue Jun 27 14:28:00 2023 ] 	Training loss: 6.7260.  Training acc: 36.21%.
[ Tue Jun 27 14:28:00 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Tue Jun 27 14:28:00 2023 ] Eval epoch: 4
[ Tue Jun 27 14:28:01 2023 ] 	Mean test loss of 625 batches: 4.674818.
[ Tue Jun 27 14:28:01 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:28:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:01 2023 ] Training epoch: 5
[ Tue Jun 27 14:28:03 2023 ] 	Training loss: 3.9113.  Training acc: 46.51%.
[ Tue Jun 27 14:28:03 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 14:28:03 2023 ] Eval epoch: 5
[ Tue Jun 27 14:28:04 2023 ] 	Mean test loss of 625 batches: 4.341672.
[ Tue Jun 27 14:28:04 2023 ] 	Top1: 40.35%
[ Tue Jun 27 14:28:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:04 2023 ] Training epoch: 6
[ Tue Jun 27 14:28:06 2023 ] 	Training loss: 3.0273.  Training acc: 60.48%.
[ Tue Jun 27 14:28:06 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:28:06 2023 ] Eval epoch: 6
[ Tue Jun 27 14:28:07 2023 ] 	Mean test loss of 625 batches: 2.414579.
[ Tue Jun 27 14:28:07 2023 ] 	Top1: 28.07%
[ Tue Jun 27 14:28:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:07 2023 ] Training epoch: 7
[ Tue Jun 27 14:28:10 2023 ] 	Training loss: 1.8176.  Training acc: 65.99%.
[ Tue Jun 27 14:28:10 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 14:28:10 2023 ] Eval epoch: 7
[ Tue Jun 27 14:28:10 2023 ] 	Mean test loss of 625 batches: 1.442209.
[ Tue Jun 27 14:28:10 2023 ] 	Top1: 43.86%
[ Tue Jun 27 14:28:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:10 2023 ] Training epoch: 8
[ Tue Jun 27 14:28:13 2023 ] 	Training loss: 1.9896.  Training acc: 57.44%.
[ Tue Jun 27 14:28:13 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 14:28:13 2023 ] Eval epoch: 8
[ Tue Jun 27 14:28:14 2023 ] 	Mean test loss of 625 batches: 1.829765.
[ Tue Jun 27 14:28:14 2023 ] 	Top1: 54.39%
[ Tue Jun 27 14:28:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:14 2023 ] Training epoch: 9
[ Tue Jun 27 14:28:16 2023 ] 	Training loss: 1.8527.  Training acc: 65.53%.
[ Tue Jun 27 14:28:16 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:28:16 2023 ] Eval epoch: 9
[ Tue Jun 27 14:28:17 2023 ] 	Mean test loss of 625 batches: 1.266362.
[ Tue Jun 27 14:28:17 2023 ] 	Top1: 59.65%
[ Tue Jun 27 14:28:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:17 2023 ] Training epoch: 10
[ Tue Jun 27 14:28:19 2023 ] 	Training loss: 1.5790.  Training acc: 58.27%.
[ Tue Jun 27 14:28:19 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:28:19 2023 ] Eval epoch: 10
[ Tue Jun 27 14:28:20 2023 ] 	Mean test loss of 625 batches: 0.902391.
[ Tue Jun 27 14:28:20 2023 ] 	Top1: 61.40%
[ Tue Jun 27 14:28:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:20 2023 ] Training epoch: 11
[ Tue Jun 27 14:28:23 2023 ] 	Training loss: 1.1097.  Training acc: 63.88%.
[ Tue Jun 27 14:28:23 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 14:28:23 2023 ] Eval epoch: 11
[ Tue Jun 27 14:28:23 2023 ] 	Mean test loss of 625 batches: 0.699569.
[ Tue Jun 27 14:28:23 2023 ] 	Top1: 75.44%
[ Tue Jun 27 14:28:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:23 2023 ] Training epoch: 12
[ Tue Jun 27 14:28:26 2023 ] 	Training loss: 0.9697.  Training acc: 68.38%.
[ Tue Jun 27 14:28:26 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 14:28:26 2023 ] Eval epoch: 12
[ Tue Jun 27 14:28:27 2023 ] 	Mean test loss of 625 batches: 0.790004.
[ Tue Jun 27 14:28:27 2023 ] 	Top1: 75.44%
[ Tue Jun 27 14:28:27 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:27 2023 ] Training epoch: 13
[ Tue Jun 27 14:28:29 2023 ] 	Training loss: 0.9108.  Training acc: 69.39%.
[ Tue Jun 27 14:28:29 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:28:29 2023 ] Eval epoch: 13
[ Tue Jun 27 14:28:30 2023 ] 	Mean test loss of 625 batches: 0.703438.
[ Tue Jun 27 14:28:30 2023 ] 	Top1: 73.68%
[ Tue Jun 27 14:28:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:30 2023 ] Training epoch: 14
[ Tue Jun 27 14:28:32 2023 ] 	Training loss: 0.8697.  Training acc: 71.51%.
[ Tue Jun 27 14:28:32 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:28:32 2023 ] Eval epoch: 14
[ Tue Jun 27 14:28:33 2023 ] 	Mean test loss of 625 batches: 0.750105.
[ Tue Jun 27 14:28:33 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:28:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:33 2023 ] Training epoch: 15
[ Tue Jun 27 14:28:36 2023 ] 	Training loss: 0.8440.  Training acc: 71.42%.
[ Tue Jun 27 14:28:36 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 14:28:36 2023 ] Eval epoch: 15
[ Tue Jun 27 14:28:36 2023 ] 	Mean test loss of 625 batches: 0.638483.
[ Tue Jun 27 14:28:36 2023 ] 	Top1: 71.93%
[ Tue Jun 27 14:28:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:36 2023 ] Training epoch: 16
[ Tue Jun 27 14:28:39 2023 ] 	Training loss: 0.8057.  Training acc: 73.81%.
[ Tue Jun 27 14:28:39 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Tue Jun 27 14:28:39 2023 ] Eval epoch: 16
[ Tue Jun 27 14:28:40 2023 ] 	Mean test loss of 625 batches: 0.636556.
[ Tue Jun 27 14:28:40 2023 ] 	Top1: 77.19%
[ Tue Jun 27 14:28:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:40 2023 ] Training epoch: 17
[ Tue Jun 27 14:28:42 2023 ] 	Training loss: 0.7393.  Training acc: 77.85%.
[ Tue Jun 27 14:28:42 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 14:28:42 2023 ] Eval epoch: 17
[ Tue Jun 27 14:28:43 2023 ] 	Mean test loss of 625 batches: 0.634636.
[ Tue Jun 27 14:28:43 2023 ] 	Top1: 78.95%
[ Tue Jun 27 14:28:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:43 2023 ] Training epoch: 18
[ Tue Jun 27 14:28:45 2023 ] 	Training loss: 0.7188.  Training acc: 79.41%.
[ Tue Jun 27 14:28:45 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:28:45 2023 ] Eval epoch: 18
[ Tue Jun 27 14:28:46 2023 ] 	Mean test loss of 625 batches: 0.925888.
[ Tue Jun 27 14:28:46 2023 ] 	Top1: 61.40%
[ Tue Jun 27 14:28:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:46 2023 ] Training epoch: 19
[ Tue Jun 27 14:28:49 2023 ] 	Training loss: 0.7206.  Training acc: 80.24%.
[ Tue Jun 27 14:28:49 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:28:49 2023 ] Eval epoch: 19
[ Tue Jun 27 14:28:49 2023 ] 	Mean test loss of 625 batches: 0.798423.
[ Tue Jun 27 14:28:49 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:28:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:49 2023 ] Training epoch: 20
[ Tue Jun 27 14:28:52 2023 ] 	Training loss: 0.6844.  Training acc: 82.08%.
[ Tue Jun 27 14:28:52 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Tue Jun 27 14:28:52 2023 ] Eval epoch: 20
[ Tue Jun 27 14:28:52 2023 ] 	Mean test loss of 625 batches: 0.757034.
[ Tue Jun 27 14:28:52 2023 ] 	Top1: 75.44%
[ Tue Jun 27 14:28:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:52 2023 ] Training epoch: 21
[ Tue Jun 27 14:28:55 2023 ] 	Training loss: 0.6454.  Training acc: 83.64%.
[ Tue Jun 27 14:28:55 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:28:55 2023 ] Eval epoch: 21
[ Tue Jun 27 14:28:56 2023 ] 	Mean test loss of 625 batches: 0.577856.
[ Tue Jun 27 14:28:56 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:28:56 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:56 2023 ] Training epoch: 22
[ Tue Jun 27 14:28:58 2023 ] 	Training loss: 0.6560.  Training acc: 84.56%.
[ Tue Jun 27 14:28:58 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 14:28:58 2023 ] Eval epoch: 22
[ Tue Jun 27 14:28:59 2023 ] 	Mean test loss of 625 batches: 0.599608.
[ Tue Jun 27 14:28:59 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:28:59 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:59 2023 ] Training epoch: 23
[ Tue Jun 27 14:29:01 2023 ] 	Training loss: 0.6424.  Training acc: 85.29%.
[ Tue Jun 27 14:29:01 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 14:29:01 2023 ] Eval epoch: 23
[ Tue Jun 27 14:29:02 2023 ] 	Mean test loss of 625 batches: 0.609253.
[ Tue Jun 27 14:29:02 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:02 2023 ] Training epoch: 24
[ Tue Jun 27 14:29:05 2023 ] 	Training loss: 0.6450.  Training acc: 85.02%.
[ Tue Jun 27 14:29:05 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:29:05 2023 ] Eval epoch: 24
[ Tue Jun 27 14:29:05 2023 ] 	Mean test loss of 625 batches: 0.593886.
[ Tue Jun 27 14:29:05 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:05 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:05 2023 ] Training epoch: 25
[ Tue Jun 27 14:29:08 2023 ] 	Training loss: 0.6447.  Training acc: 84.38%.
[ Tue Jun 27 14:29:08 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:29:08 2023 ] Eval epoch: 25
[ Tue Jun 27 14:29:08 2023 ] 	Mean test loss of 625 batches: 0.572579.
[ Tue Jun 27 14:29:08 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:08 2023 ] Training epoch: 26
[ Tue Jun 27 14:29:11 2023 ] 	Training loss: 0.6460.  Training acc: 83.55%.
[ Tue Jun 27 14:29:11 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:29:11 2023 ] Eval epoch: 26
[ Tue Jun 27 14:29:12 2023 ] 	Mean test loss of 625 batches: 0.602834.
[ Tue Jun 27 14:29:12 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:12 2023 ] Training epoch: 27
[ Tue Jun 27 14:29:14 2023 ] 	Training loss: 0.6534.  Training acc: 83.82%.
[ Tue Jun 27 14:29:14 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:29:14 2023 ] Eval epoch: 27
[ Tue Jun 27 14:29:15 2023 ] 	Mean test loss of 625 batches: 0.569680.
[ Tue Jun 27 14:29:15 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:15 2023 ] Training epoch: 28
[ Tue Jun 27 14:29:17 2023 ] 	Training loss: 0.6257.  Training acc: 86.58%.
[ Tue Jun 27 14:29:17 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 14:29:17 2023 ] Eval epoch: 28
[ Tue Jun 27 14:29:18 2023 ] 	Mean test loss of 625 batches: 0.578702.
[ Tue Jun 27 14:29:18 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:18 2023 ] Training epoch: 29
[ Tue Jun 27 14:29:21 2023 ] 	Training loss: 0.6240.  Training acc: 84.93%.
[ Tue Jun 27 14:29:21 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 14:29:21 2023 ] Eval epoch: 29
[ Tue Jun 27 14:29:21 2023 ] 	Mean test loss of 625 batches: 0.633238.
[ Tue Jun 27 14:29:21 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:21 2023 ] Training epoch: 30
[ Tue Jun 27 14:29:24 2023 ] 	Training loss: 0.5949.  Training acc: 88.69%.
[ Tue Jun 27 14:29:24 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:29:24 2023 ] Eval epoch: 30
[ Tue Jun 27 14:29:25 2023 ] 	Mean test loss of 625 batches: 0.551020.
[ Tue Jun 27 14:29:25 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:25 2023 ] Training epoch: 31
[ Tue Jun 27 14:29:27 2023 ] 	Training loss: 0.6382.  Training acc: 84.74%.
[ Tue Jun 27 14:29:27 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 14:29:27 2023 ] Eval epoch: 31
[ Tue Jun 27 14:29:28 2023 ] 	Mean test loss of 625 batches: 0.599773.
[ Tue Jun 27 14:29:28 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:28 2023 ] Training epoch: 32
[ Tue Jun 27 14:29:30 2023 ] 	Training loss: 0.6269.  Training acc: 84.28%.
[ Tue Jun 27 14:29:30 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:29:30 2023 ] Eval epoch: 32
[ Tue Jun 27 14:29:31 2023 ] 	Mean test loss of 625 batches: 0.552663.
[ Tue Jun 27 14:29:31 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:29:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:31 2023 ] Training epoch: 33
[ Tue Jun 27 14:29:33 2023 ] 	Training loss: 0.6029.  Training acc: 87.96%.
[ Tue Jun 27 14:29:33 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 14:29:33 2023 ] Eval epoch: 33
[ Tue Jun 27 14:29:34 2023 ] 	Mean test loss of 625 batches: 0.551395.
[ Tue Jun 27 14:29:34 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:29:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:34 2023 ] Training epoch: 34
[ Tue Jun 27 14:29:37 2023 ] 	Training loss: 0.6140.  Training acc: 86.95%.
[ Tue Jun 27 14:29:37 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Tue Jun 27 14:29:37 2023 ] Eval epoch: 34
[ Tue Jun 27 14:29:37 2023 ] 	Mean test loss of 625 batches: 0.558725.
[ Tue Jun 27 14:29:37 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:29:37 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:37 2023 ] Training epoch: 35
[ Tue Jun 27 14:29:40 2023 ] 	Training loss: 0.5981.  Training acc: 88.14%.
[ Tue Jun 27 14:29:40 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 14:29:40 2023 ] Eval epoch: 35
[ Tue Jun 27 14:29:40 2023 ] 	Mean test loss of 625 batches: 0.557064.
[ Tue Jun 27 14:29:40 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:29:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:40 2023 ] Training epoch: 36
[ Tue Jun 27 14:29:43 2023 ] 	Training loss: 0.5953.  Training acc: 90.99%.
[ Tue Jun 27 14:29:43 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 14:29:43 2023 ] Eval epoch: 36
[ Tue Jun 27 14:29:44 2023 ] 	Mean test loss of 625 batches: 0.548922.
[ Tue Jun 27 14:29:44 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:29:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:44 2023 ] Training epoch: 37
[ Tue Jun 27 14:29:46 2023 ] 	Training loss: 0.5916.  Training acc: 89.61%.
[ Tue Jun 27 14:29:46 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:29:46 2023 ] Eval epoch: 37
[ Tue Jun 27 14:29:47 2023 ] 	Mean test loss of 625 batches: 0.562897.
[ Tue Jun 27 14:29:47 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:47 2023 ] Training epoch: 38
[ Tue Jun 27 14:29:49 2023 ] 	Training loss: 0.5957.  Training acc: 89.52%.
[ Tue Jun 27 14:29:49 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:29:49 2023 ] Eval epoch: 38
[ Tue Jun 27 14:29:50 2023 ] 	Mean test loss of 625 batches: 0.606781.
[ Tue Jun 27 14:29:50 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:50 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:50 2023 ] Training epoch: 39
[ Tue Jun 27 14:29:52 2023 ] 	Training loss: 0.5927.  Training acc: 90.07%.
[ Tue Jun 27 14:29:52 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 14:29:52 2023 ] Eval epoch: 39
[ Tue Jun 27 14:29:53 2023 ] 	Mean test loss of 625 batches: 0.568132.
[ Tue Jun 27 14:29:53 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:53 2023 ] Training epoch: 40
[ Tue Jun 27 14:29:55 2023 ] 	Training loss: 0.6324.  Training acc: 85.57%.
[ Tue Jun 27 14:29:55 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 14:29:55 2023 ] Eval epoch: 40
[ Tue Jun 27 14:29:56 2023 ] 	Mean test loss of 625 batches: 0.529222.
[ Tue Jun 27 14:29:56 2023 ] 	Top1: 92.98%
[ Tue Jun 27 14:29:56 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:57 2023 ] Best accuracy: 0.9298245614035088
[ Tue Jun 27 14:29:57 2023 ] Epoch number: 40
[ Tue Jun 27 14:29:57 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 14:29:57 2023 ] Weight decay: 0.0005
[ Tue Jun 27 14:29:57 2023 ] Base LR: 0.1
[ Tue Jun 27 14:29:57 2023 ] Batch Size: 64
[ Tue Jun 27 14:29:57 2023 ] Test Batch Size: 64
[ Tue Jun 27 14:29:57 2023 ] seed: 1
[ Tue Jun 27 14:29:57 2023 ] Start training Corrector
[ Tue Jun 27 14:29:57 2023 ] Training epoch: 1
[ Tue Jun 27 15:03:09 2023 ] using warm up, epoch: 5
[ Tue Jun 27 15:03:09 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 15:03:09 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 15:03:09 2023 ] Start training Predictor
[ Tue Jun 27 15:03:09 2023 ] Training epoch: 1
[ Tue Jun 27 15:03:33 2023 ] using warm up, epoch: 5
[ Tue Jun 27 15:03:33 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 15:03:33 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 15:03:33 2023 ] Start training Predictor
[ Tue Jun 27 15:03:33 2023 ] Training epoch: 1
[ Tue Jun 27 15:03:39 2023 ] 	Training loss: 123.4655.  Training acc: 35.94%.
[ Tue Jun 27 15:03:39 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jun 27 15:03:39 2023 ] Eval epoch: 1
[ Tue Jun 27 15:03:40 2023 ] 	Mean test loss of 625 batches: 4559.084668.
[ Tue Jun 27 15:03:40 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:03:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:03:40 2023 ] Training epoch: 2
[ Tue Jun 27 15:03:42 2023 ] 	Training loss: 13.5765.  Training acc: 36.40%.
[ Tue Jun 27 15:03:42 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:03:42 2023 ] Eval epoch: 2
[ Tue Jun 27 15:03:43 2023 ] 	Mean test loss of 625 batches: 8.421229.
[ Tue Jun 27 15:03:43 2023 ] 	Top1: 36.84%
[ Tue Jun 27 15:03:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:03:43 2023 ] Training epoch: 3
[ Tue Jun 27 15:03:45 2023 ] 	Training loss: 5.5284.  Training acc: 53.40%.
[ Tue Jun 27 15:03:45 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:03:45 2023 ] Eval epoch: 3
[ Tue Jun 27 15:03:45 2023 ] 	Mean test loss of 625 batches: 27.599662.
[ Tue Jun 27 15:03:45 2023 ] 	Top1: 42.11%
[ Tue Jun 27 15:03:45 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:03:45 2023 ] Training epoch: 4
[ Tue Jun 27 15:03:47 2023 ] 	Training loss: 4.2441.  Training acc: 68.29%.
[ Tue Jun 27 15:03:47 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:03:47 2023 ] Eval epoch: 4
[ Tue Jun 27 15:03:48 2023 ] 	Mean test loss of 625 batches: 4.044038.
[ Tue Jun 27 15:03:48 2023 ] 	Top1: 70.18%
[ Tue Jun 27 15:03:48 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:03:48 2023 ] Training epoch: 5
[ Tue Jun 27 15:03:50 2023 ] 	Training loss: 4.7956.  Training acc: 64.06%.
[ Tue Jun 27 15:03:50 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 15:03:50 2023 ] Eval epoch: 5
[ Tue Jun 27 15:03:51 2023 ] 	Mean test loss of 625 batches: 1.724720.
[ Tue Jun 27 15:03:51 2023 ] 	Top1: 52.63%
[ Tue Jun 27 15:03:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:03:51 2023 ] Training epoch: 6
[ Tue Jun 27 15:03:53 2023 ] 	Training loss: 2.7819.  Training acc: 63.14%.
[ Tue Jun 27 15:03:53 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:03:53 2023 ] Eval epoch: 6
[ Tue Jun 27 15:03:53 2023 ] 	Mean test loss of 625 batches: 3.838941.
[ Tue Jun 27 15:03:53 2023 ] 	Top1: 59.65%
[ Tue Jun 27 15:03:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:03:53 2023 ] Training epoch: 7
[ Tue Jun 27 15:03:55 2023 ] 	Training loss: 2.3877.  Training acc: 61.03%.
[ Tue Jun 27 15:03:55 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:03:55 2023 ] Eval epoch: 7
[ Tue Jun 27 15:03:56 2023 ] 	Mean test loss of 625 batches: 1.617154.
[ Tue Jun 27 15:03:56 2023 ] 	Top1: 50.88%
[ Tue Jun 27 15:03:56 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:03:56 2023 ] Training epoch: 8
[ Tue Jun 27 15:03:58 2023 ] 	Training loss: 2.6075.  Training acc: 60.66%.
[ Tue Jun 27 15:03:58 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:03:58 2023 ] Eval epoch: 8
[ Tue Jun 27 15:03:58 2023 ] 	Mean test loss of 625 batches: 0.984351.
[ Tue Jun 27 15:03:58 2023 ] 	Top1: 70.18%
[ Tue Jun 27 15:03:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:03:58 2023 ] Training epoch: 9
[ Tue Jun 27 15:04:01 2023 ] 	Training loss: 1.8049.  Training acc: 69.85%.
[ Tue Jun 27 15:04:01 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:04:01 2023 ] Eval epoch: 9
[ Tue Jun 27 15:04:01 2023 ] 	Mean test loss of 625 batches: 0.614736.
[ Tue Jun 27 15:04:01 2023 ] 	Top1: 87.72%
[ Tue Jun 27 15:04:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:01 2023 ] Training epoch: 10
[ Tue Jun 27 15:04:03 2023 ] 	Training loss: 1.2965.  Training acc: 76.38%.
[ Tue Jun 27 15:04:03 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:04:03 2023 ] Eval epoch: 10
[ Tue Jun 27 15:04:04 2023 ] 	Mean test loss of 625 batches: 0.649221.
[ Tue Jun 27 15:04:04 2023 ] 	Top1: 89.47%
[ Tue Jun 27 15:04:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:04 2023 ] Training epoch: 11
[ Tue Jun 27 15:04:06 2023 ] 	Training loss: 0.8711.  Training acc: 82.17%.
[ Tue Jun 27 15:04:06 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:04:06 2023 ] Eval epoch: 11
[ Tue Jun 27 15:04:07 2023 ] 	Mean test loss of 625 batches: 0.527420.
[ Tue Jun 27 15:04:07 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:07 2023 ] Training epoch: 12
[ Tue Jun 27 15:04:09 2023 ] 	Training loss: 0.6886.  Training acc: 85.94%.
[ Tue Jun 27 15:04:09 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:04:09 2023 ] Eval epoch: 12
[ Tue Jun 27 15:04:10 2023 ] 	Mean test loss of 625 batches: 0.457832.
[ Tue Jun 27 15:04:10 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:10 2023 ] Training epoch: 13
[ Tue Jun 27 15:04:12 2023 ] 	Training loss: 0.6132.  Training acc: 89.25%.
[ Tue Jun 27 15:04:12 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:04:12 2023 ] Eval epoch: 13
[ Tue Jun 27 15:04:12 2023 ] 	Mean test loss of 625 batches: 0.387503.
[ Tue Jun 27 15:04:12 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:12 2023 ] Training epoch: 14
[ Tue Jun 27 15:04:15 2023 ] 	Training loss: 0.5707.  Training acc: 89.89%.
[ Tue Jun 27 15:04:15 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:04:15 2023 ] Eval epoch: 14
[ Tue Jun 27 15:04:15 2023 ] 	Mean test loss of 625 batches: 0.418065.
[ Tue Jun 27 15:04:15 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:15 2023 ] Training epoch: 15
[ Tue Jun 27 15:04:17 2023 ] 	Training loss: 0.5395.  Training acc: 90.81%.
[ Tue Jun 27 15:04:17 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:04:17 2023 ] Eval epoch: 15
[ Tue Jun 27 15:04:18 2023 ] 	Mean test loss of 625 batches: 0.331280.
[ Tue Jun 27 15:04:18 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:18 2023 ] Training epoch: 16
[ Tue Jun 27 15:04:20 2023 ] 	Training loss: 0.5178.  Training acc: 92.10%.
[ Tue Jun 27 15:04:20 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:04:20 2023 ] Eval epoch: 16
[ Tue Jun 27 15:04:20 2023 ] 	Mean test loss of 625 batches: 0.348335.
[ Tue Jun 27 15:04:20 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:20 2023 ] Training epoch: 17
[ Tue Jun 27 15:04:22 2023 ] 	Training loss: 0.4793.  Training acc: 92.74%.
[ Tue Jun 27 15:04:22 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:04:22 2023 ] Eval epoch: 17
[ Tue Jun 27 15:04:23 2023 ] 	Mean test loss of 625 batches: 0.377449.
[ Tue Jun 27 15:04:23 2023 ] 	Top1: 96.49%
[ Tue Jun 27 15:04:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:23 2023 ] Training epoch: 18
[ Tue Jun 27 15:04:25 2023 ] 	Training loss: 0.4547.  Training acc: 95.04%.
[ Tue Jun 27 15:04:25 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:04:25 2023 ] Eval epoch: 18
[ Tue Jun 27 15:04:25 2023 ] 	Mean test loss of 625 batches: 0.336638.
[ Tue Jun 27 15:04:25 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:25 2023 ] Training epoch: 19
[ Tue Jun 27 15:04:28 2023 ] 	Training loss: 0.4899.  Training acc: 92.46%.
[ Tue Jun 27 15:04:28 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:04:28 2023 ] Eval epoch: 19
[ Tue Jun 27 15:04:28 2023 ] 	Mean test loss of 625 batches: 0.398501.
[ Tue Jun 27 15:04:28 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:28 2023 ] Training epoch: 20
[ Tue Jun 27 15:04:30 2023 ] 	Training loss: 0.4489.  Training acc: 94.94%.
[ Tue Jun 27 15:04:30 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:04:30 2023 ] Eval epoch: 20
[ Tue Jun 27 15:04:31 2023 ] 	Mean test loss of 625 batches: 0.324128.
[ Tue Jun 27 15:04:31 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:31 2023 ] Training epoch: 21
[ Tue Jun 27 15:04:33 2023 ] 	Training loss: 0.4369.  Training acc: 94.94%.
[ Tue Jun 27 15:04:33 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:04:33 2023 ] Eval epoch: 21
[ Tue Jun 27 15:04:34 2023 ] 	Mean test loss of 625 batches: 0.338123.
[ Tue Jun 27 15:04:34 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:34 2023 ] Training epoch: 22
[ Tue Jun 27 15:04:36 2023 ] 	Training loss: 0.4161.  Training acc: 96.23%.
[ Tue Jun 27 15:04:36 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:04:36 2023 ] Eval epoch: 22
[ Tue Jun 27 15:04:36 2023 ] 	Mean test loss of 625 batches: 0.325002.
[ Tue Jun 27 15:04:36 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:36 2023 ] Training epoch: 23
[ Tue Jun 27 15:04:38 2023 ] 	Training loss: 0.4309.  Training acc: 95.04%.
[ Tue Jun 27 15:04:38 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:04:38 2023 ] Eval epoch: 23
[ Tue Jun 27 15:04:39 2023 ] 	Mean test loss of 625 batches: 0.319290.
[ Tue Jun 27 15:04:39 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:39 2023 ] Training epoch: 24
[ Tue Jun 27 15:04:41 2023 ] 	Training loss: 0.4187.  Training acc: 95.86%.
[ Tue Jun 27 15:04:41 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:04:41 2023 ] Eval epoch: 24
[ Tue Jun 27 15:04:41 2023 ] 	Mean test loss of 625 batches: 0.320860.
[ Tue Jun 27 15:04:41 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:41 2023 ] Training epoch: 25
[ Tue Jun 27 15:04:44 2023 ] 	Training loss: 0.4124.  Training acc: 96.69%.
[ Tue Jun 27 15:04:44 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Tue Jun 27 15:04:44 2023 ] Eval epoch: 25
[ Tue Jun 27 15:04:44 2023 ] 	Mean test loss of 625 batches: 0.316730.
[ Tue Jun 27 15:04:44 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:44 2023 ] Training epoch: 26
[ Tue Jun 27 15:04:46 2023 ] 	Training loss: 0.4095.  Training acc: 96.32%.
[ Tue Jun 27 15:04:46 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:04:46 2023 ] Eval epoch: 26
[ Tue Jun 27 15:04:47 2023 ] 	Mean test loss of 625 batches: 0.320675.
[ Tue Jun 27 15:04:47 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:47 2023 ] Training epoch: 27
[ Tue Jun 27 15:04:49 2023 ] 	Training loss: 0.4046.  Training acc: 97.43%.
[ Tue Jun 27 15:04:49 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:04:49 2023 ] Eval epoch: 27
[ Tue Jun 27 15:04:50 2023 ] 	Mean test loss of 625 batches: 0.317396.
[ Tue Jun 27 15:04:50 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:50 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:50 2023 ] Training epoch: 28
[ Tue Jun 27 15:04:52 2023 ] 	Training loss: 0.4022.  Training acc: 96.51%.
[ Tue Jun 27 15:04:52 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:04:52 2023 ] Eval epoch: 28
[ Tue Jun 27 15:04:53 2023 ] 	Mean test loss of 625 batches: 0.314995.
[ Tue Jun 27 15:04:53 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:53 2023 ] Training epoch: 29
[ Tue Jun 27 15:04:55 2023 ] 	Training loss: 0.4065.  Training acc: 96.88%.
[ Tue Jun 27 15:04:55 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:04:55 2023 ] Eval epoch: 29
[ Tue Jun 27 15:04:56 2023 ] 	Mean test loss of 625 batches: 0.320169.
[ Tue Jun 27 15:04:56 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:56 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:56 2023 ] Training epoch: 30
[ Tue Jun 27 15:04:58 2023 ] 	Training loss: 0.3990.  Training acc: 97.24%.
[ Tue Jun 27 15:04:58 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:04:58 2023 ] Eval epoch: 30
[ Tue Jun 27 15:04:59 2023 ] 	Mean test loss of 625 batches: 0.320092.
[ Tue Jun 27 15:04:59 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:59 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:59 2023 ] Training epoch: 31
[ Tue Jun 27 15:05:01 2023 ] 	Training loss: 0.3961.  Training acc: 97.15%.
[ Tue Jun 27 15:05:01 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:05:01 2023 ] Eval epoch: 31
[ Tue Jun 27 15:05:02 2023 ] 	Mean test loss of 625 batches: 0.312926.
[ Tue Jun 27 15:05:02 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:05:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:05:02 2023 ] Training epoch: 32
[ Tue Jun 27 15:05:04 2023 ] 	Training loss: 0.4106.  Training acc: 96.32%.
[ Tue Jun 27 15:05:04 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:05:04 2023 ] Eval epoch: 32
[ Tue Jun 27 15:05:04 2023 ] 	Mean test loss of 625 batches: 0.314542.
[ Tue Jun 27 15:05:04 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:05:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:05:04 2023 ] Training epoch: 33
[ Tue Jun 27 15:05:06 2023 ] 	Training loss: 0.3849.  Training acc: 97.70%.
[ Tue Jun 27 15:05:06 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:05:06 2023 ] Eval epoch: 33
[ Tue Jun 27 15:05:07 2023 ] 	Mean test loss of 625 batches: 0.316679.
[ Tue Jun 27 15:05:07 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:05:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:05:07 2023 ] Training epoch: 34
[ Tue Jun 27 15:05:09 2023 ] 	Training loss: 0.3951.  Training acc: 97.43%.
[ Tue Jun 27 15:05:09 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:05:09 2023 ] Eval epoch: 34
[ Tue Jun 27 15:05:10 2023 ] 	Mean test loss of 625 batches: 0.313255.
[ Tue Jun 27 15:05:10 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:05:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:05:10 2023 ] Training epoch: 35
[ Tue Jun 27 15:05:12 2023 ] 	Training loss: 0.3760.  Training acc: 98.44%.
[ Tue Jun 27 15:05:12 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:05:12 2023 ] Eval epoch: 35
[ Tue Jun 27 15:05:12 2023 ] 	Mean test loss of 625 batches: 0.315283.
[ Tue Jun 27 15:05:12 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:05:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:05:12 2023 ] Training epoch: 36
[ Tue Jun 27 15:05:14 2023 ] 	Training loss: 0.3838.  Training acc: 97.89%.
[ Tue Jun 27 15:05:14 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:05:14 2023 ] Eval epoch: 36
[ Tue Jun 27 15:05:15 2023 ] 	Mean test loss of 625 batches: 0.309317.
[ Tue Jun 27 15:05:15 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:05:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:05:15 2023 ] Training epoch: 37
[ Tue Jun 27 15:05:17 2023 ] 	Training loss: 0.3798.  Training acc: 98.07%.
[ Tue Jun 27 15:05:17 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:05:17 2023 ] Eval epoch: 37
[ Tue Jun 27 15:05:17 2023 ] 	Mean test loss of 625 batches: 0.310498.
[ Tue Jun 27 15:05:17 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:05:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:05:17 2023 ] Training epoch: 38
[ Tue Jun 27 15:05:19 2023 ] 	Training loss: 0.3810.  Training acc: 97.79%.
[ Tue Jun 27 15:05:19 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:05:19 2023 ] Eval epoch: 38
[ Tue Jun 27 15:05:20 2023 ] 	Mean test loss of 625 batches: 0.314434.
[ Tue Jun 27 15:05:20 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:05:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:05:20 2023 ] Training epoch: 39
[ Tue Jun 27 15:05:22 2023 ] 	Training loss: 0.3812.  Training acc: 98.07%.
[ Tue Jun 27 15:05:22 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:05:22 2023 ] Eval epoch: 39
[ Tue Jun 27 15:05:22 2023 ] 	Mean test loss of 625 batches: 0.311390.
[ Tue Jun 27 15:05:22 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:05:22 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:05:22 2023 ] Training epoch: 40
[ Tue Jun 27 15:05:24 2023 ] 	Training loss: 0.3939.  Training acc: 97.24%.
[ Tue Jun 27 15:05:24 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:05:24 2023 ] Eval epoch: 40
[ Tue Jun 27 15:05:25 2023 ] 	Mean test loss of 625 batches: 0.309214.
[ Tue Jun 27 15:05:25 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:05:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:05:26 2023 ] Best accuracy: 1.0
[ Tue Jun 27 15:05:26 2023 ] Epoch number: 11
[ Tue Jun 27 15:05:26 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 15:05:26 2023 ] Weight decay: 0.0005
[ Tue Jun 27 15:05:26 2023 ] Base LR: 0.1
[ Tue Jun 27 15:05:26 2023 ] Batch Size: 64
[ Tue Jun 27 15:05:26 2023 ] Test Batch Size: 64
[ Tue Jun 27 15:05:26 2023 ] seed: 1
[ Tue Jun 27 15:05:26 2023 ] Start training Corrector
[ Tue Jun 27 15:05:26 2023 ] Training epoch: 1
[ Tue Jun 27 15:08:32 2023 ] using warm up, epoch: 5
[ Tue Jun 27 15:08:32 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 15:08:32 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 15:08:32 2023 ] Start training Predictor
[ Tue Jun 27 15:08:32 2023 ] Training epoch: 1
[ Tue Jun 27 15:08:37 2023 ] 	Training loss: 104.2862.  Training acc: 34.19%.
[ Tue Jun 27 15:08:37 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Tue Jun 27 15:08:37 2023 ] Eval epoch: 1
[ Tue Jun 27 15:08:38 2023 ] 	Mean test loss of 625 batches: 70.369717.
[ Tue Jun 27 15:08:38 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:08:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:08:38 2023 ] Training epoch: 2
[ Tue Jun 27 15:08:40 2023 ] 	Training loss: 9.9553.  Training acc: 35.75%.
[ Tue Jun 27 15:08:40 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:08:40 2023 ] Eval epoch: 2
[ Tue Jun 27 15:08:40 2023 ] 	Mean test loss of 625 batches: 8.779923.
[ Tue Jun 27 15:08:40 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:08:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:08:40 2023 ] Training epoch: 3
[ Tue Jun 27 15:08:42 2023 ] 	Training loss: 6.5950.  Training acc: 43.93%.
[ Tue Jun 27 15:08:42 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:08:42 2023 ] Eval epoch: 3
[ Tue Jun 27 15:08:43 2023 ] 	Mean test loss of 625 batches: 9.054891.
[ Tue Jun 27 15:08:43 2023 ] 	Top1: 45.61%
[ Tue Jun 27 15:08:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:08:43 2023 ] Training epoch: 4
[ Tue Jun 27 15:08:45 2023 ] 	Training loss: 4.9052.  Training acc: 55.06%.
[ Tue Jun 27 15:08:45 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:08:45 2023 ] Eval epoch: 4
[ Tue Jun 27 15:08:46 2023 ] 	Mean test loss of 625 batches: 11.865361.
[ Tue Jun 27 15:08:46 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:08:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:08:46 2023 ] Training epoch: 5
[ Tue Jun 27 15:08:48 2023 ] 	Training loss: 3.8895.  Training acc: 57.26%.
[ Tue Jun 27 15:08:48 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:08:48 2023 ] Eval epoch: 5
[ Tue Jun 27 15:08:49 2023 ] 	Mean test loss of 625 batches: 15.067498.
[ Tue Jun 27 15:08:49 2023 ] 	Top1: 52.63%
[ Tue Jun 27 15:08:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:08:49 2023 ] Training epoch: 6
[ Tue Jun 27 15:08:51 2023 ] 	Training loss: 2.9516.  Training acc: 56.80%.
[ Tue Jun 27 15:08:51 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:08:51 2023 ] Eval epoch: 6
[ Tue Jun 27 15:08:51 2023 ] 	Mean test loss of 625 batches: 1.115534.
[ Tue Jun 27 15:08:51 2023 ] 	Top1: 73.68%
[ Tue Jun 27 15:08:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:08:51 2023 ] Training epoch: 7
[ Tue Jun 27 15:08:53 2023 ] 	Training loss: 2.6699.  Training acc: 55.15%.
[ Tue Jun 27 15:08:53 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:08:53 2023 ] Eval epoch: 7
[ Tue Jun 27 15:08:54 2023 ] 	Mean test loss of 625 batches: 0.927369.
[ Tue Jun 27 15:08:54 2023 ] 	Top1: 77.19%
[ Tue Jun 27 15:08:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:08:54 2023 ] Training epoch: 8
[ Tue Jun 27 15:08:56 2023 ] 	Training loss: 2.3092.  Training acc: 57.54%.
[ Tue Jun 27 15:08:56 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:08:56 2023 ] Eval epoch: 8
[ Tue Jun 27 15:08:57 2023 ] 	Mean test loss of 625 batches: 0.989930.
[ Tue Jun 27 15:08:57 2023 ] 	Top1: 77.19%
[ Tue Jun 27 15:08:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:08:57 2023 ] Training epoch: 9
[ Tue Jun 27 15:08:59 2023 ] 	Training loss: 3.6493.  Training acc: 44.94%.
[ Tue Jun 27 15:08:59 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Tue Jun 27 15:08:59 2023 ] Eval epoch: 9
[ Tue Jun 27 15:09:00 2023 ] 	Mean test loss of 625 batches: 57.519360.
[ Tue Jun 27 15:09:00 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:09:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:00 2023 ] Training epoch: 10
[ Tue Jun 27 15:09:02 2023 ] 	Training loss: 2.9546.  Training acc: 34.28%.
[ Tue Jun 27 15:09:02 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:09:02 2023 ] Eval epoch: 10
[ Tue Jun 27 15:09:02 2023 ] 	Mean test loss of 625 batches: 2.347344.
[ Tue Jun 27 15:09:02 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:09:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:02 2023 ] Training epoch: 11
[ Tue Jun 27 15:09:05 2023 ] 	Training loss: 2.2545.  Training acc: 33.00%.
[ Tue Jun 27 15:09:05 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:09:05 2023 ] Eval epoch: 11
[ Tue Jun 27 15:09:05 2023 ] 	Mean test loss of 625 batches: 1.218352.
[ Tue Jun 27 15:09:05 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:05 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:05 2023 ] Training epoch: 12
[ Tue Jun 27 15:09:08 2023 ] 	Training loss: 2.3143.  Training acc: 32.44%.
[ Tue Jun 27 15:09:08 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:09:08 2023 ] Eval epoch: 12
[ Tue Jun 27 15:09:08 2023 ] 	Mean test loss of 625 batches: 1.207495.
[ Tue Jun 27 15:09:08 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:08 2023 ] Training epoch: 13
[ Tue Jun 27 15:09:11 2023 ] 	Training loss: 2.0728.  Training acc: 34.93%.
[ Tue Jun 27 15:09:11 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:09:11 2023 ] Eval epoch: 13
[ Tue Jun 27 15:09:12 2023 ] 	Mean test loss of 625 batches: 1.137216.
[ Tue Jun 27 15:09:12 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:12 2023 ] Training epoch: 14
[ Tue Jun 27 15:09:15 2023 ] 	Training loss: 2.2113.  Training acc: 32.63%.
[ Tue Jun 27 15:09:15 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:09:15 2023 ] Eval epoch: 14
[ Tue Jun 27 15:09:16 2023 ] 	Mean test loss of 625 batches: 1.159471.
[ Tue Jun 27 15:09:16 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:16 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:16 2023 ] Training epoch: 15
[ Tue Jun 27 15:09:18 2023 ] 	Training loss: 2.0594.  Training acc: 34.65%.
[ Tue Jun 27 15:09:18 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:09:18 2023 ] Eval epoch: 15
[ Tue Jun 27 15:09:19 2023 ] 	Mean test loss of 625 batches: 1.152213.
[ Tue Jun 27 15:09:19 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:19 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:19 2023 ] Training epoch: 16
[ Tue Jun 27 15:09:22 2023 ] 	Training loss: 1.9792.  Training acc: 35.02%.
[ Tue Jun 27 15:09:22 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 15:09:22 2023 ] Eval epoch: 16
[ Tue Jun 27 15:09:23 2023 ] 	Mean test loss of 625 batches: 1.151928.
[ Tue Jun 27 15:09:23 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:23 2023 ] Training epoch: 17
[ Tue Jun 27 15:09:25 2023 ] 	Training loss: 2.0272.  Training acc: 33.36%.
[ Tue Jun 27 15:09:25 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:09:25 2023 ] Eval epoch: 17
[ Tue Jun 27 15:09:26 2023 ] 	Mean test loss of 625 batches: 1.136537.
[ Tue Jun 27 15:09:26 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:26 2023 ] Training epoch: 18
[ Tue Jun 27 15:09:29 2023 ] 	Training loss: 1.9073.  Training acc: 33.46%.
[ Tue Jun 27 15:09:29 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:09:29 2023 ] Eval epoch: 18
[ Tue Jun 27 15:09:30 2023 ] 	Mean test loss of 625 batches: 1.123071.
[ Tue Jun 27 15:09:30 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:30 2023 ] Training epoch: 19
[ Tue Jun 27 15:09:32 2023 ] 	Training loss: 1.8605.  Training acc: 33.82%.
[ Tue Jun 27 15:09:32 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Tue Jun 27 15:09:32 2023 ] Eval epoch: 19
[ Tue Jun 27 15:09:32 2023 ] 	Mean test loss of 625 batches: 1.160045.
[ Tue Jun 27 15:09:32 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:32 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:32 2023 ] Training epoch: 20
[ Tue Jun 27 15:09:35 2023 ] 	Training loss: 1.7721.  Training acc: 36.12%.
[ Tue Jun 27 15:09:35 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Tue Jun 27 15:09:35 2023 ] Eval epoch: 20
[ Tue Jun 27 15:09:35 2023 ] 	Mean test loss of 625 batches: 1.139926.
[ Tue Jun 27 15:09:35 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:35 2023 ] Training epoch: 21
[ Tue Jun 27 15:09:37 2023 ] 	Training loss: 1.7819.  Training acc: 33.55%.
[ Tue Jun 27 15:09:37 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:09:37 2023 ] Eval epoch: 21
[ Tue Jun 27 15:09:38 2023 ] 	Mean test loss of 625 batches: 1.136981.
[ Tue Jun 27 15:09:38 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:38 2023 ] Training epoch: 22
[ Tue Jun 27 15:09:40 2023 ] 	Training loss: 1.7226.  Training acc: 34.38%.
[ Tue Jun 27 15:09:40 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:09:40 2023 ] Eval epoch: 22
[ Tue Jun 27 15:09:41 2023 ] 	Mean test loss of 625 batches: 1.134218.
[ Tue Jun 27 15:09:41 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:41 2023 ] Training epoch: 23
[ Tue Jun 27 15:09:43 2023 ] 	Training loss: 1.6899.  Training acc: 36.95%.
[ Tue Jun 27 15:09:43 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:09:43 2023 ] Eval epoch: 23
[ Tue Jun 27 15:09:44 2023 ] 	Mean test loss of 625 batches: 1.129284.
[ Tue Jun 27 15:09:44 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:44 2023 ] Training epoch: 24
[ Tue Jun 27 15:09:46 2023 ] 	Training loss: 1.7181.  Training acc: 35.75%.
[ Tue Jun 27 15:09:46 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:09:46 2023 ] Eval epoch: 24
[ Tue Jun 27 15:09:46 2023 ] 	Mean test loss of 625 batches: 1.129944.
[ Tue Jun 27 15:09:46 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:46 2023 ] Training epoch: 25
[ Tue Jun 27 15:09:48 2023 ] 	Training loss: 1.7607.  Training acc: 32.26%.
[ Tue Jun 27 15:09:48 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:09:48 2023 ] Eval epoch: 25
[ Tue Jun 27 15:09:49 2023 ] 	Mean test loss of 625 batches: 1.135074.
[ Tue Jun 27 15:09:49 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:49 2023 ] Training epoch: 26
[ Tue Jun 27 15:09:51 2023 ] 	Training loss: 1.6904.  Training acc: 36.95%.
[ Tue Jun 27 15:09:51 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:09:51 2023 ] Eval epoch: 26
[ Tue Jun 27 15:09:52 2023 ] 	Mean test loss of 625 batches: 1.134562.
[ Tue Jun 27 15:09:52 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:52 2023 ] Training epoch: 27
[ Tue Jun 27 15:09:54 2023 ] 	Training loss: 1.7857.  Training acc: 31.34%.
[ Tue Jun 27 15:09:54 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:09:54 2023 ] Eval epoch: 27
[ Tue Jun 27 15:09:55 2023 ] 	Mean test loss of 625 batches: 1.132791.
[ Tue Jun 27 15:09:55 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:55 2023 ] Training epoch: 28
[ Tue Jun 27 15:09:57 2023 ] 	Training loss: 1.6927.  Training acc: 34.74%.
[ Tue Jun 27 15:09:57 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:09:57 2023 ] Eval epoch: 28
[ Tue Jun 27 15:09:57 2023 ] 	Mean test loss of 625 batches: 1.133904.
[ Tue Jun 27 15:09:57 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:57 2023 ] Training epoch: 29
[ Tue Jun 27 15:09:59 2023 ] 	Training loss: 1.7111.  Training acc: 36.12%.
[ Tue Jun 27 15:09:59 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:09:59 2023 ] Eval epoch: 29
[ Tue Jun 27 15:10:00 2023 ] 	Mean test loss of 625 batches: 1.132469.
[ Tue Jun 27 15:10:00 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:00 2023 ] Training epoch: 30
[ Tue Jun 27 15:10:02 2023 ] 	Training loss: 1.6752.  Training acc: 35.94%.
[ Tue Jun 27 15:10:02 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:10:02 2023 ] Eval epoch: 30
[ Tue Jun 27 15:10:03 2023 ] 	Mean test loss of 625 batches: 1.136230.
[ Tue Jun 27 15:10:03 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:03 2023 ] Training epoch: 31
[ Tue Jun 27 15:10:06 2023 ] 	Training loss: 1.7294.  Training acc: 33.82%.
[ Tue Jun 27 15:10:06 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:10:06 2023 ] Eval epoch: 31
[ Tue Jun 27 15:10:07 2023 ] 	Mean test loss of 625 batches: 1.134098.
[ Tue Jun 27 15:10:07 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:07 2023 ] Training epoch: 32
[ Tue Jun 27 15:10:09 2023 ] 	Training loss: 1.7269.  Training acc: 34.56%.
[ Tue Jun 27 15:10:09 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:10:09 2023 ] Eval epoch: 32
[ Tue Jun 27 15:10:10 2023 ] 	Mean test loss of 625 batches: 1.132363.
[ Tue Jun 27 15:10:10 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:10 2023 ] Training epoch: 33
[ Tue Jun 27 15:10:13 2023 ] 	Training loss: 1.6714.  Training acc: 35.39%.
[ Tue Jun 27 15:10:13 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:10:13 2023 ] Eval epoch: 33
[ Tue Jun 27 15:10:14 2023 ] 	Mean test loss of 625 batches: 1.130446.
[ Tue Jun 27 15:10:14 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:14 2023 ] Training epoch: 34
[ Tue Jun 27 15:10:17 2023 ] 	Training loss: 1.6693.  Training acc: 33.36%.
[ Tue Jun 27 15:10:17 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:10:17 2023 ] Eval epoch: 34
[ Tue Jun 27 15:10:17 2023 ] 	Mean test loss of 625 batches: 1.128301.
[ Tue Jun 27 15:10:17 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:17 2023 ] Training epoch: 35
[ Tue Jun 27 15:10:20 2023 ] 	Training loss: 1.6253.  Training acc: 35.57%.
[ Tue Jun 27 15:10:20 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:10:20 2023 ] Eval epoch: 35
[ Tue Jun 27 15:10:21 2023 ] 	Mean test loss of 625 batches: 1.124172.
[ Tue Jun 27 15:10:21 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:21 2023 ] Training epoch: 36
[ Tue Jun 27 15:10:24 2023 ] 	Training loss: 1.6644.  Training acc: 35.66%.
[ Tue Jun 27 15:10:24 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:10:24 2023 ] Eval epoch: 36
[ Tue Jun 27 15:10:25 2023 ] 	Mean test loss of 625 batches: 1.124259.
[ Tue Jun 27 15:10:25 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:25 2023 ] Training epoch: 37
[ Tue Jun 27 15:10:27 2023 ] 	Training loss: 1.7087.  Training acc: 34.01%.
[ Tue Jun 27 15:10:27 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:10:27 2023 ] Eval epoch: 37
[ Tue Jun 27 15:10:28 2023 ] 	Mean test loss of 625 batches: 1.123765.
[ Tue Jun 27 15:10:28 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:28 2023 ] Training epoch: 38
[ Tue Jun 27 15:10:30 2023 ] 	Training loss: 1.5971.  Training acc: 34.83%.
[ Tue Jun 27 15:10:30 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:10:30 2023 ] Eval epoch: 38
[ Tue Jun 27 15:10:31 2023 ] 	Mean test loss of 625 batches: 1.123465.
[ Tue Jun 27 15:10:31 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:31 2023 ] Training epoch: 39
[ Tue Jun 27 15:10:33 2023 ] 	Training loss: 1.6362.  Training acc: 34.93%.
[ Tue Jun 27 15:10:33 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:10:33 2023 ] Eval epoch: 39
[ Tue Jun 27 15:10:34 2023 ] 	Mean test loss of 625 batches: 1.126960.
[ Tue Jun 27 15:10:34 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:34 2023 ] Training epoch: 40
[ Tue Jun 27 15:10:36 2023 ] 	Training loss: 1.6996.  Training acc: 31.89%.
[ Tue Jun 27 15:10:36 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Tue Jun 27 15:10:36 2023 ] Eval epoch: 40
[ Tue Jun 27 15:10:36 2023 ] 	Mean test loss of 625 batches: 1.129099.
[ Tue Jun 27 15:10:36 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:37 2023 ] Best accuracy: 0.7719298245614035
[ Tue Jun 27 15:10:37 2023 ] Epoch number: 7
[ Tue Jun 27 15:10:37 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 15:10:37 2023 ] Weight decay: 0.0005
[ Tue Jun 27 15:10:37 2023 ] Base LR: 0.1
[ Tue Jun 27 15:10:37 2023 ] Batch Size: 64
[ Tue Jun 27 15:10:37 2023 ] Test Batch Size: 64
[ Tue Jun 27 15:10:37 2023 ] seed: 1
[ Tue Jun 27 15:10:37 2023 ] Start training Corrector
[ Tue Jun 27 15:10:37 2023 ] Training epoch: 1
[ Tue Jun 27 15:10:44 2023 ] 	Training loss: 124.4016.  Training acc: 32.94%.
[ Tue Jun 27 15:10:44 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:10:44 2023 ] Training epoch: 2
[ Tue Jun 27 15:10:50 2023 ] 	Training loss: 86.4469.  Training acc: 42.06%.
[ Tue Jun 27 15:10:50 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:10:50 2023 ] Training epoch: 3
[ Tue Jun 27 15:10:55 2023 ] 	Training loss: 63.9722.  Training acc: 51.56%.
[ Tue Jun 27 15:10:55 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 15:10:55 2023 ] Training epoch: 4
[ Tue Jun 27 15:11:01 2023 ] 	Training loss: 58.0092.  Training acc: 39.45%.
[ Tue Jun 27 15:11:01 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Jun 27 15:11:01 2023 ] Training epoch: 5
[ Tue Jun 27 15:11:08 2023 ] 	Training loss: 56.2890.  Training acc: 44.40%.
[ Tue Jun 27 15:11:08 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:11:08 2023 ] Training epoch: 6
[ Tue Jun 27 15:11:15 2023 ] 	Training loss: 53.5703.  Training acc: 52.73%.
[ Tue Jun 27 15:11:15 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:11:15 2023 ] Training epoch: 7
[ Tue Jun 27 15:11:22 2023 ] 	Training loss: 54.5260.  Training acc: 49.22%.
[ Tue Jun 27 15:11:22 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:11:22 2023 ] Training epoch: 8
[ Tue Jun 27 15:11:28 2023 ] 	Training loss: 51.0517.  Training acc: 48.44%.
[ Tue Jun 27 15:11:28 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:11:28 2023 ] Training epoch: 9
[ Tue Jun 27 15:11:33 2023 ] 	Training loss: 52.9666.  Training acc: 50.39%.
[ Tue Jun 27 15:11:33 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 15:11:33 2023 ] Training epoch: 10
[ Tue Jun 27 15:11:38 2023 ] 	Training loss: 52.8262.  Training acc: 49.61%.
[ Tue Jun 27 15:11:38 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:11:38 2023 ] Training epoch: 11
[ Tue Jun 27 15:11:43 2023 ] 	Training loss: 51.9915.  Training acc: 36.98%.
[ Tue Jun 27 15:11:43 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 15:11:43 2023 ] Training epoch: 12
[ Tue Jun 27 15:11:48 2023 ] 	Training loss: 49.0147.  Training acc: 56.64%.
[ Tue Jun 27 15:11:48 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 15:11:48 2023 ] Training epoch: 13
[ Tue Jun 27 15:11:54 2023 ] 	Training loss: 49.3071.  Training acc: 59.64%.
[ Tue Jun 27 15:11:54 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 15:11:54 2023 ] Training epoch: 14
[ Tue Jun 27 15:11:59 2023 ] 	Training loss: 48.7788.  Training acc: 56.38%.
[ Tue Jun 27 15:11:59 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:11:59 2023 ] Training epoch: 15
[ Tue Jun 27 15:12:06 2023 ] 	Training loss: 46.7476.  Training acc: 63.15%.
[ Tue Jun 27 15:12:06 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:12:06 2023 ] Training epoch: 16
[ Tue Jun 27 15:12:12 2023 ] 	Training loss: 47.4036.  Training acc: 59.51%.
[ Tue Jun 27 15:12:12 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:12:12 2023 ] Training epoch: 17
[ Tue Jun 27 15:12:18 2023 ] 	Training loss: 46.4517.  Training acc: 64.45%.
[ Tue Jun 27 15:12:18 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:12:18 2023 ] Training epoch: 18
[ Tue Jun 27 15:12:25 2023 ] 	Training loss: 46.0780.  Training acc: 62.63%.
[ Tue Jun 27 15:12:25 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:12:25 2023 ] Training epoch: 19
[ Tue Jun 27 15:12:56 2023 ] using warm up, epoch: 5
[ Tue Jun 27 15:12:56 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 15:12:56 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 15:12:56 2023 ] Start training Predictor
[ Tue Jun 27 15:12:56 2023 ] Training epoch: 1
[ Tue Jun 27 15:13:01 2023 ] 	Training loss: 103.0748.  Training acc: 36.21%.
[ Tue Jun 27 15:13:01 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Jun 27 15:13:01 2023 ] Eval epoch: 1
[ Tue Jun 27 15:13:02 2023 ] 	Mean test loss of 625 batches: 1148.833923.
[ Tue Jun 27 15:13:02 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:13:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:02 2023 ] Training epoch: 2
[ Tue Jun 27 15:13:05 2023 ] 	Training loss: 9.6802.  Training acc: 37.59%.
[ Tue Jun 27 15:13:05 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:13:05 2023 ] Eval epoch: 2
[ Tue Jun 27 15:13:06 2023 ] 	Mean test loss of 625 batches: 48.653276.
[ Tue Jun 27 15:13:06 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:13:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:06 2023 ] Training epoch: 3
[ Tue Jun 27 15:13:09 2023 ] 	Training loss: 6.1398.  Training acc: 51.56%.
[ Tue Jun 27 15:13:09 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:13:09 2023 ] Eval epoch: 3
[ Tue Jun 27 15:13:10 2023 ] 	Mean test loss of 625 batches: 9.607471.
[ Tue Jun 27 15:13:10 2023 ] 	Top1: 19.30%
[ Tue Jun 27 15:13:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:10 2023 ] Training epoch: 4
[ Tue Jun 27 15:13:12 2023 ] 	Training loss: 4.3829.  Training acc: 58.18%.
[ Tue Jun 27 15:13:12 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Tue Jun 27 15:13:12 2023 ] Eval epoch: 4
[ Tue Jun 27 15:13:13 2023 ] 	Mean test loss of 625 batches: 22.035081.
[ Tue Jun 27 15:13:13 2023 ] 	Top1: 33.33%
[ Tue Jun 27 15:13:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:13 2023 ] Training epoch: 5
[ Tue Jun 27 15:13:16 2023 ] 	Training loss: 4.9316.  Training acc: 48.25%.
[ Tue Jun 27 15:13:16 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:13:16 2023 ] Eval epoch: 5
[ Tue Jun 27 15:13:16 2023 ] 	Mean test loss of 625 batches: 2.751602.
[ Tue Jun 27 15:13:16 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:13:16 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:16 2023 ] Training epoch: 6
[ Tue Jun 27 15:13:19 2023 ] 	Training loss: 4.6254.  Training acc: 50.28%.
[ Tue Jun 27 15:13:19 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:13:19 2023 ] Eval epoch: 6
[ Tue Jun 27 15:13:20 2023 ] 	Mean test loss of 625 batches: 1.381796.
[ Tue Jun 27 15:13:20 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:13:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:20 2023 ] Training epoch: 7
[ Tue Jun 27 15:13:23 2023 ] 	Training loss: 3.6768.  Training acc: 47.52%.
[ Tue Jun 27 15:13:23 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:13:23 2023 ] Eval epoch: 7
[ Tue Jun 27 15:13:24 2023 ] 	Mean test loss of 625 batches: 1.767275.
[ Tue Jun 27 15:13:24 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:13:24 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:24 2023 ] Training epoch: 8
[ Tue Jun 27 15:13:27 2023 ] 	Training loss: 2.9285.  Training acc: 38.60%.
[ Tue Jun 27 15:13:27 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:13:27 2023 ] Eval epoch: 8
[ Tue Jun 27 15:13:28 2023 ] 	Mean test loss of 625 batches: 2.238181.
[ Tue Jun 27 15:13:28 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:13:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:28 2023 ] Training epoch: 9
[ Tue Jun 27 15:13:30 2023 ] 	Training loss: 1.7661.  Training acc: 51.56%.
[ Tue Jun 27 15:13:30 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:13:30 2023 ] Eval epoch: 9
[ Tue Jun 27 15:13:31 2023 ] 	Mean test loss of 625 batches: 0.866523.
[ Tue Jun 27 15:13:31 2023 ] 	Top1: 70.18%
[ Tue Jun 27 15:13:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:31 2023 ] Training epoch: 10
[ Tue Jun 27 15:13:34 2023 ] 	Training loss: 1.7384.  Training acc: 53.22%.
[ Tue Jun 27 15:13:34 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:13:34 2023 ] Eval epoch: 10
[ Tue Jun 27 15:13:35 2023 ] 	Mean test loss of 625 batches: 1.700892.
[ Tue Jun 27 15:13:35 2023 ] 	Top1: 68.42%
[ Tue Jun 27 15:13:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:35 2023 ] Training epoch: 11
[ Tue Jun 27 15:13:38 2023 ] 	Training loss: 1.2889.  Training acc: 59.56%.
[ Tue Jun 27 15:13:38 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:13:38 2023 ] Eval epoch: 11
[ Tue Jun 27 15:13:39 2023 ] 	Mean test loss of 625 batches: 0.923863.
[ Tue Jun 27 15:13:39 2023 ] 	Top1: 68.42%
[ Tue Jun 27 15:13:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:39 2023 ] Training epoch: 12
[ Tue Jun 27 15:13:42 2023 ] 	Training loss: 1.1535.  Training acc: 59.01%.
[ Tue Jun 27 15:13:42 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:13:42 2023 ] Eval epoch: 12
[ Tue Jun 27 15:13:42 2023 ] 	Mean test loss of 625 batches: 0.698113.
[ Tue Jun 27 15:13:42 2023 ] 	Top1: 70.18%
[ Tue Jun 27 15:13:42 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:42 2023 ] Training epoch: 13
[ Tue Jun 27 15:13:45 2023 ] 	Training loss: 1.0174.  Training acc: 62.78%.
[ Tue Jun 27 15:13:45 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:13:45 2023 ] Eval epoch: 13
[ Tue Jun 27 15:13:46 2023 ] 	Mean test loss of 625 batches: 0.770374.
[ Tue Jun 27 15:13:46 2023 ] 	Top1: 68.42%
[ Tue Jun 27 15:13:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:46 2023 ] Training epoch: 14
[ Tue Jun 27 15:13:48 2023 ] 	Training loss: 0.9674.  Training acc: 63.79%.
[ Tue Jun 27 15:13:48 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:13:48 2023 ] Eval epoch: 14
[ Tue Jun 27 15:13:49 2023 ] 	Mean test loss of 625 batches: 0.690815.
[ Tue Jun 27 15:13:49 2023 ] 	Top1: 71.93%
[ Tue Jun 27 15:13:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:49 2023 ] Training epoch: 15
[ Tue Jun 27 15:13:51 2023 ] 	Training loss: 1.0047.  Training acc: 61.58%.
[ Tue Jun 27 15:13:51 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:13:51 2023 ] Eval epoch: 15
[ Tue Jun 27 15:13:52 2023 ] 	Mean test loss of 625 batches: 0.674246.
[ Tue Jun 27 15:13:52 2023 ] 	Top1: 75.44%
[ Tue Jun 27 15:13:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:52 2023 ] Training epoch: 16
[ Tue Jun 27 15:13:54 2023 ] 	Training loss: 0.9134.  Training acc: 65.99%.
[ Tue Jun 27 15:13:54 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 15:13:54 2023 ] Eval epoch: 16
[ Tue Jun 27 15:13:55 2023 ] 	Mean test loss of 625 batches: 0.660867.
[ Tue Jun 27 15:13:55 2023 ] 	Top1: 78.95%
[ Tue Jun 27 15:13:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:55 2023 ] Training epoch: 17
[ Tue Jun 27 15:13:57 2023 ] 	Training loss: 0.8815.  Training acc: 69.21%.
[ Tue Jun 27 15:13:57 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 15:13:57 2023 ] Eval epoch: 17
[ Tue Jun 27 15:13:58 2023 ] 	Mean test loss of 625 batches: 0.574561.
[ Tue Jun 27 15:13:58 2023 ] 	Top1: 89.47%
[ Tue Jun 27 15:13:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:58 2023 ] Training epoch: 18
[ Tue Jun 27 15:14:00 2023 ] 	Training loss: 0.8905.  Training acc: 67.00%.
[ Tue Jun 27 15:14:00 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:14:00 2023 ] Eval epoch: 18
[ Tue Jun 27 15:14:01 2023 ] 	Mean test loss of 625 batches: 0.587571.
[ Tue Jun 27 15:14:01 2023 ] 	Top1: 85.96%
[ Tue Jun 27 15:14:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:01 2023 ] Training epoch: 19
[ Tue Jun 27 15:14:03 2023 ] 	Training loss: 0.8473.  Training acc: 69.85%.
[ Tue Jun 27 15:14:03 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:14:03 2023 ] Eval epoch: 19
[ Tue Jun 27 15:14:04 2023 ] 	Mean test loss of 625 batches: 0.613954.
[ Tue Jun 27 15:14:04 2023 ] 	Top1: 85.96%
[ Tue Jun 27 15:14:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:04 2023 ] Training epoch: 20
[ Tue Jun 27 15:14:06 2023 ] 	Training loss: 0.8107.  Training acc: 70.04%.
[ Tue Jun 27 15:14:06 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:14:06 2023 ] Eval epoch: 20
[ Tue Jun 27 15:14:06 2023 ] 	Mean test loss of 625 batches: 0.569123.
[ Tue Jun 27 15:14:06 2023 ] 	Top1: 87.72%
[ Tue Jun 27 15:14:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:06 2023 ] Training epoch: 21
[ Tue Jun 27 15:14:08 2023 ] 	Training loss: 0.7981.  Training acc: 72.61%.
[ Tue Jun 27 15:14:08 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:14:08 2023 ] Eval epoch: 21
[ Tue Jun 27 15:14:09 2023 ] 	Mean test loss of 625 batches: 0.536396.
[ Tue Jun 27 15:14:09 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:14:09 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:09 2023 ] Training epoch: 22
[ Tue Jun 27 15:14:11 2023 ] 	Training loss: 0.7550.  Training acc: 73.44%.
[ Tue Jun 27 15:14:11 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:14:11 2023 ] Eval epoch: 22
[ Tue Jun 27 15:14:12 2023 ] 	Mean test loss of 625 batches: 0.553908.
[ Tue Jun 27 15:14:12 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:14:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:12 2023 ] Training epoch: 23
[ Tue Jun 27 15:14:14 2023 ] 	Training loss: 0.7536.  Training acc: 74.54%.
[ Tue Jun 27 15:14:14 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:14:14 2023 ] Eval epoch: 23
[ Tue Jun 27 15:14:15 2023 ] 	Mean test loss of 625 batches: 0.567013.
[ Tue Jun 27 15:14:15 2023 ] 	Top1: 84.21%
[ Tue Jun 27 15:14:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:15 2023 ] Training epoch: 24
[ Tue Jun 27 15:14:17 2023 ] 	Training loss: 0.7728.  Training acc: 72.89%.
[ Tue Jun 27 15:14:17 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:14:17 2023 ] Eval epoch: 24
[ Tue Jun 27 15:14:18 2023 ] 	Mean test loss of 625 batches: 0.540340.
[ Tue Jun 27 15:14:18 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:14:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:18 2023 ] Training epoch: 25
[ Tue Jun 27 15:14:21 2023 ] 	Training loss: 0.7808.  Training acc: 72.70%.
[ Tue Jun 27 15:14:21 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:14:21 2023 ] Eval epoch: 25
[ Tue Jun 27 15:14:21 2023 ] 	Mean test loss of 625 batches: 0.552455.
[ Tue Jun 27 15:14:21 2023 ] 	Top1: 85.96%
[ Tue Jun 27 15:14:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:21 2023 ] Training epoch: 26
[ Tue Jun 27 15:14:24 2023 ] 	Training loss: 0.7238.  Training acc: 74.72%.
[ Tue Jun 27 15:14:24 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:14:24 2023 ] Eval epoch: 26
[ Tue Jun 27 15:14:25 2023 ] 	Mean test loss of 625 batches: 0.534233.
[ Tue Jun 27 15:14:25 2023 ] 	Top1: 92.98%
[ Tue Jun 27 15:14:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:25 2023 ] Training epoch: 27
[ Tue Jun 27 15:14:28 2023 ] 	Training loss: 0.7542.  Training acc: 71.88%.
[ Tue Jun 27 15:14:28 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:14:28 2023 ] Eval epoch: 27
[ Tue Jun 27 15:14:29 2023 ] 	Mean test loss of 625 batches: 0.554869.
[ Tue Jun 27 15:14:29 2023 ] 	Top1: 87.72%
[ Tue Jun 27 15:14:29 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:29 2023 ] Training epoch: 28
[ Tue Jun 27 15:14:32 2023 ] 	Training loss: 0.7386.  Training acc: 74.26%.
[ Tue Jun 27 15:14:32 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:14:32 2023 ] Eval epoch: 28
[ Tue Jun 27 15:14:33 2023 ] 	Mean test loss of 625 batches: 0.559548.
[ Tue Jun 27 15:14:33 2023 ] 	Top1: 85.96%
[ Tue Jun 27 15:14:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:33 2023 ] Training epoch: 29
[ Tue Jun 27 15:14:36 2023 ] 	Training loss: 0.7314.  Training acc: 74.36%.
[ Tue Jun 27 15:14:36 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:14:36 2023 ] Eval epoch: 29
[ Tue Jun 27 15:14:36 2023 ] 	Mean test loss of 625 batches: 0.543395.
[ Tue Jun 27 15:14:36 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:14:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:36 2023 ] Training epoch: 30
[ Tue Jun 27 15:14:39 2023 ] 	Training loss: 0.7164.  Training acc: 77.67%.
[ Tue Jun 27 15:14:39 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:14:39 2023 ] Eval epoch: 30
[ Tue Jun 27 15:14:40 2023 ] 	Mean test loss of 625 batches: 0.559303.
[ Tue Jun 27 15:14:40 2023 ] 	Top1: 89.47%
[ Tue Jun 27 15:14:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:40 2023 ] Training epoch: 31
[ Tue Jun 27 15:14:43 2023 ] 	Training loss: 0.7466.  Training acc: 74.17%.
[ Tue Jun 27 15:14:43 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:14:43 2023 ] Eval epoch: 31
[ Tue Jun 27 15:14:44 2023 ] 	Mean test loss of 625 batches: 0.551350.
[ Tue Jun 27 15:14:44 2023 ] 	Top1: 89.47%
[ Tue Jun 27 15:14:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:44 2023 ] Training epoch: 32
[ Tue Jun 27 15:14:47 2023 ] 	Training loss: 0.7259.  Training acc: 74.26%.
[ Tue Jun 27 15:14:47 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:14:47 2023 ] Eval epoch: 32
[ Tue Jun 27 15:14:48 2023 ] 	Mean test loss of 625 batches: 0.550281.
[ Tue Jun 27 15:14:48 2023 ] 	Top1: 89.47%
[ Tue Jun 27 15:14:48 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:48 2023 ] Training epoch: 33
[ Tue Jun 27 15:14:51 2023 ] 	Training loss: 0.7169.  Training acc: 76.75%.
[ Tue Jun 27 15:14:51 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:14:51 2023 ] Eval epoch: 33
[ Tue Jun 27 15:14:51 2023 ] 	Mean test loss of 625 batches: 0.539390.
[ Tue Jun 27 15:14:51 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:14:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:51 2023 ] Training epoch: 34
[ Tue Jun 27 15:14:54 2023 ] 	Training loss: 0.7380.  Training acc: 75.28%.
[ Tue Jun 27 15:14:54 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:14:54 2023 ] Eval epoch: 34
[ Tue Jun 27 15:14:54 2023 ] 	Mean test loss of 625 batches: 0.551896.
[ Tue Jun 27 15:14:54 2023 ] 	Top1: 89.47%
[ Tue Jun 27 15:14:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:54 2023 ] Training epoch: 35
[ Tue Jun 27 15:14:56 2023 ] 	Training loss: 0.7119.  Training acc: 76.01%.
[ Tue Jun 27 15:14:56 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:14:56 2023 ] Eval epoch: 35
[ Tue Jun 27 15:14:57 2023 ] 	Mean test loss of 625 batches: 0.543765.
[ Tue Jun 27 15:14:57 2023 ] 	Top1: 92.98%
[ Tue Jun 27 15:14:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:57 2023 ] Training epoch: 36
[ Tue Jun 27 15:14:59 2023 ] 	Training loss: 0.7077.  Training acc: 77.11%.
[ Tue Jun 27 15:14:59 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:14:59 2023 ] Eval epoch: 36
[ Tue Jun 27 15:15:00 2023 ] 	Mean test loss of 625 batches: 0.547961.
[ Tue Jun 27 15:15:00 2023 ] 	Top1: 85.96%
[ Tue Jun 27 15:15:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:15:00 2023 ] Training epoch: 37
[ Tue Jun 27 15:15:02 2023 ] 	Training loss: 0.7028.  Training acc: 77.39%.
[ Tue Jun 27 15:15:02 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:15:02 2023 ] Eval epoch: 37
[ Tue Jun 27 15:15:03 2023 ] 	Mean test loss of 625 batches: 0.522652.
[ Tue Jun 27 15:15:03 2023 ] 	Top1: 92.98%
[ Tue Jun 27 15:15:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:15:03 2023 ] Training epoch: 38
[ Tue Jun 27 15:15:05 2023 ] 	Training loss: 0.6991.  Training acc: 76.75%.
[ Tue Jun 27 15:15:05 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 15:15:05 2023 ] Eval epoch: 38
[ Tue Jun 27 15:15:06 2023 ] 	Mean test loss of 625 batches: 0.531079.
[ Tue Jun 27 15:15:06 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:15:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:15:06 2023 ] Training epoch: 39
[ Tue Jun 27 15:15:08 2023 ] 	Training loss: 0.6963.  Training acc: 78.77%.
[ Tue Jun 27 15:15:08 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:15:08 2023 ] Eval epoch: 39
[ Tue Jun 27 15:15:08 2023 ] 	Mean test loss of 625 batches: 0.535514.
[ Tue Jun 27 15:15:08 2023 ] 	Top1: 92.98%
[ Tue Jun 27 15:15:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:15:08 2023 ] Training epoch: 40
[ Tue Jun 27 15:15:10 2023 ] 	Training loss: 0.7193.  Training acc: 75.09%.
[ Tue Jun 27 15:15:10 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:15:11 2023 ] Eval epoch: 40
[ Tue Jun 27 15:15:11 2023 ] 	Mean test loss of 625 batches: 0.539162.
[ Tue Jun 27 15:15:11 2023 ] 	Top1: 89.47%
[ Tue Jun 27 15:15:11 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:15:12 2023 ] Best accuracy: 0.9473684210526315
[ Tue Jun 27 15:15:12 2023 ] Epoch number: 24
[ Tue Jun 27 15:15:12 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 15:15:12 2023 ] Weight decay: 0.0005
[ Tue Jun 27 15:15:12 2023 ] Base LR: 0.1
[ Tue Jun 27 15:15:12 2023 ] Batch Size: 64
[ Tue Jun 27 15:15:12 2023 ] Test Batch Size: 64
[ Tue Jun 27 15:15:12 2023 ] seed: 1
[ Tue Jun 27 15:15:12 2023 ] Start training Corrector
[ Tue Jun 27 15:15:12 2023 ] Training epoch: 1
[ Tue Jun 27 15:15:19 2023 ] 	Training loss: 129.7937.  Training acc: 32.42%.
[ Tue Jun 27 15:15:19 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Jun 27 15:15:19 2023 ] Training epoch: 2
[ Tue Jun 27 15:15:25 2023 ] 	Training loss: 84.6928.  Training acc: 36.07%.
[ Tue Jun 27 15:15:25 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Jun 27 15:15:25 2023 ] Training epoch: 3
[ Tue Jun 27 15:15:32 2023 ] 	Training loss: 67.1394.  Training acc: 28.52%.
[ Tue Jun 27 15:15:32 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Jun 27 15:15:32 2023 ] Training epoch: 4
[ Tue Jun 27 15:15:39 2023 ] 	Training loss: 60.2131.  Training acc: 42.45%.
[ Tue Jun 27 15:15:39 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:15:39 2023 ] Training epoch: 5
[ Tue Jun 27 15:15:46 2023 ] 	Training loss: 59.0163.  Training acc: 36.33%.
[ Tue Jun 27 15:15:46 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:15:46 2023 ] Training epoch: 6
[ Tue Jun 27 15:15:53 2023 ] 	Training loss: 56.1320.  Training acc: 30.34%.
[ Tue Jun 27 15:15:53 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:15:53 2023 ] Training epoch: 7
[ Tue Jun 27 15:16:00 2023 ] 	Training loss: 56.8200.  Training acc: 19.01%.
[ Tue Jun 27 15:16:00 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:16:00 2023 ] Training epoch: 8
[ Tue Jun 27 15:16:05 2023 ] 	Training loss: 55.7411.  Training acc: 31.90%.
[ Tue Jun 27 15:16:05 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:16:05 2023 ] Training epoch: 9
[ Tue Jun 27 15:16:11 2023 ] 	Training loss: 57.1954.  Training acc: 42.84%.
[ Tue Jun 27 15:16:11 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:16:11 2023 ] Training epoch: 10
[ Tue Jun 27 15:16:16 2023 ] 	Training loss: 56.0800.  Training acc: 45.18%.
[ Tue Jun 27 15:16:16 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:16:16 2023 ] Training epoch: 11
[ Tue Jun 27 15:16:22 2023 ] 	Training loss: 54.8658.  Training acc: 57.55%.
[ Tue Jun 27 15:16:22 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:16:22 2023 ] Training epoch: 12
[ Tue Jun 27 15:16:27 2023 ] 	Training loss: 53.5898.  Training acc: 48.57%.
[ Tue Jun 27 15:16:27 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:16:27 2023 ] Training epoch: 13
[ Tue Jun 27 15:16:33 2023 ] 	Training loss: 55.5135.  Training acc: 68.62%.
[ Tue Jun 27 15:16:33 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:16:33 2023 ] Training epoch: 14
[ Tue Jun 27 15:16:40 2023 ] 	Training loss: 55.3298.  Training acc: 67.45%.
[ Tue Jun 27 15:16:40 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:16:40 2023 ] Training epoch: 15
[ Tue Jun 27 15:16:47 2023 ] 	Training loss: 53.8884.  Training acc: 77.73%.
[ Tue Jun 27 15:16:47 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Tue Jun 27 15:16:47 2023 ] Training epoch: 16
[ Tue Jun 27 15:16:54 2023 ] 	Training loss: 53.9961.  Training acc: 71.74%.
[ Tue Jun 27 15:16:54 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:16:54 2023 ] Training epoch: 17
[ Tue Jun 27 15:17:01 2023 ] 	Training loss: 53.6215.  Training acc: 81.77%.
[ Tue Jun 27 15:17:01 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:17:01 2023 ] Training epoch: 18
[ Tue Jun 27 15:17:08 2023 ] 	Training loss: 53.6273.  Training acc: 77.08%.
[ Tue Jun 27 15:17:08 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:17:08 2023 ] Training epoch: 19
[ Tue Jun 27 15:17:14 2023 ] 	Training loss: 53.1239.  Training acc: 77.47%.
[ Tue Jun 27 15:17:14 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:17:14 2023 ] Training epoch: 20
[ Tue Jun 27 15:17:19 2023 ] 	Training loss: 54.2766.  Training acc: 76.56%.
[ Tue Jun 27 15:17:19 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:17:19 2023 ] Training epoch: 21
[ Tue Jun 27 15:17:25 2023 ] 	Training loss: 54.4711.  Training acc: 60.55%.
[ Tue Jun 27 15:17:25 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:17:25 2023 ] Training epoch: 22
[ Tue Jun 27 15:17:30 2023 ] 	Training loss: 52.7851.  Training acc: 69.01%.
[ Tue Jun 27 15:17:30 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:17:30 2023 ] Training epoch: 23
[ Tue Jun 27 15:17:36 2023 ] 	Training loss: 54.2233.  Training acc: 79.69%.
[ Tue Jun 27 15:17:36 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:17:36 2023 ] Training epoch: 24
[ Tue Jun 27 15:17:42 2023 ] 	Training loss: 53.5500.  Training acc: 80.34%.
[ Tue Jun 27 15:17:42 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:17:42 2023 ] Training epoch: 25
[ Tue Jun 27 15:17:48 2023 ] 	Training loss: 54.0342.  Training acc: 79.69%.
[ Tue Jun 27 15:17:48 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:17:48 2023 ] Training epoch: 26
[ Tue Jun 27 15:17:55 2023 ] 	Training loss: 54.2332.  Training acc: 81.90%.
[ Tue Jun 27 15:17:55 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:17:55 2023 ] Training epoch: 27
[ Tue Jun 27 15:18:03 2023 ] 	Training loss: 54.6733.  Training acc: 77.34%.
[ Tue Jun 27 15:18:03 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Tue Jun 27 15:18:03 2023 ] Training epoch: 28
[ Tue Jun 27 15:18:10 2023 ] 	Training loss: 55.1602.  Training acc: 79.69%.
[ Tue Jun 27 15:18:10 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:18:10 2023 ] Training epoch: 29
[ Tue Jun 27 15:18:17 2023 ] 	Training loss: 52.2903.  Training acc: 75.65%.
[ Tue Jun 27 15:18:17 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:18:17 2023 ] Training epoch: 30
[ Tue Jun 27 15:18:24 2023 ] 	Training loss: 54.7136.  Training acc: 75.26%.
[ Tue Jun 27 15:18:24 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:18:24 2023 ] Training epoch: 31
[ Tue Jun 27 15:18:30 2023 ] 	Training loss: 53.0973.  Training acc: 73.44%.
[ Tue Jun 27 15:18:30 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 15:18:30 2023 ] Training epoch: 32
[ Tue Jun 27 15:18:36 2023 ] 	Training loss: 54.3226.  Training acc: 77.99%.
[ Tue Jun 27 15:18:36 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:18:36 2023 ] Training epoch: 33
[ Tue Jun 27 15:18:41 2023 ] 	Training loss: 52.8338.  Training acc: 79.43%.
[ Tue Jun 27 15:18:41 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 15:18:41 2023 ] Training epoch: 34
[ Tue Jun 27 15:18:47 2023 ] 	Training loss: 53.6329.  Training acc: 74.87%.
[ Tue Jun 27 15:18:47 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:18:47 2023 ] Training epoch: 35
[ Tue Jun 27 15:18:52 2023 ] 	Training loss: 53.7301.  Training acc: 73.83%.
[ Tue Jun 27 15:18:52 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:18:52 2023 ] Training epoch: 36
[ Tue Jun 27 15:18:58 2023 ] 	Training loss: 52.5682.  Training acc: 73.44%.
[ Tue Jun 27 15:18:58 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 15:18:58 2023 ] Training epoch: 37
[ Tue Jun 27 15:19:04 2023 ] 	Training loss: 53.9435.  Training acc: 71.88%.
[ Tue Jun 27 15:19:04 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:19:04 2023 ] Training epoch: 38
[ Tue Jun 27 15:19:12 2023 ] 	Training loss: 54.5104.  Training acc: 69.92%.
[ Tue Jun 27 15:19:12 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:19:12 2023 ] Training epoch: 39
[ Tue Jun 27 15:19:18 2023 ] 	Training loss: 54.0940.  Training acc: 71.09%.
[ Tue Jun 27 15:19:18 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:19:18 2023 ] Training epoch: 40
[ Tue Jun 27 15:19:25 2023 ] 	Training loss: 52.6959.  Training acc: 70.83%.
[ Tue Jun 27 15:19:25 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:27:36 2023 ] using warm up, epoch: 5
[ Tue Jun 27 15:27:36 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 15:27:36 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 15:27:36 2023 ] Start training Predictor
[ Tue Jun 27 15:27:36 2023 ] Training epoch: 1
[ Tue Jun 27 15:27:42 2023 ] 	Training loss: 109.1553.  Training acc: 35.48%.
[ Tue Jun 27 15:27:42 2023 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue Jun 27 15:27:42 2023 ] Eval epoch: 1
[ Tue Jun 27 15:27:43 2023 ] 	Mean test loss of 625 batches: 194.740533.
[ Tue Jun 27 15:27:43 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:27:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:27:43 2023 ] Training epoch: 2
[ Tue Jun 27 15:27:46 2023 ] 	Training loss: 9.6539.  Training acc: 34.10%.
[ Tue Jun 27 15:27:46 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:27:46 2023 ] Eval epoch: 2
[ Tue Jun 27 15:27:46 2023 ] 	Mean test loss of 625 batches: 1.420038.
[ Tue Jun 27 15:27:46 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:27:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:27:46 2023 ] Training epoch: 3
[ Tue Jun 27 15:27:48 2023 ] 	Training loss: 6.1528.  Training acc: 42.00%.
[ Tue Jun 27 15:27:48 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:27:48 2023 ] Eval epoch: 3
[ Tue Jun 27 15:27:49 2023 ] 	Mean test loss of 625 batches: 4.427734.
[ Tue Jun 27 15:27:49 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:27:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:27:49 2023 ] Training epoch: 4
[ Tue Jun 27 15:27:51 2023 ] 	Training loss: 4.9340.  Training acc: 47.15%.
[ Tue Jun 27 15:27:51 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:27:51 2023 ] Eval epoch: 4
[ Tue Jun 27 15:27:52 2023 ] 	Mean test loss of 625 batches: 5.770910.
[ Tue Jun 27 15:27:52 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:27:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:27:52 2023 ] Training epoch: 5
[ Tue Jun 27 15:27:54 2023 ] 	Training loss: 4.3639.  Training acc: 48.99%.
[ Tue Jun 27 15:27:54 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:27:54 2023 ] Eval epoch: 5
[ Tue Jun 27 15:27:54 2023 ] 	Mean test loss of 625 batches: 4.311692.
[ Tue Jun 27 15:27:54 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:27:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:27:54 2023 ] Training epoch: 6
[ Tue Jun 27 15:27:56 2023 ] 	Training loss: 3.7711.  Training acc: 42.46%.
[ Tue Jun 27 15:27:56 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:27:56 2023 ] Eval epoch: 6
[ Tue Jun 27 15:27:57 2023 ] 	Mean test loss of 625 batches: 3.395636.
[ Tue Jun 27 15:27:57 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:27:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:27:57 2023 ] Training epoch: 7
[ Tue Jun 27 15:27:59 2023 ] 	Training loss: 3.5261.  Training acc: 37.50%.
[ Tue Jun 27 15:27:59 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:27:59 2023 ] Eval epoch: 7
[ Tue Jun 27 15:27:59 2023 ] 	Mean test loss of 625 batches: 2.496838.
[ Tue Jun 27 15:27:59 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:27:59 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:27:59 2023 ] Training epoch: 8
[ Tue Jun 27 15:28:01 2023 ] 	Training loss: 3.5256.  Training acc: 34.19%.
[ Tue Jun 27 15:28:01 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:28:01 2023 ] Eval epoch: 8
[ Tue Jun 27 15:28:02 2023 ] 	Mean test loss of 625 batches: 1.134078.
[ Tue Jun 27 15:28:02 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:28:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:02 2023 ] Training epoch: 9
[ Tue Jun 27 15:28:04 2023 ] 	Training loss: 3.0750.  Training acc: 33.92%.
[ Tue Jun 27 15:28:04 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:28:04 2023 ] Eval epoch: 9
[ Tue Jun 27 15:28:05 2023 ] 	Mean test loss of 625 batches: 1.727339.
[ Tue Jun 27 15:28:05 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:05 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:05 2023 ] Training epoch: 10
[ Tue Jun 27 15:28:07 2023 ] 	Training loss: 3.0620.  Training acc: 34.65%.
[ Tue Jun 27 15:28:07 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:28:07 2023 ] Eval epoch: 10
[ Tue Jun 27 15:28:07 2023 ] 	Mean test loss of 625 batches: 1.157521.
[ Tue Jun 27 15:28:07 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:07 2023 ] Training epoch: 11
[ Tue Jun 27 15:28:09 2023 ] 	Training loss: 1.8529.  Training acc: 34.38%.
[ Tue Jun 27 15:28:09 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:28:09 2023 ] Eval epoch: 11
[ Tue Jun 27 15:28:10 2023 ] 	Mean test loss of 625 batches: 1.110134.
[ Tue Jun 27 15:28:10 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:10 2023 ] Training epoch: 12
[ Tue Jun 27 15:28:12 2023 ] 	Training loss: 1.8913.  Training acc: 32.63%.
[ Tue Jun 27 15:28:12 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:28:12 2023 ] Eval epoch: 12
[ Tue Jun 27 15:28:13 2023 ] 	Mean test loss of 625 batches: 1.125541.
[ Tue Jun 27 15:28:13 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:13 2023 ] Training epoch: 13
[ Tue Jun 27 15:28:15 2023 ] 	Training loss: 1.7283.  Training acc: 35.85%.
[ Tue Jun 27 15:28:15 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:28:15 2023 ] Eval epoch: 13
[ Tue Jun 27 15:28:15 2023 ] 	Mean test loss of 625 batches: 1.121966.
[ Tue Jun 27 15:28:15 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:15 2023 ] Training epoch: 14
[ Tue Jun 27 15:28:17 2023 ] 	Training loss: 1.8061.  Training acc: 33.18%.
[ Tue Jun 27 15:28:17 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:28:17 2023 ] Eval epoch: 14
[ Tue Jun 27 15:28:18 2023 ] 	Mean test loss of 625 batches: 1.125699.
[ Tue Jun 27 15:28:18 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:18 2023 ] Training epoch: 15
[ Tue Jun 27 15:28:20 2023 ] 	Training loss: 1.7370.  Training acc: 33.92%.
[ Tue Jun 27 15:28:20 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 15:28:20 2023 ] Eval epoch: 15
[ Tue Jun 27 15:28:21 2023 ] 	Mean test loss of 625 batches: 1.114989.
[ Tue Jun 27 15:28:21 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:21 2023 ] Training epoch: 16
[ Tue Jun 27 15:28:24 2023 ] 	Training loss: 1.6795.  Training acc: 35.39%.
[ Tue Jun 27 15:28:24 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 27 15:28:24 2023 ] Eval epoch: 16
[ Tue Jun 27 15:28:24 2023 ] 	Mean test loss of 625 batches: 1.119527.
[ Tue Jun 27 15:28:24 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:24 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:24 2023 ] Training epoch: 17
[ Tue Jun 27 15:28:27 2023 ] 	Training loss: 1.6706.  Training acc: 35.11%.
[ Tue Jun 27 15:28:27 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Tue Jun 27 15:28:27 2023 ] Eval epoch: 17
[ Tue Jun 27 15:28:28 2023 ] 	Mean test loss of 625 batches: 1.110197.
[ Tue Jun 27 15:28:28 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:28 2023 ] Training epoch: 18
[ Tue Jun 27 15:28:31 2023 ] 	Training loss: 1.6536.  Training acc: 34.10%.
[ Tue Jun 27 15:28:31 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:28:31 2023 ] Eval epoch: 18
[ Tue Jun 27 15:28:31 2023 ] 	Mean test loss of 625 batches: 1.103371.
[ Tue Jun 27 15:28:31 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:31 2023 ] Training epoch: 19
[ Tue Jun 27 15:28:34 2023 ] 	Training loss: 1.6146.  Training acc: 34.56%.
[ Tue Jun 27 15:28:34 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:28:34 2023 ] Eval epoch: 19
[ Tue Jun 27 15:28:35 2023 ] 	Mean test loss of 625 batches: 1.129461.
[ Tue Jun 27 15:28:35 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:35 2023 ] Training epoch: 20
[ Tue Jun 27 15:28:38 2023 ] 	Training loss: 1.5225.  Training acc: 34.83%.
[ Tue Jun 27 15:28:38 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 27 15:28:38 2023 ] Eval epoch: 20
[ Tue Jun 27 15:28:39 2023 ] 	Mean test loss of 625 batches: 1.119289.
[ Tue Jun 27 15:28:39 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:39 2023 ] Training epoch: 21
[ Tue Jun 27 15:28:41 2023 ] 	Training loss: 1.5330.  Training acc: 34.93%.
[ Tue Jun 27 15:28:41 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:28:41 2023 ] Eval epoch: 21
[ Tue Jun 27 15:28:41 2023 ] 	Mean test loss of 625 batches: 1.116529.
[ Tue Jun 27 15:28:41 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:41 2023 ] Training epoch: 22
[ Tue Jun 27 15:28:43 2023 ] 	Training loss: 1.5072.  Training acc: 34.47%.
[ Tue Jun 27 15:28:43 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:28:43 2023 ] Eval epoch: 22
[ Tue Jun 27 15:28:44 2023 ] 	Mean test loss of 625 batches: 1.113865.
[ Tue Jun 27 15:28:44 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:44 2023 ] Training epoch: 23
[ Tue Jun 27 15:28:46 2023 ] 	Training loss: 1.4759.  Training acc: 37.68%.
[ Tue Jun 27 15:28:46 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 15:28:46 2023 ] Eval epoch: 23
[ Tue Jun 27 15:28:47 2023 ] 	Mean test loss of 625 batches: 1.111611.
[ Tue Jun 27 15:28:47 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:47 2023 ] Training epoch: 24
[ Tue Jun 27 15:28:49 2023 ] 	Training loss: 1.5128.  Training acc: 33.64%.
[ Tue Jun 27 15:28:49 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:28:49 2023 ] Eval epoch: 24
[ Tue Jun 27 15:28:49 2023 ] 	Mean test loss of 625 batches: 1.112198.
[ Tue Jun 27 15:28:49 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:49 2023 ] Training epoch: 25
[ Tue Jun 27 15:28:51 2023 ] 	Training loss: 1.5743.  Training acc: 33.18%.
[ Tue Jun 27 15:28:51 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 15:28:51 2023 ] Eval epoch: 25
[ Tue Jun 27 15:28:52 2023 ] 	Mean test loss of 625 batches: 1.114629.
[ Tue Jun 27 15:28:52 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:52 2023 ] Training epoch: 26
[ Tue Jun 27 15:28:54 2023 ] 	Training loss: 1.4987.  Training acc: 36.67%.
[ Tue Jun 27 15:28:54 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:28:54 2023 ] Eval epoch: 26
[ Tue Jun 27 15:28:55 2023 ] 	Mean test loss of 625 batches: 1.114299.
[ Tue Jun 27 15:28:55 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:55 2023 ] Training epoch: 27
[ Tue Jun 27 15:28:57 2023 ] 	Training loss: 1.5711.  Training acc: 33.36%.
[ Tue Jun 27 15:28:57 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:28:57 2023 ] Eval epoch: 27
[ Tue Jun 27 15:28:57 2023 ] 	Mean test loss of 625 batches: 1.113904.
[ Tue Jun 27 15:28:57 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:57 2023 ] Training epoch: 28
[ Tue Jun 27 15:28:59 2023 ] 	Training loss: 1.4948.  Training acc: 34.47%.
[ Tue Jun 27 15:28:59 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:28:59 2023 ] Eval epoch: 28
[ Tue Jun 27 15:29:00 2023 ] 	Mean test loss of 625 batches: 1.115570.
[ Tue Jun 27 15:29:00 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:00 2023 ] Training epoch: 29
[ Tue Jun 27 15:29:02 2023 ] 	Training loss: 1.5288.  Training acc: 33.73%.
[ Tue Jun 27 15:29:02 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:29:02 2023 ] Eval epoch: 29
[ Tue Jun 27 15:29:03 2023 ] 	Mean test loss of 625 batches: 1.114989.
[ Tue Jun 27 15:29:03 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:03 2023 ] Training epoch: 30
[ Tue Jun 27 15:29:05 2023 ] 	Training loss: 1.4618.  Training acc: 34.28%.
[ Tue Jun 27 15:29:05 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:29:05 2023 ] Eval epoch: 30
[ Tue Jun 27 15:29:05 2023 ] 	Mean test loss of 625 batches: 1.117063.
[ Tue Jun 27 15:29:05 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:05 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:05 2023 ] Training epoch: 31
[ Tue Jun 27 15:29:08 2023 ] 	Training loss: 1.5121.  Training acc: 35.20%.
[ Tue Jun 27 15:29:08 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:29:08 2023 ] Eval epoch: 31
[ Tue Jun 27 15:29:08 2023 ] 	Mean test loss of 625 batches: 1.115374.
[ Tue Jun 27 15:29:08 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:08 2023 ] Training epoch: 32
[ Tue Jun 27 15:29:10 2023 ] 	Training loss: 1.5227.  Training acc: 33.18%.
[ Tue Jun 27 15:29:10 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:29:10 2023 ] Eval epoch: 32
[ Tue Jun 27 15:29:11 2023 ] 	Mean test loss of 625 batches: 1.114258.
[ Tue Jun 27 15:29:11 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:11 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:11 2023 ] Training epoch: 33
[ Tue Jun 27 15:29:14 2023 ] 	Training loss: 1.4486.  Training acc: 35.85%.
[ Tue Jun 27 15:29:14 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:29:14 2023 ] Eval epoch: 33
[ Tue Jun 27 15:29:14 2023 ] 	Mean test loss of 625 batches: 1.113840.
[ Tue Jun 27 15:29:14 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:14 2023 ] Training epoch: 34
[ Tue Jun 27 15:29:17 2023 ] 	Training loss: 1.5009.  Training acc: 31.80%.
[ Tue Jun 27 15:29:17 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:29:17 2023 ] Eval epoch: 34
[ Tue Jun 27 15:29:18 2023 ] 	Mean test loss of 625 batches: 1.111933.
[ Tue Jun 27 15:29:18 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:18 2023 ] Training epoch: 35
[ Tue Jun 27 15:29:21 2023 ] 	Training loss: 1.4637.  Training acc: 34.56%.
[ Tue Jun 27 15:29:21 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:29:21 2023 ] Eval epoch: 35
[ Tue Jun 27 15:29:21 2023 ] 	Mean test loss of 625 batches: 1.109601.
[ Tue Jun 27 15:29:21 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:21 2023 ] Training epoch: 36
[ Tue Jun 27 15:29:24 2023 ] 	Training loss: 1.4596.  Training acc: 36.76%.
[ Tue Jun 27 15:29:24 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:29:24 2023 ] Eval epoch: 36
[ Tue Jun 27 15:29:25 2023 ] 	Mean test loss of 625 batches: 1.109487.
[ Tue Jun 27 15:29:25 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:25 2023 ] Training epoch: 37
[ Tue Jun 27 15:29:28 2023 ] 	Training loss: 1.5105.  Training acc: 34.74%.
[ Tue Jun 27 15:29:28 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:29:28 2023 ] Eval epoch: 37
[ Tue Jun 27 15:29:28 2023 ] 	Mean test loss of 625 batches: 1.108674.
[ Tue Jun 27 15:29:28 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:28 2023 ] Training epoch: 38
[ Tue Jun 27 15:29:31 2023 ] 	Training loss: 1.4386.  Training acc: 33.27%.
[ Tue Jun 27 15:29:31 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:29:31 2023 ] Eval epoch: 38
[ Tue Jun 27 15:29:32 2023 ] 	Mean test loss of 625 batches: 1.107697.
[ Tue Jun 27 15:29:32 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:32 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:32 2023 ] Training epoch: 39
[ Tue Jun 27 15:29:34 2023 ] 	Training loss: 1.4526.  Training acc: 36.31%.
[ Tue Jun 27 15:29:34 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:29:34 2023 ] Eval epoch: 39
[ Tue Jun 27 15:29:35 2023 ] 	Mean test loss of 625 batches: 1.110085.
[ Tue Jun 27 15:29:35 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:35 2023 ] Training epoch: 40
[ Tue Jun 27 15:29:37 2023 ] 	Training loss: 1.5114.  Training acc: 31.34%.
[ Tue Jun 27 15:29:37 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:29:37 2023 ] Eval epoch: 40
[ Tue Jun 27 15:29:38 2023 ] 	Mean test loss of 625 batches: 1.111755.
[ Tue Jun 27 15:29:38 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:38 2023 ] Best accuracy: 0.8947368421052632
[ Tue Jun 27 15:29:38 2023 ] Epoch number: 1
[ Tue Jun 27 15:29:38 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 15:29:38 2023 ] Weight decay: 0.0005
[ Tue Jun 27 15:29:38 2023 ] Base LR: 0.1
[ Tue Jun 27 15:29:38 2023 ] Batch Size: 64
[ Tue Jun 27 15:29:38 2023 ] Test Batch Size: 64
[ Tue Jun 27 15:29:38 2023 ] seed: 1
[ Tue Jun 27 15:29:38 2023 ] Start training Corrector
[ Tue Jun 27 15:32:52 2023 ] using warm up, epoch: 5
[ Tue Jun 27 15:32:52 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 15:32:52 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 15:32:52 2023 ] Start training Predictor
[ Tue Jun 27 15:32:52 2023 ] Training epoch: 1
[ Tue Jun 27 15:32:57 2023 ] 	Training loss: 120.9869.  Training acc: 33.64%.
[ Tue Jun 27 15:32:57 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jun 27 15:32:57 2023 ] Eval epoch: 1
[ Tue Jun 27 15:32:58 2023 ] 	Mean test loss of 625 batches: 1390.947705.
[ Tue Jun 27 15:32:58 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:32:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:32:59 2023 ] Training epoch: 2
[ Tue Jun 27 15:33:01 2023 ] 	Training loss: 9.4288.  Training acc: 34.83%.
[ Tue Jun 27 15:33:01 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:33:01 2023 ] Eval epoch: 2
[ Tue Jun 27 15:33:02 2023 ] 	Mean test loss of 625 batches: 3.136926.
[ Tue Jun 27 15:33:02 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:33:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:02 2023 ] Training epoch: 3
[ Tue Jun 27 15:33:05 2023 ] 	Training loss: 6.4509.  Training acc: 42.19%.
[ Tue Jun 27 15:33:05 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Tue Jun 27 15:33:05 2023 ] Eval epoch: 3
[ Tue Jun 27 15:33:06 2023 ] 	Mean test loss of 625 batches: 3.293919.
[ Tue Jun 27 15:33:06 2023 ] 	Top1: 42.11%
[ Tue Jun 27 15:33:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:06 2023 ] Training epoch: 4
[ Tue Jun 27 15:33:09 2023 ] 	Training loss: 4.7233.  Training acc: 58.82%.
[ Tue Jun 27 15:33:09 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:33:09 2023 ] Eval epoch: 4
[ Tue Jun 27 15:33:09 2023 ] 	Mean test loss of 625 batches: 9.973351.
[ Tue Jun 27 15:33:09 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:33:09 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:09 2023 ] Training epoch: 5
[ Tue Jun 27 15:33:12 2023 ] 	Training loss: 3.0458.  Training acc: 62.68%.
[ Tue Jun 27 15:33:12 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:33:12 2023 ] Eval epoch: 5
[ Tue Jun 27 15:33:13 2023 ] 	Mean test loss of 625 batches: 4.334932.
[ Tue Jun 27 15:33:13 2023 ] 	Top1: 47.37%
[ Tue Jun 27 15:33:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:13 2023 ] Training epoch: 6
[ Tue Jun 27 15:33:16 2023 ] 	Training loss: 1.9889.  Training acc: 64.98%.
[ Tue Jun 27 15:33:16 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:33:16 2023 ] Eval epoch: 6
[ Tue Jun 27 15:33:16 2023 ] 	Mean test loss of 625 batches: 1.269522.
[ Tue Jun 27 15:33:16 2023 ] 	Top1: 59.65%
[ Tue Jun 27 15:33:16 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:16 2023 ] Training epoch: 7
[ Tue Jun 27 15:33:19 2023 ] 	Training loss: 2.5844.  Training acc: 66.73%.
[ Tue Jun 27 15:33:19 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:33:19 2023 ] Eval epoch: 7
[ Tue Jun 27 15:33:20 2023 ] 	Mean test loss of 625 batches: 2.542947.
[ Tue Jun 27 15:33:20 2023 ] 	Top1: 50.88%
[ Tue Jun 27 15:33:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:20 2023 ] Training epoch: 8
[ Tue Jun 27 15:33:23 2023 ] 	Training loss: 1.9711.  Training acc: 60.57%.
[ Tue Jun 27 15:33:23 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:33:23 2023 ] Eval epoch: 8
[ Tue Jun 27 15:33:24 2023 ] 	Mean test loss of 625 batches: 4.978865.
[ Tue Jun 27 15:33:24 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:33:24 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:24 2023 ] Training epoch: 9
[ Tue Jun 27 15:33:26 2023 ] 	Training loss: 0.8832.  Training acc: 78.68%.
[ Tue Jun 27 15:33:26 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:33:26 2023 ] Eval epoch: 9
[ Tue Jun 27 15:33:26 2023 ] 	Mean test loss of 625 batches: 1.236105.
[ Tue Jun 27 15:33:26 2023 ] 	Top1: 66.67%
[ Tue Jun 27 15:33:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:27 2023 ] Training epoch: 10
[ Tue Jun 27 15:33:29 2023 ] 	Training loss: 0.6963.  Training acc: 86.58%.
[ Tue Jun 27 15:33:29 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:33:29 2023 ] Eval epoch: 10
[ Tue Jun 27 15:33:29 2023 ] 	Mean test loss of 625 batches: 1.210415.
[ Tue Jun 27 15:33:29 2023 ] 	Top1: 52.63%
[ Tue Jun 27 15:33:29 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:29 2023 ] Training epoch: 11
[ Tue Jun 27 15:33:31 2023 ] 	Training loss: 0.5243.  Training acc: 92.28%.
[ Tue Jun 27 15:33:31 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 15:33:31 2023 ] Eval epoch: 11
[ Tue Jun 27 15:33:32 2023 ] 	Mean test loss of 625 batches: 0.350639.
[ Tue Jun 27 15:33:32 2023 ] 	Top1: 98.25%
[ Tue Jun 27 15:33:32 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:32 2023 ] Training epoch: 12
[ Tue Jun 27 15:33:34 2023 ] 	Training loss: 0.5149.  Training acc: 93.57%.
[ Tue Jun 27 15:33:34 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:33:34 2023 ] Eval epoch: 12
[ Tue Jun 27 15:33:35 2023 ] 	Mean test loss of 625 batches: 0.472251.
[ Tue Jun 27 15:33:35 2023 ] 	Top1: 92.98%
[ Tue Jun 27 15:33:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:35 2023 ] Training epoch: 13
[ Tue Jun 27 15:33:37 2023 ] 	Training loss: 0.4897.  Training acc: 93.66%.
[ Tue Jun 27 15:33:37 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:33:37 2023 ] Eval epoch: 13
[ Tue Jun 27 15:33:37 2023 ] 	Mean test loss of 625 batches: 0.341094.
[ Tue Jun 27 15:33:37 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:33:37 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:38 2023 ] Training epoch: 14
[ Tue Jun 27 15:33:40 2023 ] 	Training loss: 0.4784.  Training acc: 94.94%.
[ Tue Jun 27 15:33:40 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:33:40 2023 ] Eval epoch: 14
[ Tue Jun 27 15:33:40 2023 ] 	Mean test loss of 625 batches: 0.385148.
[ Tue Jun 27 15:33:40 2023 ] 	Top1: 98.25%
[ Tue Jun 27 15:33:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:40 2023 ] Training epoch: 15
[ Tue Jun 27 15:33:42 2023 ] 	Training loss: 0.4625.  Training acc: 94.85%.
[ Tue Jun 27 15:33:42 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:33:42 2023 ] Eval epoch: 15
[ Tue Jun 27 15:33:43 2023 ] 	Mean test loss of 625 batches: 0.347824.
[ Tue Jun 27 15:33:43 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:33:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:43 2023 ] Training epoch: 16
[ Tue Jun 27 15:33:45 2023 ] 	Training loss: 0.4360.  Training acc: 96.69%.
[ Tue Jun 27 15:33:45 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:33:45 2023 ] Eval epoch: 16
[ Tue Jun 27 15:33:46 2023 ] 	Mean test loss of 625 batches: 0.336632.
[ Tue Jun 27 15:33:46 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:33:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:46 2023 ] Training epoch: 17
[ Tue Jun 27 15:33:48 2023 ] 	Training loss: 0.4336.  Training acc: 97.06%.
[ Tue Jun 27 15:33:48 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:33:48 2023 ] Eval epoch: 17
[ Tue Jun 27 15:33:49 2023 ] 	Mean test loss of 625 batches: 0.331931.
[ Tue Jun 27 15:33:49 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:33:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:49 2023 ] Training epoch: 18
[ Tue Jun 27 15:33:51 2023 ] 	Training loss: 0.4290.  Training acc: 96.88%.
[ Tue Jun 27 15:33:51 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:33:51 2023 ] Eval epoch: 18
[ Tue Jun 27 15:33:51 2023 ] 	Mean test loss of 625 batches: 0.359704.
[ Tue Jun 27 15:33:51 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:33:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:51 2023 ] Training epoch: 19
[ Tue Jun 27 15:33:54 2023 ] 	Training loss: 0.4398.  Training acc: 96.05%.
[ Tue Jun 27 15:33:54 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:33:54 2023 ] Eval epoch: 19
[ Tue Jun 27 15:33:54 2023 ] 	Mean test loss of 625 batches: 0.346523.
[ Tue Jun 27 15:33:54 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:33:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:54 2023 ] Training epoch: 20
[ Tue Jun 27 15:33:57 2023 ] 	Training loss: 0.4071.  Training acc: 97.33%.
[ Tue Jun 27 15:33:57 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:33:57 2023 ] Eval epoch: 20
[ Tue Jun 27 15:33:57 2023 ] 	Mean test loss of 625 batches: 0.352293.
[ Tue Jun 27 15:33:57 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:33:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:57 2023 ] Training epoch: 21
[ Tue Jun 27 15:34:00 2023 ] 	Training loss: 0.4217.  Training acc: 97.33%.
[ Tue Jun 27 15:34:00 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:34:00 2023 ] Eval epoch: 21
[ Tue Jun 27 15:34:01 2023 ] 	Mean test loss of 625 batches: 0.336298.
[ Tue Jun 27 15:34:01 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:01 2023 ] Training epoch: 22
[ Tue Jun 27 15:34:04 2023 ] 	Training loss: 0.3995.  Training acc: 98.25%.
[ Tue Jun 27 15:34:04 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:34:04 2023 ] Eval epoch: 22
[ Tue Jun 27 15:34:04 2023 ] 	Mean test loss of 625 batches: 0.330506.
[ Tue Jun 27 15:34:04 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:04 2023 ] Training epoch: 23
[ Tue Jun 27 15:34:07 2023 ] 	Training loss: 0.3964.  Training acc: 97.89%.
[ Tue Jun 27 15:34:07 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:34:07 2023 ] Eval epoch: 23
[ Tue Jun 27 15:34:08 2023 ] 	Mean test loss of 625 batches: 0.327872.
[ Tue Jun 27 15:34:08 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:08 2023 ] Training epoch: 24
[ Tue Jun 27 15:34:11 2023 ] 	Training loss: 0.3868.  Training acc: 98.07%.
[ Tue Jun 27 15:34:11 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:34:11 2023 ] Eval epoch: 24
[ Tue Jun 27 15:34:12 2023 ] 	Mean test loss of 625 batches: 0.320775.
[ Tue Jun 27 15:34:12 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:12 2023 ] Training epoch: 25
[ Tue Jun 27 15:34:15 2023 ] 	Training loss: 0.3887.  Training acc: 98.25%.
[ Tue Jun 27 15:34:15 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Tue Jun 27 15:34:15 2023 ] Eval epoch: 25
[ Tue Jun 27 15:34:15 2023 ] 	Mean test loss of 625 batches: 0.330770.
[ Tue Jun 27 15:34:15 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:15 2023 ] Training epoch: 26
[ Tue Jun 27 15:34:18 2023 ] 	Training loss: 0.3952.  Training acc: 98.25%.
[ Tue Jun 27 15:34:18 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:34:18 2023 ] Eval epoch: 26
[ Tue Jun 27 15:34:19 2023 ] 	Mean test loss of 625 batches: 0.324595.
[ Tue Jun 27 15:34:19 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:19 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:19 2023 ] Training epoch: 27
[ Tue Jun 27 15:34:22 2023 ] 	Training loss: 0.3812.  Training acc: 98.90%.
[ Tue Jun 27 15:34:22 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:34:22 2023 ] Eval epoch: 27
[ Tue Jun 27 15:34:23 2023 ] 	Mean test loss of 625 batches: 0.330817.
[ Tue Jun 27 15:34:23 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:23 2023 ] Training epoch: 28
[ Tue Jun 27 15:34:26 2023 ] 	Training loss: 0.3728.  Training acc: 98.81%.
[ Tue Jun 27 15:34:26 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:34:26 2023 ] Eval epoch: 28
[ Tue Jun 27 15:34:26 2023 ] 	Mean test loss of 625 batches: 0.338107.
[ Tue Jun 27 15:34:26 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:26 2023 ] Training epoch: 29
[ Tue Jun 27 15:34:29 2023 ] 	Training loss: 0.3903.  Training acc: 97.98%.
[ Tue Jun 27 15:34:29 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:34:29 2023 ] Eval epoch: 29
[ Tue Jun 27 15:34:30 2023 ] 	Mean test loss of 625 batches: 0.322479.
[ Tue Jun 27 15:34:30 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:30 2023 ] Training epoch: 30
[ Tue Jun 27 15:34:33 2023 ] 	Training loss: 0.3842.  Training acc: 98.53%.
[ Tue Jun 27 15:34:33 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:34:33 2023 ] Eval epoch: 30
[ Tue Jun 27 15:34:33 2023 ] 	Mean test loss of 625 batches: 0.321793.
[ Tue Jun 27 15:34:33 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:33 2023 ] Training epoch: 31
[ Tue Jun 27 15:34:35 2023 ] 	Training loss: 0.3814.  Training acc: 98.62%.
[ Tue Jun 27 15:34:35 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:34:35 2023 ] Eval epoch: 31
[ Tue Jun 27 15:34:36 2023 ] 	Mean test loss of 625 batches: 0.321546.
[ Tue Jun 27 15:34:36 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:36 2023 ] Training epoch: 32
[ Tue Jun 27 15:34:38 2023 ] 	Training loss: 0.3895.  Training acc: 97.79%.
[ Tue Jun 27 15:34:38 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:34:38 2023 ] Eval epoch: 32
[ Tue Jun 27 15:34:39 2023 ] 	Mean test loss of 625 batches: 0.322512.
[ Tue Jun 27 15:34:39 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:39 2023 ] Training epoch: 33
[ Tue Jun 27 15:34:41 2023 ] 	Training loss: 0.3792.  Training acc: 98.25%.
[ Tue Jun 27 15:34:41 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:34:41 2023 ] Eval epoch: 33
[ Tue Jun 27 15:34:41 2023 ] 	Mean test loss of 625 batches: 0.322015.
[ Tue Jun 27 15:34:41 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:41 2023 ] Training epoch: 34
[ Tue Jun 27 15:34:43 2023 ] 	Training loss: 0.3743.  Training acc: 98.99%.
[ Tue Jun 27 15:34:43 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:34:43 2023 ] Eval epoch: 34
[ Tue Jun 27 15:34:44 2023 ] 	Mean test loss of 625 batches: 0.317930.
[ Tue Jun 27 15:34:44 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:44 2023 ] Training epoch: 35
[ Tue Jun 27 15:34:46 2023 ] 	Training loss: 0.3759.  Training acc: 98.53%.
[ Tue Jun 27 15:34:46 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:34:46 2023 ] Eval epoch: 35
[ Tue Jun 27 15:34:47 2023 ] 	Mean test loss of 625 batches: 0.325969.
[ Tue Jun 27 15:34:47 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:47 2023 ] Training epoch: 36
[ Tue Jun 27 15:34:49 2023 ] 	Training loss: 0.3749.  Training acc: 98.99%.
[ Tue Jun 27 15:34:49 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:34:49 2023 ] Eval epoch: 36
[ Tue Jun 27 15:34:49 2023 ] 	Mean test loss of 625 batches: 0.324596.
[ Tue Jun 27 15:34:49 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:49 2023 ] Training epoch: 37
[ Tue Jun 27 15:34:51 2023 ] 	Training loss: 0.3773.  Training acc: 98.53%.
[ Tue Jun 27 15:34:51 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:34:51 2023 ] Eval epoch: 37
[ Tue Jun 27 15:34:52 2023 ] 	Mean test loss of 625 batches: 0.317361.
[ Tue Jun 27 15:34:52 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:52 2023 ] Training epoch: 38
[ Tue Jun 27 15:34:54 2023 ] 	Training loss: 0.3673.  Training acc: 99.26%.
[ Tue Jun 27 15:34:54 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:34:54 2023 ] Eval epoch: 38
[ Tue Jun 27 15:34:55 2023 ] 	Mean test loss of 625 batches: 0.317691.
[ Tue Jun 27 15:34:55 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:55 2023 ] Training epoch: 39
[ Tue Jun 27 15:34:57 2023 ] 	Training loss: 0.3723.  Training acc: 98.99%.
[ Tue Jun 27 15:34:57 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:34:57 2023 ] Eval epoch: 39
[ Tue Jun 27 15:34:57 2023 ] 	Mean test loss of 625 batches: 0.329618.
[ Tue Jun 27 15:34:57 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:57 2023 ] Training epoch: 40
[ Tue Jun 27 15:35:00 2023 ] 	Training loss: 0.3882.  Training acc: 98.53%.
[ Tue Jun 27 15:35:00 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:35:00 2023 ] Eval epoch: 40
[ Tue Jun 27 15:35:00 2023 ] 	Mean test loss of 625 batches: 0.324395.
[ Tue Jun 27 15:35:00 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:35:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:01 2023 ] Best accuracy: 1.0
[ Tue Jun 27 15:35:01 2023 ] Epoch number: 13
[ Tue Jun 27 15:35:01 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 15:35:01 2023 ] Weight decay: 0.0005
[ Tue Jun 27 15:35:01 2023 ] Base LR: 0.1
[ Tue Jun 27 15:35:01 2023 ] Batch Size: 64
[ Tue Jun 27 15:35:01 2023 ] Test Batch Size: 64
[ Tue Jun 27 15:35:01 2023 ] seed: 1
[ Tue Jun 27 15:35:01 2023 ] Start training Corrector
[ Tue Jun 27 15:35:23 2023 ] using warm up, epoch: 5
[ Tue Jun 27 15:35:24 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 15:35:24 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 15:35:24 2023 ] Start training Predictor
[ Tue Jun 27 15:35:24 2023 ] Training epoch: 1
[ Tue Jun 27 15:35:29 2023 ] 	Training loss: 111.4898.  Training acc: 35.11%.
[ Tue Jun 27 15:35:29 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jun 27 15:35:29 2023 ] Eval epoch: 1
[ Tue Jun 27 15:35:30 2023 ] 	Mean test loss of 625 batches: 2750.861719.
[ Tue Jun 27 15:35:30 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:35:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:30 2023 ] Training epoch: 2
[ Tue Jun 27 15:35:33 2023 ] 	Training loss: 14.7206.  Training acc: 33.64%.
[ Tue Jun 27 15:35:33 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Tue Jun 27 15:35:33 2023 ] Eval epoch: 2
[ Tue Jun 27 15:35:34 2023 ] 	Mean test loss of 625 batches: 13.499561.
[ Tue Jun 27 15:35:34 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:35:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:34 2023 ] Training epoch: 3
[ Tue Jun 27 15:35:37 2023 ] 	Training loss: 7.3236.  Training acc: 32.81%.
[ Tue Jun 27 15:35:37 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:35:37 2023 ] Eval epoch: 3
[ Tue Jun 27 15:35:38 2023 ] 	Mean test loss of 625 batches: 2.326755.
[ Tue Jun 27 15:35:38 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:35:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:38 2023 ] Training epoch: 4
[ Tue Jun 27 15:35:41 2023 ] 	Training loss: 6.0117.  Training acc: 31.43%.
[ Tue Jun 27 15:35:41 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:35:41 2023 ] Eval epoch: 4
[ Tue Jun 27 15:35:41 2023 ] 	Mean test loss of 625 batches: 1.602655.
[ Tue Jun 27 15:35:41 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:35:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:41 2023 ] Training epoch: 5
[ Tue Jun 27 15:35:43 2023 ] 	Training loss: 4.7531.  Training acc: 36.03%.
[ Tue Jun 27 15:35:43 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:35:43 2023 ] Eval epoch: 5
[ Tue Jun 27 15:35:44 2023 ] 	Mean test loss of 625 batches: 1.230711.
[ Tue Jun 27 15:35:44 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:35:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:44 2023 ] Training epoch: 6
[ Tue Jun 27 15:35:46 2023 ] 	Training loss: 11.3076.  Training acc: 36.58%.
[ Tue Jun 27 15:35:46 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:35:46 2023 ] Eval epoch: 6
[ Tue Jun 27 15:35:47 2023 ] 	Mean test loss of 625 batches: 1.158163.
[ Tue Jun 27 15:35:47 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:35:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:47 2023 ] Training epoch: 7
[ Tue Jun 27 15:35:49 2023 ] 	Training loss: 2.9209.  Training acc: 34.28%.
[ Tue Jun 27 15:35:49 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:35:49 2023 ] Eval epoch: 7
[ Tue Jun 27 15:35:49 2023 ] 	Mean test loss of 625 batches: 1.209037.
[ Tue Jun 27 15:35:49 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:35:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:49 2023 ] Training epoch: 8
[ Tue Jun 27 15:35:51 2023 ] 	Training loss: 2.5811.  Training acc: 31.53%.
[ Tue Jun 27 15:35:51 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:35:51 2023 ] Eval epoch: 8
[ Tue Jun 27 15:35:52 2023 ] 	Mean test loss of 625 batches: 1.139563.
[ Tue Jun 27 15:35:52 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:35:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:52 2023 ] Training epoch: 9
[ Tue Jun 27 15:35:54 2023 ] 	Training loss: 2.0023.  Training acc: 34.56%.
[ Tue Jun 27 15:35:54 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:35:54 2023 ] Eval epoch: 9
[ Tue Jun 27 15:35:54 2023 ] 	Mean test loss of 625 batches: 1.136637.
[ Tue Jun 27 15:35:54 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:35:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:54 2023 ] Training epoch: 10
[ Tue Jun 27 15:35:57 2023 ] 	Training loss: 1.8511.  Training acc: 33.36%.
[ Tue Jun 27 15:35:57 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:35:57 2023 ] Eval epoch: 10
[ Tue Jun 27 15:35:57 2023 ] 	Mean test loss of 625 batches: 1.131136.
[ Tue Jun 27 15:35:57 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:35:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:57 2023 ] Training epoch: 11
[ Tue Jun 27 15:35:59 2023 ] 	Training loss: 1.5894.  Training acc: 33.00%.
[ Tue Jun 27 15:35:59 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:35:59 2023 ] Eval epoch: 11
[ Tue Jun 27 15:36:00 2023 ] 	Mean test loss of 625 batches: 1.124687.
[ Tue Jun 27 15:36:00 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:00 2023 ] Training epoch: 12
[ Tue Jun 27 15:36:02 2023 ] 	Training loss: 1.5803.  Training acc: 35.20%.
[ Tue Jun 27 15:36:02 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:36:02 2023 ] Eval epoch: 12
[ Tue Jun 27 15:36:02 2023 ] 	Mean test loss of 625 batches: 1.137854.
[ Tue Jun 27 15:36:02 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:02 2023 ] Training epoch: 13
[ Tue Jun 27 15:36:05 2023 ] 	Training loss: 1.4989.  Training acc: 36.40%.
[ Tue Jun 27 15:36:05 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:36:05 2023 ] Eval epoch: 13
[ Tue Jun 27 15:36:05 2023 ] 	Mean test loss of 625 batches: 1.123769.
[ Tue Jun 27 15:36:05 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:05 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:05 2023 ] Training epoch: 14
[ Tue Jun 27 15:36:07 2023 ] 	Training loss: 1.5734.  Training acc: 33.55%.
[ Tue Jun 27 15:36:07 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:36:07 2023 ] Eval epoch: 14
[ Tue Jun 27 15:36:08 2023 ] 	Mean test loss of 625 batches: 1.124134.
[ Tue Jun 27 15:36:08 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:08 2023 ] Training epoch: 15
[ Tue Jun 27 15:36:10 2023 ] 	Training loss: 1.5219.  Training acc: 35.02%.
[ Tue Jun 27 15:36:10 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:36:10 2023 ] Eval epoch: 15
[ Tue Jun 27 15:36:11 2023 ] 	Mean test loss of 625 batches: 1.129952.
[ Tue Jun 27 15:36:11 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:11 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:11 2023 ] Training epoch: 16
[ Tue Jun 27 15:36:13 2023 ] 	Training loss: 1.4757.  Training acc: 35.85%.
[ Tue Jun 27 15:36:13 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:36:13 2023 ] Eval epoch: 16
[ Tue Jun 27 15:36:14 2023 ] 	Mean test loss of 625 batches: 1.126239.
[ Tue Jun 27 15:36:14 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:14 2023 ] Training epoch: 17
[ Tue Jun 27 15:36:17 2023 ] 	Training loss: 1.4645.  Training acc: 35.85%.
[ Tue Jun 27 15:36:17 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:36:17 2023 ] Eval epoch: 17
[ Tue Jun 27 15:36:17 2023 ] 	Mean test loss of 625 batches: 1.120181.
[ Tue Jun 27 15:36:17 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:17 2023 ] Training epoch: 18
[ Tue Jun 27 15:36:21 2023 ] 	Training loss: 1.4411.  Training acc: 34.10%.
[ Tue Jun 27 15:36:21 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:36:21 2023 ] Eval epoch: 18
[ Tue Jun 27 15:36:21 2023 ] 	Mean test loss of 625 batches: 1.110955.
[ Tue Jun 27 15:36:21 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:21 2023 ] Training epoch: 19
[ Tue Jun 27 15:36:24 2023 ] 	Training loss: 1.4296.  Training acc: 34.28%.
[ Tue Jun 27 15:36:24 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:36:24 2023 ] Eval epoch: 19
[ Tue Jun 27 15:36:25 2023 ] 	Mean test loss of 625 batches: 1.123562.
[ Tue Jun 27 15:36:25 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:25 2023 ] Training epoch: 20
[ Tue Jun 27 15:36:28 2023 ] 	Training loss: 1.3761.  Training acc: 36.03%.
[ Tue Jun 27 15:36:28 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:36:28 2023 ] Eval epoch: 20
[ Tue Jun 27 15:36:29 2023 ] 	Mean test loss of 625 batches: 1.121184.
[ Tue Jun 27 15:36:29 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:29 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:29 2023 ] Training epoch: 21
[ Tue Jun 27 15:36:32 2023 ] 	Training loss: 1.3770.  Training acc: 36.31%.
[ Tue Jun 27 15:36:32 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:36:32 2023 ] Eval epoch: 21
[ Tue Jun 27 15:36:33 2023 ] 	Mean test loss of 625 batches: 1.120068.
[ Tue Jun 27 15:36:33 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:33 2023 ] Training epoch: 22
[ Tue Jun 27 15:36:35 2023 ] 	Training loss: 1.3568.  Training acc: 36.95%.
[ Tue Jun 27 15:36:36 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 27 15:36:36 2023 ] Eval epoch: 22
[ Tue Jun 27 15:36:36 2023 ] 	Mean test loss of 625 batches: 1.119528.
[ Tue Jun 27 15:36:36 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:36 2023 ] Training epoch: 23
[ Tue Jun 27 15:36:39 2023 ] 	Training loss: 1.3509.  Training acc: 35.57%.
[ Tue Jun 27 15:36:39 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:36:39 2023 ] Eval epoch: 23
[ Tue Jun 27 15:36:40 2023 ] 	Mean test loss of 625 batches: 1.117841.
[ Tue Jun 27 15:36:40 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:40 2023 ] Training epoch: 24
[ Tue Jun 27 15:36:43 2023 ] 	Training loss: 1.3629.  Training acc: 34.10%.
[ Tue Jun 27 15:36:43 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:36:43 2023 ] Eval epoch: 24
[ Tue Jun 27 15:36:43 2023 ] 	Mean test loss of 625 batches: 1.117514.
[ Tue Jun 27 15:36:43 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:43 2023 ] Training epoch: 25
[ Tue Jun 27 15:36:46 2023 ] 	Training loss: 1.3940.  Training acc: 33.64%.
[ Tue Jun 27 15:36:46 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:36:46 2023 ] Eval epoch: 25
[ Tue Jun 27 15:36:47 2023 ] 	Mean test loss of 625 batches: 1.118492.
[ Tue Jun 27 15:36:47 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:47 2023 ] Training epoch: 26
[ Tue Jun 27 15:36:50 2023 ] 	Training loss: 1.3589.  Training acc: 35.57%.
[ Tue Jun 27 15:36:50 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:36:50 2023 ] Eval epoch: 26
[ Tue Jun 27 15:36:51 2023 ] 	Mean test loss of 625 batches: 1.117366.
[ Tue Jun 27 15:36:51 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:51 2023 ] Training epoch: 27
[ Tue Jun 27 15:36:54 2023 ] 	Training loss: 1.4210.  Training acc: 34.01%.
[ Tue Jun 27 15:36:54 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:36:54 2023 ] Eval epoch: 27
[ Tue Jun 27 15:36:55 2023 ] 	Mean test loss of 625 batches: 1.116429.
[ Tue Jun 27 15:36:55 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:55 2023 ] Training epoch: 28
[ Tue Jun 27 15:36:57 2023 ] 	Training loss: 1.3539.  Training acc: 35.85%.
[ Tue Jun 27 15:36:57 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:36:57 2023 ] Eval epoch: 28
[ Tue Jun 27 15:36:57 2023 ] 	Mean test loss of 625 batches: 1.116981.
[ Tue Jun 27 15:36:57 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:57 2023 ] Training epoch: 29
[ Tue Jun 27 15:36:59 2023 ] 	Training loss: 1.3808.  Training acc: 34.93%.
[ Tue Jun 27 15:36:59 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:36:59 2023 ] Eval epoch: 29
[ Tue Jun 27 15:37:00 2023 ] 	Mean test loss of 625 batches: 1.116420.
[ Tue Jun 27 15:37:00 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:00 2023 ] Training epoch: 30
[ Tue Jun 27 15:37:02 2023 ] 	Training loss: 1.3423.  Training acc: 34.83%.
[ Tue Jun 27 15:37:02 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:37:02 2023 ] Eval epoch: 30
[ Tue Jun 27 15:37:03 2023 ] 	Mean test loss of 625 batches: 1.117775.
[ Tue Jun 27 15:37:03 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:03 2023 ] Training epoch: 31
[ Tue Jun 27 15:37:05 2023 ] 	Training loss: 1.3623.  Training acc: 36.03%.
[ Tue Jun 27 15:37:05 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:37:05 2023 ] Eval epoch: 31
[ Tue Jun 27 15:37:06 2023 ] 	Mean test loss of 625 batches: 1.116782.
[ Tue Jun 27 15:37:06 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:06 2023 ] Training epoch: 32
[ Tue Jun 27 15:37:08 2023 ] 	Training loss: 1.3748.  Training acc: 33.92%.
[ Tue Jun 27 15:37:08 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:37:08 2023 ] Eval epoch: 32
[ Tue Jun 27 15:37:08 2023 ] 	Mean test loss of 625 batches: 1.116391.
[ Tue Jun 27 15:37:08 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:08 2023 ] Training epoch: 33
[ Tue Jun 27 15:37:11 2023 ] 	Training loss: 1.3158.  Training acc: 35.94%.
[ Tue Jun 27 15:37:11 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:37:11 2023 ] Eval epoch: 33
[ Tue Jun 27 15:37:11 2023 ] 	Mean test loss of 625 batches: 1.116415.
[ Tue Jun 27 15:37:11 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:11 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:11 2023 ] Training epoch: 34
[ Tue Jun 27 15:37:14 2023 ] 	Training loss: 1.3511.  Training acc: 32.44%.
[ Tue Jun 27 15:37:14 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:37:14 2023 ] Eval epoch: 34
[ Tue Jun 27 15:37:14 2023 ] 	Mean test loss of 625 batches: 1.115599.
[ Tue Jun 27 15:37:14 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:14 2023 ] Training epoch: 35
[ Tue Jun 27 15:37:16 2023 ] 	Training loss: 1.3449.  Training acc: 33.82%.
[ Tue Jun 27 15:37:16 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:37:16 2023 ] Eval epoch: 35
[ Tue Jun 27 15:37:17 2023 ] 	Mean test loss of 625 batches: 1.113563.
[ Tue Jun 27 15:37:17 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:17 2023 ] Training epoch: 36
[ Tue Jun 27 15:37:19 2023 ] 	Training loss: 1.3376.  Training acc: 34.93%.
[ Tue Jun 27 15:37:19 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 15:37:19 2023 ] Eval epoch: 36
[ Tue Jun 27 15:37:20 2023 ] 	Mean test loss of 625 batches: 1.113789.
[ Tue Jun 27 15:37:20 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:20 2023 ] Training epoch: 37
[ Tue Jun 27 15:37:22 2023 ] 	Training loss: 1.3684.  Training acc: 33.82%.
[ Tue Jun 27 15:37:22 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:37:22 2023 ] Eval epoch: 37
[ Tue Jun 27 15:37:22 2023 ] 	Mean test loss of 625 batches: 1.113474.
[ Tue Jun 27 15:37:22 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:22 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:22 2023 ] Training epoch: 38
[ Tue Jun 27 15:37:24 2023 ] 	Training loss: 1.3210.  Training acc: 33.09%.
[ Tue Jun 27 15:37:24 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:37:24 2023 ] Eval epoch: 38
[ Tue Jun 27 15:37:25 2023 ] 	Mean test loss of 625 batches: 1.112978.
[ Tue Jun 27 15:37:25 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:25 2023 ] Training epoch: 39
[ Tue Jun 27 15:37:27 2023 ] 	Training loss: 1.3443.  Training acc: 34.10%.
[ Tue Jun 27 15:37:27 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:37:27 2023 ] Eval epoch: 39
[ Tue Jun 27 15:37:28 2023 ] 	Mean test loss of 625 batches: 1.113991.
[ Tue Jun 27 15:37:28 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:28 2023 ] Training epoch: 40
[ Tue Jun 27 15:37:31 2023 ] 	Training loss: 1.3779.  Training acc: 32.90%.
[ Tue Jun 27 15:37:31 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:37:31 2023 ] Eval epoch: 40
[ Tue Jun 27 15:37:31 2023 ] 	Mean test loss of 625 batches: 1.114445.
[ Tue Jun 27 15:37:31 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:32 2023 ] Best accuracy: 0.8947368421052632
[ Tue Jun 27 15:37:32 2023 ] Epoch number: 1
[ Tue Jun 27 15:37:32 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 15:37:32 2023 ] Weight decay: 0.0005
[ Tue Jun 27 15:37:32 2023 ] Base LR: 0.1
[ Tue Jun 27 15:37:32 2023 ] Batch Size: 64
[ Tue Jun 27 15:37:32 2023 ] Test Batch Size: 64
[ Tue Jun 27 15:37:32 2023 ] seed: 1
[ Tue Jun 27 15:37:32 2023 ] Start training Corrector
[ Tue Jun 27 15:40:34 2023 ] using warm up, epoch: 5
[ Tue Jun 27 15:40:34 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 15:40:34 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 15:40:34 2023 ] Start training Predictor
[ Tue Jun 27 15:40:34 2023 ] Training epoch: 1
[ Tue Jun 27 15:40:40 2023 ] 	Training loss: 119.9766.  Training acc: 35.85%.
[ Tue Jun 27 15:40:40 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Jun 27 15:40:40 2023 ] Eval epoch: 1
[ Tue Jun 27 15:40:41 2023 ] 	Mean test loss of 625 batches: 4772.667285.
[ Tue Jun 27 15:40:41 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:40:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:40:41 2023 ] Training epoch: 2
[ Tue Jun 27 15:40:43 2023 ] 	Training loss: 13.6168.  Training acc: 35.66%.
[ Tue Jun 27 15:40:43 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:40:43 2023 ] Eval epoch: 2
[ Tue Jun 27 15:40:44 2023 ] 	Mean test loss of 625 batches: 2.709926.
[ Tue Jun 27 15:40:44 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:40:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:40:44 2023 ] Training epoch: 3
[ Tue Jun 27 15:40:46 2023 ] 	Training loss: 7.7428.  Training acc: 35.48%.
[ Tue Jun 27 15:40:46 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:40:46 2023 ] Eval epoch: 3
[ Tue Jun 27 15:40:46 2023 ] 	Mean test loss of 625 batches: 3.361574.
[ Tue Jun 27 15:40:46 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:40:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:40:46 2023 ] Training epoch: 4
[ Tue Jun 27 15:40:48 2023 ] 	Training loss: 5.9871.  Training acc: 38.97%.
[ Tue Jun 27 15:40:48 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:40:48 2023 ] Eval epoch: 4
[ Tue Jun 27 15:40:49 2023 ] 	Mean test loss of 625 batches: 3.582383.
[ Tue Jun 27 15:40:49 2023 ] 	Top1: 42.11%
[ Tue Jun 27 15:40:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:40:49 2023 ] Training epoch: 5
[ Tue Jun 27 15:40:51 2023 ] 	Training loss: 3.8521.  Training acc: 53.58%.
[ Tue Jun 27 15:40:51 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:40:51 2023 ] Eval epoch: 5
[ Tue Jun 27 15:40:52 2023 ] 	Mean test loss of 625 batches: 1.599099.
[ Tue Jun 27 15:40:52 2023 ] 	Top1: 70.18%
[ Tue Jun 27 15:40:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:40:52 2023 ] Training epoch: 6
[ Tue Jun 27 15:40:54 2023 ] 	Training loss: 2.5759.  Training acc: 62.41%.
[ Tue Jun 27 15:40:54 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:40:54 2023 ] Eval epoch: 6
[ Tue Jun 27 15:40:54 2023 ] 	Mean test loss of 625 batches: 2.743328.
[ Tue Jun 27 15:40:54 2023 ] 	Top1: 71.93%
[ Tue Jun 27 15:40:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:40:54 2023 ] Training epoch: 7
[ Tue Jun 27 15:40:56 2023 ] 	Training loss: 1.6137.  Training acc: 67.00%.
[ Tue Jun 27 15:40:56 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:40:56 2023 ] Eval epoch: 7
[ Tue Jun 27 15:40:57 2023 ] 	Mean test loss of 625 batches: 1.059413.
[ Tue Jun 27 15:40:57 2023 ] 	Top1: 66.67%
[ Tue Jun 27 15:40:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:40:57 2023 ] Training epoch: 8
[ Tue Jun 27 15:40:59 2023 ] 	Training loss: 1.5003.  Training acc: 68.11%.
[ Tue Jun 27 15:40:59 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:40:59 2023 ] Eval epoch: 8
[ Tue Jun 27 15:41:00 2023 ] 	Mean test loss of 625 batches: 1.690240.
[ Tue Jun 27 15:41:00 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:41:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:00 2023 ] Training epoch: 9
[ Tue Jun 27 15:41:02 2023 ] 	Training loss: 1.1643.  Training acc: 72.98%.
[ Tue Jun 27 15:41:02 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:41:02 2023 ] Eval epoch: 9
[ Tue Jun 27 15:41:02 2023 ] 	Mean test loss of 625 batches: 1.074190.
[ Tue Jun 27 15:41:02 2023 ] 	Top1: 68.42%
[ Tue Jun 27 15:41:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:02 2023 ] Training epoch: 10
[ Tue Jun 27 15:41:04 2023 ] 	Training loss: 1.1496.  Training acc: 71.60%.
[ Tue Jun 27 15:41:04 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:41:04 2023 ] Eval epoch: 10
[ Tue Jun 27 15:41:05 2023 ] 	Mean test loss of 625 batches: 0.631627.
[ Tue Jun 27 15:41:05 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:41:05 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:05 2023 ] Training epoch: 11
[ Tue Jun 27 15:41:07 2023 ] 	Training loss: 0.8037.  Training acc: 83.92%.
[ Tue Jun 27 15:41:07 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 15:41:07 2023 ] Eval epoch: 11
[ Tue Jun 27 15:41:08 2023 ] 	Mean test loss of 625 batches: 0.573199.
[ Tue Jun 27 15:41:08 2023 ] 	Top1: 96.49%
[ Tue Jun 27 15:41:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:08 2023 ] Training epoch: 12
[ Tue Jun 27 15:41:10 2023 ] 	Training loss: 0.7512.  Training acc: 88.14%.
[ Tue Jun 27 15:41:10 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:41:10 2023 ] Eval epoch: 12
[ Tue Jun 27 15:41:10 2023 ] 	Mean test loss of 625 batches: 0.518665.
[ Tue Jun 27 15:41:10 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:10 2023 ] Training epoch: 13
[ Tue Jun 27 15:41:12 2023 ] 	Training loss: 0.7039.  Training acc: 89.71%.
[ Tue Jun 27 15:41:12 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:41:12 2023 ] Eval epoch: 13
[ Tue Jun 27 15:41:13 2023 ] 	Mean test loss of 625 batches: 0.545137.
[ Tue Jun 27 15:41:13 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:13 2023 ] Training epoch: 14
[ Tue Jun 27 15:41:16 2023 ] 	Training loss: 0.6731.  Training acc: 91.91%.
[ Tue Jun 27 15:41:16 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:41:16 2023 ] Eval epoch: 14
[ Tue Jun 27 15:41:17 2023 ] 	Mean test loss of 625 batches: 0.535256.
[ Tue Jun 27 15:41:17 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:17 2023 ] Training epoch: 15
[ Tue Jun 27 15:41:20 2023 ] 	Training loss: 0.6499.  Training acc: 93.29%.
[ Tue Jun 27 15:41:20 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:41:20 2023 ] Eval epoch: 15
[ Tue Jun 27 15:41:20 2023 ] 	Mean test loss of 625 batches: 0.496499.
[ Tue Jun 27 15:41:20 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:20 2023 ] Training epoch: 16
[ Tue Jun 27 15:41:23 2023 ] 	Training loss: 0.6150.  Training acc: 94.12%.
[ Tue Jun 27 15:41:23 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:41:23 2023 ] Eval epoch: 16
[ Tue Jun 27 15:41:24 2023 ] 	Mean test loss of 625 batches: 0.493946.
[ Tue Jun 27 15:41:24 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:24 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:24 2023 ] Training epoch: 17
[ Tue Jun 27 15:41:27 2023 ] 	Training loss: 0.5716.  Training acc: 95.96%.
[ Tue Jun 27 15:41:27 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:41:27 2023 ] Eval epoch: 17
[ Tue Jun 27 15:41:27 2023 ] 	Mean test loss of 625 batches: 0.470622.
[ Tue Jun 27 15:41:27 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:27 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:27 2023 ] Training epoch: 18
[ Tue Jun 27 15:41:30 2023 ] 	Training loss: 0.5525.  Training acc: 95.68%.
[ Tue Jun 27 15:41:30 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:41:30 2023 ] Eval epoch: 18
[ Tue Jun 27 15:41:31 2023 ] 	Mean test loss of 625 batches: 0.470889.
[ Tue Jun 27 15:41:31 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:31 2023 ] Training epoch: 19
[ Tue Jun 27 15:41:34 2023 ] 	Training loss: 0.5949.  Training acc: 93.93%.
[ Tue Jun 27 15:41:34 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:41:34 2023 ] Eval epoch: 19
[ Tue Jun 27 15:41:35 2023 ] 	Mean test loss of 625 batches: 0.442410.
[ Tue Jun 27 15:41:35 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:35 2023 ] Training epoch: 20
[ Tue Jun 27 15:41:38 2023 ] 	Training loss: 0.5414.  Training acc: 96.05%.
[ Tue Jun 27 15:41:38 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:41:38 2023 ] Eval epoch: 20
[ Tue Jun 27 15:41:38 2023 ] 	Mean test loss of 625 batches: 0.443621.
[ Tue Jun 27 15:41:38 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:38 2023 ] Training epoch: 21
[ Tue Jun 27 15:41:41 2023 ] 	Training loss: 0.5152.  Training acc: 97.33%.
[ Tue Jun 27 15:41:41 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:41:41 2023 ] Eval epoch: 21
[ Tue Jun 27 15:41:42 2023 ] 	Mean test loss of 625 batches: 0.450562.
[ Tue Jun 27 15:41:42 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:42 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:42 2023 ] Training epoch: 22
[ Tue Jun 27 15:41:45 2023 ] 	Training loss: 0.5126.  Training acc: 97.06%.
[ Tue Jun 27 15:41:45 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Tue Jun 27 15:41:45 2023 ] Eval epoch: 22
[ Tue Jun 27 15:41:46 2023 ] 	Mean test loss of 625 batches: 0.447566.
[ Tue Jun 27 15:41:46 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:46 2023 ] Training epoch: 23
[ Tue Jun 27 15:41:49 2023 ] 	Training loss: 0.5146.  Training acc: 97.43%.
[ Tue Jun 27 15:41:49 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:41:49 2023 ] Eval epoch: 23
[ Tue Jun 27 15:41:49 2023 ] 	Mean test loss of 625 batches: 0.445504.
[ Tue Jun 27 15:41:49 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:49 2023 ] Training epoch: 24
[ Tue Jun 27 15:41:52 2023 ] 	Training loss: 0.5081.  Training acc: 96.97%.
[ Tue Jun 27 15:41:52 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:41:52 2023 ] Eval epoch: 24
[ Tue Jun 27 15:41:53 2023 ] 	Mean test loss of 625 batches: 0.443282.
[ Tue Jun 27 15:41:53 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:53 2023 ] Training epoch: 25
[ Tue Jun 27 15:41:56 2023 ] 	Training loss: 0.5172.  Training acc: 95.86%.
[ Tue Jun 27 15:41:56 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:41:56 2023 ] Eval epoch: 25
[ Tue Jun 27 15:41:57 2023 ] 	Mean test loss of 625 batches: 0.445308.
[ Tue Jun 27 15:41:57 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:57 2023 ] Training epoch: 26
[ Tue Jun 27 15:42:00 2023 ] 	Training loss: 0.5198.  Training acc: 96.88%.
[ Tue Jun 27 15:42:00 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:42:00 2023 ] Eval epoch: 26
[ Tue Jun 27 15:42:00 2023 ] 	Mean test loss of 625 batches: 0.439695.
[ Tue Jun 27 15:42:00 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:00 2023 ] Training epoch: 27
[ Tue Jun 27 15:42:03 2023 ] 	Training loss: 0.5107.  Training acc: 96.97%.
[ Tue Jun 27 15:42:03 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:42:03 2023 ] Eval epoch: 27
[ Tue Jun 27 15:42:04 2023 ] 	Mean test loss of 625 batches: 0.441367.
[ Tue Jun 27 15:42:04 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:04 2023 ] Training epoch: 28
[ Tue Jun 27 15:42:06 2023 ] 	Training loss: 0.5082.  Training acc: 96.97%.
[ Tue Jun 27 15:42:06 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:42:06 2023 ] Eval epoch: 28
[ Tue Jun 27 15:42:07 2023 ] 	Mean test loss of 625 batches: 0.440755.
[ Tue Jun 27 15:42:07 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:07 2023 ] Training epoch: 29
[ Tue Jun 27 15:42:09 2023 ] 	Training loss: 0.5244.  Training acc: 95.96%.
[ Tue Jun 27 15:42:09 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:42:09 2023 ] Eval epoch: 29
[ Tue Jun 27 15:42:09 2023 ] 	Mean test loss of 625 batches: 0.434891.
[ Tue Jun 27 15:42:09 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:09 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:09 2023 ] Training epoch: 30
[ Tue Jun 27 15:42:11 2023 ] 	Training loss: 0.5043.  Training acc: 96.32%.
[ Tue Jun 27 15:42:11 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:42:11 2023 ] Eval epoch: 30
[ Tue Jun 27 15:42:12 2023 ] 	Mean test loss of 625 batches: 0.432892.
[ Tue Jun 27 15:42:12 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:12 2023 ] Training epoch: 31
[ Tue Jun 27 15:42:14 2023 ] 	Training loss: 0.5167.  Training acc: 96.32%.
[ Tue Jun 27 15:42:14 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:42:14 2023 ] Eval epoch: 31
[ Tue Jun 27 15:42:15 2023 ] 	Mean test loss of 625 batches: 0.430335.
[ Tue Jun 27 15:42:15 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:15 2023 ] Training epoch: 32
[ Tue Jun 27 15:42:17 2023 ] 	Training loss: 0.5108.  Training acc: 96.51%.
[ Tue Jun 27 15:42:17 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:42:17 2023 ] Eval epoch: 32
[ Tue Jun 27 15:42:17 2023 ] 	Mean test loss of 625 batches: 0.431867.
[ Tue Jun 27 15:42:17 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:17 2023 ] Training epoch: 33
[ Tue Jun 27 15:42:19 2023 ] 	Training loss: 0.4703.  Training acc: 98.16%.
[ Tue Jun 27 15:42:19 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:42:19 2023 ] Eval epoch: 33
[ Tue Jun 27 15:42:20 2023 ] 	Mean test loss of 625 batches: 0.420174.
[ Tue Jun 27 15:42:20 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:20 2023 ] Training epoch: 34
[ Tue Jun 27 15:42:22 2023 ] 	Training loss: 0.4762.  Training acc: 96.78%.
[ Tue Jun 27 15:42:22 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:42:22 2023 ] Eval epoch: 34
[ Tue Jun 27 15:42:23 2023 ] 	Mean test loss of 625 batches: 0.411865.
[ Tue Jun 27 15:42:23 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:23 2023 ] Training epoch: 35
[ Tue Jun 27 15:42:25 2023 ] 	Training loss: 0.4820.  Training acc: 97.24%.
[ Tue Jun 27 15:42:25 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:42:25 2023 ] Eval epoch: 35
[ Tue Jun 27 15:42:25 2023 ] 	Mean test loss of 625 batches: 0.421268.
[ Tue Jun 27 15:42:25 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:25 2023 ] Training epoch: 36
[ Tue Jun 27 15:42:27 2023 ] 	Training loss: 0.4824.  Training acc: 97.33%.
[ Tue Jun 27 15:42:27 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:42:27 2023 ] Eval epoch: 36
[ Tue Jun 27 15:42:28 2023 ] 	Mean test loss of 625 batches: 0.399181.
[ Tue Jun 27 15:42:28 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:28 2023 ] Training epoch: 37
[ Tue Jun 27 15:42:30 2023 ] 	Training loss: 0.4750.  Training acc: 97.61%.
[ Tue Jun 27 15:42:30 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:42:30 2023 ] Eval epoch: 37
[ Tue Jun 27 15:42:31 2023 ] 	Mean test loss of 625 batches: 0.388643.
[ Tue Jun 27 15:42:31 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:31 2023 ] Training epoch: 38
[ Tue Jun 27 15:42:33 2023 ] 	Training loss: 0.4617.  Training acc: 97.52%.
[ Tue Jun 27 15:42:33 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:42:33 2023 ] Eval epoch: 38
[ Tue Jun 27 15:42:34 2023 ] 	Mean test loss of 625 batches: 0.388838.
[ Tue Jun 27 15:42:34 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:34 2023 ] Training epoch: 39
[ Tue Jun 27 15:42:36 2023 ] 	Training loss: 0.4681.  Training acc: 97.33%.
[ Tue Jun 27 15:42:36 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:42:36 2023 ] Eval epoch: 39
[ Tue Jun 27 15:42:37 2023 ] 	Mean test loss of 625 batches: 0.370915.
[ Tue Jun 27 15:42:37 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:37 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:37 2023 ] Training epoch: 40
[ Tue Jun 27 15:42:40 2023 ] 	Training loss: 0.4723.  Training acc: 97.06%.
[ Tue Jun 27 15:42:40 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:42:40 2023 ] Eval epoch: 40
[ Tue Jun 27 15:42:41 2023 ] 	Mean test loss of 625 batches: 0.353063.
[ Tue Jun 27 15:42:41 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:41 2023 ] Best accuracy: 1.0
[ Tue Jun 27 15:42:41 2023 ] Epoch number: 12
[ Tue Jun 27 15:42:41 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 15:42:41 2023 ] Weight decay: 0.0005
[ Tue Jun 27 15:42:41 2023 ] Base LR: 0.1
[ Tue Jun 27 15:42:41 2023 ] Batch Size: 64
[ Tue Jun 27 15:42:41 2023 ] Test Batch Size: 64
[ Tue Jun 27 15:42:41 2023 ] seed: 1
[ Tue Jun 27 15:42:41 2023 ] Start training Corrector
[ Tue Jun 27 15:47:38 2023 ] using warm up, epoch: 5
[ Tue Jun 27 15:47:38 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 15:47:38 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 15:47:38 2023 ] Start training Predictor
[ Tue Jun 27 15:47:38 2023 ] Training epoch: 1
[ Tue Jun 27 15:47:42 2023 ] 	Training loss: 104.8860.  Training acc: 34.19%.
[ Tue Jun 27 15:47:42 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jun 27 15:47:42 2023 ] Eval epoch: 1
[ Tue Jun 27 15:47:43 2023 ] 	Mean test loss of 625 batches: 978.287256.
[ Tue Jun 27 15:47:43 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:47:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:47:43 2023 ] Training epoch: 2
[ Tue Jun 27 15:47:45 2023 ] 	Training loss: 18.7444.  Training acc: 36.40%.
[ Tue Jun 27 15:47:45 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:47:45 2023 ] Eval epoch: 2
[ Tue Jun 27 15:47:46 2023 ] 	Mean test loss of 625 batches: 1050.685474.
[ Tue Jun 27 15:47:46 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:47:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:47:46 2023 ] Training epoch: 3
[ Tue Jun 27 15:47:48 2023 ] 	Training loss: 7.0683.  Training acc: 41.27%.
[ Tue Jun 27 15:47:48 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:47:48 2023 ] Eval epoch: 3
[ Tue Jun 27 15:47:48 2023 ] 	Mean test loss of 625 batches: 36.760842.
[ Tue Jun 27 15:47:48 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:47:48 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:47:48 2023 ] Training epoch: 4
[ Tue Jun 27 15:47:50 2023 ] 	Training loss: 6.5829.  Training acc: 40.26%.
[ Tue Jun 27 15:47:50 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 15:47:50 2023 ] Eval epoch: 4
[ Tue Jun 27 15:47:51 2023 ] 	Mean test loss of 625 batches: 16.520362.
[ Tue Jun 27 15:47:51 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:47:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:47:51 2023 ] Training epoch: 5
[ Tue Jun 27 15:47:52 2023 ] 	Training loss: 7.0204.  Training acc: 49.45%.
[ Tue Jun 27 15:47:52 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:47:52 2023 ] Eval epoch: 5
[ Tue Jun 27 15:47:53 2023 ] 	Mean test loss of 625 batches: 5.653563.
[ Tue Jun 27 15:47:53 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:47:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:47:53 2023 ] Training epoch: 6
[ Tue Jun 27 15:47:55 2023 ] 	Training loss: 2.8673.  Training acc: 56.43%.
[ Tue Jun 27 15:47:55 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 15:47:55 2023 ] Eval epoch: 6
[ Tue Jun 27 15:47:56 2023 ] 	Mean test loss of 625 batches: 2.046410.
[ Tue Jun 27 15:47:56 2023 ] 	Top1: 56.14%
[ Tue Jun 27 15:47:56 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:47:56 2023 ] Training epoch: 7
[ Tue Jun 27 15:47:58 2023 ] 	Training loss: 1.6091.  Training acc: 62.32%.
[ Tue Jun 27 15:47:58 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:47:58 2023 ] Eval epoch: 7
[ Tue Jun 27 15:47:58 2023 ] 	Mean test loss of 625 batches: 0.991474.
[ Tue Jun 27 15:47:58 2023 ] 	Top1: 64.91%
[ Tue Jun 27 15:47:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:47:58 2023 ] Training epoch: 8
[ Tue Jun 27 15:48:00 2023 ] 	Training loss: 1.9073.  Training acc: 63.24%.
[ Tue Jun 27 15:48:00 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 15:48:00 2023 ] Eval epoch: 8
[ Tue Jun 27 15:48:01 2023 ] 	Mean test loss of 625 batches: 1.176965.
[ Tue Jun 27 15:48:01 2023 ] 	Top1: 77.19%
[ Tue Jun 27 15:48:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:01 2023 ] Training epoch: 9
[ Tue Jun 27 15:48:03 2023 ] 	Training loss: 1.1902.  Training acc: 72.79%.
[ Tue Jun 27 15:48:03 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:48:03 2023 ] Eval epoch: 9
[ Tue Jun 27 15:48:03 2023 ] 	Mean test loss of 625 batches: 0.959694.
[ Tue Jun 27 15:48:03 2023 ] 	Top1: 75.44%
[ Tue Jun 27 15:48:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:03 2023 ] Training epoch: 10
[ Tue Jun 27 15:48:06 2023 ] 	Training loss: 0.9896.  Training acc: 75.55%.
[ Tue Jun 27 15:48:06 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 27 15:48:06 2023 ] Eval epoch: 10
[ Tue Jun 27 15:48:06 2023 ] 	Mean test loss of 625 batches: 0.816847.
[ Tue Jun 27 15:48:06 2023 ] 	Top1: 78.95%
[ Tue Jun 27 15:48:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:06 2023 ] Training epoch: 11
[ Tue Jun 27 15:48:09 2023 ] 	Training loss: 0.8502.  Training acc: 79.69%.
[ Tue Jun 27 15:48:09 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 27 15:48:09 2023 ] Eval epoch: 11
[ Tue Jun 27 15:48:10 2023 ] 	Mean test loss of 625 batches: 0.715951.
[ Tue Jun 27 15:48:10 2023 ] 	Top1: 80.70%
[ Tue Jun 27 15:48:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:10 2023 ] Training epoch: 12
[ Tue Jun 27 15:48:13 2023 ] 	Training loss: 0.8112.  Training acc: 80.97%.
[ Tue Jun 27 15:48:13 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 27 15:48:13 2023 ] Eval epoch: 12
[ Tue Jun 27 15:48:13 2023 ] 	Mean test loss of 625 batches: 0.678766.
[ Tue Jun 27 15:48:13 2023 ] 	Top1: 84.21%
[ Tue Jun 27 15:48:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:13 2023 ] Training epoch: 13
[ Tue Jun 27 15:48:16 2023 ] 	Training loss: 0.7550.  Training acc: 83.18%.
[ Tue Jun 27 15:48:16 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 27 15:48:16 2023 ] Eval epoch: 13
[ Tue Jun 27 15:48:17 2023 ] 	Mean test loss of 625 batches: 0.652956.
[ Tue Jun 27 15:48:17 2023 ] 	Top1: 89.47%
[ Tue Jun 27 15:48:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:17 2023 ] Training epoch: 14
[ Tue Jun 27 15:48:20 2023 ] 	Training loss: 0.7425.  Training acc: 86.12%.
[ Tue Jun 27 15:48:20 2023 ] 	Time consumption: [Data]12%, [Network]87%
[ Tue Jun 27 15:48:20 2023 ] Eval epoch: 14
[ Tue Jun 27 15:48:20 2023 ] 	Mean test loss of 625 batches: 0.621412.
[ Tue Jun 27 15:48:20 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:48:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:20 2023 ] Training epoch: 15
[ Tue Jun 27 15:48:23 2023 ] 	Training loss: 0.7272.  Training acc: 84.74%.
[ Tue Jun 27 15:48:23 2023 ] 	Time consumption: [Data]12%, [Network]87%
[ Tue Jun 27 15:48:23 2023 ] Eval epoch: 15
[ Tue Jun 27 15:48:23 2023 ] 	Mean test loss of 625 batches: 0.582193.
[ Tue Jun 27 15:48:23 2023 ] 	Top1: 96.49%
[ Tue Jun 27 15:48:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:23 2023 ] Training epoch: 16
[ Tue Jun 27 15:48:25 2023 ] 	Training loss: 0.7342.  Training acc: 86.03%.
[ Tue Jun 27 15:48:25 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:48:25 2023 ] Eval epoch: 16
[ Tue Jun 27 15:48:26 2023 ] 	Mean test loss of 625 batches: 0.526110.
[ Tue Jun 27 15:48:26 2023 ] 	Top1: 98.25%
[ Tue Jun 27 15:48:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:26 2023 ] Training epoch: 17
[ Tue Jun 27 15:48:28 2023 ] 	Training loss: 0.6840.  Training acc: 89.43%.
[ Tue Jun 27 15:48:28 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:48:28 2023 ] Eval epoch: 17
[ Tue Jun 27 15:48:28 2023 ] 	Mean test loss of 625 batches: 0.506492.
[ Tue Jun 27 15:48:28 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:48:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:29 2023 ] Training epoch: 18
[ Tue Jun 27 15:48:31 2023 ] 	Training loss: 0.6772.  Training acc: 89.06%.
[ Tue Jun 27 15:48:31 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:48:31 2023 ] Eval epoch: 18
[ Tue Jun 27 15:48:31 2023 ] 	Mean test loss of 625 batches: 0.547649.
[ Tue Jun 27 15:48:31 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:48:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:31 2023 ] Training epoch: 19
[ Tue Jun 27 15:48:33 2023 ] 	Training loss: 0.6692.  Training acc: 89.06%.
[ Tue Jun 27 15:48:33 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:48:33 2023 ] Eval epoch: 19
[ Tue Jun 27 15:48:34 2023 ] 	Mean test loss of 625 batches: 0.551228.
[ Tue Jun 27 15:48:34 2023 ] 	Top1: 96.49%
[ Tue Jun 27 15:48:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:34 2023 ] Training epoch: 20
[ Tue Jun 27 15:48:36 2023 ] 	Training loss: 0.6473.  Training acc: 89.43%.
[ Tue Jun 27 15:48:36 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:48:36 2023 ] Eval epoch: 20
[ Tue Jun 27 15:48:36 2023 ] 	Mean test loss of 625 batches: 0.607819.
[ Tue Jun 27 15:48:36 2023 ] 	Top1: 89.47%
[ Tue Jun 27 15:48:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:36 2023 ] Training epoch: 21
[ Tue Jun 27 15:48:38 2023 ] 	Training loss: 0.6609.  Training acc: 90.07%.
[ Tue Jun 27 15:48:38 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:48:38 2023 ] Eval epoch: 21
[ Tue Jun 27 15:48:39 2023 ] 	Mean test loss of 625 batches: 0.499467.
[ Tue Jun 27 15:48:39 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:48:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:39 2023 ] Training epoch: 22
[ Tue Jun 27 15:48:40 2023 ] 	Training loss: 0.6252.  Training acc: 90.81%.
[ Tue Jun 27 15:48:40 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:48:40 2023 ] Eval epoch: 22
[ Tue Jun 27 15:48:41 2023 ] 	Mean test loss of 625 batches: 0.500260.
[ Tue Jun 27 15:48:41 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:48:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:41 2023 ] Training epoch: 23
[ Tue Jun 27 15:48:43 2023 ] 	Training loss: 0.6132.  Training acc: 92.28%.
[ Tue Jun 27 15:48:43 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:48:43 2023 ] Eval epoch: 23
[ Tue Jun 27 15:48:44 2023 ] 	Mean test loss of 625 batches: 0.478096.
[ Tue Jun 27 15:48:44 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:48:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:44 2023 ] Training epoch: 24
[ Tue Jun 27 15:48:46 2023 ] 	Training loss: 0.5973.  Training acc: 92.46%.
[ Tue Jun 27 15:48:46 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 15:48:46 2023 ] Eval epoch: 24
[ Tue Jun 27 15:48:46 2023 ] 	Mean test loss of 625 batches: 0.487047.
[ Tue Jun 27 15:48:46 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:48:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:46 2023 ] Training epoch: 25
[ Tue Jun 27 15:48:48 2023 ] 	Training loss: 0.6086.  Training acc: 91.91%.
[ Tue Jun 27 15:48:48 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:48:48 2023 ] Eval epoch: 25
[ Tue Jun 27 15:48:49 2023 ] 	Mean test loss of 625 batches: 0.479925.
[ Tue Jun 27 15:48:49 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:48:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:49 2023 ] Training epoch: 26
[ Tue Jun 27 15:48:51 2023 ] 	Training loss: 0.6007.  Training acc: 92.19%.
[ Tue Jun 27 15:48:51 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:48:51 2023 ] Eval epoch: 26
[ Tue Jun 27 15:48:52 2023 ] 	Mean test loss of 625 batches: 0.489943.
[ Tue Jun 27 15:48:52 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:48:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:52 2023 ] Training epoch: 27
[ Tue Jun 27 15:48:54 2023 ] 	Training loss: 0.6173.  Training acc: 92.19%.
[ Tue Jun 27 15:48:54 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:48:54 2023 ] Eval epoch: 27
[ Tue Jun 27 15:48:54 2023 ] 	Mean test loss of 625 batches: 0.479172.
[ Tue Jun 27 15:48:54 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:48:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:54 2023 ] Training epoch: 28
[ Tue Jun 27 15:48:56 2023 ] 	Training loss: 0.5757.  Training acc: 93.66%.
[ Tue Jun 27 15:48:56 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:48:56 2023 ] Eval epoch: 28
[ Tue Jun 27 15:48:57 2023 ] 	Mean test loss of 625 batches: 0.478404.
[ Tue Jun 27 15:48:57 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:48:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:57 2023 ] Training epoch: 29
[ Tue Jun 27 15:49:00 2023 ] 	Training loss: 0.5703.  Training acc: 93.29%.
[ Tue Jun 27 15:49:00 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 27 15:49:00 2023 ] Eval epoch: 29
[ Tue Jun 27 15:49:00 2023 ] 	Mean test loss of 625 batches: 0.490989.
[ Tue Jun 27 15:49:00 2023 ] 	Top1: 98.25%
[ Tue Jun 27 15:49:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:00 2023 ] Training epoch: 30
[ Tue Jun 27 15:49:03 2023 ] 	Training loss: 0.5543.  Training acc: 93.93%.
[ Tue Jun 27 15:49:03 2023 ] 	Time consumption: [Data]12%, [Network]87%
[ Tue Jun 27 15:49:03 2023 ] Eval epoch: 30
[ Tue Jun 27 15:49:04 2023 ] 	Mean test loss of 625 batches: 0.475705.
[ Tue Jun 27 15:49:04 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:04 2023 ] Training epoch: 31
[ Tue Jun 27 15:49:06 2023 ] 	Training loss: 0.5692.  Training acc: 93.57%.
[ Tue Jun 27 15:49:06 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 27 15:49:06 2023 ] Eval epoch: 31
[ Tue Jun 27 15:49:07 2023 ] 	Mean test loss of 625 batches: 0.468460.
[ Tue Jun 27 15:49:07 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:07 2023 ] Training epoch: 32
[ Tue Jun 27 15:49:10 2023 ] 	Training loss: 0.5858.  Training acc: 92.56%.
[ Tue Jun 27 15:49:10 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 27 15:49:10 2023 ] Eval epoch: 32
[ Tue Jun 27 15:49:10 2023 ] 	Mean test loss of 625 batches: 0.477607.
[ Tue Jun 27 15:49:10 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:10 2023 ] Training epoch: 33
[ Tue Jun 27 15:49:13 2023 ] 	Training loss: 0.5393.  Training acc: 94.94%.
[ Tue Jun 27 15:49:13 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 27 15:49:13 2023 ] Eval epoch: 33
[ Tue Jun 27 15:49:14 2023 ] 	Mean test loss of 625 batches: 0.463982.
[ Tue Jun 27 15:49:14 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:14 2023 ] Training epoch: 34
[ Tue Jun 27 15:49:16 2023 ] 	Training loss: 0.5429.  Training acc: 94.21%.
[ Tue Jun 27 15:49:16 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 27 15:49:16 2023 ] Eval epoch: 34
[ Tue Jun 27 15:49:17 2023 ] 	Mean test loss of 625 batches: 0.470806.
[ Tue Jun 27 15:49:17 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:17 2023 ] Training epoch: 35
[ Tue Jun 27 15:49:20 2023 ] 	Training loss: 0.5279.  Training acc: 96.05%.
[ Tue Jun 27 15:49:20 2023 ] 	Time consumption: [Data]12%, [Network]87%
[ Tue Jun 27 15:49:20 2023 ] Eval epoch: 35
[ Tue Jun 27 15:49:20 2023 ] 	Mean test loss of 625 batches: 0.466979.
[ Tue Jun 27 15:49:20 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:20 2023 ] Training epoch: 36
[ Tue Jun 27 15:49:22 2023 ] 	Training loss: 0.5266.  Training acc: 96.32%.
[ Tue Jun 27 15:49:22 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 15:49:22 2023 ] Eval epoch: 36
[ Tue Jun 27 15:49:23 2023 ] 	Mean test loss of 625 batches: 0.465555.
[ Tue Jun 27 15:49:23 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:23 2023 ] Training epoch: 37
[ Tue Jun 27 15:49:25 2023 ] 	Training loss: 0.5404.  Training acc: 95.59%.
[ Tue Jun 27 15:49:25 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:49:25 2023 ] Eval epoch: 37
[ Tue Jun 27 15:49:25 2023 ] 	Mean test loss of 625 batches: 0.459565.
[ Tue Jun 27 15:49:25 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:25 2023 ] Training epoch: 38
[ Tue Jun 27 15:49:27 2023 ] 	Training loss: 0.5585.  Training acc: 94.21%.
[ Tue Jun 27 15:49:27 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:49:27 2023 ] Eval epoch: 38
[ Tue Jun 27 15:49:28 2023 ] 	Mean test loss of 625 batches: 0.468066.
[ Tue Jun 27 15:49:28 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:28 2023 ] Training epoch: 39
[ Tue Jun 27 15:49:30 2023 ] 	Training loss: 0.5361.  Training acc: 95.77%.
[ Tue Jun 27 15:49:30 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:49:30 2023 ] Eval epoch: 39
[ Tue Jun 27 15:49:30 2023 ] 	Mean test loss of 625 batches: 0.468055.
[ Tue Jun 27 15:49:30 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:31 2023 ] Training epoch: 40
[ Tue Jun 27 15:49:32 2023 ] 	Training loss: 0.5528.  Training acc: 92.92%.
[ Tue Jun 27 15:49:32 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:49:32 2023 ] Eval epoch: 40
[ Tue Jun 27 15:49:33 2023 ] 	Mean test loss of 625 batches: 0.469400.
[ Tue Jun 27 15:49:33 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:34 2023 ] Best accuracy: 1.0
[ Tue Jun 27 15:49:34 2023 ] Epoch number: 17
[ Tue Jun 27 15:49:34 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 15:49:34 2023 ] Weight decay: 0.0005
[ Tue Jun 27 15:49:34 2023 ] Base LR: 0.1
[ Tue Jun 27 15:49:34 2023 ] Batch Size: 64
[ Tue Jun 27 15:49:34 2023 ] Test Batch Size: 64
[ Tue Jun 27 15:49:34 2023 ] seed: 1
[ Tue Jun 27 15:49:34 2023 ] Start training Corrector
[ Tue Jun 27 15:53:27 2023 ] using warm up, epoch: 5
[ Tue Jun 27 15:53:27 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 15:53:27 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 15:53:27 2023 ] Start training Predictor
[ Tue Jun 27 15:53:27 2023 ] Training epoch: 1
[ Tue Jun 27 15:53:32 2023 ] 	Training loss: 108.8274.  Training acc: 34.38%.
[ Tue Jun 27 15:53:32 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:53:32 2023 ] Eval epoch: 1
[ Tue Jun 27 15:53:33 2023 ] 	Mean test loss of 625 batches: 10589.984766.
[ Tue Jun 27 15:53:33 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:53:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:53:33 2023 ] Training epoch: 2
[ Tue Jun 27 15:53:35 2023 ] 	Training loss: 14.4269.  Training acc: 39.34%.
[ Tue Jun 27 15:53:35 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:53:35 2023 ] Eval epoch: 2
[ Tue Jun 27 15:53:35 2023 ] 	Mean test loss of 625 batches: 5199.514990.
[ Tue Jun 27 15:53:35 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:53:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:53:35 2023 ] Training epoch: 3
[ Tue Jun 27 15:53:38 2023 ] 	Training loss: 6.5364.  Training acc: 44.58%.
[ Tue Jun 27 15:53:38 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:53:38 2023 ] Eval epoch: 3
[ Tue Jun 27 15:53:38 2023 ] 	Mean test loss of 625 batches: 15.623695.
[ Tue Jun 27 15:53:38 2023 ] 	Top1: 7.02%
[ Tue Jun 27 15:53:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:53:38 2023 ] Training epoch: 4
[ Tue Jun 27 15:53:40 2023 ] 	Training loss: 5.5094.  Training acc: 48.71%.
[ Tue Jun 27 15:53:40 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:53:40 2023 ] Eval epoch: 4
[ Tue Jun 27 15:53:41 2023 ] 	Mean test loss of 625 batches: 1.829950.
[ Tue Jun 27 15:53:41 2023 ] 	Top1: 52.63%
[ Tue Jun 27 15:53:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:53:41 2023 ] Training epoch: 5
[ Tue Jun 27 15:53:43 2023 ] 	Training loss: 6.9287.  Training acc: 42.65%.
[ Tue Jun 27 15:53:43 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:53:43 2023 ] Eval epoch: 5
[ Tue Jun 27 15:53:44 2023 ] 	Mean test loss of 625 batches: 1606.305151.
[ Tue Jun 27 15:53:44 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:53:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:53:44 2023 ] Training epoch: 6
[ Tue Jun 27 15:53:46 2023 ] 	Training loss: 4.0148.  Training acc: 52.11%.
[ Tue Jun 27 15:53:46 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:53:46 2023 ] Eval epoch: 6
[ Tue Jun 27 15:53:46 2023 ] 	Mean test loss of 625 batches: 5.176137.
[ Tue Jun 27 15:53:46 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:53:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:53:46 2023 ] Training epoch: 7
[ Tue Jun 27 15:53:49 2023 ] 	Training loss: 2.1418.  Training acc: 60.85%.
[ Tue Jun 27 15:53:49 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:53:49 2023 ] Eval epoch: 7
[ Tue Jun 27 15:53:50 2023 ] 	Mean test loss of 625 batches: 2.129398.
[ Tue Jun 27 15:53:50 2023 ] 	Top1: 35.09%
[ Tue Jun 27 15:53:50 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:53:50 2023 ] Training epoch: 8
[ Tue Jun 27 15:53:53 2023 ] 	Training loss: 1.9625.  Training acc: 58.64%.
[ Tue Jun 27 15:53:53 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:53:53 2023 ] Eval epoch: 8
[ Tue Jun 27 15:53:53 2023 ] 	Mean test loss of 625 batches: 1.929126.
[ Tue Jun 27 15:53:53 2023 ] 	Top1: 40.35%
[ Tue Jun 27 15:53:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:53:53 2023 ] Training epoch: 9
[ Tue Jun 27 15:53:56 2023 ] 	Training loss: 1.5025.  Training acc: 63.05%.
[ Tue Jun 27 15:53:56 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:53:56 2023 ] Eval epoch: 9
[ Tue Jun 27 15:53:57 2023 ] 	Mean test loss of 625 batches: 0.845993.
[ Tue Jun 27 15:53:57 2023 ] 	Top1: 64.91%
[ Tue Jun 27 15:53:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:53:57 2023 ] Training epoch: 10
[ Tue Jun 27 15:54:00 2023 ] 	Training loss: 1.6185.  Training acc: 58.92%.
[ Tue Jun 27 15:54:00 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:54:00 2023 ] Eval epoch: 10
[ Tue Jun 27 15:54:01 2023 ] 	Mean test loss of 625 batches: 1.353903.
[ Tue Jun 27 15:54:01 2023 ] 	Top1: 70.18%
[ Tue Jun 27 15:54:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:01 2023 ] Training epoch: 11
[ Tue Jun 27 15:54:03 2023 ] 	Training loss: 1.3164.  Training acc: 64.71%.
[ Tue Jun 27 15:54:03 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:54:03 2023 ] Eval epoch: 11
[ Tue Jun 27 15:54:04 2023 ] 	Mean test loss of 625 batches: 0.700450.
[ Tue Jun 27 15:54:04 2023 ] 	Top1: 84.21%
[ Tue Jun 27 15:54:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:04 2023 ] Training epoch: 12
[ Tue Jun 27 15:54:07 2023 ] 	Training loss: 1.1978.  Training acc: 64.71%.
[ Tue Jun 27 15:54:07 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:54:07 2023 ] Eval epoch: 12
[ Tue Jun 27 15:54:07 2023 ] 	Mean test loss of 625 batches: 0.702256.
[ Tue Jun 27 15:54:07 2023 ] 	Top1: 80.70%
[ Tue Jun 27 15:54:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:08 2023 ] Training epoch: 13
[ Tue Jun 27 15:54:10 2023 ] 	Training loss: 1.0526.  Training acc: 68.29%.
[ Tue Jun 27 15:54:10 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:54:10 2023 ] Eval epoch: 13
[ Tue Jun 27 15:54:11 2023 ] 	Mean test loss of 625 batches: 0.703488.
[ Tue Jun 27 15:54:11 2023 ] 	Top1: 77.19%
[ Tue Jun 27 15:54:11 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:11 2023 ] Training epoch: 14
[ Tue Jun 27 15:54:14 2023 ] 	Training loss: 1.0215.  Training acc: 70.04%.
[ Tue Jun 27 15:54:14 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:54:14 2023 ] Eval epoch: 14
[ Tue Jun 27 15:54:14 2023 ] 	Mean test loss of 625 batches: 0.675968.
[ Tue Jun 27 15:54:14 2023 ] 	Top1: 80.70%
[ Tue Jun 27 15:54:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:14 2023 ] Training epoch: 15
[ Tue Jun 27 15:54:17 2023 ] 	Training loss: 0.9971.  Training acc: 69.30%.
[ Tue Jun 27 15:54:17 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:54:17 2023 ] Eval epoch: 15
[ Tue Jun 27 15:54:18 2023 ] 	Mean test loss of 625 batches: 0.639994.
[ Tue Jun 27 15:54:18 2023 ] 	Top1: 92.98%
[ Tue Jun 27 15:54:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:18 2023 ] Training epoch: 16
[ Tue Jun 27 15:54:21 2023 ] 	Training loss: 0.9761.  Training acc: 71.97%.
[ Tue Jun 27 15:54:21 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:54:21 2023 ] Eval epoch: 16
[ Tue Jun 27 15:54:22 2023 ] 	Mean test loss of 625 batches: 0.626773.
[ Tue Jun 27 15:54:22 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:54:22 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:22 2023 ] Training epoch: 17
[ Tue Jun 27 15:54:25 2023 ] 	Training loss: 0.9402.  Training acc: 73.99%.
[ Tue Jun 27 15:54:25 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:54:25 2023 ] Eval epoch: 17
[ Tue Jun 27 15:54:25 2023 ] 	Mean test loss of 625 batches: 0.614467.
[ Tue Jun 27 15:54:25 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:54:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:25 2023 ] Training epoch: 18
[ Tue Jun 27 15:54:27 2023 ] 	Training loss: 0.9442.  Training acc: 73.53%.
[ Tue Jun 27 15:54:27 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:54:27 2023 ] Eval epoch: 18
[ Tue Jun 27 15:54:28 2023 ] 	Mean test loss of 625 batches: 0.584350.
[ Tue Jun 27 15:54:28 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:54:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:28 2023 ] Training epoch: 19
[ Tue Jun 27 15:54:30 2023 ] 	Training loss: 0.9922.  Training acc: 74.26%.
[ Tue Jun 27 15:54:30 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:54:30 2023 ] Eval epoch: 19
[ Tue Jun 27 15:54:31 2023 ] 	Mean test loss of 625 batches: 0.614977.
[ Tue Jun 27 15:54:31 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:54:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:31 2023 ] Training epoch: 20
[ Tue Jun 27 15:54:33 2023 ] 	Training loss: 0.9812.  Training acc: 73.53%.
[ Tue Jun 27 15:54:33 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:54:33 2023 ] Eval epoch: 20
[ Tue Jun 27 15:54:33 2023 ] 	Mean test loss of 625 batches: 0.529877.
[ Tue Jun 27 15:54:33 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:54:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:33 2023 ] Training epoch: 21
[ Tue Jun 27 15:54:35 2023 ] 	Training loss: 0.8442.  Training acc: 78.31%.
[ Tue Jun 27 15:54:35 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:54:35 2023 ] Eval epoch: 21
[ Tue Jun 27 15:54:36 2023 ] 	Mean test loss of 625 batches: 0.563211.
[ Tue Jun 27 15:54:36 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:54:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:36 2023 ] Training epoch: 22
[ Tue Jun 27 15:54:38 2023 ] 	Training loss: 0.8829.  Training acc: 74.82%.
[ Tue Jun 27 15:54:38 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:54:38 2023 ] Eval epoch: 22
[ Tue Jun 27 15:54:39 2023 ] 	Mean test loss of 625 batches: 0.556108.
[ Tue Jun 27 15:54:39 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:54:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:39 2023 ] Training epoch: 23
[ Tue Jun 27 15:54:41 2023 ] 	Training loss: 0.8451.  Training acc: 78.22%.
[ Tue Jun 27 15:54:41 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:54:41 2023 ] Eval epoch: 23
[ Tue Jun 27 15:54:42 2023 ] 	Mean test loss of 625 batches: 0.589376.
[ Tue Jun 27 15:54:42 2023 ] 	Top1: 87.72%
[ Tue Jun 27 15:54:42 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:42 2023 ] Training epoch: 24
[ Tue Jun 27 15:54:44 2023 ] 	Training loss: 0.8445.  Training acc: 77.39%.
[ Tue Jun 27 15:54:44 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:54:44 2023 ] Eval epoch: 24
[ Tue Jun 27 15:54:44 2023 ] 	Mean test loss of 625 batches: 0.582784.
[ Tue Jun 27 15:54:44 2023 ] 	Top1: 89.47%
[ Tue Jun 27 15:54:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:44 2023 ] Training epoch: 25
[ Tue Jun 27 15:54:47 2023 ] 	Training loss: 0.8750.  Training acc: 76.75%.
[ Tue Jun 27 15:54:47 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:54:47 2023 ] Eval epoch: 25
[ Tue Jun 27 15:54:47 2023 ] 	Mean test loss of 625 batches: 0.566979.
[ Tue Jun 27 15:54:47 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:54:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:47 2023 ] Training epoch: 26
[ Tue Jun 27 15:54:49 2023 ] 	Training loss: 0.8576.  Training acc: 80.33%.
[ Tue Jun 27 15:54:49 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:54:49 2023 ] Eval epoch: 26
[ Tue Jun 27 15:54:50 2023 ] 	Mean test loss of 625 batches: 0.564016.
[ Tue Jun 27 15:54:50 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:54:50 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:50 2023 ] Training epoch: 27
[ Tue Jun 27 15:54:52 2023 ] 	Training loss: 0.8544.  Training acc: 77.85%.
[ Tue Jun 27 15:54:52 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:54:52 2023 ] Eval epoch: 27
[ Tue Jun 27 15:54:53 2023 ] 	Mean test loss of 625 batches: 0.588817.
[ Tue Jun 27 15:54:53 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:54:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:53 2023 ] Training epoch: 28
[ Tue Jun 27 15:54:55 2023 ] 	Training loss: 0.8458.  Training acc: 80.24%.
[ Tue Jun 27 15:54:55 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:54:55 2023 ] Eval epoch: 28
[ Tue Jun 27 15:54:55 2023 ] 	Mean test loss of 625 batches: 0.585070.
[ Tue Jun 27 15:54:55 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:54:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:55 2023 ] Training epoch: 29
[ Tue Jun 27 15:54:57 2023 ] 	Training loss: 0.8147.  Training acc: 80.42%.
[ Tue Jun 27 15:54:57 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:54:57 2023 ] Eval epoch: 29
[ Tue Jun 27 15:54:58 2023 ] 	Mean test loss of 625 batches: 0.568527.
[ Tue Jun 27 15:54:58 2023 ] 	Top1: 92.98%
[ Tue Jun 27 15:54:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:58 2023 ] Training epoch: 30
[ Tue Jun 27 15:55:01 2023 ] 	Training loss: 0.7815.  Training acc: 81.16%.
[ Tue Jun 27 15:55:01 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:55:01 2023 ] Eval epoch: 30
[ Tue Jun 27 15:55:02 2023 ] 	Mean test loss of 625 batches: 0.569008.
[ Tue Jun 27 15:55:02 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:55:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:02 2023 ] Training epoch: 31
[ Tue Jun 27 15:55:05 2023 ] 	Training loss: 0.8013.  Training acc: 81.53%.
[ Tue Jun 27 15:55:05 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:55:05 2023 ] Eval epoch: 31
[ Tue Jun 27 15:55:06 2023 ] 	Mean test loss of 625 batches: 0.556972.
[ Tue Jun 27 15:55:06 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:55:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:06 2023 ] Training epoch: 32
[ Tue Jun 27 15:55:09 2023 ] 	Training loss: 0.8221.  Training acc: 80.88%.
[ Tue Jun 27 15:55:09 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:55:09 2023 ] Eval epoch: 32
[ Tue Jun 27 15:55:09 2023 ] 	Mean test loss of 625 batches: 0.574266.
[ Tue Jun 27 15:55:09 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:55:09 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:09 2023 ] Training epoch: 33
[ Tue Jun 27 15:55:12 2023 ] 	Training loss: 0.7749.  Training acc: 82.35%.
[ Tue Jun 27 15:55:12 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:55:12 2023 ] Eval epoch: 33
[ Tue Jun 27 15:55:13 2023 ] 	Mean test loss of 625 batches: 0.570266.
[ Tue Jun 27 15:55:13 2023 ] 	Top1: 92.98%
[ Tue Jun 27 15:55:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:13 2023 ] Training epoch: 34
[ Tue Jun 27 15:55:16 2023 ] 	Training loss: 0.7785.  Training acc: 81.89%.
[ Tue Jun 27 15:55:16 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:55:16 2023 ] Eval epoch: 34
[ Tue Jun 27 15:55:17 2023 ] 	Mean test loss of 625 batches: 0.567942.
[ Tue Jun 27 15:55:17 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:55:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:17 2023 ] Training epoch: 35
[ Tue Jun 27 15:55:20 2023 ] 	Training loss: 0.7762.  Training acc: 83.27%.
[ Tue Jun 27 15:55:20 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:55:20 2023 ] Eval epoch: 35
[ Tue Jun 27 15:55:20 2023 ] 	Mean test loss of 625 batches: 0.567928.
[ Tue Jun 27 15:55:20 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:55:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:20 2023 ] Training epoch: 36
[ Tue Jun 27 15:55:23 2023 ] 	Training loss: 0.7746.  Training acc: 83.55%.
[ Tue Jun 27 15:55:23 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:55:23 2023 ] Eval epoch: 36
[ Tue Jun 27 15:55:24 2023 ] 	Mean test loss of 625 batches: 0.579187.
[ Tue Jun 27 15:55:24 2023 ] 	Top1: 92.98%
[ Tue Jun 27 15:55:24 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:24 2023 ] Training epoch: 37
[ Tue Jun 27 15:55:27 2023 ] 	Training loss: 0.7962.  Training acc: 82.44%.
[ Tue Jun 27 15:55:27 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:55:27 2023 ] Eval epoch: 37
[ Tue Jun 27 15:55:28 2023 ] 	Mean test loss of 625 batches: 0.564917.
[ Tue Jun 27 15:55:28 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:55:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:28 2023 ] Training epoch: 38
[ Tue Jun 27 15:55:31 2023 ] 	Training loss: 0.8204.  Training acc: 79.50%.
[ Tue Jun 27 15:55:31 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:55:31 2023 ] Eval epoch: 38
[ Tue Jun 27 15:55:31 2023 ] 	Mean test loss of 625 batches: 0.569925.
[ Tue Jun 27 15:55:31 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:55:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:31 2023 ] Training epoch: 39
[ Tue Jun 27 15:55:34 2023 ] 	Training loss: 0.7665.  Training acc: 83.36%.
[ Tue Jun 27 15:55:34 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:55:34 2023 ] Eval epoch: 39
[ Tue Jun 27 15:55:35 2023 ] 	Mean test loss of 625 batches: 0.564737.
[ Tue Jun 27 15:55:35 2023 ] 	Top1: 96.49%
[ Tue Jun 27 15:55:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:35 2023 ] Training epoch: 40
[ Tue Jun 27 15:55:37 2023 ] 	Training loss: 0.7872.  Training acc: 80.70%.
[ Tue Jun 27 15:55:37 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 15:55:37 2023 ] Eval epoch: 40
[ Tue Jun 27 15:55:38 2023 ] 	Mean test loss of 625 batches: 0.547606.
[ Tue Jun 27 15:55:38 2023 ] 	Top1: 96.49%
[ Tue Jun 27 15:55:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:39 2023 ] Best accuracy: 0.9649122807017544
[ Tue Jun 27 15:55:39 2023 ] Epoch number: 39
[ Tue Jun 27 15:55:39 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 15:55:39 2023 ] Weight decay: 0.0005
[ Tue Jun 27 15:55:39 2023 ] Base LR: 0.1
[ Tue Jun 27 15:55:39 2023 ] Batch Size: 64
[ Tue Jun 27 15:55:39 2023 ] Test Batch Size: 64
[ Tue Jun 27 15:55:39 2023 ] seed: 1
[ Tue Jun 27 15:55:39 2023 ] Start training Corrector
[ Tue Jun 27 16:38:52 2023 ] using warm up, epoch: 5
[ Tue Jun 27 16:38:52 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 16:38:52 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 16:38:52 2023 ] Start training Predictor
[ Tue Jun 27 16:38:52 2023 ] Training epoch: 1
[ Tue Jun 27 16:38:58 2023 ] 	Training loss: 101.9899.  Training acc: 34.74%.
[ Tue Jun 27 16:38:58 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Jun 27 16:38:58 2023 ] Eval epoch: 1
[ Tue Jun 27 16:38:58 2023 ] 	Mean test loss of 625 batches: 1255.190503.
[ Tue Jun 27 16:38:58 2023 ] 	Top1: 29.82%
[ Tue Jun 27 16:38:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:38:58 2023 ] Training epoch: 2
[ Tue Jun 27 16:39:01 2023 ] 	Training loss: 23.1777.  Training acc: 34.65%.
[ Tue Jun 27 16:39:01 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 16:39:01 2023 ] Eval epoch: 2
[ Tue Jun 27 16:39:01 2023 ] 	Mean test loss of 625 batches: 1.821319.
[ Tue Jun 27 16:39:01 2023 ] 	Top1: 29.82%
[ Tue Jun 27 16:39:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:01 2023 ] Training epoch: 3
[ Tue Jun 27 16:39:03 2023 ] 	Training loss: 6.8540.  Training acc: 38.97%.
[ Tue Jun 27 16:39:03 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 16:39:03 2023 ] Eval epoch: 3
[ Tue Jun 27 16:39:04 2023 ] 	Mean test loss of 625 batches: 5.692295.
[ Tue Jun 27 16:39:04 2023 ] 	Top1: 33.33%
[ Tue Jun 27 16:39:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:04 2023 ] Training epoch: 4
[ Tue Jun 27 16:39:06 2023 ] 	Training loss: 8.8034.  Training acc: 40.81%.
[ Tue Jun 27 16:39:06 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 16:39:06 2023 ] Eval epoch: 4
[ Tue Jun 27 16:39:07 2023 ] 	Mean test loss of 625 batches: 5.738342.
[ Tue Jun 27 16:39:07 2023 ] 	Top1: 38.60%
[ Tue Jun 27 16:39:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:07 2023 ] Training epoch: 5
[ Tue Jun 27 16:39:09 2023 ] 	Training loss: 6.4375.  Training acc: 37.68%.
[ Tue Jun 27 16:39:09 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 16:39:09 2023 ] Eval epoch: 5
[ Tue Jun 27 16:39:10 2023 ] 	Mean test loss of 625 batches: 2.510940.
[ Tue Jun 27 16:39:10 2023 ] 	Top1: 38.60%
[ Tue Jun 27 16:39:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:10 2023 ] Training epoch: 6
[ Tue Jun 27 16:39:12 2023 ] 	Training loss: 4.8917.  Training acc: 35.20%.
[ Tue Jun 27 16:39:12 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 16:39:12 2023 ] Eval epoch: 6
[ Tue Jun 27 16:39:13 2023 ] 	Mean test loss of 625 batches: 1.281090.
[ Tue Jun 27 16:39:13 2023 ] 	Top1: 38.60%
[ Tue Jun 27 16:39:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:13 2023 ] Training epoch: 7
[ Tue Jun 27 16:39:15 2023 ] 	Training loss: 4.4560.  Training acc: 30.88%.
[ Tue Jun 27 16:39:15 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 16:39:15 2023 ] Eval epoch: 7
[ Tue Jun 27 16:39:15 2023 ] 	Mean test loss of 625 batches: 2.851632.
[ Tue Jun 27 16:39:15 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:15 2023 ] Training epoch: 8
[ Tue Jun 27 16:39:18 2023 ] 	Training loss: 2.9468.  Training acc: 32.90%.
[ Tue Jun 27 16:39:18 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 16:39:18 2023 ] Eval epoch: 8
[ Tue Jun 27 16:39:18 2023 ] 	Mean test loss of 625 batches: 1.266245.
[ Tue Jun 27 16:39:18 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:18 2023 ] Training epoch: 9
[ Tue Jun 27 16:39:20 2023 ] 	Training loss: 2.0882.  Training acc: 33.55%.
[ Tue Jun 27 16:39:20 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 16:39:20 2023 ] Eval epoch: 9
[ Tue Jun 27 16:39:21 2023 ] 	Mean test loss of 625 batches: 1.109682.
[ Tue Jun 27 16:39:21 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:21 2023 ] Training epoch: 10
[ Tue Jun 27 16:39:23 2023 ] 	Training loss: 1.8727.  Training acc: 33.82%.
[ Tue Jun 27 16:39:23 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 16:39:23 2023 ] Eval epoch: 10
[ Tue Jun 27 16:39:24 2023 ] 	Mean test loss of 625 batches: 1.099651.
[ Tue Jun 27 16:39:24 2023 ] 	Top1: 29.82%
[ Tue Jun 27 16:39:24 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:24 2023 ] Training epoch: 11
[ Tue Jun 27 16:39:27 2023 ] 	Training loss: 1.6036.  Training acc: 33.92%.
[ Tue Jun 27 16:39:27 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:39:27 2023 ] Eval epoch: 11
[ Tue Jun 27 16:39:27 2023 ] 	Mean test loss of 625 batches: 1.117603.
[ Tue Jun 27 16:39:27 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:27 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:27 2023 ] Training epoch: 12
[ Tue Jun 27 16:39:30 2023 ] 	Training loss: 1.6132.  Training acc: 34.10%.
[ Tue Jun 27 16:39:30 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:39:30 2023 ] Eval epoch: 12
[ Tue Jun 27 16:39:30 2023 ] 	Mean test loss of 625 batches: 1.128681.
[ Tue Jun 27 16:39:30 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:30 2023 ] Training epoch: 13
[ Tue Jun 27 16:39:33 2023 ] 	Training loss: 1.5206.  Training acc: 33.55%.
[ Tue Jun 27 16:39:33 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 16:39:33 2023 ] Eval epoch: 13
[ Tue Jun 27 16:39:34 2023 ] 	Mean test loss of 625 batches: 1.112145.
[ Tue Jun 27 16:39:34 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:34 2023 ] Training epoch: 14
[ Tue Jun 27 16:39:37 2023 ] 	Training loss: 1.5975.  Training acc: 33.18%.
[ Tue Jun 27 16:39:37 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:39:37 2023 ] Eval epoch: 14
[ Tue Jun 27 16:39:37 2023 ] 	Mean test loss of 625 batches: 1.116946.
[ Tue Jun 27 16:39:37 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:37 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:37 2023 ] Training epoch: 15
[ Tue Jun 27 16:39:40 2023 ] 	Training loss: 1.5412.  Training acc: 34.01%.
[ Tue Jun 27 16:39:40 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:39:40 2023 ] Eval epoch: 15
[ Tue Jun 27 16:39:41 2023 ] 	Mean test loss of 625 batches: 1.115264.
[ Tue Jun 27 16:39:41 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:41 2023 ] Training epoch: 16
[ Tue Jun 27 16:39:43 2023 ] 	Training loss: 1.5013.  Training acc: 34.47%.
[ Tue Jun 27 16:39:43 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 16:39:43 2023 ] Eval epoch: 16
[ Tue Jun 27 16:39:44 2023 ] 	Mean test loss of 625 batches: 1.116938.
[ Tue Jun 27 16:39:44 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:44 2023 ] Training epoch: 17
[ Tue Jun 27 16:39:47 2023 ] 	Training loss: 1.4987.  Training acc: 33.92%.
[ Tue Jun 27 16:39:47 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 16:39:47 2023 ] Eval epoch: 17
[ Tue Jun 27 16:39:47 2023 ] 	Mean test loss of 625 batches: 1.113127.
[ Tue Jun 27 16:39:47 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:47 2023 ] Training epoch: 18
[ Tue Jun 27 16:39:50 2023 ] 	Training loss: 1.4604.  Training acc: 33.55%.
[ Tue Jun 27 16:39:50 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:39:50 2023 ] Eval epoch: 18
[ Tue Jun 27 16:39:51 2023 ] 	Mean test loss of 625 batches: 1.105438.
[ Tue Jun 27 16:39:51 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:51 2023 ] Training epoch: 19
[ Tue Jun 27 16:39:54 2023 ] 	Training loss: 1.4368.  Training acc: 34.93%.
[ Tue Jun 27 16:39:54 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 16:39:54 2023 ] Eval epoch: 19
[ Tue Jun 27 16:39:54 2023 ] 	Mean test loss of 625 batches: 1.117538.
[ Tue Jun 27 16:39:54 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:54 2023 ] Training epoch: 20
[ Tue Jun 27 16:39:57 2023 ] 	Training loss: 1.3810.  Training acc: 36.67%.
[ Tue Jun 27 16:39:57 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:39:57 2023 ] Eval epoch: 20
[ Tue Jun 27 16:39:58 2023 ] 	Mean test loss of 625 batches: 1.115069.
[ Tue Jun 27 16:39:58 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:58 2023 ] Training epoch: 21
[ Tue Jun 27 16:40:00 2023 ] 	Training loss: 1.3759.  Training acc: 35.94%.
[ Tue Jun 27 16:40:00 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 16:40:00 2023 ] Eval epoch: 21
[ Tue Jun 27 16:40:01 2023 ] 	Mean test loss of 625 batches: 1.113885.
[ Tue Jun 27 16:40:01 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:01 2023 ] Training epoch: 22
[ Tue Jun 27 16:40:04 2023 ] 	Training loss: 1.3633.  Training acc: 34.83%.
[ Tue Jun 27 16:40:04 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 16:40:04 2023 ] Eval epoch: 22
[ Tue Jun 27 16:40:04 2023 ] 	Mean test loss of 625 batches: 1.112991.
[ Tue Jun 27 16:40:04 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:04 2023 ] Training epoch: 23
[ Tue Jun 27 16:40:07 2023 ] 	Training loss: 1.3563.  Training acc: 36.95%.
[ Tue Jun 27 16:40:07 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:40:07 2023 ] Eval epoch: 23
[ Tue Jun 27 16:40:07 2023 ] 	Mean test loss of 625 batches: 1.111542.
[ Tue Jun 27 16:40:07 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:07 2023 ] Training epoch: 24
[ Tue Jun 27 16:40:10 2023 ] 	Training loss: 1.3624.  Training acc: 35.02%.
[ Tue Jun 27 16:40:10 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:40:10 2023 ] Eval epoch: 24
[ Tue Jun 27 16:40:11 2023 ] 	Mean test loss of 625 batches: 1.111578.
[ Tue Jun 27 16:40:11 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:11 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:11 2023 ] Training epoch: 25
[ Tue Jun 27 16:40:13 2023 ] 	Training loss: 1.3783.  Training acc: 34.01%.
[ Tue Jun 27 16:40:13 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 16:40:13 2023 ] Eval epoch: 25
[ Tue Jun 27 16:40:14 2023 ] 	Mean test loss of 625 batches: 1.113083.
[ Tue Jun 27 16:40:14 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:14 2023 ] Training epoch: 26
[ Tue Jun 27 16:40:17 2023 ] 	Training loss: 1.3659.  Training acc: 36.31%.
[ Tue Jun 27 16:40:17 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 16:40:17 2023 ] Eval epoch: 26
[ Tue Jun 27 16:40:17 2023 ] 	Mean test loss of 625 batches: 1.112188.
[ Tue Jun 27 16:40:17 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:17 2023 ] Training epoch: 27
[ Tue Jun 27 16:40:20 2023 ] 	Training loss: 1.4055.  Training acc: 32.90%.
[ Tue Jun 27 16:40:20 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 16:40:20 2023 ] Eval epoch: 27
[ Tue Jun 27 16:40:21 2023 ] 	Mean test loss of 625 batches: 1.111092.
[ Tue Jun 27 16:40:21 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:21 2023 ] Training epoch: 28
[ Tue Jun 27 16:40:24 2023 ] 	Training loss: 1.3367.  Training acc: 35.20%.
[ Tue Jun 27 16:40:24 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:40:24 2023 ] Eval epoch: 28
[ Tue Jun 27 16:40:24 2023 ] 	Mean test loss of 625 batches: 1.112015.
[ Tue Jun 27 16:40:24 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:24 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:24 2023 ] Training epoch: 29
[ Tue Jun 27 16:40:27 2023 ] 	Training loss: 1.3614.  Training acc: 36.12%.
[ Tue Jun 27 16:40:27 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 16:40:27 2023 ] Eval epoch: 29
[ Tue Jun 27 16:40:28 2023 ] 	Mean test loss of 625 batches: 1.111970.
[ Tue Jun 27 16:40:28 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:28 2023 ] Training epoch: 30
[ Tue Jun 27 16:40:30 2023 ] 	Training loss: 1.3282.  Training acc: 35.11%.
[ Tue Jun 27 16:40:30 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:40:30 2023 ] Eval epoch: 30
[ Tue Jun 27 16:40:31 2023 ] 	Mean test loss of 625 batches: 1.113564.
[ Tue Jun 27 16:40:31 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:31 2023 ] Training epoch: 31
[ Tue Jun 27 16:40:34 2023 ] 	Training loss: 1.3830.  Training acc: 34.19%.
[ Tue Jun 27 16:40:34 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 16:40:34 2023 ] Eval epoch: 31
[ Tue Jun 27 16:40:34 2023 ] 	Mean test loss of 625 batches: 1.112845.
[ Tue Jun 27 16:40:34 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:34 2023 ] Training epoch: 32
[ Tue Jun 27 16:40:37 2023 ] 	Training loss: 1.3601.  Training acc: 34.93%.
[ Tue Jun 27 16:40:37 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 16:40:37 2023 ] Eval epoch: 32
[ Tue Jun 27 16:40:38 2023 ] 	Mean test loss of 625 batches: 1.112254.
[ Tue Jun 27 16:40:38 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:38 2023 ] Training epoch: 33
[ Tue Jun 27 16:40:40 2023 ] 	Training loss: 1.3180.  Training acc: 36.12%.
[ Tue Jun 27 16:40:40 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:40:40 2023 ] Eval epoch: 33
[ Tue Jun 27 16:40:41 2023 ] 	Mean test loss of 625 batches: 1.112147.
[ Tue Jun 27 16:40:41 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:41 2023 ] Training epoch: 34
[ Tue Jun 27 16:40:44 2023 ] 	Training loss: 1.3534.  Training acc: 32.17%.
[ Tue Jun 27 16:40:44 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 16:40:44 2023 ] Eval epoch: 34
[ Tue Jun 27 16:40:45 2023 ] 	Mean test loss of 625 batches: 1.110738.
[ Tue Jun 27 16:40:45 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:45 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:45 2023 ] Training epoch: 35
[ Tue Jun 27 16:40:47 2023 ] 	Training loss: 1.3361.  Training acc: 34.28%.
[ Tue Jun 27 16:40:47 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:40:47 2023 ] Eval epoch: 35
[ Tue Jun 27 16:40:48 2023 ] 	Mean test loss of 625 batches: 1.109112.
[ Tue Jun 27 16:40:48 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:48 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:48 2023 ] Training epoch: 36
[ Tue Jun 27 16:40:50 2023 ] 	Training loss: 1.3477.  Training acc: 34.83%.
[ Tue Jun 27 16:40:50 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:40:50 2023 ] Eval epoch: 36
[ Tue Jun 27 16:40:51 2023 ] 	Mean test loss of 625 batches: 1.109347.
[ Tue Jun 27 16:40:51 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:51 2023 ] Training epoch: 37
[ Tue Jun 27 16:40:53 2023 ] 	Training loss: 1.3673.  Training acc: 33.92%.
[ Tue Jun 27 16:40:53 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:40:53 2023 ] Eval epoch: 37
[ Tue Jun 27 16:40:54 2023 ] 	Mean test loss of 625 batches: 1.108706.
[ Tue Jun 27 16:40:54 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:54 2023 ] Training epoch: 38
[ Tue Jun 27 16:40:57 2023 ] 	Training loss: 1.3137.  Training acc: 37.22%.
[ Tue Jun 27 16:40:57 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 16:40:57 2023 ] Eval epoch: 38
[ Tue Jun 27 16:40:57 2023 ] 	Mean test loss of 625 batches: 1.107911.
[ Tue Jun 27 16:40:57 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:57 2023 ] Training epoch: 39
[ Tue Jun 27 16:41:00 2023 ] 	Training loss: 1.3351.  Training acc: 35.29%.
[ Tue Jun 27 16:41:00 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:41:00 2023 ] Eval epoch: 39
[ Tue Jun 27 16:41:01 2023 ] 	Mean test loss of 625 batches: 1.108959.
[ Tue Jun 27 16:41:01 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:41:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:41:01 2023 ] Training epoch: 40
[ Tue Jun 27 16:41:03 2023 ] 	Training loss: 1.3692.  Training acc: 32.63%.
[ Tue Jun 27 16:41:03 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:41:03 2023 ] Eval epoch: 40
[ Tue Jun 27 16:41:04 2023 ] 	Mean test loss of 625 batches: 1.110316.
[ Tue Jun 27 16:41:04 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:41:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:41:05 2023 ] Best accuracy: 0.38596491228070173
[ Tue Jun 27 16:41:05 2023 ] Epoch number: 4
[ Tue Jun 27 16:41:05 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 16:41:05 2023 ] Weight decay: 0.0005
[ Tue Jun 27 16:41:05 2023 ] Base LR: 0.1
[ Tue Jun 27 16:41:05 2023 ] Batch Size: 64
[ Tue Jun 27 16:41:05 2023 ] Test Batch Size: 64
[ Tue Jun 27 16:41:05 2023 ] seed: 1
[ Tue Jun 27 16:41:05 2023 ] Start training Corrector
[ Tue Jun 27 16:41:06 2023 ] Training epoch: 1
[ Tue Jun 27 16:41:14 2023 ] 	Training loss: 137.9819.  Training acc: 33.20%.
[ Tue Jun 27 16:41:14 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Jun 27 16:41:15 2023 ] Training epoch: 2
[ Tue Jun 27 16:41:22 2023 ] 	Training loss: 95.9971.  Training acc: 33.20%.
[ Tue Jun 27 16:41:22 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Tue Jun 27 16:41:22 2023 ] Training epoch: 3
[ Tue Jun 27 16:41:28 2023 ] 	Training loss: 74.1226.  Training acc: 33.20%.
[ Tue Jun 27 16:41:28 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Jun 27 16:41:29 2023 ] Training epoch: 4
[ Tue Jun 27 16:41:34 2023 ] 	Training loss: 63.3482.  Training acc: 32.94%.
[ Tue Jun 27 16:41:34 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 27 16:41:35 2023 ] Training epoch: 5
[ Tue Jun 27 16:41:41 2023 ] 	Training loss: 59.9819.  Training acc: 33.07%.
[ Tue Jun 27 16:41:41 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:41:41 2023 ] Training epoch: 6
[ Tue Jun 27 16:41:47 2023 ] 	Training loss: 59.2924.  Training acc: 33.07%.
[ Tue Jun 27 16:41:47 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 16:41:47 2023 ] Training epoch: 7
[ Tue Jun 27 16:41:54 2023 ] 	Training loss: 57.8502.  Training acc: 33.20%.
[ Tue Jun 27 16:41:54 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:41:54 2023 ] Training epoch: 8
[ Tue Jun 27 16:42:01 2023 ] 	Training loss: 58.0435.  Training acc: 33.20%.
[ Tue Jun 27 16:42:01 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:42:02 2023 ] Training epoch: 9
[ Tue Jun 27 16:42:08 2023 ] 	Training loss: 58.0429.  Training acc: 33.20%.
[ Tue Jun 27 16:42:08 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:42:09 2023 ] Training epoch: 10
[ Tue Jun 27 16:42:16 2023 ] 	Training loss: 56.2364.  Training acc: 33.20%.
[ Tue Jun 27 16:42:16 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:42:16 2023 ] Training epoch: 11
[ Tue Jun 27 16:42:23 2023 ] 	Training loss: 55.9647.  Training acc: 33.20%.
[ Tue Jun 27 16:42:23 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Tue Jun 27 16:42:24 2023 ] Training epoch: 12
[ Tue Jun 27 16:42:30 2023 ] 	Training loss: 55.9594.  Training acc: 33.20%.
[ Tue Jun 27 16:42:30 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:42:31 2023 ] Training epoch: 13
[ Tue Jun 27 16:42:38 2023 ] 	Training loss: 55.5630.  Training acc: 33.20%.
[ Tue Jun 27 16:42:38 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:42:38 2023 ] Training epoch: 14
[ Tue Jun 27 16:42:45 2023 ] 	Training loss: 55.6177.  Training acc: 33.20%.
[ Tue Jun 27 16:42:45 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:42:46 2023 ] Training epoch: 15
[ Tue Jun 27 16:42:53 2023 ] 	Training loss: 57.0349.  Training acc: 33.20%.
[ Tue Jun 27 16:42:53 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:42:53 2023 ] Training epoch: 16
[ Tue Jun 27 16:43:00 2023 ] 	Training loss: 55.4454.  Training acc: 33.07%.
[ Tue Jun 27 16:43:00 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:43:01 2023 ] Training epoch: 17
[ Tue Jun 27 16:43:07 2023 ] 	Training loss: 54.9703.  Training acc: 33.07%.
[ Tue Jun 27 16:43:07 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:43:08 2023 ] Training epoch: 18
[ Tue Jun 27 16:43:14 2023 ] 	Training loss: 55.8560.  Training acc: 33.07%.
[ Tue Jun 27 16:43:14 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:43:15 2023 ] Training epoch: 19
[ Tue Jun 27 16:43:22 2023 ] 	Training loss: 54.4661.  Training acc: 33.20%.
[ Tue Jun 27 16:43:22 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:43:22 2023 ] Training epoch: 20
[ Tue Jun 27 16:43:29 2023 ] 	Training loss: 55.6122.  Training acc: 33.07%.
[ Tue Jun 27 16:43:29 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:43:29 2023 ] Training epoch: 21
[ Tue Jun 27 16:43:35 2023 ] 	Training loss: 56.0763.  Training acc: 33.07%.
[ Tue Jun 27 16:43:35 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:43:36 2023 ] Training epoch: 22
[ Tue Jun 27 16:43:41 2023 ] 	Training loss: 54.4800.  Training acc: 33.07%.
[ Tue Jun 27 16:43:41 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:43:42 2023 ] Training epoch: 23
[ Tue Jun 27 16:43:48 2023 ] 	Training loss: 55.7496.  Training acc: 33.20%.
[ Tue Jun 27 16:43:48 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:43:48 2023 ] Training epoch: 24
[ Tue Jun 27 16:43:54 2023 ] 	Training loss: 54.7143.  Training acc: 32.94%.
[ Tue Jun 27 16:43:54 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:43:55 2023 ] Training epoch: 25
[ Tue Jun 27 16:44:01 2023 ] 	Training loss: 56.8142.  Training acc: 32.94%.
[ Tue Jun 27 16:44:01 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:44:02 2023 ] Training epoch: 26
[ Tue Jun 27 16:44:09 2023 ] 	Training loss: 55.7227.  Training acc: 33.20%.
[ Tue Jun 27 16:44:09 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:44:09 2023 ] Training epoch: 27
[ Tue Jun 27 16:44:16 2023 ] using warm up, epoch: 5
[ Tue Jun 27 16:44:16 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 16:44:16 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 16:44:16 2023 ] Start training Predictor
[ Tue Jun 27 16:44:16 2023 ] Training epoch: 1
[ Tue Jun 27 16:44:22 2023 ] 	Training loss: 108.2082.  Training acc: 35.94%.
[ Tue Jun 27 16:44:22 2023 ] 	Time consumption: [Data]05%, [Network]94%
[ Tue Jun 27 16:44:22 2023 ] Eval epoch: 1
[ Tue Jun 27 16:44:23 2023 ] 	Mean test loss of 625 batches: 302.542288.
[ Tue Jun 27 16:44:23 2023 ] 	Top1: 29.82%
[ Tue Jun 27 16:44:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:23 2023 ] Training epoch: 2
[ Tue Jun 27 16:44:25 2023 ] 	Training loss: 8.9051.  Training acc: 36.58%.
[ Tue Jun 27 16:44:25 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:44:25 2023 ] Eval epoch: 2
[ Tue Jun 27 16:44:26 2023 ] 	Mean test loss of 625 batches: 1.563980.
[ Tue Jun 27 16:44:26 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:44:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:26 2023 ] Training epoch: 3
[ Tue Jun 27 16:44:29 2023 ] 	Training loss: 7.0752.  Training acc: 38.88%.
[ Tue Jun 27 16:44:29 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:44:29 2023 ] Eval epoch: 3
[ Tue Jun 27 16:44:29 2023 ] 	Mean test loss of 625 batches: 3.136811.
[ Tue Jun 27 16:44:29 2023 ] 	Top1: 33.33%
[ Tue Jun 27 16:44:29 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:29 2023 ] Training epoch: 4
[ Tue Jun 27 16:44:32 2023 ] 	Training loss: 6.0475.  Training acc: 42.10%.
[ Tue Jun 27 16:44:32 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:44:32 2023 ] Eval epoch: 4
[ Tue Jun 27 16:44:33 2023 ] 	Mean test loss of 625 batches: 1.228071.
[ Tue Jun 27 16:44:33 2023 ] 	Top1: 64.91%
[ Tue Jun 27 16:44:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:33 2023 ] Training epoch: 5
[ Tue Jun 27 16:44:35 2023 ] 	Training loss: 3.6124.  Training acc: 52.57%.
[ Tue Jun 27 16:44:35 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:44:35 2023 ] Eval epoch: 5
[ Tue Jun 27 16:44:36 2023 ] 	Mean test loss of 625 batches: 1.357995.
[ Tue Jun 27 16:44:36 2023 ] 	Top1: 73.68%
[ Tue Jun 27 16:44:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:36 2023 ] Training epoch: 6
[ Tue Jun 27 16:44:39 2023 ] 	Training loss: 3.0785.  Training acc: 57.81%.
[ Tue Jun 27 16:44:39 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 16:44:39 2023 ] Eval epoch: 6
[ Tue Jun 27 16:44:39 2023 ] 	Mean test loss of 625 batches: 1.704206.
[ Tue Jun 27 16:44:39 2023 ] 	Top1: 66.67%
[ Tue Jun 27 16:44:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:39 2023 ] Training epoch: 7
[ Tue Jun 27 16:44:42 2023 ] 	Training loss: 2.3870.  Training acc: 57.35%.
[ Tue Jun 27 16:44:42 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 16:44:42 2023 ] Eval epoch: 7
[ Tue Jun 27 16:44:43 2023 ] 	Mean test loss of 625 batches: 4.069230.
[ Tue Jun 27 16:44:43 2023 ] 	Top1: 57.89%
[ Tue Jun 27 16:44:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:43 2023 ] Training epoch: 8
[ Tue Jun 27 16:44:45 2023 ] 	Training loss: 1.9207.  Training acc: 62.96%.
[ Tue Jun 27 16:44:45 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:44:45 2023 ] Eval epoch: 8
[ Tue Jun 27 16:44:46 2023 ] 	Mean test loss of 625 batches: 1.633154.
[ Tue Jun 27 16:44:46 2023 ] 	Top1: 52.63%
[ Tue Jun 27 16:44:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:46 2023 ] Training epoch: 9
[ Tue Jun 27 16:44:48 2023 ] 	Training loss: 1.2680.  Training acc: 67.28%.
[ Tue Jun 27 16:44:48 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 16:44:48 2023 ] Eval epoch: 9
[ Tue Jun 27 16:44:49 2023 ] 	Mean test loss of 625 batches: 1.120150.
[ Tue Jun 27 16:44:49 2023 ] 	Top1: 66.67%
[ Tue Jun 27 16:44:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:49 2023 ] Training epoch: 10
[ Tue Jun 27 16:44:52 2023 ] 	Training loss: 1.2430.  Training acc: 66.54%.
[ Tue Jun 27 16:44:52 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 16:44:52 2023 ] Eval epoch: 10
[ Tue Jun 27 16:44:53 2023 ] 	Mean test loss of 625 batches: 0.637863.
[ Tue Jun 27 16:44:53 2023 ] 	Top1: 82.46%
[ Tue Jun 27 16:44:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:53 2023 ] Training epoch: 11
[ Tue Jun 27 16:44:55 2023 ] 	Training loss: 0.9849.  Training acc: 64.71%.
[ Tue Jun 27 16:44:55 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:44:55 2023 ] Eval epoch: 11
[ Tue Jun 27 16:44:56 2023 ] 	Mean test loss of 625 batches: 0.732453.
[ Tue Jun 27 16:44:56 2023 ] 	Top1: 52.63%
[ Tue Jun 27 16:44:56 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:56 2023 ] Training epoch: 12
[ Tue Jun 27 16:44:59 2023 ] 	Training loss: 0.8976.  Training acc: 68.29%.
[ Tue Jun 27 16:44:59 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:44:59 2023 ] Eval epoch: 12
[ Tue Jun 27 16:44:59 2023 ] 	Mean test loss of 625 batches: 0.623756.
[ Tue Jun 27 16:44:59 2023 ] 	Top1: 89.47%
[ Tue Jun 27 16:44:59 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:00 2023 ] Training epoch: 13
[ Tue Jun 27 16:45:02 2023 ] 	Training loss: 0.8146.  Training acc: 76.65%.
[ Tue Jun 27 16:45:02 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 16:45:02 2023 ] Eval epoch: 13
[ Tue Jun 27 16:45:03 2023 ] 	Mean test loss of 625 batches: 0.589568.
[ Tue Jun 27 16:45:03 2023 ] 	Top1: 91.23%
[ Tue Jun 27 16:45:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:03 2023 ] Training epoch: 14
[ Tue Jun 27 16:45:06 2023 ] 	Training loss: 0.7634.  Training acc: 79.04%.
[ Tue Jun 27 16:45:06 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 16:45:06 2023 ] Eval epoch: 14
[ Tue Jun 27 16:45:07 2023 ] 	Mean test loss of 625 batches: 0.540452.
[ Tue Jun 27 16:45:07 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:07 2023 ] Training epoch: 15
[ Tue Jun 27 16:45:09 2023 ] 	Training loss: 0.7508.  Training acc: 79.04%.
[ Tue Jun 27 16:45:09 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:45:09 2023 ] Eval epoch: 15
[ Tue Jun 27 16:45:10 2023 ] 	Mean test loss of 625 batches: 0.519865.
[ Tue Jun 27 16:45:10 2023 ] 	Top1: 98.25%
[ Tue Jun 27 16:45:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:10 2023 ] Training epoch: 16
[ Tue Jun 27 16:45:13 2023 ] 	Training loss: 0.7471.  Training acc: 79.87%.
[ Tue Jun 27 16:45:13 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 16:45:13 2023 ] Eval epoch: 16
[ Tue Jun 27 16:45:13 2023 ] 	Mean test loss of 625 batches: 0.515033.
[ Tue Jun 27 16:45:13 2023 ] 	Top1: 94.74%
[ Tue Jun 27 16:45:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:13 2023 ] Training epoch: 17
[ Tue Jun 27 16:45:16 2023 ] 	Training loss: 0.7137.  Training acc: 81.43%.
[ Tue Jun 27 16:45:16 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:45:16 2023 ] Eval epoch: 17
[ Tue Jun 27 16:45:17 2023 ] 	Mean test loss of 625 batches: 0.496435.
[ Tue Jun 27 16:45:17 2023 ] 	Top1: 94.74%
[ Tue Jun 27 16:45:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:17 2023 ] Training epoch: 18
[ Tue Jun 27 16:45:19 2023 ] 	Training loss: 0.7120.  Training acc: 81.25%.
[ Tue Jun 27 16:45:19 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:45:19 2023 ] Eval epoch: 18
[ Tue Jun 27 16:45:20 2023 ] 	Mean test loss of 625 batches: 0.482237.
[ Tue Jun 27 16:45:20 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:20 2023 ] Training epoch: 19
[ Tue Jun 27 16:45:23 2023 ] 	Training loss: 0.7164.  Training acc: 82.72%.
[ Tue Jun 27 16:45:23 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:45:23 2023 ] Eval epoch: 19
[ Tue Jun 27 16:45:23 2023 ] 	Mean test loss of 625 batches: 0.477510.
[ Tue Jun 27 16:45:23 2023 ] 	Top1: 98.25%
[ Tue Jun 27 16:45:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:23 2023 ] Training epoch: 20
[ Tue Jun 27 16:45:26 2023 ] 	Training loss: 0.6704.  Training acc: 85.02%.
[ Tue Jun 27 16:45:26 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:45:26 2023 ] Eval epoch: 20
[ Tue Jun 27 16:45:26 2023 ] 	Mean test loss of 625 batches: 0.485883.
[ Tue Jun 27 16:45:26 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:26 2023 ] Training epoch: 21
[ Tue Jun 27 16:45:29 2023 ] 	Training loss: 0.6490.  Training acc: 87.68%.
[ Tue Jun 27 16:45:29 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 16:45:29 2023 ] Eval epoch: 21
[ Tue Jun 27 16:45:30 2023 ] 	Mean test loss of 625 batches: 0.490056.
[ Tue Jun 27 16:45:30 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:30 2023 ] Training epoch: 22
[ Tue Jun 27 16:45:33 2023 ] 	Training loss: 0.6632.  Training acc: 85.39%.
[ Tue Jun 27 16:45:33 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:45:33 2023 ] Eval epoch: 22
[ Tue Jun 27 16:45:33 2023 ] 	Mean test loss of 625 batches: 0.491727.
[ Tue Jun 27 16:45:33 2023 ] 	Top1: 98.25%
[ Tue Jun 27 16:45:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:33 2023 ] Training epoch: 23
[ Tue Jun 27 16:45:36 2023 ] 	Training loss: 0.6436.  Training acc: 86.31%.
[ Tue Jun 27 16:45:36 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:45:36 2023 ] Eval epoch: 23
[ Tue Jun 27 16:45:37 2023 ] 	Mean test loss of 625 batches: 0.492929.
[ Tue Jun 27 16:45:37 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:37 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:37 2023 ] Training epoch: 24
[ Tue Jun 27 16:45:40 2023 ] 	Training loss: 0.6116.  Training acc: 89.61%.
[ Tue Jun 27 16:45:40 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:45:40 2023 ] Eval epoch: 24
[ Tue Jun 27 16:45:40 2023 ] 	Mean test loss of 625 batches: 0.494638.
[ Tue Jun 27 16:45:40 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:40 2023 ] Training epoch: 25
[ Tue Jun 27 16:45:43 2023 ] 	Training loss: 0.6249.  Training acc: 87.68%.
[ Tue Jun 27 16:45:43 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 16:45:43 2023 ] Eval epoch: 25
[ Tue Jun 27 16:45:44 2023 ] 	Mean test loss of 625 batches: 0.494019.
[ Tue Jun 27 16:45:44 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:44 2023 ] Training epoch: 26
[ Tue Jun 27 16:45:46 2023 ] 	Training loss: 0.6429.  Training acc: 87.50%.
[ Tue Jun 27 16:45:46 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 16:45:46 2023 ] Eval epoch: 26
[ Tue Jun 27 16:45:47 2023 ] 	Mean test loss of 625 batches: 0.485808.
[ Tue Jun 27 16:45:47 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:47 2023 ] Training epoch: 27
[ Tue Jun 27 16:45:50 2023 ] 	Training loss: 0.6099.  Training acc: 89.71%.
[ Tue Jun 27 16:45:50 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 16:45:50 2023 ] Eval epoch: 27
[ Tue Jun 27 16:45:50 2023 ] 	Mean test loss of 625 batches: 0.494132.
[ Tue Jun 27 16:45:50 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:50 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:50 2023 ] Training epoch: 28
[ Tue Jun 27 16:45:53 2023 ] 	Training loss: 0.5895.  Training acc: 90.81%.
[ Tue Jun 27 16:45:53 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 16:45:53 2023 ] Eval epoch: 28
[ Tue Jun 27 16:45:53 2023 ] 	Mean test loss of 625 batches: 0.476396.
[ Tue Jun 27 16:45:53 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:53 2023 ] Training epoch: 29
[ Tue Jun 27 16:45:56 2023 ] 	Training loss: 0.5962.  Training acc: 89.71%.
[ Tue Jun 27 16:45:56 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 16:45:56 2023 ] Eval epoch: 29
[ Tue Jun 27 16:45:57 2023 ] 	Mean test loss of 625 batches: 0.480111.
[ Tue Jun 27 16:45:57 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:57 2023 ] Training epoch: 30
[ Tue Jun 27 16:45:59 2023 ] 	Training loss: 0.5940.  Training acc: 90.44%.
[ Tue Jun 27 16:45:59 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 16:45:59 2023 ] Eval epoch: 30
[ Tue Jun 27 16:46:00 2023 ] 	Mean test loss of 625 batches: 0.491217.
[ Tue Jun 27 16:46:00 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:46:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:00 2023 ] Training epoch: 31
[ Tue Jun 27 16:46:02 2023 ] 	Training loss: 0.5860.  Training acc: 89.89%.
[ Tue Jun 27 16:46:02 2023 ] 	Time consumption: [Data]22%, [Network]77%
[ Tue Jun 27 16:46:02 2023 ] Eval epoch: 31
[ Tue Jun 27 16:46:03 2023 ] 	Mean test loss of 625 batches: 0.484751.
[ Tue Jun 27 16:46:03 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:46:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:03 2023 ] Training epoch: 32
[ Tue Jun 27 16:46:05 2023 ] 	Training loss: 0.6075.  Training acc: 88.33%.
[ Tue Jun 27 16:46:05 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Tue Jun 27 16:46:05 2023 ] Eval epoch: 32
[ Tue Jun 27 16:46:06 2023 ] 	Mean test loss of 625 batches: 0.492199.
[ Tue Jun 27 16:46:06 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:46:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:06 2023 ] Training epoch: 33
[ Tue Jun 27 16:46:09 2023 ] 	Training loss: 0.5733.  Training acc: 91.08%.
[ Tue Jun 27 16:46:09 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 16:46:09 2023 ] Eval epoch: 33
[ Tue Jun 27 16:46:09 2023 ] 	Mean test loss of 625 batches: 0.482159.
[ Tue Jun 27 16:46:09 2023 ] 	Top1: 98.25%
[ Tue Jun 27 16:46:09 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:09 2023 ] Training epoch: 34
[ Tue Jun 27 16:46:12 2023 ] 	Training loss: 0.5816.  Training acc: 90.99%.
[ Tue Jun 27 16:46:12 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 16:46:12 2023 ] Eval epoch: 34
[ Tue Jun 27 16:46:12 2023 ] 	Mean test loss of 625 batches: 0.471858.
[ Tue Jun 27 16:46:12 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:46:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:12 2023 ] Training epoch: 35
[ Tue Jun 27 16:46:15 2023 ] 	Training loss: 0.5772.  Training acc: 91.45%.
[ Tue Jun 27 16:46:15 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 16:46:15 2023 ] Eval epoch: 35
[ Tue Jun 27 16:46:15 2023 ] 	Mean test loss of 625 batches: 0.479939.
[ Tue Jun 27 16:46:15 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:46:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:15 2023 ] Training epoch: 36
[ Tue Jun 27 16:46:18 2023 ] 	Training loss: 0.5778.  Training acc: 91.36%.
[ Tue Jun 27 16:46:18 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 16:46:18 2023 ] Eval epoch: 36
[ Tue Jun 27 16:46:19 2023 ] 	Mean test loss of 625 batches: 0.484988.
[ Tue Jun 27 16:46:19 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:46:19 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:19 2023 ] Training epoch: 37
[ Tue Jun 27 16:46:22 2023 ] 	Training loss: 0.5800.  Training acc: 91.82%.
[ Tue Jun 27 16:46:22 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 16:46:22 2023 ] Eval epoch: 37
[ Tue Jun 27 16:46:22 2023 ] 	Mean test loss of 625 batches: 0.475576.
[ Tue Jun 27 16:46:22 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:46:22 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:22 2023 ] Training epoch: 38
[ Tue Jun 27 16:46:25 2023 ] 	Training loss: 0.5862.  Training acc: 90.62%.
[ Tue Jun 27 16:46:25 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 16:46:25 2023 ] Eval epoch: 38
[ Tue Jun 27 16:46:26 2023 ] 	Mean test loss of 625 batches: 0.475372.
[ Tue Jun 27 16:46:26 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:46:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:26 2023 ] Training epoch: 39
[ Tue Jun 27 16:46:29 2023 ] 	Training loss: 0.5889.  Training acc: 90.99%.
[ Tue Jun 27 16:46:29 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 16:46:29 2023 ] Eval epoch: 39
[ Tue Jun 27 16:46:30 2023 ] 	Mean test loss of 625 batches: 0.476237.
[ Tue Jun 27 16:46:30 2023 ] 	Top1: 98.25%
[ Tue Jun 27 16:46:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:30 2023 ] Training epoch: 40
[ Tue Jun 27 16:46:32 2023 ] 	Training loss: 0.5982.  Training acc: 89.80%.
[ Tue Jun 27 16:46:32 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 16:46:32 2023 ] Eval epoch: 40
[ Tue Jun 27 16:46:33 2023 ] 	Mean test loss of 625 batches: 0.488101.
[ Tue Jun 27 16:46:33 2023 ] 	Top1: 98.25%
[ Tue Jun 27 16:46:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:34 2023 ] Best accuracy: 0.9824561403508771
[ Tue Jun 27 16:46:34 2023 ] Epoch number: 15
[ Tue Jun 27 16:46:34 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 16:46:34 2023 ] Weight decay: 0.0005
[ Tue Jun 27 16:46:34 2023 ] Base LR: 0.1
[ Tue Jun 27 16:46:34 2023 ] Batch Size: 64
[ Tue Jun 27 16:46:34 2023 ] Test Batch Size: 64
[ Tue Jun 27 16:46:34 2023 ] seed: 1
[ Tue Jun 27 16:46:34 2023 ] Start training Corrector
[ Tue Jun 27 16:46:36 2023 ] Training epoch: 1
[ Tue Jun 27 16:46:45 2023 ] 	Training loss: 136.7540.  Training acc: 38.28%.
[ Tue Jun 27 16:46:45 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Jun 27 16:46:45 2023 ] Training epoch: 2
[ Tue Jun 27 16:46:52 2023 ] 	Training loss: 98.3876.  Training acc: 25.52%.
[ Tue Jun 27 16:46:52 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:46:53 2023 ] Training epoch: 3
[ Tue Jun 27 16:47:00 2023 ] 	Training loss: 71.0875.  Training acc: 38.15%.
[ Tue Jun 27 16:47:00 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:47:01 2023 ] Training epoch: 4
[ Tue Jun 27 16:47:08 2023 ] 	Training loss: 60.9122.  Training acc: 45.18%.
[ Tue Jun 27 16:47:08 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:47:09 2023 ] Training epoch: 5
[ Tue Jun 27 16:47:16 2023 ] 	Training loss: 59.0259.  Training acc: 57.29%.
[ Tue Jun 27 16:47:16 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:47:16 2023 ] Training epoch: 6
[ Tue Jun 27 16:47:23 2023 ] 	Training loss: 58.2735.  Training acc: 71.61%.
[ Tue Jun 27 16:47:23 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:47:24 2023 ] Training epoch: 7
[ Tue Jun 27 16:47:31 2023 ] 	Training loss: 57.1343.  Training acc: 68.62%.
[ Tue Jun 27 16:47:31 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:47:32 2023 ] Training epoch: 8
[ Tue Jun 27 16:47:39 2023 ] 	Training loss: 55.2864.  Training acc: 67.71%.
[ Tue Jun 27 16:47:39 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:47:40 2023 ] Training epoch: 9
[ Tue Jun 27 16:47:46 2023 ] 	Training loss: 56.0683.  Training acc: 61.85%.
[ Tue Jun 27 16:47:46 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:47:47 2023 ] Training epoch: 10
[ Tue Jun 27 16:47:54 2023 ] 	Training loss: 55.0072.  Training acc: 65.36%.
[ Tue Jun 27 16:47:54 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:47:55 2023 ] Training epoch: 11
[ Tue Jun 27 16:48:01 2023 ] 	Training loss: 54.6783.  Training acc: 76.43%.
[ Tue Jun 27 16:48:01 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:48:02 2023 ] Training epoch: 12
[ Tue Jun 27 16:48:08 2023 ] 	Training loss: 54.0312.  Training acc: 78.78%.
[ Tue Jun 27 16:48:08 2023 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Jun 27 16:48:09 2023 ] Training epoch: 13
[ Tue Jun 27 16:48:15 2023 ] 	Training loss: 53.4197.  Training acc: 86.85%.
[ Tue Jun 27 16:48:15 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 16:48:15 2023 ] Training epoch: 14
[ Tue Jun 27 16:48:21 2023 ] 	Training loss: 54.4341.  Training acc: 84.77%.
[ Tue Jun 27 16:48:21 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:48:22 2023 ] Training epoch: 15
[ Tue Jun 27 16:48:29 2023 ] 	Training loss: 54.7670.  Training acc: 80.60%.
[ Tue Jun 27 16:48:29 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Jun 27 16:48:30 2023 ] Training epoch: 16
[ Tue Jun 27 16:48:37 2023 ] 	Training loss: 53.8731.  Training acc: 81.51%.
[ Tue Jun 27 16:48:37 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:48:38 2023 ] Training epoch: 17
[ Tue Jun 27 16:48:45 2023 ] 	Training loss: 53.5563.  Training acc: 82.55%.
[ Tue Jun 27 16:48:45 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:48:45 2023 ] Training epoch: 18
[ Tue Jun 27 16:48:52 2023 ] 	Training loss: 54.5901.  Training acc: 81.64%.
[ Tue Jun 27 16:48:52 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:48:53 2023 ] Training epoch: 19
[ Tue Jun 27 16:49:00 2023 ] 	Training loss: 53.0476.  Training acc: 83.20%.
[ Tue Jun 27 16:49:00 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:49:01 2023 ] Training epoch: 20
[ Tue Jun 27 16:49:08 2023 ] 	Training loss: 54.4973.  Training acc: 79.82%.
[ Tue Jun 27 16:49:08 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:49:09 2023 ] Training epoch: 21
[ Tue Jun 27 16:49:16 2023 ] 	Training loss: 54.4466.  Training acc: 81.90%.
[ Tue Jun 27 16:49:16 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:49:16 2023 ] Training epoch: 22
[ Tue Jun 27 16:49:24 2023 ] 	Training loss: 52.5354.  Training acc: 79.56%.
[ Tue Jun 27 16:49:24 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:49:24 2023 ] Training epoch: 23
[ Tue Jun 27 16:49:32 2023 ] 	Training loss: 53.5847.  Training acc: 80.86%.
[ Tue Jun 27 16:49:32 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:49:32 2023 ] Training epoch: 24
[ Tue Jun 27 16:49:40 2023 ] 	Training loss: 52.6156.  Training acc: 82.94%.
[ Tue Jun 27 16:49:40 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:49:40 2023 ] Training epoch: 25
[ Tue Jun 27 16:49:48 2023 ] 	Training loss: 53.7918.  Training acc: 85.03%.
[ Tue Jun 27 16:49:48 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:49:48 2023 ] Training epoch: 26
[ Tue Jun 27 16:49:56 2023 ] 	Training loss: 53.9902.  Training acc: 85.94%.
[ Tue Jun 27 16:49:56 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:49:56 2023 ] Training epoch: 27
[ Tue Jun 27 16:50:03 2023 ] 	Training loss: 54.7478.  Training acc: 84.77%.
[ Tue Jun 27 16:50:03 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:50:04 2023 ] Training epoch: 28
[ Tue Jun 27 16:50:10 2023 ] 	Training loss: 53.2491.  Training acc: 86.33%.
[ Tue Jun 27 16:50:10 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 16:50:11 2023 ] Training epoch: 29
[ Tue Jun 27 16:50:17 2023 ] 	Training loss: 52.8424.  Training acc: 83.72%.
[ Tue Jun 27 16:50:17 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 16:50:18 2023 ] Training epoch: 30
[ Tue Jun 27 16:50:24 2023 ] 	Training loss: 53.7882.  Training acc: 84.90%.
[ Tue Jun 27 16:50:24 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:50:25 2023 ] Training epoch: 31
[ Tue Jun 27 16:50:32 2023 ] 	Training loss: 52.4508.  Training acc: 83.07%.
[ Tue Jun 27 16:50:32 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:50:32 2023 ] Training epoch: 32
[ Tue Jun 27 16:50:40 2023 ] 	Training loss: 53.5582.  Training acc: 84.51%.
[ Tue Jun 27 16:50:40 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:50:40 2023 ] Training epoch: 33
[ Tue Jun 27 16:50:48 2023 ] 	Training loss: 54.0900.  Training acc: 87.37%.
[ Tue Jun 27 16:50:48 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:50:48 2023 ] Training epoch: 34
[ Tue Jun 27 16:50:55 2023 ] 	Training loss: 51.8644.  Training acc: 85.16%.
[ Tue Jun 27 16:50:55 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:50:56 2023 ] Training epoch: 35
[ Tue Jun 27 16:51:03 2023 ] 	Training loss: 52.7906.  Training acc: 84.51%.
[ Tue Jun 27 16:51:03 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:51:04 2023 ] Training epoch: 36
[ Tue Jun 27 16:51:11 2023 ] 	Training loss: 51.8439.  Training acc: 83.85%.
[ Tue Jun 27 16:51:11 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:51:12 2023 ] Training epoch: 37
[ Tue Jun 27 16:51:19 2023 ] 	Training loss: 54.1384.  Training acc: 83.72%.
[ Tue Jun 27 16:51:19 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:51:20 2023 ] Training epoch: 38
[ Tue Jun 27 16:51:27 2023 ] 	Training loss: 54.2299.  Training acc: 79.30%.
[ Tue Jun 27 16:51:27 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Tue Jun 27 16:51:27 2023 ] Training epoch: 39
[ Tue Jun 27 16:51:34 2023 ] 	Training loss: 54.5294.  Training acc: 79.95%.
[ Tue Jun 27 16:51:34 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:51:35 2023 ] Training epoch: 40
[ Tue Jun 27 16:51:42 2023 ] 	Training loss: 52.7714.  Training acc: 79.82%.
[ Tue Jun 27 16:51:42 2023 ] 	Time consumption: [Data]08%, [Network]91%
