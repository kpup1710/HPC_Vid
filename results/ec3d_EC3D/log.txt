[ Tue Jun 20 04:34:12 2023 ] using warm up, epoch: 5
[ Tue Jun 20 04:34:14 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 20 04:34:14 2023 ] # Parameters: 1538958
[ Tue Jun 20 04:34:14 2023 ] Training epoch: 1
[ Tue Jun 20 04:34:18 2023 ] 	Training loss: 88.5274.  Training acc: 33.82%.
[ Tue Jun 20 04:34:18 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Jun 20 04:34:18 2023 ] Eval epoch: 1
[ Tue Jun 20 04:34:19 2023 ] 	Mean test loss of 625 batches: 1219.693628.
[ Tue Jun 20 04:34:19 2023 ] 	Top1: 38.60%
[ Tue Jun 20 04:34:19 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:34:19 2023 ] Training epoch: 2
[ Tue Jun 20 04:34:21 2023 ] 	Training loss: 8.4884.  Training acc: 35.85%.
[ Tue Jun 20 04:34:21 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 04:34:21 2023 ] Eval epoch: 2
[ Tue Jun 20 04:34:22 2023 ] 	Mean test loss of 625 batches: 21.500105.
[ Tue Jun 20 04:34:22 2023 ] 	Top1: 38.60%
[ Tue Jun 20 04:34:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:34:22 2023 ] Training epoch: 3
[ Tue Jun 20 04:34:23 2023 ] 	Training loss: 5.2676.  Training acc: 49.36%.
[ Tue Jun 20 04:34:23 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 04:34:23 2023 ] Eval epoch: 3
[ Tue Jun 20 04:34:24 2023 ] 	Mean test loss of 625 batches: 19.204166.
[ Tue Jun 20 04:34:24 2023 ] 	Top1: 38.60%
[ Tue Jun 20 04:34:24 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:34:24 2023 ] Training epoch: 4
[ Tue Jun 20 04:34:26 2023 ] 	Training loss: 2.5894.  Training acc: 72.79%.
[ Tue Jun 20 04:34:26 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 04:34:26 2023 ] Eval epoch: 4
[ Tue Jun 20 04:34:26 2023 ] 	Mean test loss of 625 batches: 5.958696.
[ Tue Jun 20 04:34:26 2023 ] 	Top1: 61.40%
[ Tue Jun 20 04:34:26 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:34:26 2023 ] Training epoch: 5
[ Tue Jun 20 04:34:28 2023 ] 	Training loss: 3.7895.  Training acc: 57.72%.
[ Tue Jun 20 04:34:28 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 04:34:28 2023 ] Eval epoch: 5
[ Tue Jun 20 04:34:29 2023 ] 	Mean test loss of 625 batches: 71.419635.
[ Tue Jun 20 04:34:29 2023 ] 	Top1: 29.82%
[ Tue Jun 20 04:34:29 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:34:29 2023 ] Training epoch: 6
[ Tue Jun 20 04:34:31 2023 ] 	Training loss: 5.8226.  Training acc: 60.48%.
[ Tue Jun 20 04:34:31 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 04:34:31 2023 ] Eval epoch: 6
[ Tue Jun 20 04:34:31 2023 ] 	Mean test loss of 625 batches: 39.918753.
[ Tue Jun 20 04:34:31 2023 ] 	Top1: 38.60%
[ Tue Jun 20 04:34:31 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:34:31 2023 ] Training epoch: 7
[ Tue Jun 20 04:34:33 2023 ] 	Training loss: 3.9803.  Training acc: 52.67%.
[ Tue Jun 20 04:34:33 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 04:34:33 2023 ] Eval epoch: 7
[ Tue Jun 20 04:34:34 2023 ] 	Mean test loss of 625 batches: 15.128516.
[ Tue Jun 20 04:34:34 2023 ] 	Top1: 54.39%
[ Tue Jun 20 04:34:34 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:34:34 2023 ] Training epoch: 8
[ Tue Jun 20 04:34:36 2023 ] 	Training loss: 3.0962.  Training acc: 31.62%.
[ Tue Jun 20 04:34:36 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 20 04:34:36 2023 ] Eval epoch: 8
[ Tue Jun 2[ Sun Jun 25 15:58:51 2023 ] using warm up, epoch: 5
[ Sun Jun 25 15:58:53 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 60, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Sun Jun 25 15:58:53 2023 ] # Parameters Predictor: 1553607
[ Sun Jun 25 15:58:53 2023 ] Start training Predictor
[ Sun Jun 25 15:58:53 2023 ] Training epoch: 1
[ Sun Jun 25 16:02:06 2023 ] using warm up, epoch: 5
[ Sun Jun 25 16:02:07 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 60, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Sun Jun 25 16:02:07 2023 ] # Parameters Predictor: 1553607
[ Sun Jun 25 16:02:07 2023 ] Start training Predictor
[ Sun Jun 25 16:02:07 2023 ] Training epoch: 1
[ Sun Jun 25 16:02:39 2023 ] using warm up, epoch: 5
[ Sun Jun 25 16:02:40 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 60, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Sun Jun 25 16:02:40 2023 ] # Parameters Predictor: 1553607
[ Sun Jun 25 16:02:40 2023 ] Start training Predictor
[ Sun Jun 25 16:02:40 2023 ] Training epoch: 1
[ Tue Jun 27 13:49:27 2023 ] using warm up, epoch: 5
[ Tue Jun 27 13:50:53 2023 ] using warm up, epoch: 5
[ Tue Jun 27 13:52:07 2023 ] using warm up, epoch: 5
[ Tue Jun 27 13:52:33 2023 ] using warm up, epoch: 5
[ Tue Jun 27 13:52:51 2023 ] using warm up, epoch: 5
[ Tue Jun 27 13:52:53 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 13:52:53 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 13:52:53 2023 ] Start training Predictor
[ Tue Jun 27 13:52:53 2023 ] Training epoch: 1
[ Tue Jun 27 13:52:59 2023 ] 	Training loss: 109.5587.  Training acc: 36.40%.
[ Tue Jun 27 13:52:59 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 13:52:59 2023 ] Eval epoch: 1
[ Tue Jun 27 13:55:41 2023 ] using warm up, epoch: 5
[ Tue Jun 27 13:55:43 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 13:55:43 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 13:55:43 2023 ] Start training Predictor
[ Tue Jun 27 13:55:43 2023 ] Training epoch: 1
[ Tue Jun 27 13:56:50 2023 ] using warm up, epoch: 5
[ Tue Jun 27 13:56:52 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 13:56:52 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 13:56:52 2023 ] Start training Predictor
[ Tue Jun 27 13:56:52 2023 ] Training epoch: 1
[ Tue Jun 27 13:56:57 2023 ] 	Training loss: 115.7417.  Training acc: 33.73%.
[ Tue Jun 27 13:56:57 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jun 27 13:56:57 2023 ] Eval epoch: 1
[ Tue Jun 27 13:56:58 2023 ] 	Mean test loss of 625 batches: 1658.780640.
[ Tue Jun 27 13:56:58 2023 ] 	Top1: 38.60%
[ Tue Jun 27 13:56:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:56:58 2023 ] Training epoch: 2
[ Tue Jun 27 13:57:00 2023 ] 	Training loss: 11.2867.  Training acc: 34.93%.
[ Tue Jun 27 13:57:00 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 13:57:00 2023 ] Eval epoch: 2
[ Tue Jun 27 13:57:01 2023 ] 	Mean test loss of 625 batches: 1.575934.
[ Tue Jun 27 13:57:01 2023 ] 	Top1: 31.58%
[ Tue Jun 27 13:57:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:57:01 2023 ] Training epoch: 3
[ Tue Jun 27 13:57:03 2023 ] 	Training loss: 7.5996.  Training acc: 34.65%.
[ Tue Jun 27 13:57:03 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 13:57:03 2023 ] Eval epoch: 3
[ Tue Jun 27 13:57:04 2023 ] 	Mean test loss of 625 batches: 3.893192.
[ Tue Jun 27 13:57:04 2023 ] 	Top1: 31.58%
[ Tue Jun 27 13:57:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:57:04 2023 ] Training epoch: 4
[ Tue Jun 27 13:58:24 2023 ] using warm up, epoch: 5
[ Tue Jun 27 13:58:25 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 13:58:25 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 13:58:25 2023 ] Start training Predictor
[ Tue Jun 27 13:58:25 2023 ] Training epoch: 1
[ Tue Jun 27 13:58:30 2023 ] 	Training loss: 100.1440.  Training acc: 34.83%.
[ Tue Jun 27 13:58:30 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Jun 27 13:58:30 2023 ] Eval epoch: 1
[ Tue Jun 27 13:58:30 2023 ] 	Mean test loss of 625 batches: 10469.936914.
[ Tue Jun 27 13:58:30 2023 ] 	Top1: 29.82%
[ Tue Jun 27 13:58:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:30 2023 ] Training epoch: 2
[ Tue Jun 27 13:58:32 2023 ] 	Training loss: 24.3064.  Training acc: 39.15%.
[ Tue Jun 27 13:58:32 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:58:33 2023 ] Eval epoch: 2
[ Tue Jun 27 13:58:33 2023 ] 	Mean test loss of 625 batches: 73.783802.
[ Tue Jun 27 13:58:33 2023 ] 	Top1: 40.35%
[ Tue Jun 27 13:58:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:33 2023 ] Training epoch: 3
[ Tue Jun 27 13:58:35 2023 ] 	Training loss: 11.3042.  Training acc: 35.57%.
[ Tue Jun 27 13:58:35 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:58:35 2023 ] Eval epoch: 3
[ Tue Jun 27 13:58:36 2023 ] 	Mean test loss of 625 batches: 2.362692.
[ Tue Jun 27 13:58:36 2023 ] 	Top1: 42.11%
[ Tue Jun 27 13:58:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:36 2023 ] Training epoch: 4
[ Tue Jun 27 13:58:38 2023 ] 	Training loss: 5.8534.  Training acc: 38.88%.
[ Tue Jun 27 13:58:38 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:58:38 2023 ] Eval epoch: 4
[ Tue Jun 27 13:58:38 2023 ] 	Mean test loss of 625 batches: 2.814429.
[ Tue Jun 27 13:58:38 2023 ] 	Top1: 40.35%
[ Tue Jun 27 13:58:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:38 2023 ] Training epoch: 5
[ Tue Jun 27 13:58:41 2023 ] 	Training loss: 4.9206.  Training acc: 44.21%.
[ Tue Jun 27 13:58:41 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:58:41 2023 ] Eval epoch: 5
[ Tue Jun 27 13:58:41 2023 ] 	Mean test loss of 625 batches: 11.311417.
[ Tue Jun 27 13:58:41 2023 ] 	Top1: 43.86%
[ Tue Jun 27 13:58:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:41 2023 ] Training epoch: 6
[ Tue Jun 27 13:58:43 2023 ] 	Training loss: 3.4599.  Training acc: 51.93%.
[ Tue Jun 27 13:58:43 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 13:58:43 2023 ] Eval epoch: 6
[ Tue Jun 27 13:58:44 2023 ] 	Mean test loss of 625 batches: 1.189034.
[ Tue Jun 27 13:58:44 2023 ] 	Top1: 45.61%
[ Tue Jun 27 13:58:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:44 2023 ] Training epoch: 7
[ Tue Jun 27 13:58:46 2023 ] 	Training loss: 1.9195.  Training acc: 51.84%.
[ Tue Jun 27 13:58:46 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:58:46 2023 ] Eval epoch: 7
[ Tue Jun 27 13:58:46 2023 ] 	Mean test loss of 625 batches: 2.385581.
[ Tue Jun 27 13:58:46 2023 ] 	Top1: 31.58%
[ Tue Jun 27 13:58:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:46 2023 ] Training epoch: 8
[ Tue Jun 27 13:58:49 2023 ] 	Training loss: 3.0066.  Training acc: 55.70%.
[ Tue Jun 27 13:58:49 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 13:58:49 2023 ] Eval epoch: 8
[ Tue Jun 27 13:58:49 2023 ] 	Mean test loss of 625 batches: 1.072437.
[ Tue Jun 27 13:58:49 2023 ] 	Top1: 42.11%
[ Tue Jun 27 13:58:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:49 2023 ] Training epoch: 9
[ Tue Jun 27 13:58:51 2023 ] 	Training loss: 1.9910.  Training acc: 60.11%.
[ Tue Jun 27 13:58:51 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 13:58:51 2023 ] Eval epoch: 9
[ Tue Jun 27 13:58:52 2023 ] 	Mean test loss of 625 batches: 2.403122.
[ Tue Jun 27 13:58:52 2023 ] 	Top1: 31.58%
[ Tue Jun 27 13:58:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:52 2023 ] Training epoch: 10
[ Tue Jun 27 13:58:54 2023 ] 	Training loss: 1.6636.  Training acc: 56.99%.
[ Tue Jun 27 13:58:54 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:58:54 2023 ] Eval epoch: 10
[ Tue Jun 27 13:58:54 2023 ] 	Mean test loss of 625 batches: 1.856842.
[ Tue Jun 27 13:58:54 2023 ] 	Top1: 31.58%
[ Tue Jun 27 13:58:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:54 2023 ] Training epoch: 11
[ Tue Jun 27 13:58:56 2023 ] 	Training loss: 1.4464.  Training acc: 59.28%.
[ Tue Jun 27 13:58:56 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:58:56 2023 ] Eval epoch: 11
[ Tue Jun 27 13:58:57 2023 ] 	Mean test loss of 625 batches: 0.830895.
[ Tue Jun 27 13:58:57 2023 ] 	Top1: 59.65%
[ Tue Jun 27 13:58:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:58:57 2023 ] Training epoch: 12
[ Tue Jun 27 13:58:59 2023 ] 	Training loss: 1.3609.  Training acc: 60.75%.
[ Tue Jun 27 13:58:59 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:58:59 2023 ] Eval epoch: 12
[ Tue Jun 27 13:59:00 2023 ] 	Mean test loss of 625 batches: 0.737848.
[ Tue Jun 27 13:59:00 2023 ] 	Top1: 70.18%
[ Tue Jun 27 13:59:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:00 2023 ] Training epoch: 13
[ Tue Jun 27 13:59:02 2023 ] 	Training loss: 1.2263.  Training acc: 62.41%.
[ Tue Jun 27 13:59:02 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 13:59:02 2023 ] Eval epoch: 13
[ Tue Jun 27 13:59:03 2023 ] 	Mean test loss of 625 batches: 0.771405.
[ Tue Jun 27 13:59:03 2023 ] 	Top1: 68.42%
[ Tue Jun 27 13:59:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:03 2023 ] Training epoch: 14
[ Tue Jun 27 13:59:05 2023 ] 	Training loss: 1.2264.  Training acc: 64.61%.
[ Tue Jun 27 13:59:05 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 13:59:05 2023 ] Eval epoch: 14
[ Tue Jun 27 13:59:06 2023 ] 	Mean test loss of 625 batches: 0.695661.
[ Tue Jun 27 13:59:06 2023 ] 	Top1: 70.18%
[ Tue Jun 27 13:59:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:06 2023 ] Training epoch: 15
[ Tue Jun 27 13:59:08 2023 ] 	Training loss: 1.2571.  Training acc: 62.04%.
[ Tue Jun 27 13:59:08 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 13:59:08 2023 ] Eval epoch: 15
[ Tue Jun 27 13:59:09 2023 ] 	Mean test loss of 625 batches: 0.698380.
[ Tue Jun 27 13:59:09 2023 ] 	Top1: 70.18%
[ Tue Jun 27 13:59:09 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:09 2023 ] Training epoch: 16
[ Tue Jun 27 13:59:11 2023 ] 	Training loss: 1.1829.  Training acc: 63.88%.
[ Tue Jun 27 13:59:11 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:59:11 2023 ] Eval epoch: 16
[ Tue Jun 27 13:59:11 2023 ] 	Mean test loss of 625 batches: 0.688894.
[ Tue Jun 27 13:59:11 2023 ] 	Top1: 70.18%
[ Tue Jun 27 13:59:11 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:11 2023 ] Training epoch: 17
[ Tue Jun 27 13:59:14 2023 ] 	Training loss: 1.1544.  Training acc: 62.59%.
[ Tue Jun 27 13:59:14 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:59:14 2023 ] Eval epoch: 17
[ Tue Jun 27 13:59:14 2023 ] 	Mean test loss of 625 batches: 0.686606.
[ Tue Jun 27 13:59:14 2023 ] 	Top1: 73.68%
[ Tue Jun 27 13:59:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:14 2023 ] Training epoch: 18
[ Tue Jun 27 13:59:16 2023 ] 	Training loss: 1.1340.  Training acc: 63.05%.
[ Tue Jun 27 13:59:16 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:59:17 2023 ] Eval epoch: 18
[ Tue Jun 27 13:59:17 2023 ] 	Mean test loss of 625 batches: 0.662801.
[ Tue Jun 27 13:59:17 2023 ] 	Top1: 82.46%
[ Tue Jun 27 13:59:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:17 2023 ] Training epoch: 19
[ Tue Jun 27 13:59:19 2023 ] 	Training loss: 1.0827.  Training acc: 65.53%.
[ Tue Jun 27 13:59:19 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 13:59:19 2023 ] Eval epoch: 19
[ Tue Jun 27 13:59:20 2023 ] 	Mean test loss of 625 batches: 0.721548.
[ Tue Jun 27 13:59:20 2023 ] 	Top1: 75.44%
[ Tue Jun 27 13:59:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:20 2023 ] Training epoch: 20
[ Tue Jun 27 13:59:22 2023 ] 	Training loss: 0.9813.  Training acc: 69.21%.
[ Tue Jun 27 13:59:22 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 13:59:22 2023 ] Eval epoch: 20
[ Tue Jun 27 13:59:23 2023 ] 	Mean test loss of 625 batches: 0.668444.
[ Tue Jun 27 13:59:23 2023 ] 	Top1: 78.95%
[ Tue Jun 27 13:59:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:23 2023 ] Training epoch: 21
[ Tue Jun 27 13:59:25 2023 ] 	Training loss: 1.0096.  Training acc: 67.74%.
[ Tue Jun 27 13:59:25 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:59:25 2023 ] Eval epoch: 21
[ Tue Jun 27 13:59:26 2023 ] 	Mean test loss of 625 batches: 0.663707.
[ Tue Jun 27 13:59:26 2023 ] 	Top1: 80.70%
[ Tue Jun 27 13:59:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:26 2023 ] Training epoch: 22
[ Tue Jun 27 13:59:28 2023 ] 	Training loss: 0.9417.  Training acc: 70.22%.
[ Tue Jun 27 13:59:28 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Tue Jun 27 13:59:28 2023 ] Eval epoch: 22
[ Tue Jun 27 13:59:29 2023 ] 	Mean test loss of 625 batches: 0.643037.
[ Tue Jun 27 13:59:29 2023 ] 	Top1: 78.95%
[ Tue Jun 27 13:59:29 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:29 2023 ] Training epoch: 23
[ Tue Jun 27 13:59:31 2023 ] 	Training loss: 0.9777.  Training acc: 68.66%.
[ Tue Jun 27 13:59:31 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 13:59:31 2023 ] Eval epoch: 23
[ Tue Jun 27 13:59:32 2023 ] 	Mean test loss of 625 batches: 0.636263.
[ Tue Jun 27 13:59:32 2023 ] 	Top1: 80.70%
[ Tue Jun 27 13:59:32 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:32 2023 ] Training epoch: 24
[ Tue Jun 27 13:59:34 2023 ] 	Training loss: 0.9415.  Training acc: 70.40%.
[ Tue Jun 27 13:59:34 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 13:59:34 2023 ] Eval epoch: 24
[ Tue Jun 27 13:59:35 2023 ] 	Mean test loss of 625 batches: 0.636494.
[ Tue Jun 27 13:59:35 2023 ] 	Top1: 80.70%
[ Tue Jun 27 13:59:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:35 2023 ] Training epoch: 25
[ Tue Jun 27 13:59:37 2023 ] 	Training loss: 0.9646.  Training acc: 69.58%.
[ Tue Jun 27 13:59:37 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 13:59:37 2023 ] Eval epoch: 25
[ Tue Jun 27 13:59:38 2023 ] 	Mean test loss of 625 batches: 0.642202.
[ Tue Jun 27 13:59:38 2023 ] 	Top1: 80.70%
[ Tue Jun 27 13:59:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:38 2023 ] Training epoch: 26
[ Tue Jun 27 13:59:40 2023 ] 	Training loss: 0.9328.  Training acc: 71.23%.
[ Tue Jun 27 13:59:40 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 13:59:40 2023 ] Eval epoch: 26
[ Tue Jun 27 13:59:41 2023 ] 	Mean test loss of 625 batches: 0.632260.
[ Tue Jun 27 13:59:41 2023 ] 	Top1: 80.70%
[ Tue Jun 27 13:59:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:41 2023 ] Training epoch: 27
[ Tue Jun 27 13:59:43 2023 ] 	Training loss: 0.9577.  Training acc: 69.85%.
[ Tue Jun 27 13:59:43 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 13:59:43 2023 ] Eval epoch: 27
[ Tue Jun 27 13:59:44 2023 ] 	Mean test loss of 625 batches: 0.631299.
[ Tue Jun 27 13:59:44 2023 ] 	Top1: 78.95%
[ Tue Jun 27 13:59:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:44 2023 ] Training epoch: 28
[ Tue Jun 27 13:59:46 2023 ] 	Training loss: 0.9518.  Training acc: 71.23%.
[ Tue Jun 27 13:59:46 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:59:46 2023 ] Eval epoch: 28
[ Tue Jun 27 13:59:47 2023 ] 	Mean test loss of 625 batches: 0.631414.
[ Tue Jun 27 13:59:47 2023 ] 	Top1: 80.70%
[ Tue Jun 27 13:59:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:47 2023 ] Training epoch: 29
[ Tue Jun 27 13:59:49 2023 ] 	Training loss: 0.9196.  Training acc: 72.79%.
[ Tue Jun 27 13:59:49 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 13:59:49 2023 ] Eval epoch: 29
[ Tue Jun 27 13:59:50 2023 ] 	Mean test loss of 625 batches: 0.635160.
[ Tue Jun 27 13:59:50 2023 ] 	Top1: 82.46%
[ Tue Jun 27 13:59:50 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:50 2023 ] Training epoch: 30
[ Tue Jun 27 13:59:52 2023 ] 	Training loss: 0.8911.  Training acc: 72.06%.
[ Tue Jun 27 13:59:52 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 13:59:52 2023 ] Eval epoch: 30
[ Tue Jun 27 13:59:53 2023 ] 	Mean test loss of 625 batches: 0.625212.
[ Tue Jun 27 13:59:53 2023 ] 	Top1: 80.70%
[ Tue Jun 27 13:59:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 13:59:53 2023 ] Best accuracy: 0.8245614035087719
[ Tue Jun 27 13:59:53 2023 ] Epoch number: 18
[ Tue Jun 27 13:59:53 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 13:59:53 2023 ] Weight decay: 0.0005
[ Tue Jun 27 13:59:53 2023 ] Base LR: 0.1
[ Tue Jun 27 13:59:53 2023 ] Batch Size: 64
[ Tue Jun 27 13:59:53 2023 ] Test Batch Size: 64
[ Tue Jun 27 13:59:53 2023 ] seed: 1
[ Tue Jun 27 14:01:00 2023 ] using warm up, epoch: 5
[ Tue Jun 27 14:01:02 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 14:01:02 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 14:01:02 2023 ] Start training Predictor
[ Tue Jun 27 14:01:02 2023 ] Training epoch: 1
[ Tue Jun 27 14:01:07 2023 ] 	Training loss: 105.0571.  Training acc: 35.57%.
[ Tue Jun 27 14:01:07 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jun 27 14:01:07 2023 ] Eval epoch: 1
[ Tue Jun 27 14:01:08 2023 ] 	Mean test loss of 625 batches: 9916.885303.
[ Tue Jun 27 14:01:08 2023 ] 	Top1: 29.82%
[ Tue Jun 27 14:01:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:08 2023 ] Training epoch: 2
[ Tue Jun 27 14:01:10 2023 ] 	Training loss: 17.9997.  Training acc: 38.97%.
[ Tue Jun 27 14:01:10 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 14:01:10 2023 ] Eval epoch: 2
[ Tue Jun 27 14:01:11 2023 ] 	Mean test loss of 625 batches: 2172.547998.
[ Tue Jun 27 14:01:11 2023 ] 	Top1: 29.82%
[ Tue Jun 27 14:01:11 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:11 2023 ] Training epoch: 3
[ Tue Jun 27 14:01:13 2023 ] 	Training loss: 6.4831.  Training acc: 40.99%.
[ Tue Jun 27 14:01:13 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:01:13 2023 ] Eval epoch: 3
[ Tue Jun 27 14:01:13 2023 ] 	Mean test loss of 625 batches: 23.002123.
[ Tue Jun 27 14:01:13 2023 ] 	Top1: 29.82%
[ Tue Jun 27 14:01:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:13 2023 ] Training epoch: 4
[ Tue Jun 27 14:01:16 2023 ] 	Training loss: 5.8920.  Training acc: 38.69%.
[ Tue Jun 27 14:01:16 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:01:16 2023 ] Eval epoch: 4
[ Tue Jun 27 14:01:16 2023 ] 	Mean test loss of 625 batches: 6.472894.
[ Tue Jun 27 14:01:16 2023 ] 	Top1: 29.82%
[ Tue Jun 27 14:01:16 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:16 2023 ] Training epoch: 5
[ Tue Jun 27 14:01:18 2023 ] 	Training loss: 3.5655.  Training acc: 56.07%.
[ Tue Jun 27 14:01:18 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:01:18 2023 ] Eval epoch: 5
[ Tue Jun 27 14:01:19 2023 ] 	Mean test loss of 625 batches: 1.394858.
[ Tue Jun 27 14:01:19 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:01:19 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:19 2023 ] Training epoch: 6
[ Tue Jun 27 14:01:21 2023 ] 	Training loss: 2.5142.  Training acc: 57.63%.
[ Tue Jun 27 14:01:21 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:01:21 2023 ] Eval epoch: 6
[ Tue Jun 27 14:01:22 2023 ] 	Mean test loss of 625 batches: 26.309593.
[ Tue Jun 27 14:01:22 2023 ] 	Top1: 29.82%
[ Tue Jun 27 14:01:22 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:22 2023 ] Training epoch: 7
[ Tue Jun 27 14:01:24 2023 ] 	Training loss: 2.3178.  Training acc: 60.29%.
[ Tue Jun 27 14:01:24 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 14:01:24 2023 ] Eval epoch: 7
[ Tue Jun 27 14:01:25 2023 ] 	Mean test loss of 625 batches: 5.277068.
[ Tue Jun 27 14:01:25 2023 ] 	Top1: 50.88%
[ Tue Jun 27 14:01:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:25 2023 ] Training epoch: 8
[ Tue Jun 27 14:01:27 2023 ] 	Training loss: 1.8893.  Training acc: 61.67%.
[ Tue Jun 27 14:01:27 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 14:01:27 2023 ] Eval epoch: 8
[ Tue Jun 27 14:01:28 2023 ] 	Mean test loss of 625 batches: 1.625292.
[ Tue Jun 27 14:01:28 2023 ] 	Top1: 68.42%
[ Tue Jun 27 14:01:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:28 2023 ] Training epoch: 9
[ Tue Jun 27 14:01:30 2023 ] 	Training loss: 1.4047.  Training acc: 61.31%.
[ Tue Jun 27 14:01:30 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:01:30 2023 ] Eval epoch: 9
[ Tue Jun 27 14:01:31 2023 ] 	Mean test loss of 625 batches: 0.877045.
[ Tue Jun 27 14:01:31 2023 ] 	Top1: 64.91%
[ Tue Jun 27 14:01:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:31 2023 ] Training epoch: 10
[ Tue Jun 27 14:01:33 2023 ] 	Training loss: 1.2627.  Training acc: 60.48%.
[ Tue Jun 27 14:01:33 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:01:33 2023 ] Eval epoch: 10
[ Tue Jun 27 14:01:34 2023 ] 	Mean test loss of 625 batches: 1.109237.
[ Tue Jun 27 14:01:34 2023 ] 	Top1: 66.67%
[ Tue Jun 27 14:01:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:34 2023 ] Training epoch: 11
[ Tue Jun 27 14:01:36 2023 ] 	Training loss: 1.2074.  Training acc: 63.14%.
[ Tue Jun 27 14:01:36 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:01:36 2023 ] Eval epoch: 11
[ Tue Jun 27 14:01:36 2023 ] 	Mean test loss of 625 batches: 0.816517.
[ Tue Jun 27 14:01:36 2023 ] 	Top1: 64.91%
[ Tue Jun 27 14:01:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:36 2023 ] Training epoch: 12
[ Tue Jun 27 14:01:39 2023 ] 	Training loss: 1.0294.  Training acc: 64.25%.
[ Tue Jun 27 14:01:39 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:01:39 2023 ] Eval epoch: 12
[ Tue Jun 27 14:01:39 2023 ] 	Mean test loss of 625 batches: 0.739190.
[ Tue Jun 27 14:01:39 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:01:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:39 2023 ] Training epoch: 13
[ Tue Jun 27 14:01:42 2023 ] 	Training loss: 0.8958.  Training acc: 67.19%.
[ Tue Jun 27 14:01:42 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:01:42 2023 ] Eval epoch: 13
[ Tue Jun 27 14:01:42 2023 ] 	Mean test loss of 625 batches: 0.727985.
[ Tue Jun 27 14:01:42 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:01:42 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:42 2023 ] Training epoch: 14
[ Tue Jun 27 14:01:44 2023 ] 	Training loss: 0.8683.  Training acc: 65.44%.
[ Tue Jun 27 14:01:44 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:01:44 2023 ] Eval epoch: 14
[ Tue Jun 27 14:01:45 2023 ] 	Mean test loss of 625 batches: 0.717627.
[ Tue Jun 27 14:01:45 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:01:45 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:45 2023 ] Training epoch: 15
[ Tue Jun 27 14:01:47 2023 ] 	Training loss: 0.8822.  Training acc: 66.08%.
[ Tue Jun 27 14:01:47 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:01:47 2023 ] Eval epoch: 15
[ Tue Jun 27 14:01:48 2023 ] 	Mean test loss of 625 batches: 0.737741.
[ Tue Jun 27 14:01:48 2023 ] 	Top1: 68.42%
[ Tue Jun 27 14:01:48 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:48 2023 ] Training epoch: 16
[ Tue Jun 27 14:01:50 2023 ] 	Training loss: 0.8656.  Training acc: 69.21%.
[ Tue Jun 27 14:01:50 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 14:01:50 2023 ] Eval epoch: 16
[ Tue Jun 27 14:01:51 2023 ] 	Mean test loss of 625 batches: 0.725928.
[ Tue Jun 27 14:01:51 2023 ] 	Top1: 71.93%
[ Tue Jun 27 14:01:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:51 2023 ] Training epoch: 17
[ Tue Jun 27 14:01:53 2023 ] 	Training loss: 0.7935.  Training acc: 70.77%.
[ Tue Jun 27 14:01:53 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:01:53 2023 ] Eval epoch: 17
[ Tue Jun 27 14:01:54 2023 ] 	Mean test loss of 625 batches: 0.668416.
[ Tue Jun 27 14:01:54 2023 ] 	Top1: 78.95%
[ Tue Jun 27 14:01:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:54 2023 ] Training epoch: 18
[ Tue Jun 27 14:01:56 2023 ] 	Training loss: 0.7862.  Training acc: 72.52%.
[ Tue Jun 27 14:01:56 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:01:56 2023 ] Eval epoch: 18
[ Tue Jun 27 14:01:57 2023 ] 	Mean test loss of 625 batches: 0.686954.
[ Tue Jun 27 14:01:57 2023 ] 	Top1: 71.93%
[ Tue Jun 27 14:01:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:01:57 2023 ] Training epoch: 19
[ Tue Jun 27 14:01:59 2023 ] 	Training loss: 0.7992.  Training acc: 72.98%.
[ Tue Jun 27 14:01:59 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:01:59 2023 ] Eval epoch: 19
[ Tue Jun 27 14:02:00 2023 ] 	Mean test loss of 625 batches: 0.795414.
[ Tue Jun 27 14:02:00 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:02:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:00 2023 ] Training epoch: 20
[ Tue Jun 27 14:02:02 2023 ] 	Training loss: 0.7594.  Training acc: 75.83%.
[ Tue Jun 27 14:02:02 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:02:02 2023 ] Eval epoch: 20
[ Tue Jun 27 14:02:03 2023 ] 	Mean test loss of 625 batches: 0.715280.
[ Tue Jun 27 14:02:03 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:02:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:03 2023 ] Training epoch: 21
[ Tue Jun 27 14:02:05 2023 ] 	Training loss: 0.7306.  Training acc: 78.03%.
[ Tue Jun 27 14:02:05 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:02:05 2023 ] Eval epoch: 21
[ Tue Jun 27 14:02:06 2023 ] 	Mean test loss of 625 batches: 0.620975.
[ Tue Jun 27 14:02:06 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:06 2023 ] Training epoch: 22
[ Tue Jun 27 14:02:08 2023 ] 	Training loss: 0.6931.  Training acc: 80.42%.
[ Tue Jun 27 14:02:08 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 14:02:08 2023 ] Eval epoch: 22
[ Tue Jun 27 14:02:08 2023 ] 	Mean test loss of 625 batches: 0.629052.
[ Tue Jun 27 14:02:08 2023 ] 	Top1: 80.70%
[ Tue Jun 27 14:02:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:09 2023 ] Training epoch: 23
[ Tue Jun 27 14:02:11 2023 ] 	Training loss: 0.6946.  Training acc: 79.69%.
[ Tue Jun 27 14:02:11 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:02:11 2023 ] Eval epoch: 23
[ Tue Jun 27 14:02:11 2023 ] 	Mean test loss of 625 batches: 0.641322.
[ Tue Jun 27 14:02:11 2023 ] 	Top1: 80.70%
[ Tue Jun 27 14:02:11 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:11 2023 ] Training epoch: 24
[ Tue Jun 27 14:02:14 2023 ] 	Training loss: 0.6952.  Training acc: 80.42%.
[ Tue Jun 27 14:02:14 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:02:14 2023 ] Eval epoch: 24
[ Tue Jun 27 14:02:14 2023 ] 	Mean test loss of 625 batches: 0.617999.
[ Tue Jun 27 14:02:14 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:02:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:14 2023 ] Training epoch: 25
[ Tue Jun 27 14:02:17 2023 ] 	Training loss: 0.7056.  Training acc: 78.68%.
[ Tue Jun 27 14:02:17 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:02:17 2023 ] Eval epoch: 25
[ Tue Jun 27 14:02:18 2023 ] 	Mean test loss of 625 batches: 0.628484.
[ Tue Jun 27 14:02:18 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:18 2023 ] Training epoch: 26
[ Tue Jun 27 14:02:20 2023 ] 	Training loss: 0.6817.  Training acc: 81.34%.
[ Tue Jun 27 14:02:20 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:02:20 2023 ] Eval epoch: 26
[ Tue Jun 27 14:02:21 2023 ] 	Mean test loss of 625 batches: 0.626601.
[ Tue Jun 27 14:02:21 2023 ] 	Top1: 80.70%
[ Tue Jun 27 14:02:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:21 2023 ] Training epoch: 27
[ Tue Jun 27 14:02:24 2023 ] 	Training loss: 0.6971.  Training acc: 81.07%.
[ Tue Jun 27 14:02:24 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:02:24 2023 ] Eval epoch: 27
[ Tue Jun 27 14:02:24 2023 ] 	Mean test loss of 625 batches: 0.608106.
[ Tue Jun 27 14:02:24 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:24 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:24 2023 ] Training epoch: 28
[ Tue Jun 27 14:02:27 2023 ] 	Training loss: 0.6735.  Training acc: 83.00%.
[ Tue Jun 27 14:02:27 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:02:27 2023 ] Eval epoch: 28
[ Tue Jun 27 14:02:27 2023 ] 	Mean test loss of 625 batches: 0.601313.
[ Tue Jun 27 14:02:27 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:02:27 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:27 2023 ] Training epoch: 29
[ Tue Jun 27 14:02:30 2023 ] 	Training loss: 0.6642.  Training acc: 82.44%.
[ Tue Jun 27 14:02:30 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 14:02:30 2023 ] Eval epoch: 29
[ Tue Jun 27 14:02:30 2023 ] 	Mean test loss of 625 batches: 0.607080.
[ Tue Jun 27 14:02:30 2023 ] 	Top1: 82.46%
[ Tue Jun 27 14:02:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:30 2023 ] Training epoch: 30
[ Tue Jun 27 14:02:33 2023 ] 	Training loss: 0.6505.  Training acc: 84.93%.
[ Tue Jun 27 14:02:33 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:02:33 2023 ] Eval epoch: 30
[ Tue Jun 27 14:02:33 2023 ] 	Mean test loss of 625 batches: 0.594197.
[ Tue Jun 27 14:02:33 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:33 2023 ] Training epoch: 31
[ Tue Jun 27 14:02:36 2023 ] 	Training loss: 0.6622.  Training acc: 82.08%.
[ Tue Jun 27 14:02:36 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:02:36 2023 ] Eval epoch: 31
[ Tue Jun 27 14:02:36 2023 ] 	Mean test loss of 625 batches: 0.616825.
[ Tue Jun 27 14:02:36 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:02:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:36 2023 ] Training epoch: 32
[ Tue Jun 27 14:02:38 2023 ] 	Training loss: 0.6796.  Training acc: 82.81%.
[ Tue Jun 27 14:02:38 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 14:02:38 2023 ] Eval epoch: 32
[ Tue Jun 27 14:02:39 2023 ] 	Mean test loss of 625 batches: 0.605950.
[ Tue Jun 27 14:02:39 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:39 2023 ] Training epoch: 33
[ Tue Jun 27 14:02:42 2023 ] 	Training loss: 0.6491.  Training acc: 83.92%.
[ Tue Jun 27 14:02:42 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:02:42 2023 ] Eval epoch: 33
[ Tue Jun 27 14:02:42 2023 ] 	Mean test loss of 625 batches: 0.595160.
[ Tue Jun 27 14:02:42 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:42 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:42 2023 ] Training epoch: 34
[ Tue Jun 27 14:02:44 2023 ] 	Training loss: 0.6583.  Training acc: 84.19%.
[ Tue Jun 27 14:02:44 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:02:44 2023 ] Eval epoch: 34
[ Tue Jun 27 14:02:45 2023 ] 	Mean test loss of 625 batches: 0.602782.
[ Tue Jun 27 14:02:45 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:45 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:45 2023 ] Training epoch: 35
[ Tue Jun 27 14:02:47 2023 ] 	Training loss: 0.6396.  Training acc: 86.03%.
[ Tue Jun 27 14:02:47 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:02:47 2023 ] Eval epoch: 35
[ Tue Jun 27 14:02:48 2023 ] 	Mean test loss of 625 batches: 0.573930.
[ Tue Jun 27 14:02:48 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:48 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:48 2023 ] Training epoch: 36
[ Tue Jun 27 14:02:50 2023 ] 	Training loss: 0.6379.  Training acc: 85.66%.
[ Tue Jun 27 14:02:50 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:02:50 2023 ] Eval epoch: 36
[ Tue Jun 27 14:02:51 2023 ] 	Mean test loss of 625 batches: 0.586560.
[ Tue Jun 27 14:02:51 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:51 2023 ] Training epoch: 37
[ Tue Jun 27 14:02:53 2023 ] 	Training loss: 0.6431.  Training acc: 85.57%.
[ Tue Jun 27 14:02:53 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:02:53 2023 ] Eval epoch: 37
[ Tue Jun 27 14:02:54 2023 ] 	Mean test loss of 625 batches: 0.591507.
[ Tue Jun 27 14:02:54 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:54 2023 ] Training epoch: 38
[ Tue Jun 27 14:02:56 2023 ] 	Training loss: 0.6363.  Training acc: 84.83%.
[ Tue Jun 27 14:02:56 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:02:56 2023 ] Eval epoch: 38
[ Tue Jun 27 14:02:57 2023 ] 	Mean test loss of 625 batches: 0.603585.
[ Tue Jun 27 14:02:57 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:02:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:57 2023 ] Training epoch: 39
[ Tue Jun 27 14:02:59 2023 ] 	Training loss: 0.6232.  Training acc: 86.67%.
[ Tue Jun 27 14:02:59 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:02:59 2023 ] Eval epoch: 39
[ Tue Jun 27 14:02:59 2023 ] 	Mean test loss of 625 batches: 0.572214.
[ Tue Jun 27 14:02:59 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:02:59 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:02:59 2023 ] Training epoch: 40
[ Tue Jun 27 14:03:02 2023 ] 	Training loss: 0.6520.  Training acc: 84.83%.
[ Tue Jun 27 14:03:02 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 14:03:02 2023 ] Eval epoch: 40
[ Tue Jun 27 14:03:02 2023 ] 	Mean test loss of 625 batches: 0.574481.
[ Tue Jun 27 14:03:02 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:03:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:03:03 2023 ] Best accuracy: 0.8771929824561403
[ Tue Jun 27 14:03:03 2023 ] Epoch number: 39
[ Tue Jun 27 14:03:03 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 14:03:03 2023 ] Weight decay: 0.0005
[ Tue Jun 27 14:03:03 2023 ] Base LR: 0.1
[ Tue Jun 27 14:03:03 2023 ] Batch Size: 64
[ Tue Jun 27 14:03:03 2023 ] Test Batch Size: 64
[ Tue Jun 27 14:03:03 2023 ] seed: 1
[ Tue Jun 27 14:04:36 2023 ] using warm up, epoch: 5
[ Tue Jun 27 14:04:37 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 14:04:37 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 14:04:37 2023 ] Start training Predictor
[ Tue Jun 27 14:04:37 2023 ] Training epoch: 1
[ Tue Jun 27 14:04:43 2023 ] 	Training loss: 110.7125.  Training acc: 34.56%.
[ Tue Jun 27 14:04:43 2023 ] 	Time consumption: [Data]05%, [Network]94%
[ Tue Jun 27 14:04:43 2023 ] Eval epoch: 1
[ Tue Jun 27 14:04:44 2023 ] 	Mean test loss of 625 batches: 266.382657.
[ Tue Jun 27 14:04:44 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:04:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:04:44 2023 ] Training epoch: 2
[ Tue Jun 27 14:04:46 2023 ] 	Training loss: 11.0199.  Training acc: 34.65%.
[ Tue Jun 27 14:04:46 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:04:46 2023 ] Eval epoch: 2
[ Tue Jun 27 14:04:47 2023 ] 	Mean test loss of 625 batches: 3.910967.
[ Tue Jun 27 14:04:47 2023 ] 	Top1: 35.09%
[ Tue Jun 27 14:04:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:04:47 2023 ] Training epoch: 3
[ Tue Jun 27 14:04:49 2023 ] 	Training loss: 7.3739.  Training acc: 35.20%.
[ Tue Jun 27 14:04:49 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:04:49 2023 ] Eval epoch: 3
[ Tue Jun 27 14:04:50 2023 ] 	Mean test loss of 625 batches: 1.591804.
[ Tue Jun 27 14:04:50 2023 ] 	Top1: 36.84%
[ Tue Jun 27 14:04:50 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:04:50 2023 ] Training epoch: 4
[ Tue Jun 27 14:04:52 2023 ] 	Training loss: 6.7339.  Training acc: 39.06%.
[ Tue Jun 27 14:04:52 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:04:52 2023 ] Eval epoch: 4
[ Tue Jun 27 14:04:52 2023 ] 	Mean test loss of 625 batches: 7.395569.
[ Tue Jun 27 14:04:52 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:04:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:04:52 2023 ] Training epoch: 5
[ Tue Jun 27 14:04:55 2023 ] 	Training loss: 4.6160.  Training acc: 52.67%.
[ Tue Jun 27 14:04:55 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:04:55 2023 ] Eval epoch: 5
[ Tue Jun 27 14:04:55 2023 ] 	Mean test loss of 625 batches: 3.790101.
[ Tue Jun 27 14:04:55 2023 ] 	Top1: 63.16%
[ Tue Jun 27 14:04:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:04:56 2023 ] Training epoch: 6
[ Tue Jun 27 14:04:58 2023 ] 	Training loss: 3.6742.  Training acc: 54.78%.
[ Tue Jun 27 14:04:58 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:04:58 2023 ] Eval epoch: 6
[ Tue Jun 27 14:04:58 2023 ] 	Mean test loss of 625 batches: 2.917603.
[ Tue Jun 27 14:04:58 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:04:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:04:58 2023 ] Training epoch: 7
[ Tue Jun 27 14:05:01 2023 ] 	Training loss: 1.9858.  Training acc: 56.25%.
[ Tue Jun 27 14:05:01 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:05:01 2023 ] Eval epoch: 7
[ Tue Jun 27 14:05:01 2023 ] 	Mean test loss of 625 batches: 1.217876.
[ Tue Jun 27 14:05:01 2023 ] 	Top1: 63.16%
[ Tue Jun 27 14:05:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:01 2023 ] Training epoch: 8
[ Tue Jun 27 14:05:04 2023 ] 	Training loss: 1.9460.  Training acc: 51.84%.
[ Tue Jun 27 14:05:04 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:05:04 2023 ] Eval epoch: 8
[ Tue Jun 27 14:05:04 2023 ] 	Mean test loss of 625 batches: 0.799216.
[ Tue Jun 27 14:05:04 2023 ] 	Top1: 68.42%
[ Tue Jun 27 14:05:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:04 2023 ] Training epoch: 9
[ Tue Jun 27 14:05:07 2023 ] 	Training loss: 2.4020.  Training acc: 47.33%.
[ Tue Jun 27 14:05:07 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:05:07 2023 ] Eval epoch: 9
[ Tue Jun 27 14:05:07 2023 ] 	Mean test loss of 625 batches: 29.632864.
[ Tue Jun 27 14:05:07 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:05:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:07 2023 ] Training epoch: 10
[ Tue Jun 27 14:05:10 2023 ] 	Training loss: 1.7838.  Training acc: 47.70%.
[ Tue Jun 27 14:05:10 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:05:10 2023 ] Eval epoch: 10
[ Tue Jun 27 14:05:10 2023 ] 	Mean test loss of 625 batches: 22.565140.
[ Tue Jun 27 14:05:10 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:05:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:10 2023 ] Training epoch: 11
[ Tue Jun 27 14:05:12 2023 ] 	Training loss: 1.1539.  Training acc: 56.89%.
[ Tue Jun 27 14:05:12 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:05:12 2023 ] Eval epoch: 11
[ Tue Jun 27 14:05:13 2023 ] 	Mean test loss of 625 batches: 1.152249.
[ Tue Jun 27 14:05:13 2023 ] 	Top1: 54.39%
[ Tue Jun 27 14:05:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:13 2023 ] Training epoch: 12
[ Tue Jun 27 14:05:15 2023 ] 	Training loss: 0.9925.  Training acc: 58.55%.
[ Tue Jun 27 14:05:15 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:05:15 2023 ] Eval epoch: 12
[ Tue Jun 27 14:05:16 2023 ] 	Mean test loss of 625 batches: 0.882661.
[ Tue Jun 27 14:05:16 2023 ] 	Top1: 56.14%
[ Tue Jun 27 14:05:16 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:16 2023 ] Training epoch: 13
[ Tue Jun 27 14:05:19 2023 ] 	Training loss: 0.8824.  Training acc: 61.86%.
[ Tue Jun 27 14:05:19 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:05:19 2023 ] Eval epoch: 13
[ Tue Jun 27 14:05:19 2023 ] 	Mean test loss of 625 batches: 0.767506.
[ Tue Jun 27 14:05:19 2023 ] 	Top1: 59.65%
[ Tue Jun 27 14:05:19 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:19 2023 ] Training epoch: 14
[ Tue Jun 27 14:05:22 2023 ] 	Training loss: 0.8448.  Training acc: 60.94%.
[ Tue Jun 27 14:05:22 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:05:22 2023 ] Eval epoch: 14
[ Tue Jun 27 14:05:22 2023 ] 	Mean test loss of 625 batches: 0.753298.
[ Tue Jun 27 14:05:22 2023 ] 	Top1: 64.91%
[ Tue Jun 27 14:05:22 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:22 2023 ] Training epoch: 15
[ Tue Jun 27 14:05:25 2023 ] 	Training loss: 0.8359.  Training acc: 65.17%.
[ Tue Jun 27 14:05:25 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:05:25 2023 ] Eval epoch: 15
[ Tue Jun 27 14:05:26 2023 ] 	Mean test loss of 625 batches: 0.765828.
[ Tue Jun 27 14:05:26 2023 ] 	Top1: 66.67%
[ Tue Jun 27 14:05:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:26 2023 ] Training epoch: 16
[ Tue Jun 27 14:05:28 2023 ] 	Training loss: 0.8220.  Training acc: 65.17%.
[ Tue Jun 27 14:05:28 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:05:28 2023 ] Eval epoch: 16
[ Tue Jun 27 14:05:29 2023 ] 	Mean test loss of 625 batches: 0.661623.
[ Tue Jun 27 14:05:29 2023 ] 	Top1: 73.68%
[ Tue Jun 27 14:05:29 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:29 2023 ] Training epoch: 17
[ Tue Jun 27 14:05:31 2023 ] 	Training loss: 0.8053.  Training acc: 67.46%.
[ Tue Jun 27 14:05:31 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:05:31 2023 ] Eval epoch: 17
[ Tue Jun 27 14:05:32 2023 ] 	Mean test loss of 625 batches: 0.749622.
[ Tue Jun 27 14:05:32 2023 ] 	Top1: 66.67%
[ Tue Jun 27 14:05:32 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:32 2023 ] Training epoch: 18
[ Tue Jun 27 14:05:34 2023 ] 	Training loss: 0.7793.  Training acc: 68.38%.
[ Tue Jun 27 14:05:34 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:05:34 2023 ] Eval epoch: 18
[ Tue Jun 27 14:05:35 2023 ] 	Mean test loss of 625 batches: 0.702248.
[ Tue Jun 27 14:05:35 2023 ] 	Top1: 68.42%
[ Tue Jun 27 14:05:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:35 2023 ] Training epoch: 19
[ Tue Jun 27 14:05:37 2023 ] 	Training loss: 0.7899.  Training acc: 69.49%.
[ Tue Jun 27 14:05:37 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:05:37 2023 ] Eval epoch: 19
[ Tue Jun 27 14:05:38 2023 ] 	Mean test loss of 625 batches: 0.671686.
[ Tue Jun 27 14:05:38 2023 ] 	Top1: 77.19%
[ Tue Jun 27 14:05:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:38 2023 ] Training epoch: 20
[ Tue Jun 27 14:05:41 2023 ] 	Training loss: 0.7247.  Training acc: 71.78%.
[ Tue Jun 27 14:05:41 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:05:41 2023 ] Eval epoch: 20
[ Tue Jun 27 14:05:41 2023 ] 	Mean test loss of 625 batches: 0.729764.
[ Tue Jun 27 14:05:41 2023 ] 	Top1: 68.42%
[ Tue Jun 27 14:05:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:41 2023 ] Training epoch: 21
[ Tue Jun 27 14:05:43 2023 ] 	Training loss: 0.7490.  Training acc: 72.15%.
[ Tue Jun 27 14:05:43 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:05:43 2023 ] Eval epoch: 21
[ Tue Jun 27 14:05:44 2023 ] 	Mean test loss of 625 batches: 0.653507.
[ Tue Jun 27 14:05:44 2023 ] 	Top1: 77.19%
[ Tue Jun 27 14:05:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:44 2023 ] Training epoch: 22
[ Tue Jun 27 14:05:46 2023 ] 	Training loss: 0.6938.  Training acc: 74.72%.
[ Tue Jun 27 14:05:46 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:05:46 2023 ] Eval epoch: 22
[ Tue Jun 27 14:05:47 2023 ] 	Mean test loss of 625 batches: 0.631672.
[ Tue Jun 27 14:05:47 2023 ] 	Top1: 78.95%
[ Tue Jun 27 14:05:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:47 2023 ] Training epoch: 23
[ Tue Jun 27 14:05:49 2023 ] 	Training loss: 0.6922.  Training acc: 75.83%.
[ Tue Jun 27 14:05:49 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:05:49 2023 ] Eval epoch: 23
[ Tue Jun 27 14:05:50 2023 ] 	Mean test loss of 625 batches: 0.648096.
[ Tue Jun 27 14:05:50 2023 ] 	Top1: 77.19%
[ Tue Jun 27 14:05:50 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:50 2023 ] Training epoch: 24
[ Tue Jun 27 14:05:52 2023 ] 	Training loss: 0.7033.  Training acc: 74.63%.
[ Tue Jun 27 14:05:52 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:05:52 2023 ] Eval epoch: 24
[ Tue Jun 27 14:05:53 2023 ] 	Mean test loss of 625 batches: 0.636311.
[ Tue Jun 27 14:05:53 2023 ] 	Top1: 78.95%
[ Tue Jun 27 14:05:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:53 2023 ] Training epoch: 25
[ Tue Jun 27 14:05:55 2023 ] 	Training loss: 0.7126.  Training acc: 73.71%.
[ Tue Jun 27 14:05:55 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:05:55 2023 ] Eval epoch: 25
[ Tue Jun 27 14:05:56 2023 ] 	Mean test loss of 625 batches: 0.632899.
[ Tue Jun 27 14:05:56 2023 ] 	Top1: 78.95%
[ Tue Jun 27 14:05:56 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:56 2023 ] Training epoch: 26
[ Tue Jun 27 14:05:58 2023 ] 	Training loss: 0.6944.  Training acc: 75.64%.
[ Tue Jun 27 14:05:58 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:05:58 2023 ] Eval epoch: 26
[ Tue Jun 27 14:05:59 2023 ] 	Mean test loss of 625 batches: 0.620750.
[ Tue Jun 27 14:05:59 2023 ] 	Top1: 80.70%
[ Tue Jun 27 14:05:59 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:05:59 2023 ] Training epoch: 27
[ Tue Jun 27 14:06:01 2023 ] 	Training loss: 0.7054.  Training acc: 75.37%.
[ Tue Jun 27 14:06:01 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:06:01 2023 ] Eval epoch: 27
[ Tue Jun 27 14:06:02 2023 ] 	Mean test loss of 625 batches: 0.656544.
[ Tue Jun 27 14:06:02 2023 ] 	Top1: 78.95%
[ Tue Jun 27 14:06:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:02 2023 ] Training epoch: 28
[ Tue Jun 27 14:06:04 2023 ] 	Training loss: 0.6833.  Training acc: 77.02%.
[ Tue Jun 27 14:06:04 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:06:04 2023 ] Eval epoch: 28
[ Tue Jun 27 14:06:05 2023 ] 	Mean test loss of 625 batches: 0.632121.
[ Tue Jun 27 14:06:05 2023 ] 	Top1: 78.95%
[ Tue Jun 27 14:06:05 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:05 2023 ] Training epoch: 29
[ Tue Jun 27 14:06:07 2023 ] 	Training loss: 0.6827.  Training acc: 77.67%.
[ Tue Jun 27 14:06:07 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:06:07 2023 ] Eval epoch: 29
[ Tue Jun 27 14:06:08 2023 ] 	Mean test loss of 625 batches: 0.622878.
[ Tue Jun 27 14:06:08 2023 ] 	Top1: 78.95%
[ Tue Jun 27 14:06:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:08 2023 ] Training epoch: 30
[ Tue Jun 27 14:06:10 2023 ] 	Training loss: 0.6623.  Training acc: 79.69%.
[ Tue Jun 27 14:06:10 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:06:10 2023 ] Eval epoch: 30
[ Tue Jun 27 14:06:11 2023 ] 	Mean test loss of 625 batches: 0.639096.
[ Tue Jun 27 14:06:11 2023 ] 	Top1: 80.70%
[ Tue Jun 27 14:06:11 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:11 2023 ] Training epoch: 31
[ Tue Jun 27 14:06:13 2023 ] 	Training loss: 0.6752.  Training acc: 75.83%.
[ Tue Jun 27 14:06:13 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:06:13 2023 ] Eval epoch: 31
[ Tue Jun 27 14:06:14 2023 ] 	Mean test loss of 625 batches: 0.622081.
[ Tue Jun 27 14:06:14 2023 ] 	Top1: 82.46%
[ Tue Jun 27 14:06:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:14 2023 ] Training epoch: 32
[ Tue Jun 27 14:06:16 2023 ] 	Training loss: 0.6783.  Training acc: 77.39%.
[ Tue Jun 27 14:06:16 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:06:16 2023 ] Eval epoch: 32
[ Tue Jun 27 14:06:17 2023 ] 	Mean test loss of 625 batches: 0.648448.
[ Tue Jun 27 14:06:17 2023 ] 	Top1: 80.70%
[ Tue Jun 27 14:06:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:17 2023 ] Training epoch: 33
[ Tue Jun 27 14:06:19 2023 ] 	Training loss: 0.6633.  Training acc: 78.86%.
[ Tue Jun 27 14:06:19 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:06:19 2023 ] Eval epoch: 33
[ Tue Jun 27 14:06:20 2023 ] 	Mean test loss of 625 batches: 0.606030.
[ Tue Jun 27 14:06:20 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:06:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:20 2023 ] Training epoch: 34
[ Tue Jun 27 14:06:22 2023 ] 	Training loss: 0.6659.  Training acc: 77.57%.
[ Tue Jun 27 14:06:22 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:06:22 2023 ] Eval epoch: 34
[ Tue Jun 27 14:06:23 2023 ] 	Mean test loss of 625 batches: 0.603441.
[ Tue Jun 27 14:06:23 2023 ] 	Top1: 82.46%
[ Tue Jun 27 14:06:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:23 2023 ] Training epoch: 35
[ Tue Jun 27 14:06:25 2023 ] 	Training loss: 0.6594.  Training acc: 79.50%.
[ Tue Jun 27 14:06:25 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:06:25 2023 ] Eval epoch: 35
[ Tue Jun 27 14:06:26 2023 ] 	Mean test loss of 625 batches: 0.606393.
[ Tue Jun 27 14:06:26 2023 ] 	Top1: 82.46%
[ Tue Jun 27 14:06:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:26 2023 ] Training epoch: 36
[ Tue Jun 27 14:06:28 2023 ] 	Training loss: 0.6546.  Training acc: 80.24%.
[ Tue Jun 27 14:06:28 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:06:28 2023 ] Eval epoch: 36
[ Tue Jun 27 14:06:29 2023 ] 	Mean test loss of 625 batches: 0.602908.
[ Tue Jun 27 14:06:29 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:06:29 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:29 2023 ] Training epoch: 37
[ Tue Jun 27 14:06:31 2023 ] 	Training loss: 0.6595.  Training acc: 80.24%.
[ Tue Jun 27 14:06:31 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:06:31 2023 ] Eval epoch: 37
[ Tue Jun 27 14:06:32 2023 ] 	Mean test loss of 625 batches: 0.610469.
[ Tue Jun 27 14:06:32 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:06:32 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:32 2023 ] Training epoch: 38
[ Tue Jun 27 14:06:34 2023 ] 	Training loss: 0.6516.  Training acc: 81.25%.
[ Tue Jun 27 14:06:34 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:06:34 2023 ] Eval epoch: 38
[ Tue Jun 27 14:06:35 2023 ] 	Mean test loss of 625 batches: 0.628408.
[ Tue Jun 27 14:06:35 2023 ] 	Top1: 82.46%
[ Tue Jun 27 14:06:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:35 2023 ] Training epoch: 39
[ Tue Jun 27 14:06:37 2023 ] 	Training loss: 0.6461.  Training acc: 80.70%.
[ Tue Jun 27 14:06:37 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:06:37 2023 ] Eval epoch: 39
[ Tue Jun 27 14:06:38 2023 ] 	Mean test loss of 625 batches: 0.594244.
[ Tue Jun 27 14:06:38 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:06:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:38 2023 ] Training epoch: 40
[ Tue Jun 27 14:06:40 2023 ] 	Training loss: 0.6699.  Training acc: 77.85%.
[ Tue Jun 27 14:06:40 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:06:40 2023 ] Eval epoch: 40
[ Tue Jun 27 14:06:41 2023 ] 	Mean test loss of 625 batches: 0.612546.
[ Tue Jun 27 14:06:41 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:06:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:06:42 2023 ] Best accuracy: 0.8596491228070176
[ Tue Jun 27 14:06:42 2023 ] Epoch number: 37
[ Tue Jun 27 14:06:42 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 14:06:42 2023 ] Weight decay: 0.0005
[ Tue Jun 27 14:06:42 2023 ] Base LR: 0.1
[ Tue Jun 27 14:06:42 2023 ] Batch Size: 64
[ Tue Jun 27 14:06:42 2023 ] Test Batch Size: 64
[ Tue Jun 27 14:06:42 2023 ] seed: 1
[ Tue Jun 27 14:06:42 2023 ] Start training Corrector
[ Tue Jun 27 14:07:45 2023 ] using warm up, epoch: 5
[ Tue Jun 27 14:07:46 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 14:07:46 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 14:07:46 2023 ] Start training Predictor
[ Tue Jun 27 14:07:46 2023 ] Training epoch: 1
[ Tue Jun 27 14:07:51 2023 ] 	Training loss: 109.9660.  Training acc: 35.39%.
[ Tue Jun 27 14:07:51 2023 ] 	Time consumption: [Data]05%, [Network]94%
[ Tue Jun 27 14:07:51 2023 ] Eval epoch: 1
[ Tue Jun 27 14:07:52 2023 ] 	Mean test loss of 625 batches: 2254.578003.
[ Tue Jun 27 14:07:52 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:07:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:07:52 2023 ] Training epoch: 2
[ Tue Jun 27 14:07:55 2023 ] 	Training loss: 20.3376.  Training acc: 35.75%.
[ Tue Jun 27 14:07:55 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:07:55 2023 ] Eval epoch: 2
[ Tue Jun 27 14:07:55 2023 ] 	Mean test loss of 625 batches: 2.269802.
[ Tue Jun 27 14:07:55 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:07:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:07:55 2023 ] Training epoch: 3
[ Tue Jun 27 14:07:58 2023 ] 	Training loss: 7.6806.  Training acc: 33.92%.
[ Tue Jun 27 14:07:58 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:07:58 2023 ] Eval epoch: 3
[ Tue Jun 27 14:07:58 2023 ] 	Mean test loss of 625 batches: 3.884099.
[ Tue Jun 27 14:07:58 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:07:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:07:58 2023 ] Training epoch: 4
[ Tue Jun 27 14:08:00 2023 ] 	Training loss: 6.5402.  Training acc: 32.90%.
[ Tue Jun 27 14:08:00 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:08:00 2023 ] Eval epoch: 4
[ Tue Jun 27 14:08:01 2023 ] 	Mean test loss of 625 batches: 5.640648.
[ Tue Jun 27 14:08:01 2023 ] 	Top1: 17.54%
[ Tue Jun 27 14:08:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:01 2023 ] Training epoch: 5
[ Tue Jun 27 14:08:03 2023 ] 	Training loss: 5.5490.  Training acc: 40.26%.
[ Tue Jun 27 14:08:03 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 14:08:03 2023 ] Eval epoch: 5
[ Tue Jun 27 14:08:04 2023 ] 	Mean test loss of 625 batches: 2.062758.
[ Tue Jun 27 14:08:04 2023 ] 	Top1: 49.12%
[ Tue Jun 27 14:08:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:04 2023 ] Training epoch: 6
[ Tue Jun 27 14:08:06 2023 ] 	Training loss: 3.8087.  Training acc: 47.70%.
[ Tue Jun 27 14:08:06 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:08:06 2023 ] Eval epoch: 6
[ Tue Jun 27 14:08:07 2023 ] 	Mean test loss of 625 batches: 1.191411.
[ Tue Jun 27 14:08:07 2023 ] 	Top1: 54.39%
[ Tue Jun 27 14:08:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:07 2023 ] Training epoch: 7
[ Tue Jun 27 14:08:09 2023 ] 	Training loss: 2.0877.  Training acc: 57.35%.
[ Tue Jun 27 14:08:09 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:08:09 2023 ] Eval epoch: 7
[ Tue Jun 27 14:08:10 2023 ] 	Mean test loss of 625 batches: 8.773708.
[ Tue Jun 27 14:08:10 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:08:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:10 2023 ] Training epoch: 8
[ Tue Jun 27 14:08:12 2023 ] 	Training loss: 1.8185.  Training acc: 61.31%.
[ Tue Jun 27 14:08:12 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:08:12 2023 ] Eval epoch: 8
[ Tue Jun 27 14:08:13 2023 ] 	Mean test loss of 625 batches: 1.019631.
[ Tue Jun 27 14:08:13 2023 ] 	Top1: 68.42%
[ Tue Jun 27 14:08:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:13 2023 ] Training epoch: 9
[ Tue Jun 27 14:08:15 2023 ] 	Training loss: 1.2117.  Training acc: 65.44%.
[ Tue Jun 27 14:08:15 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:08:15 2023 ] Eval epoch: 9
[ Tue Jun 27 14:08:16 2023 ] 	Mean test loss of 625 batches: 0.912477.
[ Tue Jun 27 14:08:16 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:08:16 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:16 2023 ] Training epoch: 10
[ Tue Jun 27 14:08:19 2023 ] 	Training loss: 1.0563.  Training acc: 65.99%.
[ Tue Jun 27 14:08:19 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:08:19 2023 ] Eval epoch: 10
[ Tue Jun 27 14:08:19 2023 ] 	Mean test loss of 625 batches: 0.700711.
[ Tue Jun 27 14:08:19 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:08:19 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:19 2023 ] Training epoch: 11
[ Tue Jun 27 14:08:21 2023 ] 	Training loss: 0.9343.  Training acc: 62.96%.
[ Tue Jun 27 14:08:21 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:08:21 2023 ] Eval epoch: 11
[ Tue Jun 27 14:08:22 2023 ] 	Mean test loss of 625 batches: 0.726508.
[ Tue Jun 27 14:08:22 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:08:22 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:22 2023 ] Training epoch: 12
[ Tue Jun 27 14:08:24 2023 ] 	Training loss: 0.9108.  Training acc: 65.35%.
[ Tue Jun 27 14:08:24 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:08:24 2023 ] Eval epoch: 12
[ Tue Jun 27 14:08:25 2023 ] 	Mean test loss of 625 batches: 0.809410.
[ Tue Jun 27 14:08:25 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:08:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:25 2023 ] Training epoch: 13
[ Tue Jun 27 14:08:27 2023 ] 	Training loss: 0.8500.  Training acc: 67.19%.
[ Tue Jun 27 14:08:27 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:08:27 2023 ] Eval epoch: 13
[ Tue Jun 27 14:08:28 2023 ] 	Mean test loss of 625 batches: 0.705907.
[ Tue Jun 27 14:08:28 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:08:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:28 2023 ] Training epoch: 14
[ Tue Jun 27 14:08:31 2023 ] 	Training loss: 0.8007.  Training acc: 71.60%.
[ Tue Jun 27 14:08:31 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:08:31 2023 ] Eval epoch: 14
[ Tue Jun 27 14:08:31 2023 ] 	Mean test loss of 625 batches: 0.802759.
[ Tue Jun 27 14:08:31 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:08:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:31 2023 ] Training epoch: 15
[ Tue Jun 27 14:08:33 2023 ] 	Training loss: 0.7955.  Training acc: 70.86%.
[ Tue Jun 27 14:08:33 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:08:33 2023 ] Eval epoch: 15
[ Tue Jun 27 14:08:34 2023 ] 	Mean test loss of 625 batches: 0.704653.
[ Tue Jun 27 14:08:34 2023 ] 	Top1: 68.42%
[ Tue Jun 27 14:08:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:34 2023 ] Training epoch: 16
[ Tue Jun 27 14:08:36 2023 ] 	Training loss: 0.8022.  Training acc: 70.31%.
[ Tue Jun 27 14:08:36 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:08:36 2023 ] Eval epoch: 16
[ Tue Jun 27 14:08:37 2023 ] 	Mean test loss of 625 batches: 0.698325.
[ Tue Jun 27 14:08:37 2023 ] 	Top1: 71.93%
[ Tue Jun 27 14:08:37 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:37 2023 ] Training epoch: 17
[ Tue Jun 27 14:08:39 2023 ] 	Training loss: 0.7421.  Training acc: 72.24%.
[ Tue Jun 27 14:08:39 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:08:39 2023 ] Eval epoch: 17
[ Tue Jun 27 14:08:40 2023 ] 	Mean test loss of 625 batches: 0.654636.
[ Tue Jun 27 14:08:40 2023 ] 	Top1: 71.93%
[ Tue Jun 27 14:08:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:40 2023 ] Training epoch: 18
[ Tue Jun 27 14:08:42 2023 ] 	Training loss: 0.6912.  Training acc: 76.29%.
[ Tue Jun 27 14:08:42 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:08:42 2023 ] Eval epoch: 18
[ Tue Jun 27 14:08:43 2023 ] 	Mean test loss of 625 batches: 0.854641.
[ Tue Jun 27 14:08:43 2023 ] 	Top1: 71.93%
[ Tue Jun 27 14:08:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:43 2023 ] Training epoch: 19
[ Tue Jun 27 14:08:45 2023 ] 	Training loss: 0.7112.  Training acc: 76.29%.
[ Tue Jun 27 14:08:45 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:08:45 2023 ] Eval epoch: 19
[ Tue Jun 27 14:08:46 2023 ] 	Mean test loss of 625 batches: 0.690104.
[ Tue Jun 27 14:08:46 2023 ] 	Top1: 71.93%
[ Tue Jun 27 14:08:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:46 2023 ] Training epoch: 20
[ Tue Jun 27 14:08:48 2023 ] 	Training loss: 0.6451.  Training acc: 80.51%.
[ Tue Jun 27 14:08:48 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:08:48 2023 ] Eval epoch: 20
[ Tue Jun 27 14:08:49 2023 ] 	Mean test loss of 625 batches: 0.755450.
[ Tue Jun 27 14:08:49 2023 ] 	Top1: 71.93%
[ Tue Jun 27 14:08:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:49 2023 ] Training epoch: 21
[ Tue Jun 27 14:08:51 2023 ] 	Training loss: 0.6341.  Training acc: 79.78%.
[ Tue Jun 27 14:08:51 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:08:51 2023 ] Eval epoch: 21
[ Tue Jun 27 14:08:52 2023 ] 	Mean test loss of 625 batches: 0.645700.
[ Tue Jun 27 14:08:52 2023 ] 	Top1: 73.68%
[ Tue Jun 27 14:08:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:52 2023 ] Training epoch: 22
[ Tue Jun 27 14:08:54 2023 ] 	Training loss: 0.6161.  Training acc: 81.89%.
[ Tue Jun 27 14:08:54 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:08:54 2023 ] Eval epoch: 22
[ Tue Jun 27 14:08:55 2023 ] 	Mean test loss of 625 batches: 0.679143.
[ Tue Jun 27 14:08:55 2023 ] 	Top1: 71.93%
[ Tue Jun 27 14:08:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:55 2023 ] Training epoch: 23
[ Tue Jun 27 14:08:57 2023 ] 	Training loss: 0.5944.  Training acc: 82.26%.
[ Tue Jun 27 14:08:57 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:08:57 2023 ] Eval epoch: 23
[ Tue Jun 27 14:08:58 2023 ] 	Mean test loss of 625 batches: 0.661898.
[ Tue Jun 27 14:08:58 2023 ] 	Top1: 73.68%
[ Tue Jun 27 14:08:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:08:58 2023 ] Training epoch: 24
[ Tue Jun 27 14:09:01 2023 ] 	Training loss: 0.6028.  Training acc: 82.08%.
[ Tue Jun 27 14:09:01 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:09:01 2023 ] Eval epoch: 24
[ Tue Jun 27 14:09:01 2023 ] 	Mean test loss of 625 batches: 0.640602.
[ Tue Jun 27 14:09:01 2023 ] 	Top1: 73.68%
[ Tue Jun 27 14:09:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:01 2023 ] Training epoch: 25
[ Tue Jun 27 14:09:03 2023 ] 	Training loss: 0.5865.  Training acc: 84.19%.
[ Tue Jun 27 14:09:03 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:09:03 2023 ] Eval epoch: 25
[ Tue Jun 27 14:09:04 2023 ] 	Mean test loss of 625 batches: 0.640815.
[ Tue Jun 27 14:09:04 2023 ] 	Top1: 73.68%
[ Tue Jun 27 14:09:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:04 2023 ] Training epoch: 26
[ Tue Jun 27 14:09:06 2023 ] 	Training loss: 0.5699.  Training acc: 85.29%.
[ Tue Jun 27 14:09:06 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:09:06 2023 ] Eval epoch: 26
[ Tue Jun 27 14:09:07 2023 ] 	Mean test loss of 625 batches: 0.646702.
[ Tue Jun 27 14:09:07 2023 ] 	Top1: 73.68%
[ Tue Jun 27 14:09:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:07 2023 ] Training epoch: 27
[ Tue Jun 27 14:09:09 2023 ] 	Training loss: 0.5588.  Training acc: 85.39%.
[ Tue Jun 27 14:09:09 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:09:09 2023 ] Eval epoch: 27
[ Tue Jun 27 14:09:10 2023 ] 	Mean test loss of 625 batches: 0.599764.
[ Tue Jun 27 14:09:10 2023 ] 	Top1: 73.68%
[ Tue Jun 27 14:09:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:10 2023 ] Training epoch: 28
[ Tue Jun 27 14:09:12 2023 ] 	Training loss: 0.5337.  Training acc: 87.13%.
[ Tue Jun 27 14:09:12 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:09:12 2023 ] Eval epoch: 28
[ Tue Jun 27 14:09:13 2023 ] 	Mean test loss of 625 batches: 0.598869.
[ Tue Jun 27 14:09:13 2023 ] 	Top1: 75.44%
[ Tue Jun 27 14:09:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:13 2023 ] Training epoch: 29
[ Tue Jun 27 14:09:16 2023 ] 	Training loss: 0.5379.  Training acc: 87.96%.
[ Tue Jun 27 14:09:16 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:09:16 2023 ] Eval epoch: 29
[ Tue Jun 27 14:09:16 2023 ] 	Mean test loss of 625 batches: 0.569207.
[ Tue Jun 27 14:09:16 2023 ] 	Top1: 77.19%
[ Tue Jun 27 14:09:16 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:16 2023 ] Training epoch: 30
[ Tue Jun 27 14:09:19 2023 ] 	Training loss: 0.5046.  Training acc: 89.06%.
[ Tue Jun 27 14:09:19 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:09:19 2023 ] Eval epoch: 30
[ Tue Jun 27 14:09:20 2023 ] 	Mean test loss of 625 batches: 0.524050.
[ Tue Jun 27 14:09:20 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:09:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:20 2023 ] Training epoch: 31
[ Tue Jun 27 14:09:22 2023 ] 	Training loss: 0.4900.  Training acc: 91.18%.
[ Tue Jun 27 14:09:22 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:09:22 2023 ] Eval epoch: 31
[ Tue Jun 27 14:09:23 2023 ] 	Mean test loss of 625 batches: 0.502170.
[ Tue Jun 27 14:09:23 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:09:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:23 2023 ] Training epoch: 32
[ Tue Jun 27 14:09:25 2023 ] 	Training loss: 0.4946.  Training acc: 89.34%.
[ Tue Jun 27 14:09:25 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:09:25 2023 ] Eval epoch: 32
[ Tue Jun 27 14:09:26 2023 ] 	Mean test loss of 625 batches: 0.481832.
[ Tue Jun 27 14:09:26 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:09:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:26 2023 ] Training epoch: 33
[ Tue Jun 27 14:09:28 2023 ] 	Training loss: 0.4502.  Training acc: 93.47%.
[ Tue Jun 27 14:09:28 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:09:28 2023 ] Eval epoch: 33
[ Tue Jun 27 14:09:29 2023 ] 	Mean test loss of 625 batches: 0.455646.
[ Tue Jun 27 14:09:29 2023 ] 	Top1: 89.47%
[ Tue Jun 27 14:09:29 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:29 2023 ] Training epoch: 34
[ Tue Jun 27 14:09:32 2023 ] 	Training loss: 0.4426.  Training acc: 94.39%.
[ Tue Jun 27 14:09:32 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:09:32 2023 ] Eval epoch: 34
[ Tue Jun 27 14:09:32 2023 ] 	Mean test loss of 625 batches: 0.426795.
[ Tue Jun 27 14:09:32 2023 ] 	Top1: 94.74%
[ Tue Jun 27 14:09:32 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:32 2023 ] Training epoch: 35
[ Tue Jun 27 14:09:35 2023 ] 	Training loss: 0.4150.  Training acc: 95.13%.
[ Tue Jun 27 14:09:35 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:09:35 2023 ] Eval epoch: 35
[ Tue Jun 27 14:09:36 2023 ] 	Mean test loss of 625 batches: 0.393742.
[ Tue Jun 27 14:09:36 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:09:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:36 2023 ] Training epoch: 36
[ Tue Jun 27 14:09:38 2023 ] 	Training loss: 0.4201.  Training acc: 95.96%.
[ Tue Jun 27 14:09:38 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 14:09:38 2023 ] Eval epoch: 36
[ Tue Jun 27 14:09:38 2023 ] 	Mean test loss of 625 batches: 0.385004.
[ Tue Jun 27 14:09:38 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:09:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:38 2023 ] Training epoch: 37
[ Tue Jun 27 14:09:41 2023 ] 	Training loss: 0.4183.  Training acc: 95.40%.
[ Tue Jun 27 14:09:41 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:09:41 2023 ] Eval epoch: 37
[ Tue Jun 27 14:09:42 2023 ] 	Mean test loss of 625 batches: 0.378871.
[ Tue Jun 27 14:09:42 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:09:42 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:42 2023 ] Training epoch: 38
[ Tue Jun 27 14:09:44 2023 ] 	Training loss: 0.4171.  Training acc: 95.86%.
[ Tue Jun 27 14:09:44 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:09:44 2023 ] Eval epoch: 38
[ Tue Jun 27 14:09:45 2023 ] 	Mean test loss of 625 batches: 0.381249.
[ Tue Jun 27 14:09:45 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:09:45 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:45 2023 ] Training epoch: 39
[ Tue Jun 27 14:09:47 2023 ] 	Training loss: 0.4010.  Training acc: 96.88%.
[ Tue Jun 27 14:09:47 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:09:47 2023 ] Eval epoch: 39
[ Tue Jun 27 14:09:47 2023 ] 	Mean test loss of 625 batches: 0.351291.
[ Tue Jun 27 14:09:47 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:09:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:48 2023 ] Training epoch: 40
[ Tue Jun 27 14:09:50 2023 ] 	Training loss: 0.4102.  Training acc: 95.96%.
[ Tue Jun 27 14:09:50 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:09:50 2023 ] Eval epoch: 40
[ Tue Jun 27 14:09:51 2023 ] 	Mean test loss of 625 batches: 0.356684.
[ Tue Jun 27 14:09:51 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:09:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:09:51 2023 ] Best accuracy: 1.0
[ Tue Jun 27 14:09:51 2023 ] Epoch number: 35
[ Tue Jun 27 14:09:51 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 14:09:51 2023 ] Weight decay: 0.0005
[ Tue Jun 27 14:09:51 2023 ] Base LR: 0.1
[ Tue Jun 27 14:09:51 2023 ] Batch Size: 64
[ Tue Jun 27 14:09:51 2023 ] Test Batch Size: 64
[ Tue Jun 27 14:09:51 2023 ] seed: 1
[ Tue Jun 27 14:09:51 2023 ] Start training Corrector
[ Tue Jun 27 14:09:51 2023 ] Training epoch: 1
[ Tue Jun 27 14:12:56 2023 ] using warm up, epoch: 5
[ Tue Jun 27 14:12:58 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 14:12:58 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 14:12:58 2023 ] Start training Predictor
[ Tue Jun 27 14:12:58 2023 ] Training epoch: 1
[ Tue Jun 27 14:13:03 2023 ] 	Training loss: 106.5895.  Training acc: 35.57%.
[ Tue Jun 27 14:13:03 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Jun 27 14:13:03 2023 ] Eval epoch: 1
[ Tue Jun 27 14:13:04 2023 ] 	Mean test loss of 625 batches: 1375.783521.
[ Tue Jun 27 14:13:04 2023 ] 	Top1: 29.82%
[ Tue Jun 27 14:13:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:04 2023 ] Training epoch: 2
[ Tue Jun 27 14:13:07 2023 ] 	Training loss: 12.5282.  Training acc: 35.85%.
[ Tue Jun 27 14:13:07 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:13:07 2023 ] Eval epoch: 2
[ Tue Jun 27 14:13:07 2023 ] 	Mean test loss of 625 batches: 2.967765.
[ Tue Jun 27 14:13:07 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:13:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:07 2023 ] Training epoch: 3
[ Tue Jun 27 14:13:09 2023 ] 	Training loss: 7.4831.  Training acc: 34.19%.
[ Tue Jun 27 14:13:09 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:13:09 2023 ] Eval epoch: 3
[ Tue Jun 27 14:13:10 2023 ] 	Mean test loss of 625 batches: 2.617230.
[ Tue Jun 27 14:13:10 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:13:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:10 2023 ] Training epoch: 4
[ Tue Jun 27 14:13:12 2023 ] 	Training loss: 6.1471.  Training acc: 31.34%.
[ Tue Jun 27 14:13:12 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:13:12 2023 ] Eval epoch: 4
[ Tue Jun 27 14:13:13 2023 ] 	Mean test loss of 625 batches: 1.712681.
[ Tue Jun 27 14:13:13 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:13:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:13 2023 ] Training epoch: 5
[ Tue Jun 27 14:13:15 2023 ] 	Training loss: 5.2338.  Training acc: 36.40%.
[ Tue Jun 27 14:13:15 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:13:15 2023 ] Eval epoch: 5
[ Tue Jun 27 14:13:16 2023 ] 	Mean test loss of 625 batches: 1.717953.
[ Tue Jun 27 14:13:16 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:13:16 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:16 2023 ] Training epoch: 6
[ Tue Jun 27 14:13:18 2023 ] 	Training loss: 3.7186.  Training acc: 34.74%.
[ Tue Jun 27 14:13:18 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:13:18 2023 ] Eval epoch: 6
[ Tue Jun 27 14:13:19 2023 ] 	Mean test loss of 625 batches: 1.074450.
[ Tue Jun 27 14:13:19 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:13:19 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:19 2023 ] Training epoch: 7
[ Tue Jun 27 14:13:22 2023 ] 	Training loss: 2.7821.  Training acc: 37.41%.
[ Tue Jun 27 14:13:22 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:13:22 2023 ] Eval epoch: 7
[ Tue Jun 27 14:13:22 2023 ] 	Mean test loss of 625 batches: 1.343509.
[ Tue Jun 27 14:13:22 2023 ] 	Top1: 47.37%
[ Tue Jun 27 14:13:22 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:22 2023 ] Training epoch: 8
[ Tue Jun 27 14:13:25 2023 ] 	Training loss: 1.8633.  Training acc: 51.47%.
[ Tue Jun 27 14:13:25 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:13:25 2023 ] Eval epoch: 8
[ Tue Jun 27 14:13:25 2023 ] 	Mean test loss of 625 batches: 1.694526.
[ Tue Jun 27 14:13:25 2023 ] 	Top1: 35.09%
[ Tue Jun 27 14:13:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:25 2023 ] Training epoch: 9
[ Tue Jun 27 14:13:28 2023 ] 	Training loss: 1.4690.  Training acc: 65.53%.
[ Tue Jun 27 14:13:28 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 14:13:28 2023 ] Eval epoch: 9
[ Tue Jun 27 14:13:29 2023 ] 	Mean test loss of 625 batches: 4.727582.
[ Tue Jun 27 14:13:29 2023 ] 	Top1: 29.82%
[ Tue Jun 27 14:13:29 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:29 2023 ] Training epoch: 10
[ Tue Jun 27 14:13:31 2023 ] 	Training loss: 1.4260.  Training acc: 58.82%.
[ Tue Jun 27 14:13:31 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:13:31 2023 ] Eval epoch: 10
[ Tue Jun 27 14:13:32 2023 ] 	Mean test loss of 625 batches: 2.922850.
[ Tue Jun 27 14:13:32 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:13:32 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:32 2023 ] Training epoch: 11
[ Tue Jun 27 14:13:34 2023 ] 	Training loss: 1.1036.  Training acc: 69.03%.
[ Tue Jun 27 14:13:34 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:13:34 2023 ] Eval epoch: 11
[ Tue Jun 27 14:13:35 2023 ] 	Mean test loss of 625 batches: 0.638423.
[ Tue Jun 27 14:13:35 2023 ] 	Top1: 77.19%
[ Tue Jun 27 14:13:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:35 2023 ] Training epoch: 12
[ Tue Jun 27 14:13:37 2023 ] 	Training loss: 0.9600.  Training acc: 70.04%.
[ Tue Jun 27 14:13:37 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:13:37 2023 ] Eval epoch: 12
[ Tue Jun 27 14:13:38 2023 ] 	Mean test loss of 625 batches: 0.599555.
[ Tue Jun 27 14:13:38 2023 ] 	Top1: 89.47%
[ Tue Jun 27 14:13:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:38 2023 ] Training epoch: 13
[ Tue Jun 27 14:13:40 2023 ] 	Training loss: 0.8563.  Training acc: 74.17%.
[ Tue Jun 27 14:13:40 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:13:40 2023 ] Eval epoch: 13
[ Tue Jun 27 14:13:41 2023 ] 	Mean test loss of 625 batches: 0.648085.
[ Tue Jun 27 14:13:41 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:13:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:41 2023 ] Training epoch: 14
[ Tue Jun 27 14:13:43 2023 ] 	Training loss: 0.8341.  Training acc: 75.55%.
[ Tue Jun 27 14:13:43 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:13:43 2023 ] Eval epoch: 14
[ Tue Jun 27 14:13:44 2023 ] 	Mean test loss of 625 batches: 0.640134.
[ Tue Jun 27 14:13:44 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:13:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:44 2023 ] Training epoch: 15
[ Tue Jun 27 14:13:46 2023 ] 	Training loss: 0.8253.  Training acc: 77.02%.
[ Tue Jun 27 14:13:46 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:13:46 2023 ] Eval epoch: 15
[ Tue Jun 27 14:13:47 2023 ] 	Mean test loss of 625 batches: 0.611834.
[ Tue Jun 27 14:13:47 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:13:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:47 2023 ] Training epoch: 16
[ Tue Jun 27 14:13:50 2023 ] 	Training loss: 0.8057.  Training acc: 77.67%.
[ Tue Jun 27 14:13:50 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:13:50 2023 ] Eval epoch: 16
[ Tue Jun 27 14:13:51 2023 ] 	Mean test loss of 625 batches: 0.669350.
[ Tue Jun 27 14:13:51 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:13:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:51 2023 ] Training epoch: 17
[ Tue Jun 27 14:13:53 2023 ] 	Training loss: 0.7664.  Training acc: 80.15%.
[ Tue Jun 27 14:13:53 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:13:53 2023 ] Eval epoch: 17
[ Tue Jun 27 14:13:54 2023 ] 	Mean test loss of 625 batches: 0.570769.
[ Tue Jun 27 14:13:54 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:13:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:54 2023 ] Training epoch: 18
[ Tue Jun 27 14:13:56 2023 ] 	Training loss: 0.7574.  Training acc: 80.79%.
[ Tue Jun 27 14:13:56 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:13:56 2023 ] Eval epoch: 18
[ Tue Jun 27 14:13:57 2023 ] 	Mean test loss of 625 batches: 0.570245.
[ Tue Jun 27 14:13:57 2023 ] 	Top1: 91.23%
[ Tue Jun 27 14:13:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:13:57 2023 ] Training epoch: 19
[ Tue Jun 27 14:13:59 2023 ] 	Training loss: 0.7505.  Training acc: 83.27%.
[ Tue Jun 27 14:13:59 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:13:59 2023 ] Eval epoch: 19
[ Tue Jun 27 14:14:00 2023 ] 	Mean test loss of 625 batches: 0.530231.
[ Tue Jun 27 14:14:00 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:14:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:00 2023 ] Training epoch: 20
[ Tue Jun 27 14:14:02 2023 ] 	Training loss: 0.6959.  Training acc: 84.47%.
[ Tue Jun 27 14:14:02 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:14:02 2023 ] Eval epoch: 20
[ Tue Jun 27 14:14:03 2023 ] 	Mean test loss of 625 batches: 0.531663.
[ Tue Jun 27 14:14:03 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:14:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:03 2023 ] Training epoch: 21
[ Tue Jun 27 14:14:06 2023 ] 	Training loss: 0.6638.  Training acc: 85.20%.
[ Tue Jun 27 14:14:06 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:14:06 2023 ] Eval epoch: 21
[ Tue Jun 27 14:14:06 2023 ] 	Mean test loss of 625 batches: 0.506425.
[ Tue Jun 27 14:14:06 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:14:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:06 2023 ] Training epoch: 22
[ Tue Jun 27 14:14:09 2023 ] 	Training loss: 0.6656.  Training acc: 87.41%.
[ Tue Jun 27 14:14:09 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:14:09 2023 ] Eval epoch: 22
[ Tue Jun 27 14:14:09 2023 ] 	Mean test loss of 625 batches: 0.518641.
[ Tue Jun 27 14:14:09 2023 ] 	Top1: 94.74%
[ Tue Jun 27 14:14:09 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:09 2023 ] Training epoch: 23
[ Tue Jun 27 14:14:12 2023 ] 	Training loss: 0.6569.  Training acc: 87.78%.
[ Tue Jun 27 14:14:12 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:14:12 2023 ] Eval epoch: 23
[ Tue Jun 27 14:14:12 2023 ] 	Mean test loss of 625 batches: 0.512817.
[ Tue Jun 27 14:14:12 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:14:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:12 2023 ] Training epoch: 24
[ Tue Jun 27 14:14:15 2023 ] 	Training loss: 0.6655.  Training acc: 85.85%.
[ Tue Jun 27 14:14:15 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:14:15 2023 ] Eval epoch: 24
[ Tue Jun 27 14:14:15 2023 ] 	Mean test loss of 625 batches: 0.522225.
[ Tue Jun 27 14:14:15 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:14:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:15 2023 ] Training epoch: 25
[ Tue Jun 27 14:14:18 2023 ] 	Training loss: 0.6457.  Training acc: 86.67%.
[ Tue Jun 27 14:14:18 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:14:18 2023 ] Eval epoch: 25
[ Tue Jun 27 14:14:18 2023 ] 	Mean test loss of 625 batches: 0.531138.
[ Tue Jun 27 14:14:18 2023 ] 	Top1: 92.98%
[ Tue Jun 27 14:14:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:18 2023 ] Training epoch: 26
[ Tue Jun 27 14:14:21 2023 ] 	Training loss: 0.6412.  Training acc: 88.42%.
[ Tue Jun 27 14:14:21 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:14:21 2023 ] Eval epoch: 26
[ Tue Jun 27 14:14:21 2023 ] 	Mean test loss of 625 batches: 0.532836.
[ Tue Jun 27 14:14:21 2023 ] 	Top1: 92.98%
[ Tue Jun 27 14:14:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:21 2023 ] Training epoch: 27
[ Tue Jun 27 14:14:24 2023 ] 	Training loss: 0.6482.  Training acc: 87.41%.
[ Tue Jun 27 14:14:24 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:14:24 2023 ] Eval epoch: 27
[ Tue Jun 27 14:14:25 2023 ] 	Mean test loss of 625 batches: 0.538444.
[ Tue Jun 27 14:14:25 2023 ] 	Top1: 92.98%
[ Tue Jun 27 14:14:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:25 2023 ] Training epoch: 28
[ Tue Jun 27 14:14:27 2023 ] 	Training loss: 0.6327.  Training acc: 88.60%.
[ Tue Jun 27 14:14:27 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:14:27 2023 ] Eval epoch: 28
[ Tue Jun 27 14:14:28 2023 ] 	Mean test loss of 625 batches: 0.524777.
[ Tue Jun 27 14:14:28 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:14:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:28 2023 ] Training epoch: 29
[ Tue Jun 27 14:14:30 2023 ] 	Training loss: 0.6246.  Training acc: 89.80%.
[ Tue Jun 27 14:14:30 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:14:30 2023 ] Eval epoch: 29
[ Tue Jun 27 14:14:31 2023 ] 	Mean test loss of 625 batches: 0.503484.
[ Tue Jun 27 14:14:31 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:14:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:31 2023 ] Training epoch: 30
[ Tue Jun 27 14:14:34 2023 ] 	Training loss: 0.6199.  Training acc: 90.44%.
[ Tue Jun 27 14:14:34 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:14:34 2023 ] Eval epoch: 30
[ Tue Jun 27 14:14:34 2023 ] 	Mean test loss of 625 batches: 0.505487.
[ Tue Jun 27 14:14:34 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:14:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:34 2023 ] Training epoch: 31
[ Tue Jun 27 14:14:37 2023 ] 	Training loss: 0.6108.  Training acc: 90.26%.
[ Tue Jun 27 14:14:37 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:14:37 2023 ] Eval epoch: 31
[ Tue Jun 27 14:14:37 2023 ] 	Mean test loss of 625 batches: 0.517283.
[ Tue Jun 27 14:14:37 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:14:37 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:37 2023 ] Training epoch: 32
[ Tue Jun 27 14:14:40 2023 ] 	Training loss: 0.6266.  Training acc: 89.06%.
[ Tue Jun 27 14:14:40 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:14:40 2023 ] Eval epoch: 32
[ Tue Jun 27 14:14:40 2023 ] 	Mean test loss of 625 batches: 0.519752.
[ Tue Jun 27 14:14:40 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:14:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:40 2023 ] Training epoch: 33
[ Tue Jun 27 14:14:42 2023 ] 	Training loss: 0.6169.  Training acc: 90.62%.
[ Tue Jun 27 14:14:42 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:14:42 2023 ] Eval epoch: 33
[ Tue Jun 27 14:14:43 2023 ] 	Mean test loss of 625 batches: 0.489517.
[ Tue Jun 27 14:14:43 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:14:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:43 2023 ] Training epoch: 34
[ Tue Jun 27 14:14:45 2023 ] 	Training loss: 0.6243.  Training acc: 89.06%.
[ Tue Jun 27 14:14:45 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:14:45 2023 ] Eval epoch: 34
[ Tue Jun 27 14:14:46 2023 ] 	Mean test loss of 625 batches: 0.501129.
[ Tue Jun 27 14:14:46 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:14:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:46 2023 ] Training epoch: 35
[ Tue Jun 27 14:14:49 2023 ] 	Training loss: 0.5946.  Training acc: 91.08%.
[ Tue Jun 27 14:14:49 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:14:49 2023 ] Eval epoch: 35
[ Tue Jun 27 14:14:49 2023 ] 	Mean test loss of 625 batches: 0.512617.
[ Tue Jun 27 14:14:49 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:14:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:49 2023 ] Training epoch: 36
[ Tue Jun 27 14:14:52 2023 ] 	Training loss: 0.6096.  Training acc: 90.53%.
[ Tue Jun 27 14:14:52 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:14:52 2023 ] Eval epoch: 36
[ Tue Jun 27 14:14:52 2023 ] 	Mean test loss of 625 batches: 0.495757.
[ Tue Jun 27 14:14:52 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:14:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:52 2023 ] Training epoch: 37
[ Tue Jun 27 14:14:55 2023 ] 	Training loss: 0.6198.  Training acc: 89.71%.
[ Tue Jun 27 14:14:55 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:14:55 2023 ] Eval epoch: 37
[ Tue Jun 27 14:14:56 2023 ] 	Mean test loss of 625 batches: 0.495695.
[ Tue Jun 27 14:14:56 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:14:56 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:56 2023 ] Training epoch: 38
[ Tue Jun 27 14:14:58 2023 ] 	Training loss: 0.6041.  Training acc: 89.89%.
[ Tue Jun 27 14:14:58 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:14:58 2023 ] Eval epoch: 38
[ Tue Jun 27 14:14:58 2023 ] 	Mean test loss of 625 batches: 0.478477.
[ Tue Jun 27 14:14:58 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:14:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:14:58 2023 ] Training epoch: 39
[ Tue Jun 27 14:15:01 2023 ] 	Training loss: 0.6059.  Training acc: 91.18%.
[ Tue Jun 27 14:15:01 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:15:01 2023 ] Eval epoch: 39
[ Tue Jun 27 14:15:02 2023 ] 	Mean test loss of 625 batches: 0.501927.
[ Tue Jun 27 14:15:02 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:15:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:15:02 2023 ] Training epoch: 40
[ Tue Jun 27 14:15:04 2023 ] 	Training loss: 0.6244.  Training acc: 89.06%.
[ Tue Jun 27 14:15:04 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:15:04 2023 ] Eval epoch: 40
[ Tue Jun 27 14:15:05 2023 ] 	Mean test loss of 625 batches: 0.497709.
[ Tue Jun 27 14:15:05 2023 ] 	Top1: 100.00%
[ Tue Jun 27 14:15:05 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:15:06 2023 ] Best accuracy: 1.0
[ Tue Jun 27 14:15:06 2023 ] Epoch number: 19
[ Tue Jun 27 14:15:06 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 14:15:06 2023 ] Weight decay: 0.0005
[ Tue Jun 27 14:15:06 2023 ] Base LR: 0.1
[ Tue Jun 27 14:15:06 2023 ] Batch Size: 64
[ Tue Jun 27 14:15:06 2023 ] Test Batch Size: 64
[ Tue Jun 27 14:15:06 2023 ] seed: 1
[ Tue Jun 27 14:15:06 2023 ] Start training Corrector
[ Tue Jun 27 14:15:06 2023 ] Training epoch: 1
[ Tue Jun 27 14:16:38 2023 ] using warm up, epoch: 5
[ Tue Jun 27 14:16:39 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 14:16:39 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 14:16:39 2023 ] Start training Predictor
[ Tue Jun 27 14:16:39 2023 ] Training epoch: 1
[ Tue Jun 27 14:16:45 2023 ] 	Training loss: 102.3355.  Training acc: 34.93%.
[ Tue Jun 27 14:16:45 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jun 27 14:16:45 2023 ] Eval epoch: 1
[ Tue Jun 27 14:16:46 2023 ] 	Mean test loss of 625 batches: 5985.130371.
[ Tue Jun 27 14:16:46 2023 ] 	Top1: 29.82%
[ Tue Jun 27 14:16:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:16:46 2023 ] Training epoch: 2
[ Tue Jun 27 14:16:48 2023 ] 	Training loss: 17.1171.  Training acc: 35.02%.
[ Tue Jun 27 14:16:48 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:16:48 2023 ] Eval epoch: 2
[ Tue Jun 27 14:16:49 2023 ] 	Mean test loss of 625 batches: 1.762706.
[ Tue Jun 27 14:16:49 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:16:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:16:49 2023 ] Training epoch: 3
[ Tue Jun 27 14:16:51 2023 ] 	Training loss: 5.8446.  Training acc: 44.76%.
[ Tue Jun 27 14:16:51 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:16:51 2023 ] Eval epoch: 3
[ Tue Jun 27 14:16:52 2023 ] 	Mean test loss of 625 batches: 2.601907.
[ Tue Jun 27 14:16:52 2023 ] 	Top1: 59.65%
[ Tue Jun 27 14:16:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:16:52 2023 ] Training epoch: 4
[ Tue Jun 27 14:16:54 2023 ] 	Training loss: 5.6151.  Training acc: 55.79%.
[ Tue Jun 27 14:16:54 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:16:54 2023 ] Eval epoch: 4
[ Tue Jun 27 14:16:55 2023 ] 	Mean test loss of 625 batches: 5.038555.
[ Tue Jun 27 14:16:55 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:16:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:16:55 2023 ] Training epoch: 5
[ Tue Jun 27 14:16:57 2023 ] 	Training loss: 3.5563.  Training acc: 55.79%.
[ Tue Jun 27 14:16:57 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:16:57 2023 ] Eval epoch: 5
[ Tue Jun 27 14:16:57 2023 ] 	Mean test loss of 625 batches: 8.399402.
[ Tue Jun 27 14:16:57 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:16:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:16:57 2023 ] Training epoch: 6
[ Tue Jun 27 14:17:00 2023 ] 	Training loss: 5.0115.  Training acc: 55.51%.
[ Tue Jun 27 14:17:00 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:00 2023 ] Eval epoch: 6
[ Tue Jun 27 14:17:00 2023 ] 	Mean test loss of 625 batches: 5.735251.
[ Tue Jun 27 14:17:00 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:17:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:00 2023 ] Training epoch: 7
[ Tue Jun 27 14:17:03 2023 ] 	Training loss: 2.3901.  Training acc: 59.65%.
[ Tue Jun 27 14:17:03 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:03 2023 ] Eval epoch: 7
[ Tue Jun 27 14:17:03 2023 ] 	Mean test loss of 625 batches: 1.936157.
[ Tue Jun 27 14:17:03 2023 ] 	Top1: 68.42%
[ Tue Jun 27 14:17:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:03 2023 ] Training epoch: 8
[ Tue Jun 27 14:17:06 2023 ] 	Training loss: 1.7598.  Training acc: 59.56%.
[ Tue Jun 27 14:17:06 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:06 2023 ] Eval epoch: 8
[ Tue Jun 27 14:17:06 2023 ] 	Mean test loss of 625 batches: 0.710838.
[ Tue Jun 27 14:17:06 2023 ] 	Top1: 68.42%
[ Tue Jun 27 14:17:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:06 2023 ] Training epoch: 9
[ Tue Jun 27 14:17:09 2023 ] 	Training loss: 1.3426.  Training acc: 65.17%.
[ Tue Jun 27 14:17:09 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:17:09 2023 ] Eval epoch: 9
[ Tue Jun 27 14:17:09 2023 ] 	Mean test loss of 625 batches: 1.474418.
[ Tue Jun 27 14:17:09 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:17:09 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:09 2023 ] Training epoch: 10
[ Tue Jun 27 14:17:11 2023 ] 	Training loss: 1.0030.  Training acc: 75.28%.
[ Tue Jun 27 14:17:11 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:17:11 2023 ] Eval epoch: 10
[ Tue Jun 27 14:17:12 2023 ] 	Mean test loss of 625 batches: 0.797948.
[ Tue Jun 27 14:17:12 2023 ] 	Top1: 82.46%
[ Tue Jun 27 14:17:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:12 2023 ] Training epoch: 11
[ Tue Jun 27 14:17:14 2023 ] 	Training loss: 0.7000.  Training acc: 87.22%.
[ Tue Jun 27 14:17:14 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:14 2023 ] Eval epoch: 11
[ Tue Jun 27 14:17:15 2023 ] 	Mean test loss of 625 batches: 0.581801.
[ Tue Jun 27 14:17:15 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:17:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:15 2023 ] Training epoch: 12
[ Tue Jun 27 14:17:17 2023 ] 	Training loss: 0.6068.  Training acc: 89.34%.
[ Tue Jun 27 14:17:17 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:17 2023 ] Eval epoch: 12
[ Tue Jun 27 14:17:18 2023 ] 	Mean test loss of 625 batches: 0.590783.
[ Tue Jun 27 14:17:18 2023 ] 	Top1: 89.47%
[ Tue Jun 27 14:17:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:18 2023 ] Training epoch: 13
[ Tue Jun 27 14:17:20 2023 ] 	Training loss: 0.5529.  Training acc: 90.17%.
[ Tue Jun 27 14:17:21 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:21 2023 ] Eval epoch: 13
[ Tue Jun 27 14:17:21 2023 ] 	Mean test loss of 625 batches: 0.523088.
[ Tue Jun 27 14:17:21 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:17:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:21 2023 ] Training epoch: 14
[ Tue Jun 27 14:17:24 2023 ] 	Training loss: 0.5269.  Training acc: 90.81%.
[ Tue Jun 27 14:17:24 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:24 2023 ] Eval epoch: 14
[ Tue Jun 27 14:17:24 2023 ] 	Mean test loss of 625 batches: 0.416696.
[ Tue Jun 27 14:17:24 2023 ] 	Top1: 94.74%
[ Tue Jun 27 14:17:24 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:24 2023 ] Training epoch: 15
[ Tue Jun 27 14:17:27 2023 ] 	Training loss: 0.5758.  Training acc: 88.69%.
[ Tue Jun 27 14:17:27 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:27 2023 ] Eval epoch: 15
[ Tue Jun 27 14:17:27 2023 ] 	Mean test loss of 625 batches: 0.446513.
[ Tue Jun 27 14:17:27 2023 ] 	Top1: 94.74%
[ Tue Jun 27 14:17:27 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:27 2023 ] Training epoch: 16
[ Tue Jun 27 14:17:30 2023 ] 	Training loss: 0.5201.  Training acc: 92.10%.
[ Tue Jun 27 14:17:30 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:17:30 2023 ] Eval epoch: 16
[ Tue Jun 27 14:17:30 2023 ] 	Mean test loss of 625 batches: 0.500284.
[ Tue Jun 27 14:17:30 2023 ] 	Top1: 91.23%
[ Tue Jun 27 14:17:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:30 2023 ] Training epoch: 17
[ Tue Jun 27 14:17:33 2023 ] 	Training loss: 0.4914.  Training acc: 93.47%.
[ Tue Jun 27 14:17:33 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:17:33 2023 ] Eval epoch: 17
[ Tue Jun 27 14:17:33 2023 ] 	Mean test loss of 625 batches: 0.469586.
[ Tue Jun 27 14:17:33 2023 ] 	Top1: 92.98%
[ Tue Jun 27 14:17:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:33 2023 ] Training epoch: 18
[ Tue Jun 27 14:17:36 2023 ] 	Training loss: 0.5324.  Training acc: 90.81%.
[ Tue Jun 27 14:17:36 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:17:36 2023 ] Eval epoch: 18
[ Tue Jun 27 14:17:36 2023 ] 	Mean test loss of 625 batches: 0.465171.
[ Tue Jun 27 14:17:36 2023 ] 	Top1: 91.23%
[ Tue Jun 27 14:17:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:36 2023 ] Training epoch: 19
[ Tue Jun 27 14:17:38 2023 ] 	Training loss: 0.5182.  Training acc: 92.37%.
[ Tue Jun 27 14:17:38 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:38 2023 ] Eval epoch: 19
[ Tue Jun 27 14:17:39 2023 ] 	Mean test loss of 625 batches: 0.542538.
[ Tue Jun 27 14:17:39 2023 ] 	Top1: 89.47%
[ Tue Jun 27 14:17:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:39 2023 ] Training epoch: 20
[ Tue Jun 27 14:17:41 2023 ] 	Training loss: 0.4657.  Training acc: 93.57%.
[ Tue Jun 27 14:17:41 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:17:41 2023 ] Eval epoch: 20
[ Tue Jun 27 14:17:42 2023 ] 	Mean test loss of 625 batches: 0.438097.
[ Tue Jun 27 14:17:42 2023 ] 	Top1: 94.74%
[ Tue Jun 27 14:17:42 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:42 2023 ] Training epoch: 21
[ Tue Jun 27 14:17:44 2023 ] 	Training loss: 0.4645.  Training acc: 94.30%.
[ Tue Jun 27 14:17:44 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:44 2023 ] Eval epoch: 21
[ Tue Jun 27 14:17:45 2023 ] 	Mean test loss of 625 batches: 0.388977.
[ Tue Jun 27 14:17:45 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:17:45 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:45 2023 ] Training epoch: 22
[ Tue Jun 27 14:17:47 2023 ] 	Training loss: 0.4423.  Training acc: 94.49%.
[ Tue Jun 27 14:17:47 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:17:47 2023 ] Eval epoch: 22
[ Tue Jun 27 14:17:48 2023 ] 	Mean test loss of 625 batches: 0.377652.
[ Tue Jun 27 14:17:48 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:17:48 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:48 2023 ] Training epoch: 23
[ Tue Jun 27 14:17:50 2023 ] 	Training loss: 0.4358.  Training acc: 95.50%.
[ Tue Jun 27 14:17:50 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:17:50 2023 ] Eval epoch: 23
[ Tue Jun 27 14:17:51 2023 ] 	Mean test loss of 625 batches: 0.394345.
[ Tue Jun 27 14:17:51 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:17:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:51 2023 ] Training epoch: 24
[ Tue Jun 27 14:17:53 2023 ] 	Training loss: 0.4332.  Training acc: 96.14%.
[ Tue Jun 27 14:17:53 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 14:17:53 2023 ] Eval epoch: 24
[ Tue Jun 27 14:17:54 2023 ] 	Mean test loss of 625 batches: 0.378246.
[ Tue Jun 27 14:17:54 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:17:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:54 2023 ] Training epoch: 25
[ Tue Jun 27 14:17:57 2023 ] 	Training loss: 0.4368.  Training acc: 95.86%.
[ Tue Jun 27 14:17:57 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:17:57 2023 ] Eval epoch: 25
[ Tue Jun 27 14:17:57 2023 ] 	Mean test loss of 625 batches: 0.400809.
[ Tue Jun 27 14:17:57 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:17:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:17:57 2023 ] Training epoch: 26
[ Tue Jun 27 14:18:00 2023 ] 	Training loss: 0.4326.  Training acc: 95.77%.
[ Tue Jun 27 14:18:00 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:18:00 2023 ] Eval epoch: 26
[ Tue Jun 27 14:18:00 2023 ] 	Mean test loss of 625 batches: 0.363933.
[ Tue Jun 27 14:18:00 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:18:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:00 2023 ] Training epoch: 27
[ Tue Jun 27 14:18:03 2023 ] 	Training loss: 0.4270.  Training acc: 96.32%.
[ Tue Jun 27 14:18:03 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:18:03 2023 ] Eval epoch: 27
[ Tue Jun 27 14:18:03 2023 ] 	Mean test loss of 625 batches: 0.381944.
[ Tue Jun 27 14:18:03 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:18:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:03 2023 ] Training epoch: 28
[ Tue Jun 27 14:18:06 2023 ] 	Training loss: 0.4150.  Training acc: 96.69%.
[ Tue Jun 27 14:18:06 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:18:06 2023 ] Eval epoch: 28
[ Tue Jun 27 14:18:06 2023 ] 	Mean test loss of 625 batches: 0.371516.
[ Tue Jun 27 14:18:06 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:18:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:06 2023 ] Training epoch: 29
[ Tue Jun 27 14:18:09 2023 ] 	Training loss: 0.4351.  Training acc: 95.40%.
[ Tue Jun 27 14:18:09 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:18:09 2023 ] Eval epoch: 29
[ Tue Jun 27 14:18:09 2023 ] 	Mean test loss of 625 batches: 0.364708.
[ Tue Jun 27 14:18:09 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:18:09 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:09 2023 ] Training epoch: 30
[ Tue Jun 27 14:18:12 2023 ] 	Training loss: 0.4229.  Training acc: 96.14%.
[ Tue Jun 27 14:18:12 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:18:12 2023 ] Eval epoch: 30
[ Tue Jun 27 14:18:12 2023 ] 	Mean test loss of 625 batches: 0.381269.
[ Tue Jun 27 14:18:12 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:18:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:12 2023 ] Training epoch: 31
[ Tue Jun 27 14:18:15 2023 ] 	Training loss: 0.4328.  Training acc: 95.96%.
[ Tue Jun 27 14:18:15 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:18:15 2023 ] Eval epoch: 31
[ Tue Jun 27 14:18:15 2023 ] 	Mean test loss of 625 batches: 0.378118.
[ Tue Jun 27 14:18:15 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:18:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:15 2023 ] Training epoch: 32
[ Tue Jun 27 14:18:18 2023 ] 	Training loss: 0.4193.  Training acc: 95.86%.
[ Tue Jun 27 14:18:18 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:18:18 2023 ] Eval epoch: 32
[ Tue Jun 27 14:18:18 2023 ] 	Mean test loss of 625 batches: 0.370340.
[ Tue Jun 27 14:18:18 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:18:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:18 2023 ] Training epoch: 33
[ Tue Jun 27 14:18:21 2023 ] 	Training loss: 0.4153.  Training acc: 96.69%.
[ Tue Jun 27 14:18:21 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:18:21 2023 ] Eval epoch: 33
[ Tue Jun 27 14:18:21 2023 ] 	Mean test loss of 625 batches: 0.355677.
[ Tue Jun 27 14:18:21 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:18:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:21 2023 ] Training epoch: 34
[ Tue Jun 27 14:18:24 2023 ] 	Training loss: 0.4101.  Training acc: 96.97%.
[ Tue Jun 27 14:18:24 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:18:24 2023 ] Eval epoch: 34
[ Tue Jun 27 14:18:24 2023 ] 	Mean test loss of 625 batches: 0.355379.
[ Tue Jun 27 14:18:24 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:18:24 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:24 2023 ] Training epoch: 35
[ Tue Jun 27 14:18:27 2023 ] 	Training loss: 0.4184.  Training acc: 96.78%.
[ Tue Jun 27 14:18:27 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:18:27 2023 ] Eval epoch: 35
[ Tue Jun 27 14:18:27 2023 ] 	Mean test loss of 625 batches: 0.354597.
[ Tue Jun 27 14:18:27 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:18:27 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:27 2023 ] Training epoch: 36
[ Tue Jun 27 14:18:30 2023 ] 	Training loss: 0.4095.  Training acc: 96.78%.
[ Tue Jun 27 14:18:30 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:18:30 2023 ] Eval epoch: 36
[ Tue Jun 27 14:18:30 2023 ] 	Mean test loss of 625 batches: 0.372976.
[ Tue Jun 27 14:18:30 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:18:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:30 2023 ] Training epoch: 37
[ Tue Jun 27 14:18:33 2023 ] 	Training loss: 0.4173.  Training acc: 96.69%.
[ Tue Jun 27 14:18:33 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:18:33 2023 ] Eval epoch: 37
[ Tue Jun 27 14:18:33 2023 ] 	Mean test loss of 625 batches: 0.352693.
[ Tue Jun 27 14:18:33 2023 ] 	Top1: 96.49%
[ Tue Jun 27 14:18:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:33 2023 ] Training epoch: 38
[ Tue Jun 27 14:18:36 2023 ] 	Training loss: 0.4090.  Training acc: 96.97%.
[ Tue Jun 27 14:18:36 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:18:36 2023 ] Eval epoch: 38
[ Tue Jun 27 14:18:36 2023 ] 	Mean test loss of 625 batches: 0.358210.
[ Tue Jun 27 14:18:36 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:18:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:36 2023 ] Training epoch: 39
[ Tue Jun 27 14:18:39 2023 ] 	Training loss: 0.4009.  Training acc: 96.97%.
[ Tue Jun 27 14:18:39 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:18:39 2023 ] Eval epoch: 39
[ Tue Jun 27 14:18:39 2023 ] 	Mean test loss of 625 batches: 0.341408.
[ Tue Jun 27 14:18:39 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:18:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:39 2023 ] Training epoch: 40
[ Tue Jun 27 14:18:42 2023 ] 	Training loss: 0.4146.  Training acc: 96.42%.
[ Tue Jun 27 14:18:42 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:18:42 2023 ] Eval epoch: 40
[ Tue Jun 27 14:18:42 2023 ] 	Mean test loss of 625 batches: 0.360832.
[ Tue Jun 27 14:18:42 2023 ] 	Top1: 98.25%
[ Tue Jun 27 14:18:42 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:18:43 2023 ] Best accuracy: 0.9824561403508771
[ Tue Jun 27 14:18:43 2023 ] Epoch number: 26
[ Tue Jun 27 14:18:43 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 14:18:43 2023 ] Weight decay: 0.0005
[ Tue Jun 27 14:18:43 2023 ] Base LR: 0.1
[ Tue Jun 27 14:18:43 2023 ] Batch Size: 64
[ Tue Jun 27 14:18:43 2023 ] Test Batch Size: 64
[ Tue Jun 27 14:18:43 2023 ] seed: 1
[ Tue Jun 27 14:18:43 2023 ] Start training Corrector
[ Tue Jun 27 14:18:43 2023 ] Training epoch: 1
[ Tue Jun 27 14:23:58 2023 ] using warm up, epoch: 5
[ Tue Jun 27 14:23:58 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 14:23:58 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 14:23:58 2023 ] Start training Predictor
[ Tue Jun 27 14:23:58 2023 ] Training epoch: 1
[ Tue Jun 27 14:24:04 2023 ] 	Training loss: 105.0491.  Training acc: 35.48%.
[ Tue Jun 27 14:24:04 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Jun 27 14:24:04 2023 ] Eval epoch: 1
[ Tue Jun 27 14:24:04 2023 ] 	Mean test loss of 625 batches: 72.175684.
[ Tue Jun 27 14:24:04 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:24:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:05 2023 ] Training epoch: 2
[ Tue Jun 27 14:24:07 2023 ] 	Training loss: 8.2283.  Training acc: 39.25%.
[ Tue Jun 27 14:24:07 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:24:07 2023 ] Eval epoch: 2
[ Tue Jun 27 14:24:07 2023 ] 	Mean test loss of 625 batches: 17.031623.
[ Tue Jun 27 14:24:07 2023 ] 	Top1: 56.14%
[ Tue Jun 27 14:24:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:07 2023 ] Training epoch: 3
[ Tue Jun 27 14:24:10 2023 ] 	Training loss: 6.3609.  Training acc: 47.61%.
[ Tue Jun 27 14:24:10 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:24:10 2023 ] Eval epoch: 3
[ Tue Jun 27 14:24:10 2023 ] 	Mean test loss of 625 batches: 15.792705.
[ Tue Jun 27 14:24:10 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:24:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:10 2023 ] Training epoch: 4
[ Tue Jun 27 14:24:13 2023 ] 	Training loss: 7.2384.  Training acc: 64.25%.
[ Tue Jun 27 14:24:13 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:24:13 2023 ] Eval epoch: 4
[ Tue Jun 27 14:24:13 2023 ] 	Mean test loss of 625 batches: 7.427565.
[ Tue Jun 27 14:24:13 2023 ] 	Top1: 43.86%
[ Tue Jun 27 14:24:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:13 2023 ] Training epoch: 5
[ Tue Jun 27 14:24:16 2023 ] 	Training loss: 9.0349.  Training acc: 56.62%.
[ Tue Jun 27 14:24:16 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:24:16 2023 ] Eval epoch: 5
[ Tue Jun 27 14:24:16 2023 ] 	Mean test loss of 625 batches: 16.257784.
[ Tue Jun 27 14:24:16 2023 ] 	Top1: 43.86%
[ Tue Jun 27 14:24:16 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:16 2023 ] Training epoch: 6
[ Tue Jun 27 14:24:19 2023 ] 	Training loss: 2.3363.  Training acc: 55.24%.
[ Tue Jun 27 14:24:19 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:24:19 2023 ] Eval epoch: 6
[ Tue Jun 27 14:24:19 2023 ] 	Mean test loss of 625 batches: 29.427145.
[ Tue Jun 27 14:24:19 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:24:19 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:19 2023 ] Training epoch: 7
[ Tue Jun 27 14:24:21 2023 ] 	Training loss: 1.6169.  Training acc: 57.08%.
[ Tue Jun 27 14:24:21 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:24:21 2023 ] Eval epoch: 7
[ Tue Jun 27 14:24:22 2023 ] 	Mean test loss of 625 batches: 6.851389.
[ Tue Jun 27 14:24:22 2023 ] 	Top1: 33.33%
[ Tue Jun 27 14:24:22 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:22 2023 ] Training epoch: 8
[ Tue Jun 27 14:24:24 2023 ] 	Training loss: 1.6804.  Training acc: 48.71%.
[ Tue Jun 27 14:24:24 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 14:24:24 2023 ] Eval epoch: 8
[ Tue Jun 27 14:24:25 2023 ] 	Mean test loss of 625 batches: 1.310456.
[ Tue Jun 27 14:24:25 2023 ] 	Top1: 50.88%
[ Tue Jun 27 14:24:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:25 2023 ] Training epoch: 9
[ Tue Jun 27 14:24:27 2023 ] 	Training loss: 2.1178.  Training acc: 48.44%.
[ Tue Jun 27 14:24:27 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:24:27 2023 ] Eval epoch: 9
[ Tue Jun 27 14:24:28 2023 ] 	Mean test loss of 625 batches: 1.372901.
[ Tue Jun 27 14:24:28 2023 ] 	Top1: 40.35%
[ Tue Jun 27 14:24:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:28 2023 ] Training epoch: 10
[ Tue Jun 27 14:24:30 2023 ] 	Training loss: 1.4009.  Training acc: 54.78%.
[ Tue Jun 27 14:24:30 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:24:30 2023 ] Eval epoch: 10
[ Tue Jun 27 14:24:31 2023 ] 	Mean test loss of 625 batches: 4.652955.
[ Tue Jun 27 14:24:31 2023 ] 	Top1: 8.77%
[ Tue Jun 27 14:24:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:31 2023 ] Training epoch: 11
[ Tue Jun 27 14:24:33 2023 ] 	Training loss: 1.1025.  Training acc: 58.73%.
[ Tue Jun 27 14:24:33 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:24:33 2023 ] Eval epoch: 11
[ Tue Jun 27 14:24:34 2023 ] 	Mean test loss of 625 batches: 1.032710.
[ Tue Jun 27 14:24:34 2023 ] 	Top1: 36.84%
[ Tue Jun 27 14:24:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:34 2023 ] Training epoch: 12
[ Tue Jun 27 14:24:36 2023 ] 	Training loss: 1.0127.  Training acc: 57.72%.
[ Tue Jun 27 14:24:36 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:24:36 2023 ] Eval epoch: 12
[ Tue Jun 27 14:24:37 2023 ] 	Mean test loss of 625 batches: 0.769107.
[ Tue Jun 27 14:24:37 2023 ] 	Top1: 64.91%
[ Tue Jun 27 14:24:37 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:37 2023 ] Training epoch: 13
[ Tue Jun 27 14:24:39 2023 ] 	Training loss: 0.8962.  Training acc: 62.96%.
[ Tue Jun 27 14:24:39 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:24:39 2023 ] Eval epoch: 13
[ Tue Jun 27 14:24:40 2023 ] 	Mean test loss of 625 batches: 0.673707.
[ Tue Jun 27 14:24:40 2023 ] 	Top1: 82.46%
[ Tue Jun 27 14:24:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:40 2023 ] Training epoch: 14
[ Tue Jun 27 14:24:43 2023 ] 	Training loss: 0.8380.  Training acc: 65.99%.
[ Tue Jun 27 14:24:43 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:24:43 2023 ] Eval epoch: 14
[ Tue Jun 27 14:24:43 2023 ] 	Mean test loss of 625 batches: 0.739172.
[ Tue Jun 27 14:24:43 2023 ] 	Top1: 77.19%
[ Tue Jun 27 14:24:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:43 2023 ] Training epoch: 15
[ Tue Jun 27 14:24:46 2023 ] 	Training loss: 0.8518.  Training acc: 64.98%.
[ Tue Jun 27 14:24:46 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:24:46 2023 ] Eval epoch: 15
[ Tue Jun 27 14:24:46 2023 ] 	Mean test loss of 625 batches: 0.680898.
[ Tue Jun 27 14:24:46 2023 ] 	Top1: 68.42%
[ Tue Jun 27 14:24:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:46 2023 ] Training epoch: 16
[ Tue Jun 27 14:24:48 2023 ] 	Training loss: 0.7959.  Training acc: 68.29%.
[ Tue Jun 27 14:24:48 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:24:48 2023 ] Eval epoch: 16
[ Tue Jun 27 14:24:49 2023 ] 	Mean test loss of 625 batches: 0.697690.
[ Tue Jun 27 14:24:49 2023 ] 	Top1: 66.67%
[ Tue Jun 27 14:24:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:49 2023 ] Training epoch: 17
[ Tue Jun 27 14:24:52 2023 ] 	Training loss: 0.7379.  Training acc: 73.35%.
[ Tue Jun 27 14:24:52 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:24:52 2023 ] Eval epoch: 17
[ Tue Jun 27 14:24:52 2023 ] 	Mean test loss of 625 batches: 0.681639.
[ Tue Jun 27 14:24:52 2023 ] 	Top1: 71.93%
[ Tue Jun 27 14:24:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:52 2023 ] Training epoch: 18
[ Tue Jun 27 14:24:55 2023 ] 	Training loss: 0.7285.  Training acc: 72.70%.
[ Tue Jun 27 14:24:55 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:24:55 2023 ] Eval epoch: 18
[ Tue Jun 27 14:24:55 2023 ] 	Mean test loss of 625 batches: 0.662989.
[ Tue Jun 27 14:24:55 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:24:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:55 2023 ] Training epoch: 19
[ Tue Jun 27 14:24:58 2023 ] 	Training loss: 0.7085.  Training acc: 76.93%.
[ Tue Jun 27 14:24:58 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:24:58 2023 ] Eval epoch: 19
[ Tue Jun 27 14:24:58 2023 ] 	Mean test loss of 625 batches: 0.704919.
[ Tue Jun 27 14:24:58 2023 ] 	Top1: 82.46%
[ Tue Jun 27 14:24:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:24:58 2023 ] Training epoch: 20
[ Tue Jun 27 14:25:01 2023 ] 	Training loss: 0.6789.  Training acc: 79.41%.
[ Tue Jun 27 14:25:01 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:01 2023 ] Eval epoch: 20
[ Tue Jun 27 14:25:01 2023 ] 	Mean test loss of 625 batches: 0.726280.
[ Tue Jun 27 14:25:01 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:25:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:01 2023 ] Training epoch: 21
[ Tue Jun 27 14:25:03 2023 ] 	Training loss: 0.6578.  Training acc: 81.71%.
[ Tue Jun 27 14:25:03 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:03 2023 ] Eval epoch: 21
[ Tue Jun 27 14:25:04 2023 ] 	Mean test loss of 625 batches: 0.612851.
[ Tue Jun 27 14:25:04 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:25:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:04 2023 ] Training epoch: 22
[ Tue Jun 27 14:25:07 2023 ] 	Training loss: 0.6395.  Training acc: 83.09%.
[ Tue Jun 27 14:25:07 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:07 2023 ] Eval epoch: 22
[ Tue Jun 27 14:25:07 2023 ] 	Mean test loss of 625 batches: 0.622487.
[ Tue Jun 27 14:25:07 2023 ] 	Top1: 89.47%
[ Tue Jun 27 14:25:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:07 2023 ] Training epoch: 23
[ Tue Jun 27 14:25:10 2023 ] 	Training loss: 0.6231.  Training acc: 85.02%.
[ Tue Jun 27 14:25:10 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:25:10 2023 ] Eval epoch: 23
[ Tue Jun 27 14:25:10 2023 ] 	Mean test loss of 625 batches: 0.641874.
[ Tue Jun 27 14:25:10 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:25:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:10 2023 ] Training epoch: 24
[ Tue Jun 27 14:25:13 2023 ] 	Training loss: 0.6457.  Training acc: 81.53%.
[ Tue Jun 27 14:25:13 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:13 2023 ] Eval epoch: 24
[ Tue Jun 27 14:25:13 2023 ] 	Mean test loss of 625 batches: 0.626704.
[ Tue Jun 27 14:25:13 2023 ] 	Top1: 89.47%
[ Tue Jun 27 14:25:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:13 2023 ] Training epoch: 25
[ Tue Jun 27 14:25:16 2023 ] 	Training loss: 0.6422.  Training acc: 83.27%.
[ Tue Jun 27 14:25:16 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:16 2023 ] Eval epoch: 25
[ Tue Jun 27 14:25:16 2023 ] 	Mean test loss of 625 batches: 0.621373.
[ Tue Jun 27 14:25:16 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:25:16 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:16 2023 ] Training epoch: 26
[ Tue Jun 27 14:25:19 2023 ] 	Training loss: 0.6322.  Training acc: 83.64%.
[ Tue Jun 27 14:25:19 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:19 2023 ] Eval epoch: 26
[ Tue Jun 27 14:25:19 2023 ] 	Mean test loss of 625 batches: 0.590198.
[ Tue Jun 27 14:25:19 2023 ] 	Top1: 91.23%
[ Tue Jun 27 14:25:19 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:19 2023 ] Training epoch: 27
[ Tue Jun 27 14:25:22 2023 ] 	Training loss: 0.6352.  Training acc: 83.64%.
[ Tue Jun 27 14:25:22 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:22 2023 ] Eval epoch: 27
[ Tue Jun 27 14:25:22 2023 ] 	Mean test loss of 625 batches: 0.607043.
[ Tue Jun 27 14:25:22 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:25:22 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:22 2023 ] Training epoch: 28
[ Tue Jun 27 14:25:25 2023 ] 	Training loss: 0.6073.  Training acc: 86.86%.
[ Tue Jun 27 14:25:25 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:25 2023 ] Eval epoch: 28
[ Tue Jun 27 14:25:25 2023 ] 	Mean test loss of 625 batches: 0.638436.
[ Tue Jun 27 14:25:25 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:25:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:25 2023 ] Training epoch: 29
[ Tue Jun 27 14:25:28 2023 ] 	Training loss: 0.6081.  Training acc: 86.67%.
[ Tue Jun 27 14:25:28 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:28 2023 ] Eval epoch: 29
[ Tue Jun 27 14:25:28 2023 ] 	Mean test loss of 625 batches: 0.611331.
[ Tue Jun 27 14:25:28 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:25:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:28 2023 ] Training epoch: 30
[ Tue Jun 27 14:25:31 2023 ] 	Training loss: 0.6096.  Training acc: 85.75%.
[ Tue Jun 27 14:25:31 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:25:31 2023 ] Eval epoch: 30
[ Tue Jun 27 14:25:31 2023 ] 	Mean test loss of 625 batches: 0.591933.
[ Tue Jun 27 14:25:31 2023 ] 	Top1: 89.47%
[ Tue Jun 27 14:25:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:31 2023 ] Training epoch: 31
[ Tue Jun 27 14:25:34 2023 ] 	Training loss: 0.6095.  Training acc: 85.75%.
[ Tue Jun 27 14:25:34 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:34 2023 ] Eval epoch: 31
[ Tue Jun 27 14:25:34 2023 ] 	Mean test loss of 625 batches: 0.597013.
[ Tue Jun 27 14:25:34 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:25:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:34 2023 ] Training epoch: 32
[ Tue Jun 27 14:25:37 2023 ] 	Training loss: 0.6107.  Training acc: 85.66%.
[ Tue Jun 27 14:25:37 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:37 2023 ] Eval epoch: 32
[ Tue Jun 27 14:25:37 2023 ] 	Mean test loss of 625 batches: 0.586705.
[ Tue Jun 27 14:25:37 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:25:37 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:37 2023 ] Training epoch: 33
[ Tue Jun 27 14:25:39 2023 ] 	Training loss: 0.5932.  Training acc: 87.13%.
[ Tue Jun 27 14:25:39 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:39 2023 ] Eval epoch: 33
[ Tue Jun 27 14:25:40 2023 ] 	Mean test loss of 625 batches: 0.593860.
[ Tue Jun 27 14:25:40 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:25:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:40 2023 ] Training epoch: 34
[ Tue Jun 27 14:25:42 2023 ] 	Training loss: 0.5984.  Training acc: 86.76%.
[ Tue Jun 27 14:25:42 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:42 2023 ] Eval epoch: 34
[ Tue Jun 27 14:25:43 2023 ] 	Mean test loss of 625 batches: 0.592506.
[ Tue Jun 27 14:25:43 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:25:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:43 2023 ] Training epoch: 35
[ Tue Jun 27 14:25:45 2023 ] 	Training loss: 0.5891.  Training acc: 88.88%.
[ Tue Jun 27 14:25:45 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:25:45 2023 ] Eval epoch: 35
[ Tue Jun 27 14:25:46 2023 ] 	Mean test loss of 625 batches: 0.569726.
[ Tue Jun 27 14:25:46 2023 ] 	Top1: 91.23%
[ Tue Jun 27 14:25:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:46 2023 ] Training epoch: 36
[ Tue Jun 27 14:25:48 2023 ] 	Training loss: 0.5962.  Training acc: 87.50%.
[ Tue Jun 27 14:25:48 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 14:25:48 2023 ] Eval epoch: 36
[ Tue Jun 27 14:25:49 2023 ] 	Mean test loss of 625 batches: 0.561325.
[ Tue Jun 27 14:25:49 2023 ] 	Top1: 91.23%
[ Tue Jun 27 14:25:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:49 2023 ] Training epoch: 37
[ Tue Jun 27 14:25:51 2023 ] 	Training loss: 0.5899.  Training acc: 88.24%.
[ Tue Jun 27 14:25:51 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:51 2023 ] Eval epoch: 37
[ Tue Jun 27 14:25:52 2023 ] 	Mean test loss of 625 batches: 0.602103.
[ Tue Jun 27 14:25:52 2023 ] 	Top1: 84.21%
[ Tue Jun 27 14:25:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:52 2023 ] Training epoch: 38
[ Tue Jun 27 14:25:54 2023 ] 	Training loss: 0.5893.  Training acc: 87.87%.
[ Tue Jun 27 14:25:54 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:54 2023 ] Eval epoch: 38
[ Tue Jun 27 14:25:55 2023 ] 	Mean test loss of 625 batches: 0.585777.
[ Tue Jun 27 14:25:55 2023 ] 	Top1: 89.47%
[ Tue Jun 27 14:25:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:55 2023 ] Training epoch: 39
[ Tue Jun 27 14:25:57 2023 ] 	Training loss: 0.5803.  Training acc: 89.43%.
[ Tue Jun 27 14:25:57 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 14:25:57 2023 ] Eval epoch: 39
[ Tue Jun 27 14:25:58 2023 ] 	Mean test loss of 625 batches: 0.575629.
[ Tue Jun 27 14:25:58 2023 ] 	Top1: 89.47%
[ Tue Jun 27 14:25:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:25:58 2023 ] Training epoch: 40
[ Tue Jun 27 14:26:00 2023 ] 	Training loss: 0.6015.  Training acc: 87.13%.
[ Tue Jun 27 14:26:00 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 14:26:00 2023 ] Eval epoch: 40
[ Tue Jun 27 14:26:01 2023 ] 	Mean test loss of 625 batches: 0.569328.
[ Tue Jun 27 14:26:01 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:26:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:26:01 2023 ] Best accuracy: 0.9122807017543859
[ Tue Jun 27 14:26:01 2023 ] Epoch number: 26
[ Tue Jun 27 14:26:01 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 14:26:01 2023 ] Weight decay: 0.0005
[ Tue Jun 27 14:26:01 2023 ] Base LR: 0.1
[ Tue Jun 27 14:26:01 2023 ] Batch Size: 64
[ Tue Jun 27 14:26:01 2023 ] Test Batch Size: 64
[ Tue Jun 27 14:26:01 2023 ] seed: 1
[ Tue Jun 27 14:26:01 2023 ] Start training Corrector
[ Tue Jun 27 14:26:01 2023 ] Training epoch: 1
[ Tue Jun 27 14:27:44 2023 ] using warm up, epoch: 5
[ Tue Jun 27 14:27:44 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 14:27:44 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 14:27:44 2023 ] Start training Predictor
[ Tue Jun 27 14:27:44 2023 ] Training epoch: 1
[ Tue Jun 27 14:27:50 2023 ] 	Training loss: 115.6280.  Training acc: 35.11%.
[ Tue Jun 27 14:27:50 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jun 27 14:27:50 2023 ] Eval epoch: 1
[ Tue Jun 27 14:27:51 2023 ] 	Mean test loss of 625 batches: 5561.882812.
[ Tue Jun 27 14:27:51 2023 ] 	Top1: 31.58%
[ Tue Jun 27 14:27:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:27:51 2023 ] Training epoch: 2
[ Tue Jun 27 14:27:53 2023 ] 	Training loss: 10.0636.  Training acc: 34.47%.
[ Tue Jun 27 14:27:53 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 14:27:53 2023 ] Eval epoch: 2
[ Tue Jun 27 14:27:54 2023 ] 	Mean test loss of 625 batches: 4.427555.
[ Tue Jun 27 14:27:54 2023 ] 	Top1: 33.33%
[ Tue Jun 27 14:27:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:27:54 2023 ] Training epoch: 3
[ Tue Jun 27 14:27:57 2023 ] 	Training loss: 6.1542.  Training acc: 34.93%.
[ Tue Jun 27 14:27:57 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:27:57 2023 ] Eval epoch: 3
[ Tue Jun 27 14:27:57 2023 ] 	Mean test loss of 625 batches: 1.007667.
[ Tue Jun 27 14:27:57 2023 ] 	Top1: 52.63%
[ Tue Jun 27 14:27:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:27:57 2023 ] Training epoch: 4
[ Tue Jun 27 14:28:00 2023 ] 	Training loss: 6.7260.  Training acc: 36.21%.
[ Tue Jun 27 14:28:00 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Tue Jun 27 14:28:00 2023 ] Eval epoch: 4
[ Tue Jun 27 14:28:01 2023 ] 	Mean test loss of 625 batches: 4.674818.
[ Tue Jun 27 14:28:01 2023 ] 	Top1: 38.60%
[ Tue Jun 27 14:28:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:01 2023 ] Training epoch: 5
[ Tue Jun 27 14:28:03 2023 ] 	Training loss: 3.9113.  Training acc: 46.51%.
[ Tue Jun 27 14:28:03 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 14:28:03 2023 ] Eval epoch: 5
[ Tue Jun 27 14:28:04 2023 ] 	Mean test loss of 625 batches: 4.341672.
[ Tue Jun 27 14:28:04 2023 ] 	Top1: 40.35%
[ Tue Jun 27 14:28:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:04 2023 ] Training epoch: 6
[ Tue Jun 27 14:28:06 2023 ] 	Training loss: 3.0273.  Training acc: 60.48%.
[ Tue Jun 27 14:28:06 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:28:06 2023 ] Eval epoch: 6
[ Tue Jun 27 14:28:07 2023 ] 	Mean test loss of 625 batches: 2.414579.
[ Tue Jun 27 14:28:07 2023 ] 	Top1: 28.07%
[ Tue Jun 27 14:28:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:07 2023 ] Training epoch: 7
[ Tue Jun 27 14:28:10 2023 ] 	Training loss: 1.8176.  Training acc: 65.99%.
[ Tue Jun 27 14:28:10 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 14:28:10 2023 ] Eval epoch: 7
[ Tue Jun 27 14:28:10 2023 ] 	Mean test loss of 625 batches: 1.442209.
[ Tue Jun 27 14:28:10 2023 ] 	Top1: 43.86%
[ Tue Jun 27 14:28:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:10 2023 ] Training epoch: 8
[ Tue Jun 27 14:28:13 2023 ] 	Training loss: 1.9896.  Training acc: 57.44%.
[ Tue Jun 27 14:28:13 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 14:28:13 2023 ] Eval epoch: 8
[ Tue Jun 27 14:28:14 2023 ] 	Mean test loss of 625 batches: 1.829765.
[ Tue Jun 27 14:28:14 2023 ] 	Top1: 54.39%
[ Tue Jun 27 14:28:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:14 2023 ] Training epoch: 9
[ Tue Jun 27 14:28:16 2023 ] 	Training loss: 1.8527.  Training acc: 65.53%.
[ Tue Jun 27 14:28:16 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:28:16 2023 ] Eval epoch: 9
[ Tue Jun 27 14:28:17 2023 ] 	Mean test loss of 625 batches: 1.266362.
[ Tue Jun 27 14:28:17 2023 ] 	Top1: 59.65%
[ Tue Jun 27 14:28:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:17 2023 ] Training epoch: 10
[ Tue Jun 27 14:28:19 2023 ] 	Training loss: 1.5790.  Training acc: 58.27%.
[ Tue Jun 27 14:28:19 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:28:19 2023 ] Eval epoch: 10
[ Tue Jun 27 14:28:20 2023 ] 	Mean test loss of 625 batches: 0.902391.
[ Tue Jun 27 14:28:20 2023 ] 	Top1: 61.40%
[ Tue Jun 27 14:28:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:20 2023 ] Training epoch: 11
[ Tue Jun 27 14:28:23 2023 ] 	Training loss: 1.1097.  Training acc: 63.88%.
[ Tue Jun 27 14:28:23 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 14:28:23 2023 ] Eval epoch: 11
[ Tue Jun 27 14:28:23 2023 ] 	Mean test loss of 625 batches: 0.699569.
[ Tue Jun 27 14:28:23 2023 ] 	Top1: 75.44%
[ Tue Jun 27 14:28:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:23 2023 ] Training epoch: 12
[ Tue Jun 27 14:28:26 2023 ] 	Training loss: 0.9697.  Training acc: 68.38%.
[ Tue Jun 27 14:28:26 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 14:28:26 2023 ] Eval epoch: 12
[ Tue Jun 27 14:28:27 2023 ] 	Mean test loss of 625 batches: 0.790004.
[ Tue Jun 27 14:28:27 2023 ] 	Top1: 75.44%
[ Tue Jun 27 14:28:27 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:27 2023 ] Training epoch: 13
[ Tue Jun 27 14:28:29 2023 ] 	Training loss: 0.9108.  Training acc: 69.39%.
[ Tue Jun 27 14:28:29 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 14:28:29 2023 ] Eval epoch: 13
[ Tue Jun 27 14:28:30 2023 ] 	Mean test loss of 625 batches: 0.703438.
[ Tue Jun 27 14:28:30 2023 ] 	Top1: 73.68%
[ Tue Jun 27 14:28:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:30 2023 ] Training epoch: 14
[ Tue Jun 27 14:28:32 2023 ] 	Training loss: 0.8697.  Training acc: 71.51%.
[ Tue Jun 27 14:28:32 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:28:32 2023 ] Eval epoch: 14
[ Tue Jun 27 14:28:33 2023 ] 	Mean test loss of 625 batches: 0.750105.
[ Tue Jun 27 14:28:33 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:28:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:33 2023 ] Training epoch: 15
[ Tue Jun 27 14:28:36 2023 ] 	Training loss: 0.8440.  Training acc: 71.42%.
[ Tue Jun 27 14:28:36 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 14:28:36 2023 ] Eval epoch: 15
[ Tue Jun 27 14:28:36 2023 ] 	Mean test loss of 625 batches: 0.638483.
[ Tue Jun 27 14:28:36 2023 ] 	Top1: 71.93%
[ Tue Jun 27 14:28:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:36 2023 ] Training epoch: 16
[ Tue Jun 27 14:28:39 2023 ] 	Training loss: 0.8057.  Training acc: 73.81%.
[ Tue Jun 27 14:28:39 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Tue Jun 27 14:28:39 2023 ] Eval epoch: 16
[ Tue Jun 27 14:28:40 2023 ] 	Mean test loss of 625 batches: 0.636556.
[ Tue Jun 27 14:28:40 2023 ] 	Top1: 77.19%
[ Tue Jun 27 14:28:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:40 2023 ] Training epoch: 17
[ Tue Jun 27 14:28:42 2023 ] 	Training loss: 0.7393.  Training acc: 77.85%.
[ Tue Jun 27 14:28:42 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 14:28:42 2023 ] Eval epoch: 17
[ Tue Jun 27 14:28:43 2023 ] 	Mean test loss of 625 batches: 0.634636.
[ Tue Jun 27 14:28:43 2023 ] 	Top1: 78.95%
[ Tue Jun 27 14:28:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:43 2023 ] Training epoch: 18
[ Tue Jun 27 14:28:45 2023 ] 	Training loss: 0.7188.  Training acc: 79.41%.
[ Tue Jun 27 14:28:45 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:28:45 2023 ] Eval epoch: 18
[ Tue Jun 27 14:28:46 2023 ] 	Mean test loss of 625 batches: 0.925888.
[ Tue Jun 27 14:28:46 2023 ] 	Top1: 61.40%
[ Tue Jun 27 14:28:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:46 2023 ] Training epoch: 19
[ Tue Jun 27 14:28:49 2023 ] 	Training loss: 0.7206.  Training acc: 80.24%.
[ Tue Jun 27 14:28:49 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:28:49 2023 ] Eval epoch: 19
[ Tue Jun 27 14:28:49 2023 ] 	Mean test loss of 625 batches: 0.798423.
[ Tue Jun 27 14:28:49 2023 ] 	Top1: 70.18%
[ Tue Jun 27 14:28:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:49 2023 ] Training epoch: 20
[ Tue Jun 27 14:28:52 2023 ] 	Training loss: 0.6844.  Training acc: 82.08%.
[ Tue Jun 27 14:28:52 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Tue Jun 27 14:28:52 2023 ] Eval epoch: 20
[ Tue Jun 27 14:28:52 2023 ] 	Mean test loss of 625 batches: 0.757034.
[ Tue Jun 27 14:28:52 2023 ] 	Top1: 75.44%
[ Tue Jun 27 14:28:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:52 2023 ] Training epoch: 21
[ Tue Jun 27 14:28:55 2023 ] 	Training loss: 0.6454.  Training acc: 83.64%.
[ Tue Jun 27 14:28:55 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:28:55 2023 ] Eval epoch: 21
[ Tue Jun 27 14:28:56 2023 ] 	Mean test loss of 625 batches: 0.577856.
[ Tue Jun 27 14:28:56 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:28:56 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:56 2023 ] Training epoch: 22
[ Tue Jun 27 14:28:58 2023 ] 	Training loss: 0.6560.  Training acc: 84.56%.
[ Tue Jun 27 14:28:58 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 14:28:58 2023 ] Eval epoch: 22
[ Tue Jun 27 14:28:59 2023 ] 	Mean test loss of 625 batches: 0.599608.
[ Tue Jun 27 14:28:59 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:28:59 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:28:59 2023 ] Training epoch: 23
[ Tue Jun 27 14:29:01 2023 ] 	Training loss: 0.6424.  Training acc: 85.29%.
[ Tue Jun 27 14:29:01 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 14:29:01 2023 ] Eval epoch: 23
[ Tue Jun 27 14:29:02 2023 ] 	Mean test loss of 625 batches: 0.609253.
[ Tue Jun 27 14:29:02 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:02 2023 ] Training epoch: 24
[ Tue Jun 27 14:29:05 2023 ] 	Training loss: 0.6450.  Training acc: 85.02%.
[ Tue Jun 27 14:29:05 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:29:05 2023 ] Eval epoch: 24
[ Tue Jun 27 14:29:05 2023 ] 	Mean test loss of 625 batches: 0.593886.
[ Tue Jun 27 14:29:05 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:05 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:05 2023 ] Training epoch: 25
[ Tue Jun 27 14:29:08 2023 ] 	Training loss: 0.6447.  Training acc: 84.38%.
[ Tue Jun 27 14:29:08 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:29:08 2023 ] Eval epoch: 25
[ Tue Jun 27 14:29:08 2023 ] 	Mean test loss of 625 batches: 0.572579.
[ Tue Jun 27 14:29:08 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:08 2023 ] Training epoch: 26
[ Tue Jun 27 14:29:11 2023 ] 	Training loss: 0.6460.  Training acc: 83.55%.
[ Tue Jun 27 14:29:11 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:29:11 2023 ] Eval epoch: 26
[ Tue Jun 27 14:29:12 2023 ] 	Mean test loss of 625 batches: 0.602834.
[ Tue Jun 27 14:29:12 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:12 2023 ] Training epoch: 27
[ Tue Jun 27 14:29:14 2023 ] 	Training loss: 0.6534.  Training acc: 83.82%.
[ Tue Jun 27 14:29:14 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:29:14 2023 ] Eval epoch: 27
[ Tue Jun 27 14:29:15 2023 ] 	Mean test loss of 625 batches: 0.569680.
[ Tue Jun 27 14:29:15 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:15 2023 ] Training epoch: 28
[ Tue Jun 27 14:29:17 2023 ] 	Training loss: 0.6257.  Training acc: 86.58%.
[ Tue Jun 27 14:29:17 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 14:29:17 2023 ] Eval epoch: 28
[ Tue Jun 27 14:29:18 2023 ] 	Mean test loss of 625 batches: 0.578702.
[ Tue Jun 27 14:29:18 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:18 2023 ] Training epoch: 29
[ Tue Jun 27 14:29:21 2023 ] 	Training loss: 0.6240.  Training acc: 84.93%.
[ Tue Jun 27 14:29:21 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 14:29:21 2023 ] Eval epoch: 29
[ Tue Jun 27 14:29:21 2023 ] 	Mean test loss of 625 batches: 0.633238.
[ Tue Jun 27 14:29:21 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:21 2023 ] Training epoch: 30
[ Tue Jun 27 14:29:24 2023 ] 	Training loss: 0.5949.  Training acc: 88.69%.
[ Tue Jun 27 14:29:24 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 14:29:24 2023 ] Eval epoch: 30
[ Tue Jun 27 14:29:25 2023 ] 	Mean test loss of 625 batches: 0.551020.
[ Tue Jun 27 14:29:25 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:25 2023 ] Training epoch: 31
[ Tue Jun 27 14:29:27 2023 ] 	Training loss: 0.6382.  Training acc: 84.74%.
[ Tue Jun 27 14:29:27 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 14:29:27 2023 ] Eval epoch: 31
[ Tue Jun 27 14:29:28 2023 ] 	Mean test loss of 625 batches: 0.599773.
[ Tue Jun 27 14:29:28 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:28 2023 ] Training epoch: 32
[ Tue Jun 27 14:29:30 2023 ] 	Training loss: 0.6269.  Training acc: 84.28%.
[ Tue Jun 27 14:29:30 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:29:30 2023 ] Eval epoch: 32
[ Tue Jun 27 14:29:31 2023 ] 	Mean test loss of 625 batches: 0.552663.
[ Tue Jun 27 14:29:31 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:29:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:31 2023 ] Training epoch: 33
[ Tue Jun 27 14:29:33 2023 ] 	Training loss: 0.6029.  Training acc: 87.96%.
[ Tue Jun 27 14:29:33 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 14:29:33 2023 ] Eval epoch: 33
[ Tue Jun 27 14:29:34 2023 ] 	Mean test loss of 625 batches: 0.551395.
[ Tue Jun 27 14:29:34 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:29:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:34 2023 ] Training epoch: 34
[ Tue Jun 27 14:29:37 2023 ] 	Training loss: 0.6140.  Training acc: 86.95%.
[ Tue Jun 27 14:29:37 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Tue Jun 27 14:29:37 2023 ] Eval epoch: 34
[ Tue Jun 27 14:29:37 2023 ] 	Mean test loss of 625 batches: 0.558725.
[ Tue Jun 27 14:29:37 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:29:37 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:37 2023 ] Training epoch: 35
[ Tue Jun 27 14:29:40 2023 ] 	Training loss: 0.5981.  Training acc: 88.14%.
[ Tue Jun 27 14:29:40 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 14:29:40 2023 ] Eval epoch: 35
[ Tue Jun 27 14:29:40 2023 ] 	Mean test loss of 625 batches: 0.557064.
[ Tue Jun 27 14:29:40 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:29:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:40 2023 ] Training epoch: 36
[ Tue Jun 27 14:29:43 2023 ] 	Training loss: 0.5953.  Training acc: 90.99%.
[ Tue Jun 27 14:29:43 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 14:29:43 2023 ] Eval epoch: 36
[ Tue Jun 27 14:29:44 2023 ] 	Mean test loss of 625 batches: 0.548922.
[ Tue Jun 27 14:29:44 2023 ] 	Top1: 87.72%
[ Tue Jun 27 14:29:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:44 2023 ] Training epoch: 37
[ Tue Jun 27 14:29:46 2023 ] 	Training loss: 0.5916.  Training acc: 89.61%.
[ Tue Jun 27 14:29:46 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:29:46 2023 ] Eval epoch: 37
[ Tue Jun 27 14:29:47 2023 ] 	Mean test loss of 625 batches: 0.562897.
[ Tue Jun 27 14:29:47 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:47 2023 ] Training epoch: 38
[ Tue Jun 27 14:29:49 2023 ] 	Training loss: 0.5957.  Training acc: 89.52%.
[ Tue Jun 27 14:29:49 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 14:29:49 2023 ] Eval epoch: 38
[ Tue Jun 27 14:29:50 2023 ] 	Mean test loss of 625 batches: 0.606781.
[ Tue Jun 27 14:29:50 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:50 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:50 2023 ] Training epoch: 39
[ Tue Jun 27 14:29:52 2023 ] 	Training loss: 0.5927.  Training acc: 90.07%.
[ Tue Jun 27 14:29:52 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 14:29:52 2023 ] Eval epoch: 39
[ Tue Jun 27 14:29:53 2023 ] 	Mean test loss of 625 batches: 0.568132.
[ Tue Jun 27 14:29:53 2023 ] 	Top1: 85.96%
[ Tue Jun 27 14:29:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:53 2023 ] Training epoch: 40
[ Tue Jun 27 14:29:55 2023 ] 	Training loss: 0.6324.  Training acc: 85.57%.
[ Tue Jun 27 14:29:55 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 14:29:55 2023 ] Eval epoch: 40
[ Tue Jun 27 14:29:56 2023 ] 	Mean test loss of 625 batches: 0.529222.
[ Tue Jun 27 14:29:56 2023 ] 	Top1: 92.98%
[ Tue Jun 27 14:29:56 2023 ] 	Top5: 100.00%
[ Tue Jun 27 14:29:57 2023 ] Best accuracy: 0.9298245614035088
[ Tue Jun 27 14:29:57 2023 ] Epoch number: 40
[ Tue Jun 27 14:29:57 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 14:29:57 2023 ] Weight decay: 0.0005
[ Tue Jun 27 14:29:57 2023 ] Base LR: 0.1
[ Tue Jun 27 14:29:57 2023 ] Batch Size: 64
[ Tue Jun 27 14:29:57 2023 ] Test Batch Size: 64
[ Tue Jun 27 14:29:57 2023 ] seed: 1
[ Tue Jun 27 14:29:57 2023 ] Start training Corrector
[ Tue Jun 27 14:29:57 2023 ] Training epoch: 1
[ Tue Jun 27 15:03:09 2023 ] using warm up, epoch: 5
[ Tue Jun 27 15:03:09 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 15:03:09 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 15:03:09 2023 ] Start training Predictor
[ Tue Jun 27 15:03:09 2023 ] Training epoch: 1
[ Tue Jun 27 15:03:33 2023 ] using warm up, epoch: 5
[ Tue Jun 27 15:03:33 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 15:03:33 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 15:03:33 2023 ] Start training Predictor
[ Tue Jun 27 15:03:33 2023 ] Training epoch: 1
[ Tue Jun 27 15:03:39 2023 ] 	Training loss: 123.4655.  Training acc: 35.94%.
[ Tue Jun 27 15:03:39 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jun 27 15:03:39 2023 ] Eval epoch: 1
[ Tue Jun 27 15:03:40 2023 ] 	Mean test loss of 625 batches: 4559.084668.
[ Tue Jun 27 15:03:40 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:03:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:03:40 2023 ] Training epoch: 2
[ Tue Jun 27 15:03:42 2023 ] 	Training loss: 13.5765.  Training acc: 36.40%.
[ Tue Jun 27 15:03:42 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:03:42 2023 ] Eval epoch: 2
[ Tue Jun 27 15:03:43 2023 ] 	Mean test loss of 625 batches: 8.421229.
[ Tue Jun 27 15:03:43 2023 ] 	Top1: 36.84%
[ Tue Jun 27 15:03:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:03:43 2023 ] Training epoch: 3
[ Tue Jun 27 15:03:45 2023 ] 	Training loss: 5.5284.  Training acc: 53.40%.
[ Tue Jun 27 15:03:45 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:03:45 2023 ] Eval epoch: 3
[ Tue Jun 27 15:03:45 2023 ] 	Mean test loss of 625 batches: 27.599662.
[ Tue Jun 27 15:03:45 2023 ] 	Top1: 42.11%
[ Tue Jun 27 15:03:45 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:03:45 2023 ] Training epoch: 4
[ Tue Jun 27 15:03:47 2023 ] 	Training loss: 4.2441.  Training acc: 68.29%.
[ Tue Jun 27 15:03:47 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:03:47 2023 ] Eval epoch: 4
[ Tue Jun 27 15:03:48 2023 ] 	Mean test loss of 625 batches: 4.044038.
[ Tue Jun 27 15:03:48 2023 ] 	Top1: 70.18%
[ Tue Jun 27 15:03:48 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:03:48 2023 ] Training epoch: 5
[ Tue Jun 27 15:03:50 2023 ] 	Training loss: 4.7956.  Training acc: 64.06%.
[ Tue Jun 27 15:03:50 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 15:03:50 2023 ] Eval epoch: 5
[ Tue Jun 27 15:03:51 2023 ] 	Mean test loss of 625 batches: 1.724720.
[ Tue Jun 27 15:03:51 2023 ] 	Top1: 52.63%
[ Tue Jun 27 15:03:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:03:51 2023 ] Training epoch: 6
[ Tue Jun 27 15:03:53 2023 ] 	Training loss: 2.7819.  Training acc: 63.14%.
[ Tue Jun 27 15:03:53 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:03:53 2023 ] Eval epoch: 6
[ Tue Jun 27 15:03:53 2023 ] 	Mean test loss of 625 batches: 3.838941.
[ Tue Jun 27 15:03:53 2023 ] 	Top1: 59.65%
[ Tue Jun 27 15:03:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:03:53 2023 ] Training epoch: 7
[ Tue Jun 27 15:03:55 2023 ] 	Training loss: 2.3877.  Training acc: 61.03%.
[ Tue Jun 27 15:03:55 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:03:55 2023 ] Eval epoch: 7
[ Tue Jun 27 15:03:56 2023 ] 	Mean test loss of 625 batches: 1.617154.
[ Tue Jun 27 15:03:56 2023 ] 	Top1: 50.88%
[ Tue Jun 27 15:03:56 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:03:56 2023 ] Training epoch: 8
[ Tue Jun 27 15:03:58 2023 ] 	Training loss: 2.6075.  Training acc: 60.66%.
[ Tue Jun 27 15:03:58 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:03:58 2023 ] Eval epoch: 8
[ Tue Jun 27 15:03:58 2023 ] 	Mean test loss of 625 batches: 0.984351.
[ Tue Jun 27 15:03:58 2023 ] 	Top1: 70.18%
[ Tue Jun 27 15:03:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:03:58 2023 ] Training epoch: 9
[ Tue Jun 27 15:04:01 2023 ] 	Training loss: 1.8049.  Training acc: 69.85%.
[ Tue Jun 27 15:04:01 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:04:01 2023 ] Eval epoch: 9
[ Tue Jun 27 15:04:01 2023 ] 	Mean test loss of 625 batches: 0.614736.
[ Tue Jun 27 15:04:01 2023 ] 	Top1: 87.72%
[ Tue Jun 27 15:04:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:01 2023 ] Training epoch: 10
[ Tue Jun 27 15:04:03 2023 ] 	Training loss: 1.2965.  Training acc: 76.38%.
[ Tue Jun 27 15:04:03 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:04:03 2023 ] Eval epoch: 10
[ Tue Jun 27 15:04:04 2023 ] 	Mean test loss of 625 batches: 0.649221.
[ Tue Jun 27 15:04:04 2023 ] 	Top1: 89.47%
[ Tue Jun 27 15:04:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:04 2023 ] Training epoch: 11
[ Tue Jun 27 15:04:06 2023 ] 	Training loss: 0.8711.  Training acc: 82.17%.
[ Tue Jun 27 15:04:06 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:04:06 2023 ] Eval epoch: 11
[ Tue Jun 27 15:04:07 2023 ] 	Mean test loss of 625 batches: 0.527420.
[ Tue Jun 27 15:04:07 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:07 2023 ] Training epoch: 12
[ Tue Jun 27 15:04:09 2023 ] 	Training loss: 0.6886.  Training acc: 85.94%.
[ Tue Jun 27 15:04:09 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:04:09 2023 ] Eval epoch: 12
[ Tue Jun 27 15:04:10 2023 ] 	Mean test loss of 625 batches: 0.457832.
[ Tue Jun 27 15:04:10 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:10 2023 ] Training epoch: 13
[ Tue Jun 27 15:04:12 2023 ] 	Training loss: 0.6132.  Training acc: 89.25%.
[ Tue Jun 27 15:04:12 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:04:12 2023 ] Eval epoch: 13
[ Tue Jun 27 15:04:12 2023 ] 	Mean test loss of 625 batches: 0.387503.
[ Tue Jun 27 15:04:12 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:12 2023 ] Training epoch: 14
[ Tue Jun 27 15:04:15 2023 ] 	Training loss: 0.5707.  Training acc: 89.89%.
[ Tue Jun 27 15:04:15 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:04:15 2023 ] Eval epoch: 14
[ Tue Jun 27 15:04:15 2023 ] 	Mean test loss of 625 batches: 0.418065.
[ Tue Jun 27 15:04:15 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:15 2023 ] Training epoch: 15
[ Tue Jun 27 15:04:17 2023 ] 	Training loss: 0.5395.  Training acc: 90.81%.
[ Tue Jun 27 15:04:17 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:04:17 2023 ] Eval epoch: 15
[ Tue Jun 27 15:04:18 2023 ] 	Mean test loss of 625 batches: 0.331280.
[ Tue Jun 27 15:04:18 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:18 2023 ] Training epoch: 16
[ Tue Jun 27 15:04:20 2023 ] 	Training loss: 0.5178.  Training acc: 92.10%.
[ Tue Jun 27 15:04:20 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:04:20 2023 ] Eval epoch: 16
[ Tue Jun 27 15:04:20 2023 ] 	Mean test loss of 625 batches: 0.348335.
[ Tue Jun 27 15:04:20 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:20 2023 ] Training epoch: 17
[ Tue Jun 27 15:04:22 2023 ] 	Training loss: 0.4793.  Training acc: 92.74%.
[ Tue Jun 27 15:04:22 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:04:22 2023 ] Eval epoch: 17
[ Tue Jun 27 15:04:23 2023 ] 	Mean test loss of 625 batches: 0.377449.
[ Tue Jun 27 15:04:23 2023 ] 	Top1: 96.49%
[ Tue Jun 27 15:04:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:23 2023 ] Training epoch: 18
[ Tue Jun 27 15:04:25 2023 ] 	Training loss: 0.4547.  Training acc: 95.04%.
[ Tue Jun 27 15:04:25 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:04:25 2023 ] Eval epoch: 18
[ Tue Jun 27 15:04:25 2023 ] 	Mean test loss of 625 batches: 0.336638.
[ Tue Jun 27 15:04:25 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:25 2023 ] Training epoch: 19
[ Tue Jun 27 15:04:28 2023 ] 	Training loss: 0.4899.  Training acc: 92.46%.
[ Tue Jun 27 15:04:28 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:04:28 2023 ] Eval epoch: 19
[ Tue Jun 27 15:04:28 2023 ] 	Mean test loss of 625 batches: 0.398501.
[ Tue Jun 27 15:04:28 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:28 2023 ] Training epoch: 20
[ Tue Jun 27 15:04:30 2023 ] 	Training loss: 0.4489.  Training acc: 94.94%.
[ Tue Jun 27 15:04:30 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:04:30 2023 ] Eval epoch: 20
[ Tue Jun 27 15:04:31 2023 ] 	Mean test loss of 625 batches: 0.324128.
[ Tue Jun 27 15:04:31 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:31 2023 ] Training epoch: 21
[ Tue Jun 27 15:04:33 2023 ] 	Training loss: 0.4369.  Training acc: 94.94%.
[ Tue Jun 27 15:04:33 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:04:33 2023 ] Eval epoch: 21
[ Tue Jun 27 15:04:34 2023 ] 	Mean test loss of 625 batches: 0.338123.
[ Tue Jun 27 15:04:34 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:34 2023 ] Training epoch: 22
[ Tue Jun 27 15:04:36 2023 ] 	Training loss: 0.4161.  Training acc: 96.23%.
[ Tue Jun 27 15:04:36 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:04:36 2023 ] Eval epoch: 22
[ Tue Jun 27 15:04:36 2023 ] 	Mean test loss of 625 batches: 0.325002.
[ Tue Jun 27 15:04:36 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:36 2023 ] Training epoch: 23
[ Tue Jun 27 15:04:38 2023 ] 	Training loss: 0.4309.  Training acc: 95.04%.
[ Tue Jun 27 15:04:38 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:04:38 2023 ] Eval epoch: 23
[ Tue Jun 27 15:04:39 2023 ] 	Mean test loss of 625 batches: 0.319290.
[ Tue Jun 27 15:04:39 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:39 2023 ] Training epoch: 24
[ Tue Jun 27 15:04:41 2023 ] 	Training loss: 0.4187.  Training acc: 95.86%.
[ Tue Jun 27 15:04:41 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:04:41 2023 ] Eval epoch: 24
[ Tue Jun 27 15:04:41 2023 ] 	Mean test loss of 625 batches: 0.320860.
[ Tue Jun 27 15:04:41 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:41 2023 ] Training epoch: 25
[ Tue Jun 27 15:04:44 2023 ] 	Training loss: 0.4124.  Training acc: 96.69%.
[ Tue Jun 27 15:04:44 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Tue Jun 27 15:04:44 2023 ] Eval epoch: 25
[ Tue Jun 27 15:04:44 2023 ] 	Mean test loss of 625 batches: 0.316730.
[ Tue Jun 27 15:04:44 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:44 2023 ] Training epoch: 26
[ Tue Jun 27 15:04:46 2023 ] 	Training loss: 0.4095.  Training acc: 96.32%.
[ Tue Jun 27 15:04:46 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:04:46 2023 ] Eval epoch: 26
[ Tue Jun 27 15:04:47 2023 ] 	Mean test loss of 625 batches: 0.320675.
[ Tue Jun 27 15:04:47 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:47 2023 ] Training epoch: 27
[ Tue Jun 27 15:04:49 2023 ] 	Training loss: 0.4046.  Training acc: 97.43%.
[ Tue Jun 27 15:04:49 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:04:49 2023 ] Eval epoch: 27
[ Tue Jun 27 15:04:50 2023 ] 	Mean test loss of 625 batches: 0.317396.
[ Tue Jun 27 15:04:50 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:50 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:50 2023 ] Training epoch: 28
[ Tue Jun 27 15:04:52 2023 ] 	Training loss: 0.4022.  Training acc: 96.51%.
[ Tue Jun 27 15:04:52 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:04:52 2023 ] Eval epoch: 28
[ Tue Jun 27 15:04:53 2023 ] 	Mean test loss of 625 batches: 0.314995.
[ Tue Jun 27 15:04:53 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:53 2023 ] Training epoch: 29
[ Tue Jun 27 15:04:55 2023 ] 	Training loss: 0.4065.  Training acc: 96.88%.
[ Tue Jun 27 15:04:55 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:04:55 2023 ] Eval epoch: 29
[ Tue Jun 27 15:04:56 2023 ] 	Mean test loss of 625 batches: 0.320169.
[ Tue Jun 27 15:04:56 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:56 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:56 2023 ] Training epoch: 30
[ Tue Jun 27 15:04:58 2023 ] 	Training loss: 0.3990.  Training acc: 97.24%.
[ Tue Jun 27 15:04:58 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:04:58 2023 ] Eval epoch: 30
[ Tue Jun 27 15:04:59 2023 ] 	Mean test loss of 625 batches: 0.320092.
[ Tue Jun 27 15:04:59 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:04:59 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:04:59 2023 ] Training epoch: 31
[ Tue Jun 27 15:05:01 2023 ] 	Training loss: 0.3961.  Training acc: 97.15%.
[ Tue Jun 27 15:05:01 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:05:01 2023 ] Eval epoch: 31
[ Tue Jun 27 15:05:02 2023 ] 	Mean test loss of 625 batches: 0.312926.
[ Tue Jun 27 15:05:02 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:05:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:05:02 2023 ] Training epoch: 32
[ Tue Jun 27 15:05:04 2023 ] 	Training loss: 0.4106.  Training acc: 96.32%.
[ Tue Jun 27 15:05:04 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:05:04 2023 ] Eval epoch: 32
[ Tue Jun 27 15:05:04 2023 ] 	Mean test loss of 625 batches: 0.314542.
[ Tue Jun 27 15:05:04 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:05:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:05:04 2023 ] Training epoch: 33
[ Tue Jun 27 15:05:06 2023 ] 	Training loss: 0.3849.  Training acc: 97.70%.
[ Tue Jun 27 15:05:06 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:05:06 2023 ] Eval epoch: 33
[ Tue Jun 27 15:05:07 2023 ] 	Mean test loss of 625 batches: 0.316679.
[ Tue Jun 27 15:05:07 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:05:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:05:07 2023 ] Training epoch: 34
[ Tue Jun 27 15:05:09 2023 ] 	Training loss: 0.3951.  Training acc: 97.43%.
[ Tue Jun 27 15:05:09 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:05:09 2023 ] Eval epoch: 34
[ Tue Jun 27 15:05:10 2023 ] 	Mean test loss of 625 batches: 0.313255.
[ Tue Jun 27 15:05:10 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:05:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:05:10 2023 ] Training epoch: 35
[ Tue Jun 27 15:05:12 2023 ] 	Training loss: 0.3760.  Training acc: 98.44%.
[ Tue Jun 27 15:05:12 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:05:12 2023 ] Eval epoch: 35
[ Tue Jun 27 15:05:12 2023 ] 	Mean test loss of 625 batches: 0.315283.
[ Tue Jun 27 15:05:12 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:05:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:05:12 2023 ] Training epoch: 36
[ Tue Jun 27 15:05:14 2023 ] 	Training loss: 0.3838.  Training acc: 97.89%.
[ Tue Jun 27 15:05:14 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:05:14 2023 ] Eval epoch: 36
[ Tue Jun 27 15:05:15 2023 ] 	Mean test loss of 625 batches: 0.309317.
[ Tue Jun 27 15:05:15 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:05:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:05:15 2023 ] Training epoch: 37
[ Tue Jun 27 15:05:17 2023 ] 	Training loss: 0.3798.  Training acc: 98.07%.
[ Tue Jun 27 15:05:17 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:05:17 2023 ] Eval epoch: 37
[ Tue Jun 27 15:05:17 2023 ] 	Mean test loss of 625 batches: 0.310498.
[ Tue Jun 27 15:05:17 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:05:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:05:17 2023 ] Training epoch: 38
[ Tue Jun 27 15:05:19 2023 ] 	Training loss: 0.3810.  Training acc: 97.79%.
[ Tue Jun 27 15:05:19 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:05:19 2023 ] Eval epoch: 38
[ Tue Jun 27 15:05:20 2023 ] 	Mean test loss of 625 batches: 0.314434.
[ Tue Jun 27 15:05:20 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:05:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:05:20 2023 ] Training epoch: 39
[ Tue Jun 27 15:05:22 2023 ] 	Training loss: 0.3812.  Training acc: 98.07%.
[ Tue Jun 27 15:05:22 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:05:22 2023 ] Eval epoch: 39
[ Tue Jun 27 15:05:22 2023 ] 	Mean test loss of 625 batches: 0.311390.
[ Tue Jun 27 15:05:22 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:05:22 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:05:22 2023 ] Training epoch: 40
[ Tue Jun 27 15:05:24 2023 ] 	Training loss: 0.3939.  Training acc: 97.24%.
[ Tue Jun 27 15:05:24 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:05:24 2023 ] Eval epoch: 40
[ Tue Jun 27 15:05:25 2023 ] 	Mean test loss of 625 batches: 0.309214.
[ Tue Jun 27 15:05:25 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:05:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:05:26 2023 ] Best accuracy: 1.0
[ Tue Jun 27 15:05:26 2023 ] Epoch number: 11
[ Tue Jun 27 15:05:26 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 15:05:26 2023 ] Weight decay: 0.0005
[ Tue Jun 27 15:05:26 2023 ] Base LR: 0.1
[ Tue Jun 27 15:05:26 2023 ] Batch Size: 64
[ Tue Jun 27 15:05:26 2023 ] Test Batch Size: 64
[ Tue Jun 27 15:05:26 2023 ] seed: 1
[ Tue Jun 27 15:05:26 2023 ] Start training Corrector
[ Tue Jun 27 15:05:26 2023 ] Training epoch: 1
[ Tue Jun 27 15:08:32 2023 ] using warm up, epoch: 5
[ Tue Jun 27 15:08:32 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 15:08:32 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 15:08:32 2023 ] Start training Predictor
[ Tue Jun 27 15:08:32 2023 ] Training epoch: 1
[ Tue Jun 27 15:08:37 2023 ] 	Training loss: 104.2862.  Training acc: 34.19%.
[ Tue Jun 27 15:08:37 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Tue Jun 27 15:08:37 2023 ] Eval epoch: 1
[ Tue Jun 27 15:08:38 2023 ] 	Mean test loss of 625 batches: 70.369717.
[ Tue Jun 27 15:08:38 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:08:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:08:38 2023 ] Training epoch: 2
[ Tue Jun 27 15:08:40 2023 ] 	Training loss: 9.9553.  Training acc: 35.75%.
[ Tue Jun 27 15:08:40 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:08:40 2023 ] Eval epoch: 2
[ Tue Jun 27 15:08:40 2023 ] 	Mean test loss of 625 batches: 8.779923.
[ Tue Jun 27 15:08:40 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:08:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:08:40 2023 ] Training epoch: 3
[ Tue Jun 27 15:08:42 2023 ] 	Training loss: 6.5950.  Training acc: 43.93%.
[ Tue Jun 27 15:08:42 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:08:42 2023 ] Eval epoch: 3
[ Tue Jun 27 15:08:43 2023 ] 	Mean test loss of 625 batches: 9.054891.
[ Tue Jun 27 15:08:43 2023 ] 	Top1: 45.61%
[ Tue Jun 27 15:08:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:08:43 2023 ] Training epoch: 4
[ Tue Jun 27 15:08:45 2023 ] 	Training loss: 4.9052.  Training acc: 55.06%.
[ Tue Jun 27 15:08:45 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:08:45 2023 ] Eval epoch: 4
[ Tue Jun 27 15:08:46 2023 ] 	Mean test loss of 625 batches: 11.865361.
[ Tue Jun 27 15:08:46 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:08:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:08:46 2023 ] Training epoch: 5
[ Tue Jun 27 15:08:48 2023 ] 	Training loss: 3.8895.  Training acc: 57.26%.
[ Tue Jun 27 15:08:48 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:08:48 2023 ] Eval epoch: 5
[ Tue Jun 27 15:08:49 2023 ] 	Mean test loss of 625 batches: 15.067498.
[ Tue Jun 27 15:08:49 2023 ] 	Top1: 52.63%
[ Tue Jun 27 15:08:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:08:49 2023 ] Training epoch: 6
[ Tue Jun 27 15:08:51 2023 ] 	Training loss: 2.9516.  Training acc: 56.80%.
[ Tue Jun 27 15:08:51 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:08:51 2023 ] Eval epoch: 6
[ Tue Jun 27 15:08:51 2023 ] 	Mean test loss of 625 batches: 1.115534.
[ Tue Jun 27 15:08:51 2023 ] 	Top1: 73.68%
[ Tue Jun 27 15:08:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:08:51 2023 ] Training epoch: 7
[ Tue Jun 27 15:08:53 2023 ] 	Training loss: 2.6699.  Training acc: 55.15%.
[ Tue Jun 27 15:08:53 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:08:53 2023 ] Eval epoch: 7
[ Tue Jun 27 15:08:54 2023 ] 	Mean test loss of 625 batches: 0.927369.
[ Tue Jun 27 15:08:54 2023 ] 	Top1: 77.19%
[ Tue Jun 27 15:08:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:08:54 2023 ] Training epoch: 8
[ Tue Jun 27 15:08:56 2023 ] 	Training loss: 2.3092.  Training acc: 57.54%.
[ Tue Jun 27 15:08:56 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:08:56 2023 ] Eval epoch: 8
[ Tue Jun 27 15:08:57 2023 ] 	Mean test loss of 625 batches: 0.989930.
[ Tue Jun 27 15:08:57 2023 ] 	Top1: 77.19%
[ Tue Jun 27 15:08:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:08:57 2023 ] Training epoch: 9
[ Tue Jun 27 15:08:59 2023 ] 	Training loss: 3.6493.  Training acc: 44.94%.
[ Tue Jun 27 15:08:59 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Tue Jun 27 15:08:59 2023 ] Eval epoch: 9
[ Tue Jun 27 15:09:00 2023 ] 	Mean test loss of 625 batches: 57.519360.
[ Tue Jun 27 15:09:00 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:09:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:00 2023 ] Training epoch: 10
[ Tue Jun 27 15:09:02 2023 ] 	Training loss: 2.9546.  Training acc: 34.28%.
[ Tue Jun 27 15:09:02 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:09:02 2023 ] Eval epoch: 10
[ Tue Jun 27 15:09:02 2023 ] 	Mean test loss of 625 batches: 2.347344.
[ Tue Jun 27 15:09:02 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:09:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:02 2023 ] Training epoch: 11
[ Tue Jun 27 15:09:05 2023 ] 	Training loss: 2.2545.  Training acc: 33.00%.
[ Tue Jun 27 15:09:05 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:09:05 2023 ] Eval epoch: 11
[ Tue Jun 27 15:09:05 2023 ] 	Mean test loss of 625 batches: 1.218352.
[ Tue Jun 27 15:09:05 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:05 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:05 2023 ] Training epoch: 12
[ Tue Jun 27 15:09:08 2023 ] 	Training loss: 2.3143.  Training acc: 32.44%.
[ Tue Jun 27 15:09:08 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:09:08 2023 ] Eval epoch: 12
[ Tue Jun 27 15:09:08 2023 ] 	Mean test loss of 625 batches: 1.207495.
[ Tue Jun 27 15:09:08 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:08 2023 ] Training epoch: 13
[ Tue Jun 27 15:09:11 2023 ] 	Training loss: 2.0728.  Training acc: 34.93%.
[ Tue Jun 27 15:09:11 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:09:11 2023 ] Eval epoch: 13
[ Tue Jun 27 15:09:12 2023 ] 	Mean test loss of 625 batches: 1.137216.
[ Tue Jun 27 15:09:12 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:12 2023 ] Training epoch: 14
[ Tue Jun 27 15:09:15 2023 ] 	Training loss: 2.2113.  Training acc: 32.63%.
[ Tue Jun 27 15:09:15 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:09:15 2023 ] Eval epoch: 14
[ Tue Jun 27 15:09:16 2023 ] 	Mean test loss of 625 batches: 1.159471.
[ Tue Jun 27 15:09:16 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:16 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:16 2023 ] Training epoch: 15
[ Tue Jun 27 15:09:18 2023 ] 	Training loss: 2.0594.  Training acc: 34.65%.
[ Tue Jun 27 15:09:18 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:09:18 2023 ] Eval epoch: 15
[ Tue Jun 27 15:09:19 2023 ] 	Mean test loss of 625 batches: 1.152213.
[ Tue Jun 27 15:09:19 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:19 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:19 2023 ] Training epoch: 16
[ Tue Jun 27 15:09:22 2023 ] 	Training loss: 1.9792.  Training acc: 35.02%.
[ Tue Jun 27 15:09:22 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 15:09:22 2023 ] Eval epoch: 16
[ Tue Jun 27 15:09:23 2023 ] 	Mean test loss of 625 batches: 1.151928.
[ Tue Jun 27 15:09:23 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:23 2023 ] Training epoch: 17
[ Tue Jun 27 15:09:25 2023 ] 	Training loss: 2.0272.  Training acc: 33.36%.
[ Tue Jun 27 15:09:25 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:09:25 2023 ] Eval epoch: 17
[ Tue Jun 27 15:09:26 2023 ] 	Mean test loss of 625 batches: 1.136537.
[ Tue Jun 27 15:09:26 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:26 2023 ] Training epoch: 18
[ Tue Jun 27 15:09:29 2023 ] 	Training loss: 1.9073.  Training acc: 33.46%.
[ Tue Jun 27 15:09:29 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:09:29 2023 ] Eval epoch: 18
[ Tue Jun 27 15:09:30 2023 ] 	Mean test loss of 625 batches: 1.123071.
[ Tue Jun 27 15:09:30 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:30 2023 ] Training epoch: 19
[ Tue Jun 27 15:09:32 2023 ] 	Training loss: 1.8605.  Training acc: 33.82%.
[ Tue Jun 27 15:09:32 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Tue Jun 27 15:09:32 2023 ] Eval epoch: 19
[ Tue Jun 27 15:09:32 2023 ] 	Mean test loss of 625 batches: 1.160045.
[ Tue Jun 27 15:09:32 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:32 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:32 2023 ] Training epoch: 20
[ Tue Jun 27 15:09:35 2023 ] 	Training loss: 1.7721.  Training acc: 36.12%.
[ Tue Jun 27 15:09:35 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Tue Jun 27 15:09:35 2023 ] Eval epoch: 20
[ Tue Jun 27 15:09:35 2023 ] 	Mean test loss of 625 batches: 1.139926.
[ Tue Jun 27 15:09:35 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:35 2023 ] Training epoch: 21
[ Tue Jun 27 15:09:37 2023 ] 	Training loss: 1.7819.  Training acc: 33.55%.
[ Tue Jun 27 15:09:37 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:09:37 2023 ] Eval epoch: 21
[ Tue Jun 27 15:09:38 2023 ] 	Mean test loss of 625 batches: 1.136981.
[ Tue Jun 27 15:09:38 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:38 2023 ] Training epoch: 22
[ Tue Jun 27 15:09:40 2023 ] 	Training loss: 1.7226.  Training acc: 34.38%.
[ Tue Jun 27 15:09:40 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:09:40 2023 ] Eval epoch: 22
[ Tue Jun 27 15:09:41 2023 ] 	Mean test loss of 625 batches: 1.134218.
[ Tue Jun 27 15:09:41 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:41 2023 ] Training epoch: 23
[ Tue Jun 27 15:09:43 2023 ] 	Training loss: 1.6899.  Training acc: 36.95%.
[ Tue Jun 27 15:09:43 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:09:43 2023 ] Eval epoch: 23
[ Tue Jun 27 15:09:44 2023 ] 	Mean test loss of 625 batches: 1.129284.
[ Tue Jun 27 15:09:44 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:44 2023 ] Training epoch: 24
[ Tue Jun 27 15:09:46 2023 ] 	Training loss: 1.7181.  Training acc: 35.75%.
[ Tue Jun 27 15:09:46 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:09:46 2023 ] Eval epoch: 24
[ Tue Jun 27 15:09:46 2023 ] 	Mean test loss of 625 batches: 1.129944.
[ Tue Jun 27 15:09:46 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:46 2023 ] Training epoch: 25
[ Tue Jun 27 15:09:48 2023 ] 	Training loss: 1.7607.  Training acc: 32.26%.
[ Tue Jun 27 15:09:48 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:09:48 2023 ] Eval epoch: 25
[ Tue Jun 27 15:09:49 2023 ] 	Mean test loss of 625 batches: 1.135074.
[ Tue Jun 27 15:09:49 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:49 2023 ] Training epoch: 26
[ Tue Jun 27 15:09:51 2023 ] 	Training loss: 1.6904.  Training acc: 36.95%.
[ Tue Jun 27 15:09:51 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:09:51 2023 ] Eval epoch: 26
[ Tue Jun 27 15:09:52 2023 ] 	Mean test loss of 625 batches: 1.134562.
[ Tue Jun 27 15:09:52 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:52 2023 ] Training epoch: 27
[ Tue Jun 27 15:09:54 2023 ] 	Training loss: 1.7857.  Training acc: 31.34%.
[ Tue Jun 27 15:09:54 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:09:54 2023 ] Eval epoch: 27
[ Tue Jun 27 15:09:55 2023 ] 	Mean test loss of 625 batches: 1.132791.
[ Tue Jun 27 15:09:55 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:55 2023 ] Training epoch: 28
[ Tue Jun 27 15:09:57 2023 ] 	Training loss: 1.6927.  Training acc: 34.74%.
[ Tue Jun 27 15:09:57 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:09:57 2023 ] Eval epoch: 28
[ Tue Jun 27 15:09:57 2023 ] 	Mean test loss of 625 batches: 1.133904.
[ Tue Jun 27 15:09:57 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:09:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:09:57 2023 ] Training epoch: 29
[ Tue Jun 27 15:09:59 2023 ] 	Training loss: 1.7111.  Training acc: 36.12%.
[ Tue Jun 27 15:09:59 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:09:59 2023 ] Eval epoch: 29
[ Tue Jun 27 15:10:00 2023 ] 	Mean test loss of 625 batches: 1.132469.
[ Tue Jun 27 15:10:00 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:00 2023 ] Training epoch: 30
[ Tue Jun 27 15:10:02 2023 ] 	Training loss: 1.6752.  Training acc: 35.94%.
[ Tue Jun 27 15:10:02 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:10:02 2023 ] Eval epoch: 30
[ Tue Jun 27 15:10:03 2023 ] 	Mean test loss of 625 batches: 1.136230.
[ Tue Jun 27 15:10:03 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:03 2023 ] Training epoch: 31
[ Tue Jun 27 15:10:06 2023 ] 	Training loss: 1.7294.  Training acc: 33.82%.
[ Tue Jun 27 15:10:06 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:10:06 2023 ] Eval epoch: 31
[ Tue Jun 27 15:10:07 2023 ] 	Mean test loss of 625 batches: 1.134098.
[ Tue Jun 27 15:10:07 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:07 2023 ] Training epoch: 32
[ Tue Jun 27 15:10:09 2023 ] 	Training loss: 1.7269.  Training acc: 34.56%.
[ Tue Jun 27 15:10:09 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:10:09 2023 ] Eval epoch: 32
[ Tue Jun 27 15:10:10 2023 ] 	Mean test loss of 625 batches: 1.132363.
[ Tue Jun 27 15:10:10 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:10 2023 ] Training epoch: 33
[ Tue Jun 27 15:10:13 2023 ] 	Training loss: 1.6714.  Training acc: 35.39%.
[ Tue Jun 27 15:10:13 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:10:13 2023 ] Eval epoch: 33
[ Tue Jun 27 15:10:14 2023 ] 	Mean test loss of 625 batches: 1.130446.
[ Tue Jun 27 15:10:14 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:14 2023 ] Training epoch: 34
[ Tue Jun 27 15:10:17 2023 ] 	Training loss: 1.6693.  Training acc: 33.36%.
[ Tue Jun 27 15:10:17 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:10:17 2023 ] Eval epoch: 34
[ Tue Jun 27 15:10:17 2023 ] 	Mean test loss of 625 batches: 1.128301.
[ Tue Jun 27 15:10:17 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:17 2023 ] Training epoch: 35
[ Tue Jun 27 15:10:20 2023 ] 	Training loss: 1.6253.  Training acc: 35.57%.
[ Tue Jun 27 15:10:20 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:10:20 2023 ] Eval epoch: 35
[ Tue Jun 27 15:10:21 2023 ] 	Mean test loss of 625 batches: 1.124172.
[ Tue Jun 27 15:10:21 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:21 2023 ] Training epoch: 36
[ Tue Jun 27 15:10:24 2023 ] 	Training loss: 1.6644.  Training acc: 35.66%.
[ Tue Jun 27 15:10:24 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:10:24 2023 ] Eval epoch: 36
[ Tue Jun 27 15:10:25 2023 ] 	Mean test loss of 625 batches: 1.124259.
[ Tue Jun 27 15:10:25 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:25 2023 ] Training epoch: 37
[ Tue Jun 27 15:10:27 2023 ] 	Training loss: 1.7087.  Training acc: 34.01%.
[ Tue Jun 27 15:10:27 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:10:27 2023 ] Eval epoch: 37
[ Tue Jun 27 15:10:28 2023 ] 	Mean test loss of 625 batches: 1.123765.
[ Tue Jun 27 15:10:28 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:28 2023 ] Training epoch: 38
[ Tue Jun 27 15:10:30 2023 ] 	Training loss: 1.5971.  Training acc: 34.83%.
[ Tue Jun 27 15:10:30 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:10:30 2023 ] Eval epoch: 38
[ Tue Jun 27 15:10:31 2023 ] 	Mean test loss of 625 batches: 1.123465.
[ Tue Jun 27 15:10:31 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:31 2023 ] Training epoch: 39
[ Tue Jun 27 15:10:33 2023 ] 	Training loss: 1.6362.  Training acc: 34.93%.
[ Tue Jun 27 15:10:33 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:10:33 2023 ] Eval epoch: 39
[ Tue Jun 27 15:10:34 2023 ] 	Mean test loss of 625 batches: 1.126960.
[ Tue Jun 27 15:10:34 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:34 2023 ] Training epoch: 40
[ Tue Jun 27 15:10:36 2023 ] 	Training loss: 1.6996.  Training acc: 31.89%.
[ Tue Jun 27 15:10:36 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Tue Jun 27 15:10:36 2023 ] Eval epoch: 40
[ Tue Jun 27 15:10:36 2023 ] 	Mean test loss of 625 batches: 1.129099.
[ Tue Jun 27 15:10:36 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:10:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:10:37 2023 ] Best accuracy: 0.7719298245614035
[ Tue Jun 27 15:10:37 2023 ] Epoch number: 7
[ Tue Jun 27 15:10:37 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 15:10:37 2023 ] Weight decay: 0.0005
[ Tue Jun 27 15:10:37 2023 ] Base LR: 0.1
[ Tue Jun 27 15:10:37 2023 ] Batch Size: 64
[ Tue Jun 27 15:10:37 2023 ] Test Batch Size: 64
[ Tue Jun 27 15:10:37 2023 ] seed: 1
[ Tue Jun 27 15:10:37 2023 ] Start training Corrector
[ Tue Jun 27 15:10:37 2023 ] Training epoch: 1
[ Tue Jun 27 15:10:44 2023 ] 	Training loss: 124.4016.  Training acc: 32.94%.
[ Tue Jun 27 15:10:44 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:10:44 2023 ] Training epoch: 2
[ Tue Jun 27 15:10:50 2023 ] 	Training loss: 86.4469.  Training acc: 42.06%.
[ Tue Jun 27 15:10:50 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:10:50 2023 ] Training epoch: 3
[ Tue Jun 27 15:10:55 2023 ] 	Training loss: 63.9722.  Training acc: 51.56%.
[ Tue Jun 27 15:10:55 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 15:10:55 2023 ] Training epoch: 4
[ Tue Jun 27 15:11:01 2023 ] 	Training loss: 58.0092.  Training acc: 39.45%.
[ Tue Jun 27 15:11:01 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Jun 27 15:11:01 2023 ] Training epoch: 5
[ Tue Jun 27 15:11:08 2023 ] 	Training loss: 56.2890.  Training acc: 44.40%.
[ Tue Jun 27 15:11:08 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:11:08 2023 ] Training epoch: 6
[ Tue Jun 27 15:11:15 2023 ] 	Training loss: 53.5703.  Training acc: 52.73%.
[ Tue Jun 27 15:11:15 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:11:15 2023 ] Training epoch: 7
[ Tue Jun 27 15:11:22 2023 ] 	Training loss: 54.5260.  Training acc: 49.22%.
[ Tue Jun 27 15:11:22 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:11:22 2023 ] Training epoch: 8
[ Tue Jun 27 15:11:28 2023 ] 	Training loss: 51.0517.  Training acc: 48.44%.
[ Tue Jun 27 15:11:28 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:11:28 2023 ] Training epoch: 9
[ Tue Jun 27 15:11:33 2023 ] 	Training loss: 52.9666.  Training acc: 50.39%.
[ Tue Jun 27 15:11:33 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 15:11:33 2023 ] Training epoch: 10
[ Tue Jun 27 15:11:38 2023 ] 	Training loss: 52.8262.  Training acc: 49.61%.
[ Tue Jun 27 15:11:38 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:11:38 2023 ] Training epoch: 11
[ Tue Jun 27 15:11:43 2023 ] 	Training loss: 51.9915.  Training acc: 36.98%.
[ Tue Jun 27 15:11:43 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 15:11:43 2023 ] Training epoch: 12
[ Tue Jun 27 15:11:48 2023 ] 	Training loss: 49.0147.  Training acc: 56.64%.
[ Tue Jun 27 15:11:48 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 15:11:48 2023 ] Training epoch: 13
[ Tue Jun 27 15:11:54 2023 ] 	Training loss: 49.3071.  Training acc: 59.64%.
[ Tue Jun 27 15:11:54 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 15:11:54 2023 ] Training epoch: 14
[ Tue Jun 27 15:11:59 2023 ] 	Training loss: 48.7788.  Training acc: 56.38%.
[ Tue Jun 27 15:11:59 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:11:59 2023 ] Training epoch: 15
[ Tue Jun 27 15:12:06 2023 ] 	Training loss: 46.7476.  Training acc: 63.15%.
[ Tue Jun 27 15:12:06 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:12:06 2023 ] Training epoch: 16
[ Tue Jun 27 15:12:12 2023 ] 	Training loss: 47.4036.  Training acc: 59.51%.
[ Tue Jun 27 15:12:12 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:12:12 2023 ] Training epoch: 17
[ Tue Jun 27 15:12:18 2023 ] 	Training loss: 46.4517.  Training acc: 64.45%.
[ Tue Jun 27 15:12:18 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:12:18 2023 ] Training epoch: 18
[ Tue Jun 27 15:12:25 2023 ] 	Training loss: 46.0780.  Training acc: 62.63%.
[ Tue Jun 27 15:12:25 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:12:25 2023 ] Training epoch: 19
[ Tue Jun 27 15:12:56 2023 ] using warm up, epoch: 5
[ Tue Jun 27 15:12:56 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 15:12:56 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 15:12:56 2023 ] Start training Predictor
[ Tue Jun 27 15:12:56 2023 ] Training epoch: 1
[ Tue Jun 27 15:13:01 2023 ] 	Training loss: 103.0748.  Training acc: 36.21%.
[ Tue Jun 27 15:13:01 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Jun 27 15:13:01 2023 ] Eval epoch: 1
[ Tue Jun 27 15:13:02 2023 ] 	Mean test loss of 625 batches: 1148.833923.
[ Tue Jun 27 15:13:02 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:13:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:02 2023 ] Training epoch: 2
[ Tue Jun 27 15:13:05 2023 ] 	Training loss: 9.6802.  Training acc: 37.59%.
[ Tue Jun 27 15:13:05 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:13:05 2023 ] Eval epoch: 2
[ Tue Jun 27 15:13:06 2023 ] 	Mean test loss of 625 batches: 48.653276.
[ Tue Jun 27 15:13:06 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:13:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:06 2023 ] Training epoch: 3
[ Tue Jun 27 15:13:09 2023 ] 	Training loss: 6.1398.  Training acc: 51.56%.
[ Tue Jun 27 15:13:09 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:13:09 2023 ] Eval epoch: 3
[ Tue Jun 27 15:13:10 2023 ] 	Mean test loss of 625 batches: 9.607471.
[ Tue Jun 27 15:13:10 2023 ] 	Top1: 19.30%
[ Tue Jun 27 15:13:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:10 2023 ] Training epoch: 4
[ Tue Jun 27 15:13:12 2023 ] 	Training loss: 4.3829.  Training acc: 58.18%.
[ Tue Jun 27 15:13:12 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Tue Jun 27 15:13:12 2023 ] Eval epoch: 4
[ Tue Jun 27 15:13:13 2023 ] 	Mean test loss of 625 batches: 22.035081.
[ Tue Jun 27 15:13:13 2023 ] 	Top1: 33.33%
[ Tue Jun 27 15:13:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:13 2023 ] Training epoch: 5
[ Tue Jun 27 15:13:16 2023 ] 	Training loss: 4.9316.  Training acc: 48.25%.
[ Tue Jun 27 15:13:16 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:13:16 2023 ] Eval epoch: 5
[ Tue Jun 27 15:13:16 2023 ] 	Mean test loss of 625 batches: 2.751602.
[ Tue Jun 27 15:13:16 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:13:16 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:16 2023 ] Training epoch: 6
[ Tue Jun 27 15:13:19 2023 ] 	Training loss: 4.6254.  Training acc: 50.28%.
[ Tue Jun 27 15:13:19 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:13:19 2023 ] Eval epoch: 6
[ Tue Jun 27 15:13:20 2023 ] 	Mean test loss of 625 batches: 1.381796.
[ Tue Jun 27 15:13:20 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:13:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:20 2023 ] Training epoch: 7
[ Tue Jun 27 15:13:23 2023 ] 	Training loss: 3.6768.  Training acc: 47.52%.
[ Tue Jun 27 15:13:23 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:13:23 2023 ] Eval epoch: 7
[ Tue Jun 27 15:13:24 2023 ] 	Mean test loss of 625 batches: 1.767275.
[ Tue Jun 27 15:13:24 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:13:24 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:24 2023 ] Training epoch: 8
[ Tue Jun 27 15:13:27 2023 ] 	Training loss: 2.9285.  Training acc: 38.60%.
[ Tue Jun 27 15:13:27 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:13:27 2023 ] Eval epoch: 8
[ Tue Jun 27 15:13:28 2023 ] 	Mean test loss of 625 batches: 2.238181.
[ Tue Jun 27 15:13:28 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:13:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:28 2023 ] Training epoch: 9
[ Tue Jun 27 15:13:30 2023 ] 	Training loss: 1.7661.  Training acc: 51.56%.
[ Tue Jun 27 15:13:30 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:13:30 2023 ] Eval epoch: 9
[ Tue Jun 27 15:13:31 2023 ] 	Mean test loss of 625 batches: 0.866523.
[ Tue Jun 27 15:13:31 2023 ] 	Top1: 70.18%
[ Tue Jun 27 15:13:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:31 2023 ] Training epoch: 10
[ Tue Jun 27 15:13:34 2023 ] 	Training loss: 1.7384.  Training acc: 53.22%.
[ Tue Jun 27 15:13:34 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:13:34 2023 ] Eval epoch: 10
[ Tue Jun 27 15:13:35 2023 ] 	Mean test loss of 625 batches: 1.700892.
[ Tue Jun 27 15:13:35 2023 ] 	Top1: 68.42%
[ Tue Jun 27 15:13:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:35 2023 ] Training epoch: 11
[ Tue Jun 27 15:13:38 2023 ] 	Training loss: 1.2889.  Training acc: 59.56%.
[ Tue Jun 27 15:13:38 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:13:38 2023 ] Eval epoch: 11
[ Tue Jun 27 15:13:39 2023 ] 	Mean test loss of 625 batches: 0.923863.
[ Tue Jun 27 15:13:39 2023 ] 	Top1: 68.42%
[ Tue Jun 27 15:13:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:39 2023 ] Training epoch: 12
[ Tue Jun 27 15:13:42 2023 ] 	Training loss: 1.1535.  Training acc: 59.01%.
[ Tue Jun 27 15:13:42 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:13:42 2023 ] Eval epoch: 12
[ Tue Jun 27 15:13:42 2023 ] 	Mean test loss of 625 batches: 0.698113.
[ Tue Jun 27 15:13:42 2023 ] 	Top1: 70.18%
[ Tue Jun 27 15:13:42 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:42 2023 ] Training epoch: 13
[ Tue Jun 27 15:13:45 2023 ] 	Training loss: 1.0174.  Training acc: 62.78%.
[ Tue Jun 27 15:13:45 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:13:45 2023 ] Eval epoch: 13
[ Tue Jun 27 15:13:46 2023 ] 	Mean test loss of 625 batches: 0.770374.
[ Tue Jun 27 15:13:46 2023 ] 	Top1: 68.42%
[ Tue Jun 27 15:13:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:46 2023 ] Training epoch: 14
[ Tue Jun 27 15:13:48 2023 ] 	Training loss: 0.9674.  Training acc: 63.79%.
[ Tue Jun 27 15:13:48 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:13:48 2023 ] Eval epoch: 14
[ Tue Jun 27 15:13:49 2023 ] 	Mean test loss of 625 batches: 0.690815.
[ Tue Jun 27 15:13:49 2023 ] 	Top1: 71.93%
[ Tue Jun 27 15:13:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:49 2023 ] Training epoch: 15
[ Tue Jun 27 15:13:51 2023 ] 	Training loss: 1.0047.  Training acc: 61.58%.
[ Tue Jun 27 15:13:51 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:13:51 2023 ] Eval epoch: 15
[ Tue Jun 27 15:13:52 2023 ] 	Mean test loss of 625 batches: 0.674246.
[ Tue Jun 27 15:13:52 2023 ] 	Top1: 75.44%
[ Tue Jun 27 15:13:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:52 2023 ] Training epoch: 16
[ Tue Jun 27 15:13:54 2023 ] 	Training loss: 0.9134.  Training acc: 65.99%.
[ Tue Jun 27 15:13:54 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 15:13:54 2023 ] Eval epoch: 16
[ Tue Jun 27 15:13:55 2023 ] 	Mean test loss of 625 batches: 0.660867.
[ Tue Jun 27 15:13:55 2023 ] 	Top1: 78.95%
[ Tue Jun 27 15:13:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:55 2023 ] Training epoch: 17
[ Tue Jun 27 15:13:57 2023 ] 	Training loss: 0.8815.  Training acc: 69.21%.
[ Tue Jun 27 15:13:57 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 15:13:57 2023 ] Eval epoch: 17
[ Tue Jun 27 15:13:58 2023 ] 	Mean test loss of 625 batches: 0.574561.
[ Tue Jun 27 15:13:58 2023 ] 	Top1: 89.47%
[ Tue Jun 27 15:13:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:13:58 2023 ] Training epoch: 18
[ Tue Jun 27 15:14:00 2023 ] 	Training loss: 0.8905.  Training acc: 67.00%.
[ Tue Jun 27 15:14:00 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:14:00 2023 ] Eval epoch: 18
[ Tue Jun 27 15:14:01 2023 ] 	Mean test loss of 625 batches: 0.587571.
[ Tue Jun 27 15:14:01 2023 ] 	Top1: 85.96%
[ Tue Jun 27 15:14:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:01 2023 ] Training epoch: 19
[ Tue Jun 27 15:14:03 2023 ] 	Training loss: 0.8473.  Training acc: 69.85%.
[ Tue Jun 27 15:14:03 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:14:03 2023 ] Eval epoch: 19
[ Tue Jun 27 15:14:04 2023 ] 	Mean test loss of 625 batches: 0.613954.
[ Tue Jun 27 15:14:04 2023 ] 	Top1: 85.96%
[ Tue Jun 27 15:14:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:04 2023 ] Training epoch: 20
[ Tue Jun 27 15:14:06 2023 ] 	Training loss: 0.8107.  Training acc: 70.04%.
[ Tue Jun 27 15:14:06 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:14:06 2023 ] Eval epoch: 20
[ Tue Jun 27 15:14:06 2023 ] 	Mean test loss of 625 batches: 0.569123.
[ Tue Jun 27 15:14:06 2023 ] 	Top1: 87.72%
[ Tue Jun 27 15:14:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:06 2023 ] Training epoch: 21
[ Tue Jun 27 15:14:08 2023 ] 	Training loss: 0.7981.  Training acc: 72.61%.
[ Tue Jun 27 15:14:08 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:14:08 2023 ] Eval epoch: 21
[ Tue Jun 27 15:14:09 2023 ] 	Mean test loss of 625 batches: 0.536396.
[ Tue Jun 27 15:14:09 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:14:09 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:09 2023 ] Training epoch: 22
[ Tue Jun 27 15:14:11 2023 ] 	Training loss: 0.7550.  Training acc: 73.44%.
[ Tue Jun 27 15:14:11 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:14:11 2023 ] Eval epoch: 22
[ Tue Jun 27 15:14:12 2023 ] 	Mean test loss of 625 batches: 0.553908.
[ Tue Jun 27 15:14:12 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:14:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:12 2023 ] Training epoch: 23
[ Tue Jun 27 15:14:14 2023 ] 	Training loss: 0.7536.  Training acc: 74.54%.
[ Tue Jun 27 15:14:14 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:14:14 2023 ] Eval epoch: 23
[ Tue Jun 27 15:14:15 2023 ] 	Mean test loss of 625 batches: 0.567013.
[ Tue Jun 27 15:14:15 2023 ] 	Top1: 84.21%
[ Tue Jun 27 15:14:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:15 2023 ] Training epoch: 24
[ Tue Jun 27 15:14:17 2023 ] 	Training loss: 0.7728.  Training acc: 72.89%.
[ Tue Jun 27 15:14:17 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:14:17 2023 ] Eval epoch: 24
[ Tue Jun 27 15:14:18 2023 ] 	Mean test loss of 625 batches: 0.540340.
[ Tue Jun 27 15:14:18 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:14:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:18 2023 ] Training epoch: 25
[ Tue Jun 27 15:14:21 2023 ] 	Training loss: 0.7808.  Training acc: 72.70%.
[ Tue Jun 27 15:14:21 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:14:21 2023 ] Eval epoch: 25
[ Tue Jun 27 15:14:21 2023 ] 	Mean test loss of 625 batches: 0.552455.
[ Tue Jun 27 15:14:21 2023 ] 	Top1: 85.96%
[ Tue Jun 27 15:14:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:21 2023 ] Training epoch: 26
[ Tue Jun 27 15:14:24 2023 ] 	Training loss: 0.7238.  Training acc: 74.72%.
[ Tue Jun 27 15:14:24 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:14:24 2023 ] Eval epoch: 26
[ Tue Jun 27 15:14:25 2023 ] 	Mean test loss of 625 batches: 0.534233.
[ Tue Jun 27 15:14:25 2023 ] 	Top1: 92.98%
[ Tue Jun 27 15:14:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:25 2023 ] Training epoch: 27
[ Tue Jun 27 15:14:28 2023 ] 	Training loss: 0.7542.  Training acc: 71.88%.
[ Tue Jun 27 15:14:28 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:14:28 2023 ] Eval epoch: 27
[ Tue Jun 27 15:14:29 2023 ] 	Mean test loss of 625 batches: 0.554869.
[ Tue Jun 27 15:14:29 2023 ] 	Top1: 87.72%
[ Tue Jun 27 15:14:29 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:29 2023 ] Training epoch: 28
[ Tue Jun 27 15:14:32 2023 ] 	Training loss: 0.7386.  Training acc: 74.26%.
[ Tue Jun 27 15:14:32 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:14:32 2023 ] Eval epoch: 28
[ Tue Jun 27 15:14:33 2023 ] 	Mean test loss of 625 batches: 0.559548.
[ Tue Jun 27 15:14:33 2023 ] 	Top1: 85.96%
[ Tue Jun 27 15:14:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:33 2023 ] Training epoch: 29
[ Tue Jun 27 15:14:36 2023 ] 	Training loss: 0.7314.  Training acc: 74.36%.
[ Tue Jun 27 15:14:36 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:14:36 2023 ] Eval epoch: 29
[ Tue Jun 27 15:14:36 2023 ] 	Mean test loss of 625 batches: 0.543395.
[ Tue Jun 27 15:14:36 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:14:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:36 2023 ] Training epoch: 30
[ Tue Jun 27 15:14:39 2023 ] 	Training loss: 0.7164.  Training acc: 77.67%.
[ Tue Jun 27 15:14:39 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:14:39 2023 ] Eval epoch: 30
[ Tue Jun 27 15:14:40 2023 ] 	Mean test loss of 625 batches: 0.559303.
[ Tue Jun 27 15:14:40 2023 ] 	Top1: 89.47%
[ Tue Jun 27 15:14:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:40 2023 ] Training epoch: 31
[ Tue Jun 27 15:14:43 2023 ] 	Training loss: 0.7466.  Training acc: 74.17%.
[ Tue Jun 27 15:14:43 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:14:43 2023 ] Eval epoch: 31
[ Tue Jun 27 15:14:44 2023 ] 	Mean test loss of 625 batches: 0.551350.
[ Tue Jun 27 15:14:44 2023 ] 	Top1: 89.47%
[ Tue Jun 27 15:14:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:44 2023 ] Training epoch: 32
[ Tue Jun 27 15:14:47 2023 ] 	Training loss: 0.7259.  Training acc: 74.26%.
[ Tue Jun 27 15:14:47 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:14:47 2023 ] Eval epoch: 32
[ Tue Jun 27 15:14:48 2023 ] 	Mean test loss of 625 batches: 0.550281.
[ Tue Jun 27 15:14:48 2023 ] 	Top1: 89.47%
[ Tue Jun 27 15:14:48 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:48 2023 ] Training epoch: 33
[ Tue Jun 27 15:14:51 2023 ] 	Training loss: 0.7169.  Training acc: 76.75%.
[ Tue Jun 27 15:14:51 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:14:51 2023 ] Eval epoch: 33
[ Tue Jun 27 15:14:51 2023 ] 	Mean test loss of 625 batches: 0.539390.
[ Tue Jun 27 15:14:51 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:14:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:51 2023 ] Training epoch: 34
[ Tue Jun 27 15:14:54 2023 ] 	Training loss: 0.7380.  Training acc: 75.28%.
[ Tue Jun 27 15:14:54 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:14:54 2023 ] Eval epoch: 34
[ Tue Jun 27 15:14:54 2023 ] 	Mean test loss of 625 batches: 0.551896.
[ Tue Jun 27 15:14:54 2023 ] 	Top1: 89.47%
[ Tue Jun 27 15:14:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:54 2023 ] Training epoch: 35
[ Tue Jun 27 15:14:56 2023 ] 	Training loss: 0.7119.  Training acc: 76.01%.
[ Tue Jun 27 15:14:56 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:14:56 2023 ] Eval epoch: 35
[ Tue Jun 27 15:14:57 2023 ] 	Mean test loss of 625 batches: 0.543765.
[ Tue Jun 27 15:14:57 2023 ] 	Top1: 92.98%
[ Tue Jun 27 15:14:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:14:57 2023 ] Training epoch: 36
[ Tue Jun 27 15:14:59 2023 ] 	Training loss: 0.7077.  Training acc: 77.11%.
[ Tue Jun 27 15:14:59 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:14:59 2023 ] Eval epoch: 36
[ Tue Jun 27 15:15:00 2023 ] 	Mean test loss of 625 batches: 0.547961.
[ Tue Jun 27 15:15:00 2023 ] 	Top1: 85.96%
[ Tue Jun 27 15:15:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:15:00 2023 ] Training epoch: 37
[ Tue Jun 27 15:15:02 2023 ] 	Training loss: 0.7028.  Training acc: 77.39%.
[ Tue Jun 27 15:15:02 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:15:02 2023 ] Eval epoch: 37
[ Tue Jun 27 15:15:03 2023 ] 	Mean test loss of 625 batches: 0.522652.
[ Tue Jun 27 15:15:03 2023 ] 	Top1: 92.98%
[ Tue Jun 27 15:15:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:15:03 2023 ] Training epoch: 38
[ Tue Jun 27 15:15:05 2023 ] 	Training loss: 0.6991.  Training acc: 76.75%.
[ Tue Jun 27 15:15:05 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 15:15:05 2023 ] Eval epoch: 38
[ Tue Jun 27 15:15:06 2023 ] 	Mean test loss of 625 batches: 0.531079.
[ Tue Jun 27 15:15:06 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:15:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:15:06 2023 ] Training epoch: 39
[ Tue Jun 27 15:15:08 2023 ] 	Training loss: 0.6963.  Training acc: 78.77%.
[ Tue Jun 27 15:15:08 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:15:08 2023 ] Eval epoch: 39
[ Tue Jun 27 15:15:08 2023 ] 	Mean test loss of 625 batches: 0.535514.
[ Tue Jun 27 15:15:08 2023 ] 	Top1: 92.98%
[ Tue Jun 27 15:15:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:15:08 2023 ] Training epoch: 40
[ Tue Jun 27 15:15:10 2023 ] 	Training loss: 0.7193.  Training acc: 75.09%.
[ Tue Jun 27 15:15:10 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:15:11 2023 ] Eval epoch: 40
[ Tue Jun 27 15:15:11 2023 ] 	Mean test loss of 625 batches: 0.539162.
[ Tue Jun 27 15:15:11 2023 ] 	Top1: 89.47%
[ Tue Jun 27 15:15:11 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:15:12 2023 ] Best accuracy: 0.9473684210526315
[ Tue Jun 27 15:15:12 2023 ] Epoch number: 24
[ Tue Jun 27 15:15:12 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 15:15:12 2023 ] Weight decay: 0.0005
[ Tue Jun 27 15:15:12 2023 ] Base LR: 0.1
[ Tue Jun 27 15:15:12 2023 ] Batch Size: 64
[ Tue Jun 27 15:15:12 2023 ] Test Batch Size: 64
[ Tue Jun 27 15:15:12 2023 ] seed: 1
[ Tue Jun 27 15:15:12 2023 ] Start training Corrector
[ Tue Jun 27 15:15:12 2023 ] Training epoch: 1
[ Tue Jun 27 15:15:19 2023 ] 	Training loss: 129.7937.  Training acc: 32.42%.
[ Tue Jun 27 15:15:19 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Jun 27 15:15:19 2023 ] Training epoch: 2
[ Tue Jun 27 15:15:25 2023 ] 	Training loss: 84.6928.  Training acc: 36.07%.
[ Tue Jun 27 15:15:25 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Jun 27 15:15:25 2023 ] Training epoch: 3
[ Tue Jun 27 15:15:32 2023 ] 	Training loss: 67.1394.  Training acc: 28.52%.
[ Tue Jun 27 15:15:32 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Jun 27 15:15:32 2023 ] Training epoch: 4
[ Tue Jun 27 15:15:39 2023 ] 	Training loss: 60.2131.  Training acc: 42.45%.
[ Tue Jun 27 15:15:39 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:15:39 2023 ] Training epoch: 5
[ Tue Jun 27 15:15:46 2023 ] 	Training loss: 59.0163.  Training acc: 36.33%.
[ Tue Jun 27 15:15:46 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:15:46 2023 ] Training epoch: 6
[ Tue Jun 27 15:15:53 2023 ] 	Training loss: 56.1320.  Training acc: 30.34%.
[ Tue Jun 27 15:15:53 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:15:53 2023 ] Training epoch: 7
[ Tue Jun 27 15:16:00 2023 ] 	Training loss: 56.8200.  Training acc: 19.01%.
[ Tue Jun 27 15:16:00 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:16:00 2023 ] Training epoch: 8
[ Tue Jun 27 15:16:05 2023 ] 	Training loss: 55.7411.  Training acc: 31.90%.
[ Tue Jun 27 15:16:05 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:16:05 2023 ] Training epoch: 9
[ Tue Jun 27 15:16:11 2023 ] 	Training loss: 57.1954.  Training acc: 42.84%.
[ Tue Jun 27 15:16:11 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:16:11 2023 ] Training epoch: 10
[ Tue Jun 27 15:16:16 2023 ] 	Training loss: 56.0800.  Training acc: 45.18%.
[ Tue Jun 27 15:16:16 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:16:16 2023 ] Training epoch: 11
[ Tue Jun 27 15:16:22 2023 ] 	Training loss: 54.8658.  Training acc: 57.55%.
[ Tue Jun 27 15:16:22 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:16:22 2023 ] Training epoch: 12
[ Tue Jun 27 15:16:27 2023 ] 	Training loss: 53.5898.  Training acc: 48.57%.
[ Tue Jun 27 15:16:27 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:16:27 2023 ] Training epoch: 13
[ Tue Jun 27 15:16:33 2023 ] 	Training loss: 55.5135.  Training acc: 68.62%.
[ Tue Jun 27 15:16:33 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:16:33 2023 ] Training epoch: 14
[ Tue Jun 27 15:16:40 2023 ] 	Training loss: 55.3298.  Training acc: 67.45%.
[ Tue Jun 27 15:16:40 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:16:40 2023 ] Training epoch: 15
[ Tue Jun 27 15:16:47 2023 ] 	Training loss: 53.8884.  Training acc: 77.73%.
[ Tue Jun 27 15:16:47 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Tue Jun 27 15:16:47 2023 ] Training epoch: 16
[ Tue Jun 27 15:16:54 2023 ] 	Training loss: 53.9961.  Training acc: 71.74%.
[ Tue Jun 27 15:16:54 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:16:54 2023 ] Training epoch: 17
[ Tue Jun 27 15:17:01 2023 ] 	Training loss: 53.6215.  Training acc: 81.77%.
[ Tue Jun 27 15:17:01 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:17:01 2023 ] Training epoch: 18
[ Tue Jun 27 15:17:08 2023 ] 	Training loss: 53.6273.  Training acc: 77.08%.
[ Tue Jun 27 15:17:08 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:17:08 2023 ] Training epoch: 19
[ Tue Jun 27 15:17:14 2023 ] 	Training loss: 53.1239.  Training acc: 77.47%.
[ Tue Jun 27 15:17:14 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:17:14 2023 ] Training epoch: 20
[ Tue Jun 27 15:17:19 2023 ] 	Training loss: 54.2766.  Training acc: 76.56%.
[ Tue Jun 27 15:17:19 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:17:19 2023 ] Training epoch: 21
[ Tue Jun 27 15:17:25 2023 ] 	Training loss: 54.4711.  Training acc: 60.55%.
[ Tue Jun 27 15:17:25 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:17:25 2023 ] Training epoch: 22
[ Tue Jun 27 15:17:30 2023 ] 	Training loss: 52.7851.  Training acc: 69.01%.
[ Tue Jun 27 15:17:30 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:17:30 2023 ] Training epoch: 23
[ Tue Jun 27 15:17:36 2023 ] 	Training loss: 54.2233.  Training acc: 79.69%.
[ Tue Jun 27 15:17:36 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:17:36 2023 ] Training epoch: 24
[ Tue Jun 27 15:17:42 2023 ] 	Training loss: 53.5500.  Training acc: 80.34%.
[ Tue Jun 27 15:17:42 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:17:42 2023 ] Training epoch: 25
[ Tue Jun 27 15:17:48 2023 ] 	Training loss: 54.0342.  Training acc: 79.69%.
[ Tue Jun 27 15:17:48 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:17:48 2023 ] Training epoch: 26
[ Tue Jun 27 15:17:55 2023 ] 	Training loss: 54.2332.  Training acc: 81.90%.
[ Tue Jun 27 15:17:55 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:17:55 2023 ] Training epoch: 27
[ Tue Jun 27 15:18:03 2023 ] 	Training loss: 54.6733.  Training acc: 77.34%.
[ Tue Jun 27 15:18:03 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Tue Jun 27 15:18:03 2023 ] Training epoch: 28
[ Tue Jun 27 15:18:10 2023 ] 	Training loss: 55.1602.  Training acc: 79.69%.
[ Tue Jun 27 15:18:10 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:18:10 2023 ] Training epoch: 29
[ Tue Jun 27 15:18:17 2023 ] 	Training loss: 52.2903.  Training acc: 75.65%.
[ Tue Jun 27 15:18:17 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:18:17 2023 ] Training epoch: 30
[ Tue Jun 27 15:18:24 2023 ] 	Training loss: 54.7136.  Training acc: 75.26%.
[ Tue Jun 27 15:18:24 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:18:24 2023 ] Training epoch: 31
[ Tue Jun 27 15:18:30 2023 ] 	Training loss: 53.0973.  Training acc: 73.44%.
[ Tue Jun 27 15:18:30 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 15:18:30 2023 ] Training epoch: 32
[ Tue Jun 27 15:18:36 2023 ] 	Training loss: 54.3226.  Training acc: 77.99%.
[ Tue Jun 27 15:18:36 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:18:36 2023 ] Training epoch: 33
[ Tue Jun 27 15:18:41 2023 ] 	Training loss: 52.8338.  Training acc: 79.43%.
[ Tue Jun 27 15:18:41 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 15:18:41 2023 ] Training epoch: 34
[ Tue Jun 27 15:18:47 2023 ] 	Training loss: 53.6329.  Training acc: 74.87%.
[ Tue Jun 27 15:18:47 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:18:47 2023 ] Training epoch: 35
[ Tue Jun 27 15:18:52 2023 ] 	Training loss: 53.7301.  Training acc: 73.83%.
[ Tue Jun 27 15:18:52 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 15:18:52 2023 ] Training epoch: 36
[ Tue Jun 27 15:18:58 2023 ] 	Training loss: 52.5682.  Training acc: 73.44%.
[ Tue Jun 27 15:18:58 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 15:18:58 2023 ] Training epoch: 37
[ Tue Jun 27 15:19:04 2023 ] 	Training loss: 53.9435.  Training acc: 71.88%.
[ Tue Jun 27 15:19:04 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:19:04 2023 ] Training epoch: 38
[ Tue Jun 27 15:19:12 2023 ] 	Training loss: 54.5104.  Training acc: 69.92%.
[ Tue Jun 27 15:19:12 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:19:12 2023 ] Training epoch: 39
[ Tue Jun 27 15:19:18 2023 ] 	Training loss: 54.0940.  Training acc: 71.09%.
[ Tue Jun 27 15:19:18 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:19:18 2023 ] Training epoch: 40
[ Tue Jun 27 15:19:25 2023 ] 	Training loss: 52.6959.  Training acc: 70.83%.
[ Tue Jun 27 15:19:25 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 15:27:36 2023 ] using warm up, epoch: 5
[ Tue Jun 27 15:27:36 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 15:27:36 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 15:27:36 2023 ] Start training Predictor
[ Tue Jun 27 15:27:36 2023 ] Training epoch: 1
[ Tue Jun 27 15:27:42 2023 ] 	Training loss: 109.1553.  Training acc: 35.48%.
[ Tue Jun 27 15:27:42 2023 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue Jun 27 15:27:42 2023 ] Eval epoch: 1
[ Tue Jun 27 15:27:43 2023 ] 	Mean test loss of 625 batches: 194.740533.
[ Tue Jun 27 15:27:43 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:27:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:27:43 2023 ] Training epoch: 2
[ Tue Jun 27 15:27:46 2023 ] 	Training loss: 9.6539.  Training acc: 34.10%.
[ Tue Jun 27 15:27:46 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:27:46 2023 ] Eval epoch: 2
[ Tue Jun 27 15:27:46 2023 ] 	Mean test loss of 625 batches: 1.420038.
[ Tue Jun 27 15:27:46 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:27:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:27:46 2023 ] Training epoch: 3
[ Tue Jun 27 15:27:48 2023 ] 	Training loss: 6.1528.  Training acc: 42.00%.
[ Tue Jun 27 15:27:48 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:27:48 2023 ] Eval epoch: 3
[ Tue Jun 27 15:27:49 2023 ] 	Mean test loss of 625 batches: 4.427734.
[ Tue Jun 27 15:27:49 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:27:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:27:49 2023 ] Training epoch: 4
[ Tue Jun 27 15:27:51 2023 ] 	Training loss: 4.9340.  Training acc: 47.15%.
[ Tue Jun 27 15:27:51 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:27:51 2023 ] Eval epoch: 4
[ Tue Jun 27 15:27:52 2023 ] 	Mean test loss of 625 batches: 5.770910.
[ Tue Jun 27 15:27:52 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:27:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:27:52 2023 ] Training epoch: 5
[ Tue Jun 27 15:27:54 2023 ] 	Training loss: 4.3639.  Training acc: 48.99%.
[ Tue Jun 27 15:27:54 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:27:54 2023 ] Eval epoch: 5
[ Tue Jun 27 15:27:54 2023 ] 	Mean test loss of 625 batches: 4.311692.
[ Tue Jun 27 15:27:54 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:27:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:27:54 2023 ] Training epoch: 6
[ Tue Jun 27 15:27:56 2023 ] 	Training loss: 3.7711.  Training acc: 42.46%.
[ Tue Jun 27 15:27:56 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:27:56 2023 ] Eval epoch: 6
[ Tue Jun 27 15:27:57 2023 ] 	Mean test loss of 625 batches: 3.395636.
[ Tue Jun 27 15:27:57 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:27:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:27:57 2023 ] Training epoch: 7
[ Tue Jun 27 15:27:59 2023 ] 	Training loss: 3.5261.  Training acc: 37.50%.
[ Tue Jun 27 15:27:59 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:27:59 2023 ] Eval epoch: 7
[ Tue Jun 27 15:27:59 2023 ] 	Mean test loss of 625 batches: 2.496838.
[ Tue Jun 27 15:27:59 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:27:59 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:27:59 2023 ] Training epoch: 8
[ Tue Jun 27 15:28:01 2023 ] 	Training loss: 3.5256.  Training acc: 34.19%.
[ Tue Jun 27 15:28:01 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:28:01 2023 ] Eval epoch: 8
[ Tue Jun 27 15:28:02 2023 ] 	Mean test loss of 625 batches: 1.134078.
[ Tue Jun 27 15:28:02 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:28:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:02 2023 ] Training epoch: 9
[ Tue Jun 27 15:28:04 2023 ] 	Training loss: 3.0750.  Training acc: 33.92%.
[ Tue Jun 27 15:28:04 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:28:04 2023 ] Eval epoch: 9
[ Tue Jun 27 15:28:05 2023 ] 	Mean test loss of 625 batches: 1.727339.
[ Tue Jun 27 15:28:05 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:05 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:05 2023 ] Training epoch: 10
[ Tue Jun 27 15:28:07 2023 ] 	Training loss: 3.0620.  Training acc: 34.65%.
[ Tue Jun 27 15:28:07 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:28:07 2023 ] Eval epoch: 10
[ Tue Jun 27 15:28:07 2023 ] 	Mean test loss of 625 batches: 1.157521.
[ Tue Jun 27 15:28:07 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:07 2023 ] Training epoch: 11
[ Tue Jun 27 15:28:09 2023 ] 	Training loss: 1.8529.  Training acc: 34.38%.
[ Tue Jun 27 15:28:09 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:28:09 2023 ] Eval epoch: 11
[ Tue Jun 27 15:28:10 2023 ] 	Mean test loss of 625 batches: 1.110134.
[ Tue Jun 27 15:28:10 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:10 2023 ] Training epoch: 12
[ Tue Jun 27 15:28:12 2023 ] 	Training loss: 1.8913.  Training acc: 32.63%.
[ Tue Jun 27 15:28:12 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:28:12 2023 ] Eval epoch: 12
[ Tue Jun 27 15:28:13 2023 ] 	Mean test loss of 625 batches: 1.125541.
[ Tue Jun 27 15:28:13 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:13 2023 ] Training epoch: 13
[ Tue Jun 27 15:28:15 2023 ] 	Training loss: 1.7283.  Training acc: 35.85%.
[ Tue Jun 27 15:28:15 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:28:15 2023 ] Eval epoch: 13
[ Tue Jun 27 15:28:15 2023 ] 	Mean test loss of 625 batches: 1.121966.
[ Tue Jun 27 15:28:15 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:15 2023 ] Training epoch: 14
[ Tue Jun 27 15:28:17 2023 ] 	Training loss: 1.8061.  Training acc: 33.18%.
[ Tue Jun 27 15:28:17 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:28:17 2023 ] Eval epoch: 14
[ Tue Jun 27 15:28:18 2023 ] 	Mean test loss of 625 batches: 1.125699.
[ Tue Jun 27 15:28:18 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:18 2023 ] Training epoch: 15
[ Tue Jun 27 15:28:20 2023 ] 	Training loss: 1.7370.  Training acc: 33.92%.
[ Tue Jun 27 15:28:20 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 15:28:20 2023 ] Eval epoch: 15
[ Tue Jun 27 15:28:21 2023 ] 	Mean test loss of 625 batches: 1.114989.
[ Tue Jun 27 15:28:21 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:21 2023 ] Training epoch: 16
[ Tue Jun 27 15:28:24 2023 ] 	Training loss: 1.6795.  Training acc: 35.39%.
[ Tue Jun 27 15:28:24 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 27 15:28:24 2023 ] Eval epoch: 16
[ Tue Jun 27 15:28:24 2023 ] 	Mean test loss of 625 batches: 1.119527.
[ Tue Jun 27 15:28:24 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:24 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:24 2023 ] Training epoch: 17
[ Tue Jun 27 15:28:27 2023 ] 	Training loss: 1.6706.  Training acc: 35.11%.
[ Tue Jun 27 15:28:27 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Tue Jun 27 15:28:27 2023 ] Eval epoch: 17
[ Tue Jun 27 15:28:28 2023 ] 	Mean test loss of 625 batches: 1.110197.
[ Tue Jun 27 15:28:28 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:28 2023 ] Training epoch: 18
[ Tue Jun 27 15:28:31 2023 ] 	Training loss: 1.6536.  Training acc: 34.10%.
[ Tue Jun 27 15:28:31 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:28:31 2023 ] Eval epoch: 18
[ Tue Jun 27 15:28:31 2023 ] 	Mean test loss of 625 batches: 1.103371.
[ Tue Jun 27 15:28:31 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:31 2023 ] Training epoch: 19
[ Tue Jun 27 15:28:34 2023 ] 	Training loss: 1.6146.  Training acc: 34.56%.
[ Tue Jun 27 15:28:34 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:28:34 2023 ] Eval epoch: 19
[ Tue Jun 27 15:28:35 2023 ] 	Mean test loss of 625 batches: 1.129461.
[ Tue Jun 27 15:28:35 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:35 2023 ] Training epoch: 20
[ Tue Jun 27 15:28:38 2023 ] 	Training loss: 1.5225.  Training acc: 34.83%.
[ Tue Jun 27 15:28:38 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 27 15:28:38 2023 ] Eval epoch: 20
[ Tue Jun 27 15:28:39 2023 ] 	Mean test loss of 625 batches: 1.119289.
[ Tue Jun 27 15:28:39 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:39 2023 ] Training epoch: 21
[ Tue Jun 27 15:28:41 2023 ] 	Training loss: 1.5330.  Training acc: 34.93%.
[ Tue Jun 27 15:28:41 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:28:41 2023 ] Eval epoch: 21
[ Tue Jun 27 15:28:41 2023 ] 	Mean test loss of 625 batches: 1.116529.
[ Tue Jun 27 15:28:41 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:41 2023 ] Training epoch: 22
[ Tue Jun 27 15:28:43 2023 ] 	Training loss: 1.5072.  Training acc: 34.47%.
[ Tue Jun 27 15:28:43 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:28:43 2023 ] Eval epoch: 22
[ Tue Jun 27 15:28:44 2023 ] 	Mean test loss of 625 batches: 1.113865.
[ Tue Jun 27 15:28:44 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:44 2023 ] Training epoch: 23
[ Tue Jun 27 15:28:46 2023 ] 	Training loss: 1.4759.  Training acc: 37.68%.
[ Tue Jun 27 15:28:46 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 15:28:46 2023 ] Eval epoch: 23
[ Tue Jun 27 15:28:47 2023 ] 	Mean test loss of 625 batches: 1.111611.
[ Tue Jun 27 15:28:47 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:47 2023 ] Training epoch: 24
[ Tue Jun 27 15:28:49 2023 ] 	Training loss: 1.5128.  Training acc: 33.64%.
[ Tue Jun 27 15:28:49 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:28:49 2023 ] Eval epoch: 24
[ Tue Jun 27 15:28:49 2023 ] 	Mean test loss of 625 batches: 1.112198.
[ Tue Jun 27 15:28:49 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:49 2023 ] Training epoch: 25
[ Tue Jun 27 15:28:51 2023 ] 	Training loss: 1.5743.  Training acc: 33.18%.
[ Tue Jun 27 15:28:51 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 15:28:51 2023 ] Eval epoch: 25
[ Tue Jun 27 15:28:52 2023 ] 	Mean test loss of 625 batches: 1.114629.
[ Tue Jun 27 15:28:52 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:52 2023 ] Training epoch: 26
[ Tue Jun 27 15:28:54 2023 ] 	Training loss: 1.4987.  Training acc: 36.67%.
[ Tue Jun 27 15:28:54 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:28:54 2023 ] Eval epoch: 26
[ Tue Jun 27 15:28:55 2023 ] 	Mean test loss of 625 batches: 1.114299.
[ Tue Jun 27 15:28:55 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:55 2023 ] Training epoch: 27
[ Tue Jun 27 15:28:57 2023 ] 	Training loss: 1.5711.  Training acc: 33.36%.
[ Tue Jun 27 15:28:57 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:28:57 2023 ] Eval epoch: 27
[ Tue Jun 27 15:28:57 2023 ] 	Mean test loss of 625 batches: 1.113904.
[ Tue Jun 27 15:28:57 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:28:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:28:57 2023 ] Training epoch: 28
[ Tue Jun 27 15:28:59 2023 ] 	Training loss: 1.4948.  Training acc: 34.47%.
[ Tue Jun 27 15:28:59 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:28:59 2023 ] Eval epoch: 28
[ Tue Jun 27 15:29:00 2023 ] 	Mean test loss of 625 batches: 1.115570.
[ Tue Jun 27 15:29:00 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:00 2023 ] Training epoch: 29
[ Tue Jun 27 15:29:02 2023 ] 	Training loss: 1.5288.  Training acc: 33.73%.
[ Tue Jun 27 15:29:02 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:29:02 2023 ] Eval epoch: 29
[ Tue Jun 27 15:29:03 2023 ] 	Mean test loss of 625 batches: 1.114989.
[ Tue Jun 27 15:29:03 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:03 2023 ] Training epoch: 30
[ Tue Jun 27 15:29:05 2023 ] 	Training loss: 1.4618.  Training acc: 34.28%.
[ Tue Jun 27 15:29:05 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:29:05 2023 ] Eval epoch: 30
[ Tue Jun 27 15:29:05 2023 ] 	Mean test loss of 625 batches: 1.117063.
[ Tue Jun 27 15:29:05 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:05 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:05 2023 ] Training epoch: 31
[ Tue Jun 27 15:29:08 2023 ] 	Training loss: 1.5121.  Training acc: 35.20%.
[ Tue Jun 27 15:29:08 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:29:08 2023 ] Eval epoch: 31
[ Tue Jun 27 15:29:08 2023 ] 	Mean test loss of 625 batches: 1.115374.
[ Tue Jun 27 15:29:08 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:08 2023 ] Training epoch: 32
[ Tue Jun 27 15:29:10 2023 ] 	Training loss: 1.5227.  Training acc: 33.18%.
[ Tue Jun 27 15:29:10 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:29:10 2023 ] Eval epoch: 32
[ Tue Jun 27 15:29:11 2023 ] 	Mean test loss of 625 batches: 1.114258.
[ Tue Jun 27 15:29:11 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:11 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:11 2023 ] Training epoch: 33
[ Tue Jun 27 15:29:14 2023 ] 	Training loss: 1.4486.  Training acc: 35.85%.
[ Tue Jun 27 15:29:14 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:29:14 2023 ] Eval epoch: 33
[ Tue Jun 27 15:29:14 2023 ] 	Mean test loss of 625 batches: 1.113840.
[ Tue Jun 27 15:29:14 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:14 2023 ] Training epoch: 34
[ Tue Jun 27 15:29:17 2023 ] 	Training loss: 1.5009.  Training acc: 31.80%.
[ Tue Jun 27 15:29:17 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:29:17 2023 ] Eval epoch: 34
[ Tue Jun 27 15:29:18 2023 ] 	Mean test loss of 625 batches: 1.111933.
[ Tue Jun 27 15:29:18 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:18 2023 ] Training epoch: 35
[ Tue Jun 27 15:29:21 2023 ] 	Training loss: 1.4637.  Training acc: 34.56%.
[ Tue Jun 27 15:29:21 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:29:21 2023 ] Eval epoch: 35
[ Tue Jun 27 15:29:21 2023 ] 	Mean test loss of 625 batches: 1.109601.
[ Tue Jun 27 15:29:21 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:21 2023 ] Training epoch: 36
[ Tue Jun 27 15:29:24 2023 ] 	Training loss: 1.4596.  Training acc: 36.76%.
[ Tue Jun 27 15:29:24 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:29:24 2023 ] Eval epoch: 36
[ Tue Jun 27 15:29:25 2023 ] 	Mean test loss of 625 batches: 1.109487.
[ Tue Jun 27 15:29:25 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:25 2023 ] Training epoch: 37
[ Tue Jun 27 15:29:28 2023 ] 	Training loss: 1.5105.  Training acc: 34.74%.
[ Tue Jun 27 15:29:28 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:29:28 2023 ] Eval epoch: 37
[ Tue Jun 27 15:29:28 2023 ] 	Mean test loss of 625 batches: 1.108674.
[ Tue Jun 27 15:29:28 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:28 2023 ] Training epoch: 38
[ Tue Jun 27 15:29:31 2023 ] 	Training loss: 1.4386.  Training acc: 33.27%.
[ Tue Jun 27 15:29:31 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:29:31 2023 ] Eval epoch: 38
[ Tue Jun 27 15:29:32 2023 ] 	Mean test loss of 625 batches: 1.107697.
[ Tue Jun 27 15:29:32 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:32 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:32 2023 ] Training epoch: 39
[ Tue Jun 27 15:29:34 2023 ] 	Training loss: 1.4526.  Training acc: 36.31%.
[ Tue Jun 27 15:29:34 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:29:34 2023 ] Eval epoch: 39
[ Tue Jun 27 15:29:35 2023 ] 	Mean test loss of 625 batches: 1.110085.
[ Tue Jun 27 15:29:35 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:35 2023 ] Training epoch: 40
[ Tue Jun 27 15:29:37 2023 ] 	Training loss: 1.5114.  Training acc: 31.34%.
[ Tue Jun 27 15:29:37 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:29:37 2023 ] Eval epoch: 40
[ Tue Jun 27 15:29:38 2023 ] 	Mean test loss of 625 batches: 1.111755.
[ Tue Jun 27 15:29:38 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:29:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:29:38 2023 ] Best accuracy: 0.8947368421052632
[ Tue Jun 27 15:29:38 2023 ] Epoch number: 1
[ Tue Jun 27 15:29:38 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 15:29:38 2023 ] Weight decay: 0.0005
[ Tue Jun 27 15:29:38 2023 ] Base LR: 0.1
[ Tue Jun 27 15:29:38 2023 ] Batch Size: 64
[ Tue Jun 27 15:29:38 2023 ] Test Batch Size: 64
[ Tue Jun 27 15:29:38 2023 ] seed: 1
[ Tue Jun 27 15:29:38 2023 ] Start training Corrector
[ Tue Jun 27 15:32:52 2023 ] using warm up, epoch: 5
[ Tue Jun 27 15:32:52 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 15:32:52 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 15:32:52 2023 ] Start training Predictor
[ Tue Jun 27 15:32:52 2023 ] Training epoch: 1
[ Tue Jun 27 15:32:57 2023 ] 	Training loss: 120.9869.  Training acc: 33.64%.
[ Tue Jun 27 15:32:57 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jun 27 15:32:57 2023 ] Eval epoch: 1
[ Tue Jun 27 15:32:58 2023 ] 	Mean test loss of 625 batches: 1390.947705.
[ Tue Jun 27 15:32:58 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:32:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:32:59 2023 ] Training epoch: 2
[ Tue Jun 27 15:33:01 2023 ] 	Training loss: 9.4288.  Training acc: 34.83%.
[ Tue Jun 27 15:33:01 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:33:01 2023 ] Eval epoch: 2
[ Tue Jun 27 15:33:02 2023 ] 	Mean test loss of 625 batches: 3.136926.
[ Tue Jun 27 15:33:02 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:33:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:02 2023 ] Training epoch: 3
[ Tue Jun 27 15:33:05 2023 ] 	Training loss: 6.4509.  Training acc: 42.19%.
[ Tue Jun 27 15:33:05 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Tue Jun 27 15:33:05 2023 ] Eval epoch: 3
[ Tue Jun 27 15:33:06 2023 ] 	Mean test loss of 625 batches: 3.293919.
[ Tue Jun 27 15:33:06 2023 ] 	Top1: 42.11%
[ Tue Jun 27 15:33:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:06 2023 ] Training epoch: 4
[ Tue Jun 27 15:33:09 2023 ] 	Training loss: 4.7233.  Training acc: 58.82%.
[ Tue Jun 27 15:33:09 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:33:09 2023 ] Eval epoch: 4
[ Tue Jun 27 15:33:09 2023 ] 	Mean test loss of 625 batches: 9.973351.
[ Tue Jun 27 15:33:09 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:33:09 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:09 2023 ] Training epoch: 5
[ Tue Jun 27 15:33:12 2023 ] 	Training loss: 3.0458.  Training acc: 62.68%.
[ Tue Jun 27 15:33:12 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:33:12 2023 ] Eval epoch: 5
[ Tue Jun 27 15:33:13 2023 ] 	Mean test loss of 625 batches: 4.334932.
[ Tue Jun 27 15:33:13 2023 ] 	Top1: 47.37%
[ Tue Jun 27 15:33:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:13 2023 ] Training epoch: 6
[ Tue Jun 27 15:33:16 2023 ] 	Training loss: 1.9889.  Training acc: 64.98%.
[ Tue Jun 27 15:33:16 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:33:16 2023 ] Eval epoch: 6
[ Tue Jun 27 15:33:16 2023 ] 	Mean test loss of 625 batches: 1.269522.
[ Tue Jun 27 15:33:16 2023 ] 	Top1: 59.65%
[ Tue Jun 27 15:33:16 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:16 2023 ] Training epoch: 7
[ Tue Jun 27 15:33:19 2023 ] 	Training loss: 2.5844.  Training acc: 66.73%.
[ Tue Jun 27 15:33:19 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:33:19 2023 ] Eval epoch: 7
[ Tue Jun 27 15:33:20 2023 ] 	Mean test loss of 625 batches: 2.542947.
[ Tue Jun 27 15:33:20 2023 ] 	Top1: 50.88%
[ Tue Jun 27 15:33:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:20 2023 ] Training epoch: 8
[ Tue Jun 27 15:33:23 2023 ] 	Training loss: 1.9711.  Training acc: 60.57%.
[ Tue Jun 27 15:33:23 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:33:23 2023 ] Eval epoch: 8
[ Tue Jun 27 15:33:24 2023 ] 	Mean test loss of 625 batches: 4.978865.
[ Tue Jun 27 15:33:24 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:33:24 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:24 2023 ] Training epoch: 9
[ Tue Jun 27 15:33:26 2023 ] 	Training loss: 0.8832.  Training acc: 78.68%.
[ Tue Jun 27 15:33:26 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:33:26 2023 ] Eval epoch: 9
[ Tue Jun 27 15:33:26 2023 ] 	Mean test loss of 625 batches: 1.236105.
[ Tue Jun 27 15:33:26 2023 ] 	Top1: 66.67%
[ Tue Jun 27 15:33:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:27 2023 ] Training epoch: 10
[ Tue Jun 27 15:33:29 2023 ] 	Training loss: 0.6963.  Training acc: 86.58%.
[ Tue Jun 27 15:33:29 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:33:29 2023 ] Eval epoch: 10
[ Tue Jun 27 15:33:29 2023 ] 	Mean test loss of 625 batches: 1.210415.
[ Tue Jun 27 15:33:29 2023 ] 	Top1: 52.63%
[ Tue Jun 27 15:33:29 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:29 2023 ] Training epoch: 11
[ Tue Jun 27 15:33:31 2023 ] 	Training loss: 0.5243.  Training acc: 92.28%.
[ Tue Jun 27 15:33:31 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 15:33:31 2023 ] Eval epoch: 11
[ Tue Jun 27 15:33:32 2023 ] 	Mean test loss of 625 batches: 0.350639.
[ Tue Jun 27 15:33:32 2023 ] 	Top1: 98.25%
[ Tue Jun 27 15:33:32 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:32 2023 ] Training epoch: 12
[ Tue Jun 27 15:33:34 2023 ] 	Training loss: 0.5149.  Training acc: 93.57%.
[ Tue Jun 27 15:33:34 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:33:34 2023 ] Eval epoch: 12
[ Tue Jun 27 15:33:35 2023 ] 	Mean test loss of 625 batches: 0.472251.
[ Tue Jun 27 15:33:35 2023 ] 	Top1: 92.98%
[ Tue Jun 27 15:33:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:35 2023 ] Training epoch: 13
[ Tue Jun 27 15:33:37 2023 ] 	Training loss: 0.4897.  Training acc: 93.66%.
[ Tue Jun 27 15:33:37 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:33:37 2023 ] Eval epoch: 13
[ Tue Jun 27 15:33:37 2023 ] 	Mean test loss of 625 batches: 0.341094.
[ Tue Jun 27 15:33:37 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:33:37 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:38 2023 ] Training epoch: 14
[ Tue Jun 27 15:33:40 2023 ] 	Training loss: 0.4784.  Training acc: 94.94%.
[ Tue Jun 27 15:33:40 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:33:40 2023 ] Eval epoch: 14
[ Tue Jun 27 15:33:40 2023 ] 	Mean test loss of 625 batches: 0.385148.
[ Tue Jun 27 15:33:40 2023 ] 	Top1: 98.25%
[ Tue Jun 27 15:33:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:40 2023 ] Training epoch: 15
[ Tue Jun 27 15:33:42 2023 ] 	Training loss: 0.4625.  Training acc: 94.85%.
[ Tue Jun 27 15:33:42 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:33:42 2023 ] Eval epoch: 15
[ Tue Jun 27 15:33:43 2023 ] 	Mean test loss of 625 batches: 0.347824.
[ Tue Jun 27 15:33:43 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:33:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:43 2023 ] Training epoch: 16
[ Tue Jun 27 15:33:45 2023 ] 	Training loss: 0.4360.  Training acc: 96.69%.
[ Tue Jun 27 15:33:45 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:33:45 2023 ] Eval epoch: 16
[ Tue Jun 27 15:33:46 2023 ] 	Mean test loss of 625 batches: 0.336632.
[ Tue Jun 27 15:33:46 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:33:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:46 2023 ] Training epoch: 17
[ Tue Jun 27 15:33:48 2023 ] 	Training loss: 0.4336.  Training acc: 97.06%.
[ Tue Jun 27 15:33:48 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:33:48 2023 ] Eval epoch: 17
[ Tue Jun 27 15:33:49 2023 ] 	Mean test loss of 625 batches: 0.331931.
[ Tue Jun 27 15:33:49 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:33:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:49 2023 ] Training epoch: 18
[ Tue Jun 27 15:33:51 2023 ] 	Training loss: 0.4290.  Training acc: 96.88%.
[ Tue Jun 27 15:33:51 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:33:51 2023 ] Eval epoch: 18
[ Tue Jun 27 15:33:51 2023 ] 	Mean test loss of 625 batches: 0.359704.
[ Tue Jun 27 15:33:51 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:33:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:51 2023 ] Training epoch: 19
[ Tue Jun 27 15:33:54 2023 ] 	Training loss: 0.4398.  Training acc: 96.05%.
[ Tue Jun 27 15:33:54 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:33:54 2023 ] Eval epoch: 19
[ Tue Jun 27 15:33:54 2023 ] 	Mean test loss of 625 batches: 0.346523.
[ Tue Jun 27 15:33:54 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:33:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:54 2023 ] Training epoch: 20
[ Tue Jun 27 15:33:57 2023 ] 	Training loss: 0.4071.  Training acc: 97.33%.
[ Tue Jun 27 15:33:57 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:33:57 2023 ] Eval epoch: 20
[ Tue Jun 27 15:33:57 2023 ] 	Mean test loss of 625 batches: 0.352293.
[ Tue Jun 27 15:33:57 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:33:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:33:57 2023 ] Training epoch: 21
[ Tue Jun 27 15:34:00 2023 ] 	Training loss: 0.4217.  Training acc: 97.33%.
[ Tue Jun 27 15:34:00 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:34:00 2023 ] Eval epoch: 21
[ Tue Jun 27 15:34:01 2023 ] 	Mean test loss of 625 batches: 0.336298.
[ Tue Jun 27 15:34:01 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:01 2023 ] Training epoch: 22
[ Tue Jun 27 15:34:04 2023 ] 	Training loss: 0.3995.  Training acc: 98.25%.
[ Tue Jun 27 15:34:04 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:34:04 2023 ] Eval epoch: 22
[ Tue Jun 27 15:34:04 2023 ] 	Mean test loss of 625 batches: 0.330506.
[ Tue Jun 27 15:34:04 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:04 2023 ] Training epoch: 23
[ Tue Jun 27 15:34:07 2023 ] 	Training loss: 0.3964.  Training acc: 97.89%.
[ Tue Jun 27 15:34:07 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:34:07 2023 ] Eval epoch: 23
[ Tue Jun 27 15:34:08 2023 ] 	Mean test loss of 625 batches: 0.327872.
[ Tue Jun 27 15:34:08 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:08 2023 ] Training epoch: 24
[ Tue Jun 27 15:34:11 2023 ] 	Training loss: 0.3868.  Training acc: 98.07%.
[ Tue Jun 27 15:34:11 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:34:11 2023 ] Eval epoch: 24
[ Tue Jun 27 15:34:12 2023 ] 	Mean test loss of 625 batches: 0.320775.
[ Tue Jun 27 15:34:12 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:12 2023 ] Training epoch: 25
[ Tue Jun 27 15:34:15 2023 ] 	Training loss: 0.3887.  Training acc: 98.25%.
[ Tue Jun 27 15:34:15 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Tue Jun 27 15:34:15 2023 ] Eval epoch: 25
[ Tue Jun 27 15:34:15 2023 ] 	Mean test loss of 625 batches: 0.330770.
[ Tue Jun 27 15:34:15 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:15 2023 ] Training epoch: 26
[ Tue Jun 27 15:34:18 2023 ] 	Training loss: 0.3952.  Training acc: 98.25%.
[ Tue Jun 27 15:34:18 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:34:18 2023 ] Eval epoch: 26
[ Tue Jun 27 15:34:19 2023 ] 	Mean test loss of 625 batches: 0.324595.
[ Tue Jun 27 15:34:19 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:19 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:19 2023 ] Training epoch: 27
[ Tue Jun 27 15:34:22 2023 ] 	Training loss: 0.3812.  Training acc: 98.90%.
[ Tue Jun 27 15:34:22 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:34:22 2023 ] Eval epoch: 27
[ Tue Jun 27 15:34:23 2023 ] 	Mean test loss of 625 batches: 0.330817.
[ Tue Jun 27 15:34:23 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:23 2023 ] Training epoch: 28
[ Tue Jun 27 15:34:26 2023 ] 	Training loss: 0.3728.  Training acc: 98.81%.
[ Tue Jun 27 15:34:26 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:34:26 2023 ] Eval epoch: 28
[ Tue Jun 27 15:34:26 2023 ] 	Mean test loss of 625 batches: 0.338107.
[ Tue Jun 27 15:34:26 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:26 2023 ] Training epoch: 29
[ Tue Jun 27 15:34:29 2023 ] 	Training loss: 0.3903.  Training acc: 97.98%.
[ Tue Jun 27 15:34:29 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:34:29 2023 ] Eval epoch: 29
[ Tue Jun 27 15:34:30 2023 ] 	Mean test loss of 625 batches: 0.322479.
[ Tue Jun 27 15:34:30 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:30 2023 ] Training epoch: 30
[ Tue Jun 27 15:34:33 2023 ] 	Training loss: 0.3842.  Training acc: 98.53%.
[ Tue Jun 27 15:34:33 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:34:33 2023 ] Eval epoch: 30
[ Tue Jun 27 15:34:33 2023 ] 	Mean test loss of 625 batches: 0.321793.
[ Tue Jun 27 15:34:33 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:33 2023 ] Training epoch: 31
[ Tue Jun 27 15:34:35 2023 ] 	Training loss: 0.3814.  Training acc: 98.62%.
[ Tue Jun 27 15:34:35 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:34:35 2023 ] Eval epoch: 31
[ Tue Jun 27 15:34:36 2023 ] 	Mean test loss of 625 batches: 0.321546.
[ Tue Jun 27 15:34:36 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:36 2023 ] Training epoch: 32
[ Tue Jun 27 15:34:38 2023 ] 	Training loss: 0.3895.  Training acc: 97.79%.
[ Tue Jun 27 15:34:38 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:34:38 2023 ] Eval epoch: 32
[ Tue Jun 27 15:34:39 2023 ] 	Mean test loss of 625 batches: 0.322512.
[ Tue Jun 27 15:34:39 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:39 2023 ] Training epoch: 33
[ Tue Jun 27 15:34:41 2023 ] 	Training loss: 0.3792.  Training acc: 98.25%.
[ Tue Jun 27 15:34:41 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:34:41 2023 ] Eval epoch: 33
[ Tue Jun 27 15:34:41 2023 ] 	Mean test loss of 625 batches: 0.322015.
[ Tue Jun 27 15:34:41 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:41 2023 ] Training epoch: 34
[ Tue Jun 27 15:34:43 2023 ] 	Training loss: 0.3743.  Training acc: 98.99%.
[ Tue Jun 27 15:34:43 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:34:43 2023 ] Eval epoch: 34
[ Tue Jun 27 15:34:44 2023 ] 	Mean test loss of 625 batches: 0.317930.
[ Tue Jun 27 15:34:44 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:44 2023 ] Training epoch: 35
[ Tue Jun 27 15:34:46 2023 ] 	Training loss: 0.3759.  Training acc: 98.53%.
[ Tue Jun 27 15:34:46 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:34:46 2023 ] Eval epoch: 35
[ Tue Jun 27 15:34:47 2023 ] 	Mean test loss of 625 batches: 0.325969.
[ Tue Jun 27 15:34:47 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:47 2023 ] Training epoch: 36
[ Tue Jun 27 15:34:49 2023 ] 	Training loss: 0.3749.  Training acc: 98.99%.
[ Tue Jun 27 15:34:49 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:34:49 2023 ] Eval epoch: 36
[ Tue Jun 27 15:34:49 2023 ] 	Mean test loss of 625 batches: 0.324596.
[ Tue Jun 27 15:34:49 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:49 2023 ] Training epoch: 37
[ Tue Jun 27 15:34:51 2023 ] 	Training loss: 0.3773.  Training acc: 98.53%.
[ Tue Jun 27 15:34:51 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:34:51 2023 ] Eval epoch: 37
[ Tue Jun 27 15:34:52 2023 ] 	Mean test loss of 625 batches: 0.317361.
[ Tue Jun 27 15:34:52 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:52 2023 ] Training epoch: 38
[ Tue Jun 27 15:34:54 2023 ] 	Training loss: 0.3673.  Training acc: 99.26%.
[ Tue Jun 27 15:34:54 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:34:54 2023 ] Eval epoch: 38
[ Tue Jun 27 15:34:55 2023 ] 	Mean test loss of 625 batches: 0.317691.
[ Tue Jun 27 15:34:55 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:55 2023 ] Training epoch: 39
[ Tue Jun 27 15:34:57 2023 ] 	Training loss: 0.3723.  Training acc: 98.99%.
[ Tue Jun 27 15:34:57 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:34:57 2023 ] Eval epoch: 39
[ Tue Jun 27 15:34:57 2023 ] 	Mean test loss of 625 batches: 0.329618.
[ Tue Jun 27 15:34:57 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:34:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:34:57 2023 ] Training epoch: 40
[ Tue Jun 27 15:35:00 2023 ] 	Training loss: 0.3882.  Training acc: 98.53%.
[ Tue Jun 27 15:35:00 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:35:00 2023 ] Eval epoch: 40
[ Tue Jun 27 15:35:00 2023 ] 	Mean test loss of 625 batches: 0.324395.
[ Tue Jun 27 15:35:00 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:35:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:01 2023 ] Best accuracy: 1.0
[ Tue Jun 27 15:35:01 2023 ] Epoch number: 13
[ Tue Jun 27 15:35:01 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 15:35:01 2023 ] Weight decay: 0.0005
[ Tue Jun 27 15:35:01 2023 ] Base LR: 0.1
[ Tue Jun 27 15:35:01 2023 ] Batch Size: 64
[ Tue Jun 27 15:35:01 2023 ] Test Batch Size: 64
[ Tue Jun 27 15:35:01 2023 ] seed: 1
[ Tue Jun 27 15:35:01 2023 ] Start training Corrector
[ Tue Jun 27 15:35:23 2023 ] using warm up, epoch: 5
[ Tue Jun 27 15:35:24 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 15:35:24 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 15:35:24 2023 ] Start training Predictor
[ Tue Jun 27 15:35:24 2023 ] Training epoch: 1
[ Tue Jun 27 15:35:29 2023 ] 	Training loss: 111.4898.  Training acc: 35.11%.
[ Tue Jun 27 15:35:29 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jun 27 15:35:29 2023 ] Eval epoch: 1
[ Tue Jun 27 15:35:30 2023 ] 	Mean test loss of 625 batches: 2750.861719.
[ Tue Jun 27 15:35:30 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:35:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:30 2023 ] Training epoch: 2
[ Tue Jun 27 15:35:33 2023 ] 	Training loss: 14.7206.  Training acc: 33.64%.
[ Tue Jun 27 15:35:33 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Tue Jun 27 15:35:33 2023 ] Eval epoch: 2
[ Tue Jun 27 15:35:34 2023 ] 	Mean test loss of 625 batches: 13.499561.
[ Tue Jun 27 15:35:34 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:35:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:34 2023 ] Training epoch: 3
[ Tue Jun 27 15:35:37 2023 ] 	Training loss: 7.3236.  Training acc: 32.81%.
[ Tue Jun 27 15:35:37 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:35:37 2023 ] Eval epoch: 3
[ Tue Jun 27 15:35:38 2023 ] 	Mean test loss of 625 batches: 2.326755.
[ Tue Jun 27 15:35:38 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:35:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:38 2023 ] Training epoch: 4
[ Tue Jun 27 15:35:41 2023 ] 	Training loss: 6.0117.  Training acc: 31.43%.
[ Tue Jun 27 15:35:41 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:35:41 2023 ] Eval epoch: 4
[ Tue Jun 27 15:35:41 2023 ] 	Mean test loss of 625 batches: 1.602655.
[ Tue Jun 27 15:35:41 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:35:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:41 2023 ] Training epoch: 5
[ Tue Jun 27 15:35:43 2023 ] 	Training loss: 4.7531.  Training acc: 36.03%.
[ Tue Jun 27 15:35:43 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:35:43 2023 ] Eval epoch: 5
[ Tue Jun 27 15:35:44 2023 ] 	Mean test loss of 625 batches: 1.230711.
[ Tue Jun 27 15:35:44 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:35:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:44 2023 ] Training epoch: 6
[ Tue Jun 27 15:35:46 2023 ] 	Training loss: 11.3076.  Training acc: 36.58%.
[ Tue Jun 27 15:35:46 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:35:46 2023 ] Eval epoch: 6
[ Tue Jun 27 15:35:47 2023 ] 	Mean test loss of 625 batches: 1.158163.
[ Tue Jun 27 15:35:47 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:35:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:47 2023 ] Training epoch: 7
[ Tue Jun 27 15:35:49 2023 ] 	Training loss: 2.9209.  Training acc: 34.28%.
[ Tue Jun 27 15:35:49 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:35:49 2023 ] Eval epoch: 7
[ Tue Jun 27 15:35:49 2023 ] 	Mean test loss of 625 batches: 1.209037.
[ Tue Jun 27 15:35:49 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:35:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:49 2023 ] Training epoch: 8
[ Tue Jun 27 15:35:51 2023 ] 	Training loss: 2.5811.  Training acc: 31.53%.
[ Tue Jun 27 15:35:51 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:35:51 2023 ] Eval epoch: 8
[ Tue Jun 27 15:35:52 2023 ] 	Mean test loss of 625 batches: 1.139563.
[ Tue Jun 27 15:35:52 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:35:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:52 2023 ] Training epoch: 9
[ Tue Jun 27 15:35:54 2023 ] 	Training loss: 2.0023.  Training acc: 34.56%.
[ Tue Jun 27 15:35:54 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:35:54 2023 ] Eval epoch: 9
[ Tue Jun 27 15:35:54 2023 ] 	Mean test loss of 625 batches: 1.136637.
[ Tue Jun 27 15:35:54 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:35:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:54 2023 ] Training epoch: 10
[ Tue Jun 27 15:35:57 2023 ] 	Training loss: 1.8511.  Training acc: 33.36%.
[ Tue Jun 27 15:35:57 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:35:57 2023 ] Eval epoch: 10
[ Tue Jun 27 15:35:57 2023 ] 	Mean test loss of 625 batches: 1.131136.
[ Tue Jun 27 15:35:57 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:35:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:35:57 2023 ] Training epoch: 11
[ Tue Jun 27 15:35:59 2023 ] 	Training loss: 1.5894.  Training acc: 33.00%.
[ Tue Jun 27 15:35:59 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:35:59 2023 ] Eval epoch: 11
[ Tue Jun 27 15:36:00 2023 ] 	Mean test loss of 625 batches: 1.124687.
[ Tue Jun 27 15:36:00 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:00 2023 ] Training epoch: 12
[ Tue Jun 27 15:36:02 2023 ] 	Training loss: 1.5803.  Training acc: 35.20%.
[ Tue Jun 27 15:36:02 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:36:02 2023 ] Eval epoch: 12
[ Tue Jun 27 15:36:02 2023 ] 	Mean test loss of 625 batches: 1.137854.
[ Tue Jun 27 15:36:02 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:02 2023 ] Training epoch: 13
[ Tue Jun 27 15:36:05 2023 ] 	Training loss: 1.4989.  Training acc: 36.40%.
[ Tue Jun 27 15:36:05 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:36:05 2023 ] Eval epoch: 13
[ Tue Jun 27 15:36:05 2023 ] 	Mean test loss of 625 batches: 1.123769.
[ Tue Jun 27 15:36:05 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:05 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:05 2023 ] Training epoch: 14
[ Tue Jun 27 15:36:07 2023 ] 	Training loss: 1.5734.  Training acc: 33.55%.
[ Tue Jun 27 15:36:07 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:36:07 2023 ] Eval epoch: 14
[ Tue Jun 27 15:36:08 2023 ] 	Mean test loss of 625 batches: 1.124134.
[ Tue Jun 27 15:36:08 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:08 2023 ] Training epoch: 15
[ Tue Jun 27 15:36:10 2023 ] 	Training loss: 1.5219.  Training acc: 35.02%.
[ Tue Jun 27 15:36:10 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:36:10 2023 ] Eval epoch: 15
[ Tue Jun 27 15:36:11 2023 ] 	Mean test loss of 625 batches: 1.129952.
[ Tue Jun 27 15:36:11 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:11 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:11 2023 ] Training epoch: 16
[ Tue Jun 27 15:36:13 2023 ] 	Training loss: 1.4757.  Training acc: 35.85%.
[ Tue Jun 27 15:36:13 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:36:13 2023 ] Eval epoch: 16
[ Tue Jun 27 15:36:14 2023 ] 	Mean test loss of 625 batches: 1.126239.
[ Tue Jun 27 15:36:14 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:14 2023 ] Training epoch: 17
[ Tue Jun 27 15:36:17 2023 ] 	Training loss: 1.4645.  Training acc: 35.85%.
[ Tue Jun 27 15:36:17 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:36:17 2023 ] Eval epoch: 17
[ Tue Jun 27 15:36:17 2023 ] 	Mean test loss of 625 batches: 1.120181.
[ Tue Jun 27 15:36:17 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:17 2023 ] Training epoch: 18
[ Tue Jun 27 15:36:21 2023 ] 	Training loss: 1.4411.  Training acc: 34.10%.
[ Tue Jun 27 15:36:21 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:36:21 2023 ] Eval epoch: 18
[ Tue Jun 27 15:36:21 2023 ] 	Mean test loss of 625 batches: 1.110955.
[ Tue Jun 27 15:36:21 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:21 2023 ] Training epoch: 19
[ Tue Jun 27 15:36:24 2023 ] 	Training loss: 1.4296.  Training acc: 34.28%.
[ Tue Jun 27 15:36:24 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:36:24 2023 ] Eval epoch: 19
[ Tue Jun 27 15:36:25 2023 ] 	Mean test loss of 625 batches: 1.123562.
[ Tue Jun 27 15:36:25 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:25 2023 ] Training epoch: 20
[ Tue Jun 27 15:36:28 2023 ] 	Training loss: 1.3761.  Training acc: 36.03%.
[ Tue Jun 27 15:36:28 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:36:28 2023 ] Eval epoch: 20
[ Tue Jun 27 15:36:29 2023 ] 	Mean test loss of 625 batches: 1.121184.
[ Tue Jun 27 15:36:29 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:29 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:29 2023 ] Training epoch: 21
[ Tue Jun 27 15:36:32 2023 ] 	Training loss: 1.3770.  Training acc: 36.31%.
[ Tue Jun 27 15:36:32 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:36:32 2023 ] Eval epoch: 21
[ Tue Jun 27 15:36:33 2023 ] 	Mean test loss of 625 batches: 1.120068.
[ Tue Jun 27 15:36:33 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:33 2023 ] Training epoch: 22
[ Tue Jun 27 15:36:35 2023 ] 	Training loss: 1.3568.  Training acc: 36.95%.
[ Tue Jun 27 15:36:36 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 27 15:36:36 2023 ] Eval epoch: 22
[ Tue Jun 27 15:36:36 2023 ] 	Mean test loss of 625 batches: 1.119528.
[ Tue Jun 27 15:36:36 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:36 2023 ] Training epoch: 23
[ Tue Jun 27 15:36:39 2023 ] 	Training loss: 1.3509.  Training acc: 35.57%.
[ Tue Jun 27 15:36:39 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:36:39 2023 ] Eval epoch: 23
[ Tue Jun 27 15:36:40 2023 ] 	Mean test loss of 625 batches: 1.117841.
[ Tue Jun 27 15:36:40 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:40 2023 ] Training epoch: 24
[ Tue Jun 27 15:36:43 2023 ] 	Training loss: 1.3629.  Training acc: 34.10%.
[ Tue Jun 27 15:36:43 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:36:43 2023 ] Eval epoch: 24
[ Tue Jun 27 15:36:43 2023 ] 	Mean test loss of 625 batches: 1.117514.
[ Tue Jun 27 15:36:43 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:43 2023 ] Training epoch: 25
[ Tue Jun 27 15:36:46 2023 ] 	Training loss: 1.3940.  Training acc: 33.64%.
[ Tue Jun 27 15:36:46 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:36:46 2023 ] Eval epoch: 25
[ Tue Jun 27 15:36:47 2023 ] 	Mean test loss of 625 batches: 1.118492.
[ Tue Jun 27 15:36:47 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:47 2023 ] Training epoch: 26
[ Tue Jun 27 15:36:50 2023 ] 	Training loss: 1.3589.  Training acc: 35.57%.
[ Tue Jun 27 15:36:50 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:36:50 2023 ] Eval epoch: 26
[ Tue Jun 27 15:36:51 2023 ] 	Mean test loss of 625 batches: 1.117366.
[ Tue Jun 27 15:36:51 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:51 2023 ] Training epoch: 27
[ Tue Jun 27 15:36:54 2023 ] 	Training loss: 1.4210.  Training acc: 34.01%.
[ Tue Jun 27 15:36:54 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:36:54 2023 ] Eval epoch: 27
[ Tue Jun 27 15:36:55 2023 ] 	Mean test loss of 625 batches: 1.116429.
[ Tue Jun 27 15:36:55 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:55 2023 ] Training epoch: 28
[ Tue Jun 27 15:36:57 2023 ] 	Training loss: 1.3539.  Training acc: 35.85%.
[ Tue Jun 27 15:36:57 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:36:57 2023 ] Eval epoch: 28
[ Tue Jun 27 15:36:57 2023 ] 	Mean test loss of 625 batches: 1.116981.
[ Tue Jun 27 15:36:57 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:36:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:36:57 2023 ] Training epoch: 29
[ Tue Jun 27 15:36:59 2023 ] 	Training loss: 1.3808.  Training acc: 34.93%.
[ Tue Jun 27 15:36:59 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:36:59 2023 ] Eval epoch: 29
[ Tue Jun 27 15:37:00 2023 ] 	Mean test loss of 625 batches: 1.116420.
[ Tue Jun 27 15:37:00 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:00 2023 ] Training epoch: 30
[ Tue Jun 27 15:37:02 2023 ] 	Training loss: 1.3423.  Training acc: 34.83%.
[ Tue Jun 27 15:37:02 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:37:02 2023 ] Eval epoch: 30
[ Tue Jun 27 15:37:03 2023 ] 	Mean test loss of 625 batches: 1.117775.
[ Tue Jun 27 15:37:03 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:03 2023 ] Training epoch: 31
[ Tue Jun 27 15:37:05 2023 ] 	Training loss: 1.3623.  Training acc: 36.03%.
[ Tue Jun 27 15:37:05 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:37:05 2023 ] Eval epoch: 31
[ Tue Jun 27 15:37:06 2023 ] 	Mean test loss of 625 batches: 1.116782.
[ Tue Jun 27 15:37:06 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:06 2023 ] Training epoch: 32
[ Tue Jun 27 15:37:08 2023 ] 	Training loss: 1.3748.  Training acc: 33.92%.
[ Tue Jun 27 15:37:08 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:37:08 2023 ] Eval epoch: 32
[ Tue Jun 27 15:37:08 2023 ] 	Mean test loss of 625 batches: 1.116391.
[ Tue Jun 27 15:37:08 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:08 2023 ] Training epoch: 33
[ Tue Jun 27 15:37:11 2023 ] 	Training loss: 1.3158.  Training acc: 35.94%.
[ Tue Jun 27 15:37:11 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:37:11 2023 ] Eval epoch: 33
[ Tue Jun 27 15:37:11 2023 ] 	Mean test loss of 625 batches: 1.116415.
[ Tue Jun 27 15:37:11 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:11 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:11 2023 ] Training epoch: 34
[ Tue Jun 27 15:37:14 2023 ] 	Training loss: 1.3511.  Training acc: 32.44%.
[ Tue Jun 27 15:37:14 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:37:14 2023 ] Eval epoch: 34
[ Tue Jun 27 15:37:14 2023 ] 	Mean test loss of 625 batches: 1.115599.
[ Tue Jun 27 15:37:14 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:14 2023 ] Training epoch: 35
[ Tue Jun 27 15:37:16 2023 ] 	Training loss: 1.3449.  Training acc: 33.82%.
[ Tue Jun 27 15:37:16 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:37:16 2023 ] Eval epoch: 35
[ Tue Jun 27 15:37:17 2023 ] 	Mean test loss of 625 batches: 1.113563.
[ Tue Jun 27 15:37:17 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:17 2023 ] Training epoch: 36
[ Tue Jun 27 15:37:19 2023 ] 	Training loss: 1.3376.  Training acc: 34.93%.
[ Tue Jun 27 15:37:19 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 15:37:19 2023 ] Eval epoch: 36
[ Tue Jun 27 15:37:20 2023 ] 	Mean test loss of 625 batches: 1.113789.
[ Tue Jun 27 15:37:20 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:20 2023 ] Training epoch: 37
[ Tue Jun 27 15:37:22 2023 ] 	Training loss: 1.3684.  Training acc: 33.82%.
[ Tue Jun 27 15:37:22 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:37:22 2023 ] Eval epoch: 37
[ Tue Jun 27 15:37:22 2023 ] 	Mean test loss of 625 batches: 1.113474.
[ Tue Jun 27 15:37:22 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:22 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:22 2023 ] Training epoch: 38
[ Tue Jun 27 15:37:24 2023 ] 	Training loss: 1.3210.  Training acc: 33.09%.
[ Tue Jun 27 15:37:24 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:37:24 2023 ] Eval epoch: 38
[ Tue Jun 27 15:37:25 2023 ] 	Mean test loss of 625 batches: 1.112978.
[ Tue Jun 27 15:37:25 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:25 2023 ] Training epoch: 39
[ Tue Jun 27 15:37:27 2023 ] 	Training loss: 1.3443.  Training acc: 34.10%.
[ Tue Jun 27 15:37:27 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:37:27 2023 ] Eval epoch: 39
[ Tue Jun 27 15:37:28 2023 ] 	Mean test loss of 625 batches: 1.113991.
[ Tue Jun 27 15:37:28 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:28 2023 ] Training epoch: 40
[ Tue Jun 27 15:37:31 2023 ] 	Training loss: 1.3779.  Training acc: 32.90%.
[ Tue Jun 27 15:37:31 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:37:31 2023 ] Eval epoch: 40
[ Tue Jun 27 15:37:31 2023 ] 	Mean test loss of 625 batches: 1.114445.
[ Tue Jun 27 15:37:31 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:37:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:37:32 2023 ] Best accuracy: 0.8947368421052632
[ Tue Jun 27 15:37:32 2023 ] Epoch number: 1
[ Tue Jun 27 15:37:32 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 15:37:32 2023 ] Weight decay: 0.0005
[ Tue Jun 27 15:37:32 2023 ] Base LR: 0.1
[ Tue Jun 27 15:37:32 2023 ] Batch Size: 64
[ Tue Jun 27 15:37:32 2023 ] Test Batch Size: 64
[ Tue Jun 27 15:37:32 2023 ] seed: 1
[ Tue Jun 27 15:37:32 2023 ] Start training Corrector
[ Tue Jun 27 15:40:34 2023 ] using warm up, epoch: 5
[ Tue Jun 27 15:40:34 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 15:40:34 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 15:40:34 2023 ] Start training Predictor
[ Tue Jun 27 15:40:34 2023 ] Training epoch: 1
[ Tue Jun 27 15:40:40 2023 ] 	Training loss: 119.9766.  Training acc: 35.85%.
[ Tue Jun 27 15:40:40 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Jun 27 15:40:40 2023 ] Eval epoch: 1
[ Tue Jun 27 15:40:41 2023 ] 	Mean test loss of 625 batches: 4772.667285.
[ Tue Jun 27 15:40:41 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:40:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:40:41 2023 ] Training epoch: 2
[ Tue Jun 27 15:40:43 2023 ] 	Training loss: 13.6168.  Training acc: 35.66%.
[ Tue Jun 27 15:40:43 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:40:43 2023 ] Eval epoch: 2
[ Tue Jun 27 15:40:44 2023 ] 	Mean test loss of 625 batches: 2.709926.
[ Tue Jun 27 15:40:44 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:40:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:40:44 2023 ] Training epoch: 3
[ Tue Jun 27 15:40:46 2023 ] 	Training loss: 7.7428.  Training acc: 35.48%.
[ Tue Jun 27 15:40:46 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:40:46 2023 ] Eval epoch: 3
[ Tue Jun 27 15:40:46 2023 ] 	Mean test loss of 625 batches: 3.361574.
[ Tue Jun 27 15:40:46 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:40:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:40:46 2023 ] Training epoch: 4
[ Tue Jun 27 15:40:48 2023 ] 	Training loss: 5.9871.  Training acc: 38.97%.
[ Tue Jun 27 15:40:48 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:40:48 2023 ] Eval epoch: 4
[ Tue Jun 27 15:40:49 2023 ] 	Mean test loss of 625 batches: 3.582383.
[ Tue Jun 27 15:40:49 2023 ] 	Top1: 42.11%
[ Tue Jun 27 15:40:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:40:49 2023 ] Training epoch: 5
[ Tue Jun 27 15:40:51 2023 ] 	Training loss: 3.8521.  Training acc: 53.58%.
[ Tue Jun 27 15:40:51 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:40:51 2023 ] Eval epoch: 5
[ Tue Jun 27 15:40:52 2023 ] 	Mean test loss of 625 batches: 1.599099.
[ Tue Jun 27 15:40:52 2023 ] 	Top1: 70.18%
[ Tue Jun 27 15:40:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:40:52 2023 ] Training epoch: 6
[ Tue Jun 27 15:40:54 2023 ] 	Training loss: 2.5759.  Training acc: 62.41%.
[ Tue Jun 27 15:40:54 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:40:54 2023 ] Eval epoch: 6
[ Tue Jun 27 15:40:54 2023 ] 	Mean test loss of 625 batches: 2.743328.
[ Tue Jun 27 15:40:54 2023 ] 	Top1: 71.93%
[ Tue Jun 27 15:40:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:40:54 2023 ] Training epoch: 7
[ Tue Jun 27 15:40:56 2023 ] 	Training loss: 1.6137.  Training acc: 67.00%.
[ Tue Jun 27 15:40:56 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:40:56 2023 ] Eval epoch: 7
[ Tue Jun 27 15:40:57 2023 ] 	Mean test loss of 625 batches: 1.059413.
[ Tue Jun 27 15:40:57 2023 ] 	Top1: 66.67%
[ Tue Jun 27 15:40:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:40:57 2023 ] Training epoch: 8
[ Tue Jun 27 15:40:59 2023 ] 	Training loss: 1.5003.  Training acc: 68.11%.
[ Tue Jun 27 15:40:59 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:40:59 2023 ] Eval epoch: 8
[ Tue Jun 27 15:41:00 2023 ] 	Mean test loss of 625 batches: 1.690240.
[ Tue Jun 27 15:41:00 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:41:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:00 2023 ] Training epoch: 9
[ Tue Jun 27 15:41:02 2023 ] 	Training loss: 1.1643.  Training acc: 72.98%.
[ Tue Jun 27 15:41:02 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:41:02 2023 ] Eval epoch: 9
[ Tue Jun 27 15:41:02 2023 ] 	Mean test loss of 625 batches: 1.074190.
[ Tue Jun 27 15:41:02 2023 ] 	Top1: 68.42%
[ Tue Jun 27 15:41:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:02 2023 ] Training epoch: 10
[ Tue Jun 27 15:41:04 2023 ] 	Training loss: 1.1496.  Training acc: 71.60%.
[ Tue Jun 27 15:41:04 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:41:04 2023 ] Eval epoch: 10
[ Tue Jun 27 15:41:05 2023 ] 	Mean test loss of 625 batches: 0.631627.
[ Tue Jun 27 15:41:05 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:41:05 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:05 2023 ] Training epoch: 11
[ Tue Jun 27 15:41:07 2023 ] 	Training loss: 0.8037.  Training acc: 83.92%.
[ Tue Jun 27 15:41:07 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 27 15:41:07 2023 ] Eval epoch: 11
[ Tue Jun 27 15:41:08 2023 ] 	Mean test loss of 625 batches: 0.573199.
[ Tue Jun 27 15:41:08 2023 ] 	Top1: 96.49%
[ Tue Jun 27 15:41:08 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:08 2023 ] Training epoch: 12
[ Tue Jun 27 15:41:10 2023 ] 	Training loss: 0.7512.  Training acc: 88.14%.
[ Tue Jun 27 15:41:10 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:41:10 2023 ] Eval epoch: 12
[ Tue Jun 27 15:41:10 2023 ] 	Mean test loss of 625 batches: 0.518665.
[ Tue Jun 27 15:41:10 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:10 2023 ] Training epoch: 13
[ Tue Jun 27 15:41:12 2023 ] 	Training loss: 0.7039.  Training acc: 89.71%.
[ Tue Jun 27 15:41:12 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:41:12 2023 ] Eval epoch: 13
[ Tue Jun 27 15:41:13 2023 ] 	Mean test loss of 625 batches: 0.545137.
[ Tue Jun 27 15:41:13 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:13 2023 ] Training epoch: 14
[ Tue Jun 27 15:41:16 2023 ] 	Training loss: 0.6731.  Training acc: 91.91%.
[ Tue Jun 27 15:41:16 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:41:16 2023 ] Eval epoch: 14
[ Tue Jun 27 15:41:17 2023 ] 	Mean test loss of 625 batches: 0.535256.
[ Tue Jun 27 15:41:17 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:17 2023 ] Training epoch: 15
[ Tue Jun 27 15:41:20 2023 ] 	Training loss: 0.6499.  Training acc: 93.29%.
[ Tue Jun 27 15:41:20 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:41:20 2023 ] Eval epoch: 15
[ Tue Jun 27 15:41:20 2023 ] 	Mean test loss of 625 batches: 0.496499.
[ Tue Jun 27 15:41:20 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:20 2023 ] Training epoch: 16
[ Tue Jun 27 15:41:23 2023 ] 	Training loss: 0.6150.  Training acc: 94.12%.
[ Tue Jun 27 15:41:23 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:41:23 2023 ] Eval epoch: 16
[ Tue Jun 27 15:41:24 2023 ] 	Mean test loss of 625 batches: 0.493946.
[ Tue Jun 27 15:41:24 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:24 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:24 2023 ] Training epoch: 17
[ Tue Jun 27 15:41:27 2023 ] 	Training loss: 0.5716.  Training acc: 95.96%.
[ Tue Jun 27 15:41:27 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:41:27 2023 ] Eval epoch: 17
[ Tue Jun 27 15:41:27 2023 ] 	Mean test loss of 625 batches: 0.470622.
[ Tue Jun 27 15:41:27 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:27 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:27 2023 ] Training epoch: 18
[ Tue Jun 27 15:41:30 2023 ] 	Training loss: 0.5525.  Training acc: 95.68%.
[ Tue Jun 27 15:41:30 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:41:30 2023 ] Eval epoch: 18
[ Tue Jun 27 15:41:31 2023 ] 	Mean test loss of 625 batches: 0.470889.
[ Tue Jun 27 15:41:31 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:31 2023 ] Training epoch: 19
[ Tue Jun 27 15:41:34 2023 ] 	Training loss: 0.5949.  Training acc: 93.93%.
[ Tue Jun 27 15:41:34 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:41:34 2023 ] Eval epoch: 19
[ Tue Jun 27 15:41:35 2023 ] 	Mean test loss of 625 batches: 0.442410.
[ Tue Jun 27 15:41:35 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:35 2023 ] Training epoch: 20
[ Tue Jun 27 15:41:38 2023 ] 	Training loss: 0.5414.  Training acc: 96.05%.
[ Tue Jun 27 15:41:38 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:41:38 2023 ] Eval epoch: 20
[ Tue Jun 27 15:41:38 2023 ] 	Mean test loss of 625 batches: 0.443621.
[ Tue Jun 27 15:41:38 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:38 2023 ] Training epoch: 21
[ Tue Jun 27 15:41:41 2023 ] 	Training loss: 0.5152.  Training acc: 97.33%.
[ Tue Jun 27 15:41:41 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:41:41 2023 ] Eval epoch: 21
[ Tue Jun 27 15:41:42 2023 ] 	Mean test loss of 625 batches: 0.450562.
[ Tue Jun 27 15:41:42 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:42 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:42 2023 ] Training epoch: 22
[ Tue Jun 27 15:41:45 2023 ] 	Training loss: 0.5126.  Training acc: 97.06%.
[ Tue Jun 27 15:41:45 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Tue Jun 27 15:41:45 2023 ] Eval epoch: 22
[ Tue Jun 27 15:41:46 2023 ] 	Mean test loss of 625 batches: 0.447566.
[ Tue Jun 27 15:41:46 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:46 2023 ] Training epoch: 23
[ Tue Jun 27 15:41:49 2023 ] 	Training loss: 0.5146.  Training acc: 97.43%.
[ Tue Jun 27 15:41:49 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:41:49 2023 ] Eval epoch: 23
[ Tue Jun 27 15:41:49 2023 ] 	Mean test loss of 625 batches: 0.445504.
[ Tue Jun 27 15:41:49 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:49 2023 ] Training epoch: 24
[ Tue Jun 27 15:41:52 2023 ] 	Training loss: 0.5081.  Training acc: 96.97%.
[ Tue Jun 27 15:41:52 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:41:52 2023 ] Eval epoch: 24
[ Tue Jun 27 15:41:53 2023 ] 	Mean test loss of 625 batches: 0.443282.
[ Tue Jun 27 15:41:53 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:53 2023 ] Training epoch: 25
[ Tue Jun 27 15:41:56 2023 ] 	Training loss: 0.5172.  Training acc: 95.86%.
[ Tue Jun 27 15:41:56 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:41:56 2023 ] Eval epoch: 25
[ Tue Jun 27 15:41:57 2023 ] 	Mean test loss of 625 batches: 0.445308.
[ Tue Jun 27 15:41:57 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:41:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:41:57 2023 ] Training epoch: 26
[ Tue Jun 27 15:42:00 2023 ] 	Training loss: 0.5198.  Training acc: 96.88%.
[ Tue Jun 27 15:42:00 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:42:00 2023 ] Eval epoch: 26
[ Tue Jun 27 15:42:00 2023 ] 	Mean test loss of 625 batches: 0.439695.
[ Tue Jun 27 15:42:00 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:00 2023 ] Training epoch: 27
[ Tue Jun 27 15:42:03 2023 ] 	Training loss: 0.5107.  Training acc: 96.97%.
[ Tue Jun 27 15:42:03 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:42:03 2023 ] Eval epoch: 27
[ Tue Jun 27 15:42:04 2023 ] 	Mean test loss of 625 batches: 0.441367.
[ Tue Jun 27 15:42:04 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:04 2023 ] Training epoch: 28
[ Tue Jun 27 15:42:06 2023 ] 	Training loss: 0.5082.  Training acc: 96.97%.
[ Tue Jun 27 15:42:06 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:42:06 2023 ] Eval epoch: 28
[ Tue Jun 27 15:42:07 2023 ] 	Mean test loss of 625 batches: 0.440755.
[ Tue Jun 27 15:42:07 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:07 2023 ] Training epoch: 29
[ Tue Jun 27 15:42:09 2023 ] 	Training loss: 0.5244.  Training acc: 95.96%.
[ Tue Jun 27 15:42:09 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:42:09 2023 ] Eval epoch: 29
[ Tue Jun 27 15:42:09 2023 ] 	Mean test loss of 625 batches: 0.434891.
[ Tue Jun 27 15:42:09 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:09 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:09 2023 ] Training epoch: 30
[ Tue Jun 27 15:42:11 2023 ] 	Training loss: 0.5043.  Training acc: 96.32%.
[ Tue Jun 27 15:42:11 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:42:11 2023 ] Eval epoch: 30
[ Tue Jun 27 15:42:12 2023 ] 	Mean test loss of 625 batches: 0.432892.
[ Tue Jun 27 15:42:12 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:12 2023 ] Training epoch: 31
[ Tue Jun 27 15:42:14 2023 ] 	Training loss: 0.5167.  Training acc: 96.32%.
[ Tue Jun 27 15:42:14 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:42:14 2023 ] Eval epoch: 31
[ Tue Jun 27 15:42:15 2023 ] 	Mean test loss of 625 batches: 0.430335.
[ Tue Jun 27 15:42:15 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:15 2023 ] Training epoch: 32
[ Tue Jun 27 15:42:17 2023 ] 	Training loss: 0.5108.  Training acc: 96.51%.
[ Tue Jun 27 15:42:17 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:42:17 2023 ] Eval epoch: 32
[ Tue Jun 27 15:42:17 2023 ] 	Mean test loss of 625 batches: 0.431867.
[ Tue Jun 27 15:42:17 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:17 2023 ] Training epoch: 33
[ Tue Jun 27 15:42:19 2023 ] 	Training loss: 0.4703.  Training acc: 98.16%.
[ Tue Jun 27 15:42:19 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:42:19 2023 ] Eval epoch: 33
[ Tue Jun 27 15:42:20 2023 ] 	Mean test loss of 625 batches: 0.420174.
[ Tue Jun 27 15:42:20 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:20 2023 ] Training epoch: 34
[ Tue Jun 27 15:42:22 2023 ] 	Training loss: 0.4762.  Training acc: 96.78%.
[ Tue Jun 27 15:42:22 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:42:22 2023 ] Eval epoch: 34
[ Tue Jun 27 15:42:23 2023 ] 	Mean test loss of 625 batches: 0.411865.
[ Tue Jun 27 15:42:23 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:23 2023 ] Training epoch: 35
[ Tue Jun 27 15:42:25 2023 ] 	Training loss: 0.4820.  Training acc: 97.24%.
[ Tue Jun 27 15:42:25 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:42:25 2023 ] Eval epoch: 35
[ Tue Jun 27 15:42:25 2023 ] 	Mean test loss of 625 batches: 0.421268.
[ Tue Jun 27 15:42:25 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:25 2023 ] Training epoch: 36
[ Tue Jun 27 15:42:27 2023 ] 	Training loss: 0.4824.  Training acc: 97.33%.
[ Tue Jun 27 15:42:27 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:42:27 2023 ] Eval epoch: 36
[ Tue Jun 27 15:42:28 2023 ] 	Mean test loss of 625 batches: 0.399181.
[ Tue Jun 27 15:42:28 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:28 2023 ] Training epoch: 37
[ Tue Jun 27 15:42:30 2023 ] 	Training loss: 0.4750.  Training acc: 97.61%.
[ Tue Jun 27 15:42:30 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:42:30 2023 ] Eval epoch: 37
[ Tue Jun 27 15:42:31 2023 ] 	Mean test loss of 625 batches: 0.388643.
[ Tue Jun 27 15:42:31 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:31 2023 ] Training epoch: 38
[ Tue Jun 27 15:42:33 2023 ] 	Training loss: 0.4617.  Training acc: 97.52%.
[ Tue Jun 27 15:42:33 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:42:33 2023 ] Eval epoch: 38
[ Tue Jun 27 15:42:34 2023 ] 	Mean test loss of 625 batches: 0.388838.
[ Tue Jun 27 15:42:34 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:34 2023 ] Training epoch: 39
[ Tue Jun 27 15:42:36 2023 ] 	Training loss: 0.4681.  Training acc: 97.33%.
[ Tue Jun 27 15:42:36 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:42:36 2023 ] Eval epoch: 39
[ Tue Jun 27 15:42:37 2023 ] 	Mean test loss of 625 batches: 0.370915.
[ Tue Jun 27 15:42:37 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:37 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:37 2023 ] Training epoch: 40
[ Tue Jun 27 15:42:40 2023 ] 	Training loss: 0.4723.  Training acc: 97.06%.
[ Tue Jun 27 15:42:40 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:42:40 2023 ] Eval epoch: 40
[ Tue Jun 27 15:42:41 2023 ] 	Mean test loss of 625 batches: 0.353063.
[ Tue Jun 27 15:42:41 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:42:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:42:41 2023 ] Best accuracy: 1.0
[ Tue Jun 27 15:42:41 2023 ] Epoch number: 12
[ Tue Jun 27 15:42:41 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 15:42:41 2023 ] Weight decay: 0.0005
[ Tue Jun 27 15:42:41 2023 ] Base LR: 0.1
[ Tue Jun 27 15:42:41 2023 ] Batch Size: 64
[ Tue Jun 27 15:42:41 2023 ] Test Batch Size: 64
[ Tue Jun 27 15:42:41 2023 ] seed: 1
[ Tue Jun 27 15:42:41 2023 ] Start training Corrector
[ Tue Jun 27 15:47:38 2023 ] using warm up, epoch: 5
[ Tue Jun 27 15:47:38 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 15:47:38 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 15:47:38 2023 ] Start training Predictor
[ Tue Jun 27 15:47:38 2023 ] Training epoch: 1
[ Tue Jun 27 15:47:42 2023 ] 	Training loss: 104.8860.  Training acc: 34.19%.
[ Tue Jun 27 15:47:42 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jun 27 15:47:42 2023 ] Eval epoch: 1
[ Tue Jun 27 15:47:43 2023 ] 	Mean test loss of 625 batches: 978.287256.
[ Tue Jun 27 15:47:43 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:47:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:47:43 2023 ] Training epoch: 2
[ Tue Jun 27 15:47:45 2023 ] 	Training loss: 18.7444.  Training acc: 36.40%.
[ Tue Jun 27 15:47:45 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:47:45 2023 ] Eval epoch: 2
[ Tue Jun 27 15:47:46 2023 ] 	Mean test loss of 625 batches: 1050.685474.
[ Tue Jun 27 15:47:46 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:47:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:47:46 2023 ] Training epoch: 3
[ Tue Jun 27 15:47:48 2023 ] 	Training loss: 7.0683.  Training acc: 41.27%.
[ Tue Jun 27 15:47:48 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:47:48 2023 ] Eval epoch: 3
[ Tue Jun 27 15:47:48 2023 ] 	Mean test loss of 625 batches: 36.760842.
[ Tue Jun 27 15:47:48 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:47:48 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:47:48 2023 ] Training epoch: 4
[ Tue Jun 27 15:47:50 2023 ] 	Training loss: 6.5829.  Training acc: 40.26%.
[ Tue Jun 27 15:47:50 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 15:47:50 2023 ] Eval epoch: 4
[ Tue Jun 27 15:47:51 2023 ] 	Mean test loss of 625 batches: 16.520362.
[ Tue Jun 27 15:47:51 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:47:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:47:51 2023 ] Training epoch: 5
[ Tue Jun 27 15:47:52 2023 ] 	Training loss: 7.0204.  Training acc: 49.45%.
[ Tue Jun 27 15:47:52 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:47:52 2023 ] Eval epoch: 5
[ Tue Jun 27 15:47:53 2023 ] 	Mean test loss of 625 batches: 5.653563.
[ Tue Jun 27 15:47:53 2023 ] 	Top1: 31.58%
[ Tue Jun 27 15:47:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:47:53 2023 ] Training epoch: 6
[ Tue Jun 27 15:47:55 2023 ] 	Training loss: 2.8673.  Training acc: 56.43%.
[ Tue Jun 27 15:47:55 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 15:47:55 2023 ] Eval epoch: 6
[ Tue Jun 27 15:47:56 2023 ] 	Mean test loss of 625 batches: 2.046410.
[ Tue Jun 27 15:47:56 2023 ] 	Top1: 56.14%
[ Tue Jun 27 15:47:56 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:47:56 2023 ] Training epoch: 7
[ Tue Jun 27 15:47:58 2023 ] 	Training loss: 1.6091.  Training acc: 62.32%.
[ Tue Jun 27 15:47:58 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:47:58 2023 ] Eval epoch: 7
[ Tue Jun 27 15:47:58 2023 ] 	Mean test loss of 625 batches: 0.991474.
[ Tue Jun 27 15:47:58 2023 ] 	Top1: 64.91%
[ Tue Jun 27 15:47:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:47:58 2023 ] Training epoch: 8
[ Tue Jun 27 15:48:00 2023 ] 	Training loss: 1.9073.  Training acc: 63.24%.
[ Tue Jun 27 15:48:00 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 15:48:00 2023 ] Eval epoch: 8
[ Tue Jun 27 15:48:01 2023 ] 	Mean test loss of 625 batches: 1.176965.
[ Tue Jun 27 15:48:01 2023 ] 	Top1: 77.19%
[ Tue Jun 27 15:48:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:01 2023 ] Training epoch: 9
[ Tue Jun 27 15:48:03 2023 ] 	Training loss: 1.1902.  Training acc: 72.79%.
[ Tue Jun 27 15:48:03 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:48:03 2023 ] Eval epoch: 9
[ Tue Jun 27 15:48:03 2023 ] 	Mean test loss of 625 batches: 0.959694.
[ Tue Jun 27 15:48:03 2023 ] 	Top1: 75.44%
[ Tue Jun 27 15:48:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:03 2023 ] Training epoch: 10
[ Tue Jun 27 15:48:06 2023 ] 	Training loss: 0.9896.  Training acc: 75.55%.
[ Tue Jun 27 15:48:06 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 27 15:48:06 2023 ] Eval epoch: 10
[ Tue Jun 27 15:48:06 2023 ] 	Mean test loss of 625 batches: 0.816847.
[ Tue Jun 27 15:48:06 2023 ] 	Top1: 78.95%
[ Tue Jun 27 15:48:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:06 2023 ] Training epoch: 11
[ Tue Jun 27 15:48:09 2023 ] 	Training loss: 0.8502.  Training acc: 79.69%.
[ Tue Jun 27 15:48:09 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 27 15:48:09 2023 ] Eval epoch: 11
[ Tue Jun 27 15:48:10 2023 ] 	Mean test loss of 625 batches: 0.715951.
[ Tue Jun 27 15:48:10 2023 ] 	Top1: 80.70%
[ Tue Jun 27 15:48:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:10 2023 ] Training epoch: 12
[ Tue Jun 27 15:48:13 2023 ] 	Training loss: 0.8112.  Training acc: 80.97%.
[ Tue Jun 27 15:48:13 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 27 15:48:13 2023 ] Eval epoch: 12
[ Tue Jun 27 15:48:13 2023 ] 	Mean test loss of 625 batches: 0.678766.
[ Tue Jun 27 15:48:13 2023 ] 	Top1: 84.21%
[ Tue Jun 27 15:48:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:13 2023 ] Training epoch: 13
[ Tue Jun 27 15:48:16 2023 ] 	Training loss: 0.7550.  Training acc: 83.18%.
[ Tue Jun 27 15:48:16 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 27 15:48:16 2023 ] Eval epoch: 13
[ Tue Jun 27 15:48:17 2023 ] 	Mean test loss of 625 batches: 0.652956.
[ Tue Jun 27 15:48:17 2023 ] 	Top1: 89.47%
[ Tue Jun 27 15:48:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:17 2023 ] Training epoch: 14
[ Tue Jun 27 15:48:20 2023 ] 	Training loss: 0.7425.  Training acc: 86.12%.
[ Tue Jun 27 15:48:20 2023 ] 	Time consumption: [Data]12%, [Network]87%
[ Tue Jun 27 15:48:20 2023 ] Eval epoch: 14
[ Tue Jun 27 15:48:20 2023 ] 	Mean test loss of 625 batches: 0.621412.
[ Tue Jun 27 15:48:20 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:48:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:20 2023 ] Training epoch: 15
[ Tue Jun 27 15:48:23 2023 ] 	Training loss: 0.7272.  Training acc: 84.74%.
[ Tue Jun 27 15:48:23 2023 ] 	Time consumption: [Data]12%, [Network]87%
[ Tue Jun 27 15:48:23 2023 ] Eval epoch: 15
[ Tue Jun 27 15:48:23 2023 ] 	Mean test loss of 625 batches: 0.582193.
[ Tue Jun 27 15:48:23 2023 ] 	Top1: 96.49%
[ Tue Jun 27 15:48:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:23 2023 ] Training epoch: 16
[ Tue Jun 27 15:48:25 2023 ] 	Training loss: 0.7342.  Training acc: 86.03%.
[ Tue Jun 27 15:48:25 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:48:25 2023 ] Eval epoch: 16
[ Tue Jun 27 15:48:26 2023 ] 	Mean test loss of 625 batches: 0.526110.
[ Tue Jun 27 15:48:26 2023 ] 	Top1: 98.25%
[ Tue Jun 27 15:48:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:26 2023 ] Training epoch: 17
[ Tue Jun 27 15:48:28 2023 ] 	Training loss: 0.6840.  Training acc: 89.43%.
[ Tue Jun 27 15:48:28 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:48:28 2023 ] Eval epoch: 17
[ Tue Jun 27 15:48:28 2023 ] 	Mean test loss of 625 batches: 0.506492.
[ Tue Jun 27 15:48:28 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:48:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:29 2023 ] Training epoch: 18
[ Tue Jun 27 15:48:31 2023 ] 	Training loss: 0.6772.  Training acc: 89.06%.
[ Tue Jun 27 15:48:31 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:48:31 2023 ] Eval epoch: 18
[ Tue Jun 27 15:48:31 2023 ] 	Mean test loss of 625 batches: 0.547649.
[ Tue Jun 27 15:48:31 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:48:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:31 2023 ] Training epoch: 19
[ Tue Jun 27 15:48:33 2023 ] 	Training loss: 0.6692.  Training acc: 89.06%.
[ Tue Jun 27 15:48:33 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:48:33 2023 ] Eval epoch: 19
[ Tue Jun 27 15:48:34 2023 ] 	Mean test loss of 625 batches: 0.551228.
[ Tue Jun 27 15:48:34 2023 ] 	Top1: 96.49%
[ Tue Jun 27 15:48:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:34 2023 ] Training epoch: 20
[ Tue Jun 27 15:48:36 2023 ] 	Training loss: 0.6473.  Training acc: 89.43%.
[ Tue Jun 27 15:48:36 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:48:36 2023 ] Eval epoch: 20
[ Tue Jun 27 15:48:36 2023 ] 	Mean test loss of 625 batches: 0.607819.
[ Tue Jun 27 15:48:36 2023 ] 	Top1: 89.47%
[ Tue Jun 27 15:48:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:36 2023 ] Training epoch: 21
[ Tue Jun 27 15:48:38 2023 ] 	Training loss: 0.6609.  Training acc: 90.07%.
[ Tue Jun 27 15:48:38 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:48:38 2023 ] Eval epoch: 21
[ Tue Jun 27 15:48:39 2023 ] 	Mean test loss of 625 batches: 0.499467.
[ Tue Jun 27 15:48:39 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:48:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:39 2023 ] Training epoch: 22
[ Tue Jun 27 15:48:40 2023 ] 	Training loss: 0.6252.  Training acc: 90.81%.
[ Tue Jun 27 15:48:40 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:48:40 2023 ] Eval epoch: 22
[ Tue Jun 27 15:48:41 2023 ] 	Mean test loss of 625 batches: 0.500260.
[ Tue Jun 27 15:48:41 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:48:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:41 2023 ] Training epoch: 23
[ Tue Jun 27 15:48:43 2023 ] 	Training loss: 0.6132.  Training acc: 92.28%.
[ Tue Jun 27 15:48:43 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:48:43 2023 ] Eval epoch: 23
[ Tue Jun 27 15:48:44 2023 ] 	Mean test loss of 625 batches: 0.478096.
[ Tue Jun 27 15:48:44 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:48:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:44 2023 ] Training epoch: 24
[ Tue Jun 27 15:48:46 2023 ] 	Training loss: 0.5973.  Training acc: 92.46%.
[ Tue Jun 27 15:48:46 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 15:48:46 2023 ] Eval epoch: 24
[ Tue Jun 27 15:48:46 2023 ] 	Mean test loss of 625 batches: 0.487047.
[ Tue Jun 27 15:48:46 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:48:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:46 2023 ] Training epoch: 25
[ Tue Jun 27 15:48:48 2023 ] 	Training loss: 0.6086.  Training acc: 91.91%.
[ Tue Jun 27 15:48:48 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 15:48:48 2023 ] Eval epoch: 25
[ Tue Jun 27 15:48:49 2023 ] 	Mean test loss of 625 batches: 0.479925.
[ Tue Jun 27 15:48:49 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:48:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:49 2023 ] Training epoch: 26
[ Tue Jun 27 15:48:51 2023 ] 	Training loss: 0.6007.  Training acc: 92.19%.
[ Tue Jun 27 15:48:51 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:48:51 2023 ] Eval epoch: 26
[ Tue Jun 27 15:48:52 2023 ] 	Mean test loss of 625 batches: 0.489943.
[ Tue Jun 27 15:48:52 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:48:52 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:52 2023 ] Training epoch: 27
[ Tue Jun 27 15:48:54 2023 ] 	Training loss: 0.6173.  Training acc: 92.19%.
[ Tue Jun 27 15:48:54 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:48:54 2023 ] Eval epoch: 27
[ Tue Jun 27 15:48:54 2023 ] 	Mean test loss of 625 batches: 0.479172.
[ Tue Jun 27 15:48:54 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:48:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:54 2023 ] Training epoch: 28
[ Tue Jun 27 15:48:56 2023 ] 	Training loss: 0.5757.  Training acc: 93.66%.
[ Tue Jun 27 15:48:56 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:48:56 2023 ] Eval epoch: 28
[ Tue Jun 27 15:48:57 2023 ] 	Mean test loss of 625 batches: 0.478404.
[ Tue Jun 27 15:48:57 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:48:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:48:57 2023 ] Training epoch: 29
[ Tue Jun 27 15:49:00 2023 ] 	Training loss: 0.5703.  Training acc: 93.29%.
[ Tue Jun 27 15:49:00 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 27 15:49:00 2023 ] Eval epoch: 29
[ Tue Jun 27 15:49:00 2023 ] 	Mean test loss of 625 batches: 0.490989.
[ Tue Jun 27 15:49:00 2023 ] 	Top1: 98.25%
[ Tue Jun 27 15:49:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:00 2023 ] Training epoch: 30
[ Tue Jun 27 15:49:03 2023 ] 	Training loss: 0.5543.  Training acc: 93.93%.
[ Tue Jun 27 15:49:03 2023 ] 	Time consumption: [Data]12%, [Network]87%
[ Tue Jun 27 15:49:03 2023 ] Eval epoch: 30
[ Tue Jun 27 15:49:04 2023 ] 	Mean test loss of 625 batches: 0.475705.
[ Tue Jun 27 15:49:04 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:04 2023 ] Training epoch: 31
[ Tue Jun 27 15:49:06 2023 ] 	Training loss: 0.5692.  Training acc: 93.57%.
[ Tue Jun 27 15:49:06 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 27 15:49:06 2023 ] Eval epoch: 31
[ Tue Jun 27 15:49:07 2023 ] 	Mean test loss of 625 batches: 0.468460.
[ Tue Jun 27 15:49:07 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:07 2023 ] Training epoch: 32
[ Tue Jun 27 15:49:10 2023 ] 	Training loss: 0.5858.  Training acc: 92.56%.
[ Tue Jun 27 15:49:10 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 27 15:49:10 2023 ] Eval epoch: 32
[ Tue Jun 27 15:49:10 2023 ] 	Mean test loss of 625 batches: 0.477607.
[ Tue Jun 27 15:49:10 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:10 2023 ] Training epoch: 33
[ Tue Jun 27 15:49:13 2023 ] 	Training loss: 0.5393.  Training acc: 94.94%.
[ Tue Jun 27 15:49:13 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 27 15:49:13 2023 ] Eval epoch: 33
[ Tue Jun 27 15:49:14 2023 ] 	Mean test loss of 625 batches: 0.463982.
[ Tue Jun 27 15:49:14 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:14 2023 ] Training epoch: 34
[ Tue Jun 27 15:49:16 2023 ] 	Training loss: 0.5429.  Training acc: 94.21%.
[ Tue Jun 27 15:49:16 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 27 15:49:16 2023 ] Eval epoch: 34
[ Tue Jun 27 15:49:17 2023 ] 	Mean test loss of 625 batches: 0.470806.
[ Tue Jun 27 15:49:17 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:17 2023 ] Training epoch: 35
[ Tue Jun 27 15:49:20 2023 ] 	Training loss: 0.5279.  Training acc: 96.05%.
[ Tue Jun 27 15:49:20 2023 ] 	Time consumption: [Data]12%, [Network]87%
[ Tue Jun 27 15:49:20 2023 ] Eval epoch: 35
[ Tue Jun 27 15:49:20 2023 ] 	Mean test loss of 625 batches: 0.466979.
[ Tue Jun 27 15:49:20 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:20 2023 ] Training epoch: 36
[ Tue Jun 27 15:49:22 2023 ] 	Training loss: 0.5266.  Training acc: 96.32%.
[ Tue Jun 27 15:49:22 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 15:49:22 2023 ] Eval epoch: 36
[ Tue Jun 27 15:49:23 2023 ] 	Mean test loss of 625 batches: 0.465555.
[ Tue Jun 27 15:49:23 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:23 2023 ] Training epoch: 37
[ Tue Jun 27 15:49:25 2023 ] 	Training loss: 0.5404.  Training acc: 95.59%.
[ Tue Jun 27 15:49:25 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:49:25 2023 ] Eval epoch: 37
[ Tue Jun 27 15:49:25 2023 ] 	Mean test loss of 625 batches: 0.459565.
[ Tue Jun 27 15:49:25 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:25 2023 ] Training epoch: 38
[ Tue Jun 27 15:49:27 2023 ] 	Training loss: 0.5585.  Training acc: 94.21%.
[ Tue Jun 27 15:49:27 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:49:27 2023 ] Eval epoch: 38
[ Tue Jun 27 15:49:28 2023 ] 	Mean test loss of 625 batches: 0.468066.
[ Tue Jun 27 15:49:28 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:28 2023 ] Training epoch: 39
[ Tue Jun 27 15:49:30 2023 ] 	Training loss: 0.5361.  Training acc: 95.77%.
[ Tue Jun 27 15:49:30 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:49:30 2023 ] Eval epoch: 39
[ Tue Jun 27 15:49:30 2023 ] 	Mean test loss of 625 batches: 0.468055.
[ Tue Jun 27 15:49:30 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:31 2023 ] Training epoch: 40
[ Tue Jun 27 15:49:32 2023 ] 	Training loss: 0.5528.  Training acc: 92.92%.
[ Tue Jun 27 15:49:32 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:49:32 2023 ] Eval epoch: 40
[ Tue Jun 27 15:49:33 2023 ] 	Mean test loss of 625 batches: 0.469400.
[ Tue Jun 27 15:49:33 2023 ] 	Top1: 100.00%
[ Tue Jun 27 15:49:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:49:34 2023 ] Best accuracy: 1.0
[ Tue Jun 27 15:49:34 2023 ] Epoch number: 17
[ Tue Jun 27 15:49:34 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 15:49:34 2023 ] Weight decay: 0.0005
[ Tue Jun 27 15:49:34 2023 ] Base LR: 0.1
[ Tue Jun 27 15:49:34 2023 ] Batch Size: 64
[ Tue Jun 27 15:49:34 2023 ] Test Batch Size: 64
[ Tue Jun 27 15:49:34 2023 ] seed: 1
[ Tue Jun 27 15:49:34 2023 ] Start training Corrector
[ Tue Jun 27 15:53:27 2023 ] using warm up, epoch: 5
[ Tue Jun 27 15:53:27 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 15:53:27 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 15:53:27 2023 ] Start training Predictor
[ Tue Jun 27 15:53:27 2023 ] Training epoch: 1
[ Tue Jun 27 15:53:32 2023 ] 	Training loss: 108.8274.  Training acc: 34.38%.
[ Tue Jun 27 15:53:32 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 15:53:32 2023 ] Eval epoch: 1
[ Tue Jun 27 15:53:33 2023 ] 	Mean test loss of 625 batches: 10589.984766.
[ Tue Jun 27 15:53:33 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:53:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:53:33 2023 ] Training epoch: 2
[ Tue Jun 27 15:53:35 2023 ] 	Training loss: 14.4269.  Training acc: 39.34%.
[ Tue Jun 27 15:53:35 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Tue Jun 27 15:53:35 2023 ] Eval epoch: 2
[ Tue Jun 27 15:53:35 2023 ] 	Mean test loss of 625 batches: 5199.514990.
[ Tue Jun 27 15:53:35 2023 ] 	Top1: 29.82%
[ Tue Jun 27 15:53:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:53:35 2023 ] Training epoch: 3
[ Tue Jun 27 15:53:38 2023 ] 	Training loss: 6.5364.  Training acc: 44.58%.
[ Tue Jun 27 15:53:38 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:53:38 2023 ] Eval epoch: 3
[ Tue Jun 27 15:53:38 2023 ] 	Mean test loss of 625 batches: 15.623695.
[ Tue Jun 27 15:53:38 2023 ] 	Top1: 7.02%
[ Tue Jun 27 15:53:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:53:38 2023 ] Training epoch: 4
[ Tue Jun 27 15:53:40 2023 ] 	Training loss: 5.5094.  Training acc: 48.71%.
[ Tue Jun 27 15:53:40 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:53:40 2023 ] Eval epoch: 4
[ Tue Jun 27 15:53:41 2023 ] 	Mean test loss of 625 batches: 1.829950.
[ Tue Jun 27 15:53:41 2023 ] 	Top1: 52.63%
[ Tue Jun 27 15:53:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:53:41 2023 ] Training epoch: 5
[ Tue Jun 27 15:53:43 2023 ] 	Training loss: 6.9287.  Training acc: 42.65%.
[ Tue Jun 27 15:53:43 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:53:43 2023 ] Eval epoch: 5
[ Tue Jun 27 15:53:44 2023 ] 	Mean test loss of 625 batches: 1606.305151.
[ Tue Jun 27 15:53:44 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:53:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:53:44 2023 ] Training epoch: 6
[ Tue Jun 27 15:53:46 2023 ] 	Training loss: 4.0148.  Training acc: 52.11%.
[ Tue Jun 27 15:53:46 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:53:46 2023 ] Eval epoch: 6
[ Tue Jun 27 15:53:46 2023 ] 	Mean test loss of 625 batches: 5.176137.
[ Tue Jun 27 15:53:46 2023 ] 	Top1: 38.60%
[ Tue Jun 27 15:53:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:53:46 2023 ] Training epoch: 7
[ Tue Jun 27 15:53:49 2023 ] 	Training loss: 2.1418.  Training acc: 60.85%.
[ Tue Jun 27 15:53:49 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:53:49 2023 ] Eval epoch: 7
[ Tue Jun 27 15:53:50 2023 ] 	Mean test loss of 625 batches: 2.129398.
[ Tue Jun 27 15:53:50 2023 ] 	Top1: 35.09%
[ Tue Jun 27 15:53:50 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:53:50 2023 ] Training epoch: 8
[ Tue Jun 27 15:53:53 2023 ] 	Training loss: 1.9625.  Training acc: 58.64%.
[ Tue Jun 27 15:53:53 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:53:53 2023 ] Eval epoch: 8
[ Tue Jun 27 15:53:53 2023 ] 	Mean test loss of 625 batches: 1.929126.
[ Tue Jun 27 15:53:53 2023 ] 	Top1: 40.35%
[ Tue Jun 27 15:53:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:53:53 2023 ] Training epoch: 9
[ Tue Jun 27 15:53:56 2023 ] 	Training loss: 1.5025.  Training acc: 63.05%.
[ Tue Jun 27 15:53:56 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:53:56 2023 ] Eval epoch: 9
[ Tue Jun 27 15:53:57 2023 ] 	Mean test loss of 625 batches: 0.845993.
[ Tue Jun 27 15:53:57 2023 ] 	Top1: 64.91%
[ Tue Jun 27 15:53:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:53:57 2023 ] Training epoch: 10
[ Tue Jun 27 15:54:00 2023 ] 	Training loss: 1.6185.  Training acc: 58.92%.
[ Tue Jun 27 15:54:00 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:54:00 2023 ] Eval epoch: 10
[ Tue Jun 27 15:54:01 2023 ] 	Mean test loss of 625 batches: 1.353903.
[ Tue Jun 27 15:54:01 2023 ] 	Top1: 70.18%
[ Tue Jun 27 15:54:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:01 2023 ] Training epoch: 11
[ Tue Jun 27 15:54:03 2023 ] 	Training loss: 1.3164.  Training acc: 64.71%.
[ Tue Jun 27 15:54:03 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 15:54:03 2023 ] Eval epoch: 11
[ Tue Jun 27 15:54:04 2023 ] 	Mean test loss of 625 batches: 0.700450.
[ Tue Jun 27 15:54:04 2023 ] 	Top1: 84.21%
[ Tue Jun 27 15:54:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:04 2023 ] Training epoch: 12
[ Tue Jun 27 15:54:07 2023 ] 	Training loss: 1.1978.  Training acc: 64.71%.
[ Tue Jun 27 15:54:07 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:54:07 2023 ] Eval epoch: 12
[ Tue Jun 27 15:54:07 2023 ] 	Mean test loss of 625 batches: 0.702256.
[ Tue Jun 27 15:54:07 2023 ] 	Top1: 80.70%
[ Tue Jun 27 15:54:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:08 2023 ] Training epoch: 13
[ Tue Jun 27 15:54:10 2023 ] 	Training loss: 1.0526.  Training acc: 68.29%.
[ Tue Jun 27 15:54:10 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:54:10 2023 ] Eval epoch: 13
[ Tue Jun 27 15:54:11 2023 ] 	Mean test loss of 625 batches: 0.703488.
[ Tue Jun 27 15:54:11 2023 ] 	Top1: 77.19%
[ Tue Jun 27 15:54:11 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:11 2023 ] Training epoch: 14
[ Tue Jun 27 15:54:14 2023 ] 	Training loss: 1.0215.  Training acc: 70.04%.
[ Tue Jun 27 15:54:14 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:54:14 2023 ] Eval epoch: 14
[ Tue Jun 27 15:54:14 2023 ] 	Mean test loss of 625 batches: 0.675968.
[ Tue Jun 27 15:54:14 2023 ] 	Top1: 80.70%
[ Tue Jun 27 15:54:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:14 2023 ] Training epoch: 15
[ Tue Jun 27 15:54:17 2023 ] 	Training loss: 0.9971.  Training acc: 69.30%.
[ Tue Jun 27 15:54:17 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 15:54:17 2023 ] Eval epoch: 15
[ Tue Jun 27 15:54:18 2023 ] 	Mean test loss of 625 batches: 0.639994.
[ Tue Jun 27 15:54:18 2023 ] 	Top1: 92.98%
[ Tue Jun 27 15:54:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:18 2023 ] Training epoch: 16
[ Tue Jun 27 15:54:21 2023 ] 	Training loss: 0.9761.  Training acc: 71.97%.
[ Tue Jun 27 15:54:21 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:54:21 2023 ] Eval epoch: 16
[ Tue Jun 27 15:54:22 2023 ] 	Mean test loss of 625 batches: 0.626773.
[ Tue Jun 27 15:54:22 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:54:22 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:22 2023 ] Training epoch: 17
[ Tue Jun 27 15:54:25 2023 ] 	Training loss: 0.9402.  Training acc: 73.99%.
[ Tue Jun 27 15:54:25 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:54:25 2023 ] Eval epoch: 17
[ Tue Jun 27 15:54:25 2023 ] 	Mean test loss of 625 batches: 0.614467.
[ Tue Jun 27 15:54:25 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:54:25 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:25 2023 ] Training epoch: 18
[ Tue Jun 27 15:54:27 2023 ] 	Training loss: 0.9442.  Training acc: 73.53%.
[ Tue Jun 27 15:54:27 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:54:27 2023 ] Eval epoch: 18
[ Tue Jun 27 15:54:28 2023 ] 	Mean test loss of 625 batches: 0.584350.
[ Tue Jun 27 15:54:28 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:54:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:28 2023 ] Training epoch: 19
[ Tue Jun 27 15:54:30 2023 ] 	Training loss: 0.9922.  Training acc: 74.26%.
[ Tue Jun 27 15:54:30 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:54:30 2023 ] Eval epoch: 19
[ Tue Jun 27 15:54:31 2023 ] 	Mean test loss of 625 batches: 0.614977.
[ Tue Jun 27 15:54:31 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:54:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:31 2023 ] Training epoch: 20
[ Tue Jun 27 15:54:33 2023 ] 	Training loss: 0.9812.  Training acc: 73.53%.
[ Tue Jun 27 15:54:33 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:54:33 2023 ] Eval epoch: 20
[ Tue Jun 27 15:54:33 2023 ] 	Mean test loss of 625 batches: 0.529877.
[ Tue Jun 27 15:54:33 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:54:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:33 2023 ] Training epoch: 21
[ Tue Jun 27 15:54:35 2023 ] 	Training loss: 0.8442.  Training acc: 78.31%.
[ Tue Jun 27 15:54:35 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:54:35 2023 ] Eval epoch: 21
[ Tue Jun 27 15:54:36 2023 ] 	Mean test loss of 625 batches: 0.563211.
[ Tue Jun 27 15:54:36 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:54:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:36 2023 ] Training epoch: 22
[ Tue Jun 27 15:54:38 2023 ] 	Training loss: 0.8829.  Training acc: 74.82%.
[ Tue Jun 27 15:54:38 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:54:38 2023 ] Eval epoch: 22
[ Tue Jun 27 15:54:39 2023 ] 	Mean test loss of 625 batches: 0.556108.
[ Tue Jun 27 15:54:39 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:54:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:39 2023 ] Training epoch: 23
[ Tue Jun 27 15:54:41 2023 ] 	Training loss: 0.8451.  Training acc: 78.22%.
[ Tue Jun 27 15:54:41 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:54:41 2023 ] Eval epoch: 23
[ Tue Jun 27 15:54:42 2023 ] 	Mean test loss of 625 batches: 0.589376.
[ Tue Jun 27 15:54:42 2023 ] 	Top1: 87.72%
[ Tue Jun 27 15:54:42 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:42 2023 ] Training epoch: 24
[ Tue Jun 27 15:54:44 2023 ] 	Training loss: 0.8445.  Training acc: 77.39%.
[ Tue Jun 27 15:54:44 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 15:54:44 2023 ] Eval epoch: 24
[ Tue Jun 27 15:54:44 2023 ] 	Mean test loss of 625 batches: 0.582784.
[ Tue Jun 27 15:54:44 2023 ] 	Top1: 89.47%
[ Tue Jun 27 15:54:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:44 2023 ] Training epoch: 25
[ Tue Jun 27 15:54:47 2023 ] 	Training loss: 0.8750.  Training acc: 76.75%.
[ Tue Jun 27 15:54:47 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:54:47 2023 ] Eval epoch: 25
[ Tue Jun 27 15:54:47 2023 ] 	Mean test loss of 625 batches: 0.566979.
[ Tue Jun 27 15:54:47 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:54:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:47 2023 ] Training epoch: 26
[ Tue Jun 27 15:54:49 2023 ] 	Training loss: 0.8576.  Training acc: 80.33%.
[ Tue Jun 27 15:54:49 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 15:54:49 2023 ] Eval epoch: 26
[ Tue Jun 27 15:54:50 2023 ] 	Mean test loss of 625 batches: 0.564016.
[ Tue Jun 27 15:54:50 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:54:50 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:50 2023 ] Training epoch: 27
[ Tue Jun 27 15:54:52 2023 ] 	Training loss: 0.8544.  Training acc: 77.85%.
[ Tue Jun 27 15:54:52 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:54:52 2023 ] Eval epoch: 27
[ Tue Jun 27 15:54:53 2023 ] 	Mean test loss of 625 batches: 0.588817.
[ Tue Jun 27 15:54:53 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:54:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:53 2023 ] Training epoch: 28
[ Tue Jun 27 15:54:55 2023 ] 	Training loss: 0.8458.  Training acc: 80.24%.
[ Tue Jun 27 15:54:55 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:54:55 2023 ] Eval epoch: 28
[ Tue Jun 27 15:54:55 2023 ] 	Mean test loss of 625 batches: 0.585070.
[ Tue Jun 27 15:54:55 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:54:55 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:55 2023 ] Training epoch: 29
[ Tue Jun 27 15:54:57 2023 ] 	Training loss: 0.8147.  Training acc: 80.42%.
[ Tue Jun 27 15:54:57 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 15:54:57 2023 ] Eval epoch: 29
[ Tue Jun 27 15:54:58 2023 ] 	Mean test loss of 625 batches: 0.568527.
[ Tue Jun 27 15:54:58 2023 ] 	Top1: 92.98%
[ Tue Jun 27 15:54:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:54:58 2023 ] Training epoch: 30
[ Tue Jun 27 15:55:01 2023 ] 	Training loss: 0.7815.  Training acc: 81.16%.
[ Tue Jun 27 15:55:01 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 27 15:55:01 2023 ] Eval epoch: 30
[ Tue Jun 27 15:55:02 2023 ] 	Mean test loss of 625 batches: 0.569008.
[ Tue Jun 27 15:55:02 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:55:02 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:02 2023 ] Training epoch: 31
[ Tue Jun 27 15:55:05 2023 ] 	Training loss: 0.8013.  Training acc: 81.53%.
[ Tue Jun 27 15:55:05 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 15:55:05 2023 ] Eval epoch: 31
[ Tue Jun 27 15:55:06 2023 ] 	Mean test loss of 625 batches: 0.556972.
[ Tue Jun 27 15:55:06 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:55:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:06 2023 ] Training epoch: 32
[ Tue Jun 27 15:55:09 2023 ] 	Training loss: 0.8221.  Training acc: 80.88%.
[ Tue Jun 27 15:55:09 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:55:09 2023 ] Eval epoch: 32
[ Tue Jun 27 15:55:09 2023 ] 	Mean test loss of 625 batches: 0.574266.
[ Tue Jun 27 15:55:09 2023 ] 	Top1: 91.23%
[ Tue Jun 27 15:55:09 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:09 2023 ] Training epoch: 33
[ Tue Jun 27 15:55:12 2023 ] 	Training loss: 0.7749.  Training acc: 82.35%.
[ Tue Jun 27 15:55:12 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:55:12 2023 ] Eval epoch: 33
[ Tue Jun 27 15:55:13 2023 ] 	Mean test loss of 625 batches: 0.570266.
[ Tue Jun 27 15:55:13 2023 ] 	Top1: 92.98%
[ Tue Jun 27 15:55:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:13 2023 ] Training epoch: 34
[ Tue Jun 27 15:55:16 2023 ] 	Training loss: 0.7785.  Training acc: 81.89%.
[ Tue Jun 27 15:55:16 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:55:16 2023 ] Eval epoch: 34
[ Tue Jun 27 15:55:17 2023 ] 	Mean test loss of 625 batches: 0.567942.
[ Tue Jun 27 15:55:17 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:55:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:17 2023 ] Training epoch: 35
[ Tue Jun 27 15:55:20 2023 ] 	Training loss: 0.7762.  Training acc: 83.27%.
[ Tue Jun 27 15:55:20 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:55:20 2023 ] Eval epoch: 35
[ Tue Jun 27 15:55:20 2023 ] 	Mean test loss of 625 batches: 0.567928.
[ Tue Jun 27 15:55:20 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:55:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:20 2023 ] Training epoch: 36
[ Tue Jun 27 15:55:23 2023 ] 	Training loss: 0.7746.  Training acc: 83.55%.
[ Tue Jun 27 15:55:23 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 15:55:23 2023 ] Eval epoch: 36
[ Tue Jun 27 15:55:24 2023 ] 	Mean test loss of 625 batches: 0.579187.
[ Tue Jun 27 15:55:24 2023 ] 	Top1: 92.98%
[ Tue Jun 27 15:55:24 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:24 2023 ] Training epoch: 37
[ Tue Jun 27 15:55:27 2023 ] 	Training loss: 0.7962.  Training acc: 82.44%.
[ Tue Jun 27 15:55:27 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:55:27 2023 ] Eval epoch: 37
[ Tue Jun 27 15:55:28 2023 ] 	Mean test loss of 625 batches: 0.564917.
[ Tue Jun 27 15:55:28 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:55:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:28 2023 ] Training epoch: 38
[ Tue Jun 27 15:55:31 2023 ] 	Training loss: 0.8204.  Training acc: 79.50%.
[ Tue Jun 27 15:55:31 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:55:31 2023 ] Eval epoch: 38
[ Tue Jun 27 15:55:31 2023 ] 	Mean test loss of 625 batches: 0.569925.
[ Tue Jun 27 15:55:31 2023 ] 	Top1: 94.74%
[ Tue Jun 27 15:55:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:31 2023 ] Training epoch: 39
[ Tue Jun 27 15:55:34 2023 ] 	Training loss: 0.7665.  Training acc: 83.36%.
[ Tue Jun 27 15:55:34 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 27 15:55:34 2023 ] Eval epoch: 39
[ Tue Jun 27 15:55:35 2023 ] 	Mean test loss of 625 batches: 0.564737.
[ Tue Jun 27 15:55:35 2023 ] 	Top1: 96.49%
[ Tue Jun 27 15:55:35 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:35 2023 ] Training epoch: 40
[ Tue Jun 27 15:55:37 2023 ] 	Training loss: 0.7872.  Training acc: 80.70%.
[ Tue Jun 27 15:55:37 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 15:55:37 2023 ] Eval epoch: 40
[ Tue Jun 27 15:55:38 2023 ] 	Mean test loss of 625 batches: 0.547606.
[ Tue Jun 27 15:55:38 2023 ] 	Top1: 96.49%
[ Tue Jun 27 15:55:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 15:55:39 2023 ] Best accuracy: 0.9649122807017544
[ Tue Jun 27 15:55:39 2023 ] Epoch number: 39
[ Tue Jun 27 15:55:39 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 15:55:39 2023 ] Weight decay: 0.0005
[ Tue Jun 27 15:55:39 2023 ] Base LR: 0.1
[ Tue Jun 27 15:55:39 2023 ] Batch Size: 64
[ Tue Jun 27 15:55:39 2023 ] Test Batch Size: 64
[ Tue Jun 27 15:55:39 2023 ] seed: 1
[ Tue Jun 27 15:55:39 2023 ] Start training Corrector
[ Tue Jun 27 16:38:52 2023 ] using warm up, epoch: 5
[ Tue Jun 27 16:38:52 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 16:38:52 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 16:38:52 2023 ] Start training Predictor
[ Tue Jun 27 16:38:52 2023 ] Training epoch: 1
[ Tue Jun 27 16:38:58 2023 ] 	Training loss: 101.9899.  Training acc: 34.74%.
[ Tue Jun 27 16:38:58 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Jun 27 16:38:58 2023 ] Eval epoch: 1
[ Tue Jun 27 16:38:58 2023 ] 	Mean test loss of 625 batches: 1255.190503.
[ Tue Jun 27 16:38:58 2023 ] 	Top1: 29.82%
[ Tue Jun 27 16:38:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:38:58 2023 ] Training epoch: 2
[ Tue Jun 27 16:39:01 2023 ] 	Training loss: 23.1777.  Training acc: 34.65%.
[ Tue Jun 27 16:39:01 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 16:39:01 2023 ] Eval epoch: 2
[ Tue Jun 27 16:39:01 2023 ] 	Mean test loss of 625 batches: 1.821319.
[ Tue Jun 27 16:39:01 2023 ] 	Top1: 29.82%
[ Tue Jun 27 16:39:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:01 2023 ] Training epoch: 3
[ Tue Jun 27 16:39:03 2023 ] 	Training loss: 6.8540.  Training acc: 38.97%.
[ Tue Jun 27 16:39:03 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 16:39:03 2023 ] Eval epoch: 3
[ Tue Jun 27 16:39:04 2023 ] 	Mean test loss of 625 batches: 5.692295.
[ Tue Jun 27 16:39:04 2023 ] 	Top1: 33.33%
[ Tue Jun 27 16:39:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:04 2023 ] Training epoch: 4
[ Tue Jun 27 16:39:06 2023 ] 	Training loss: 8.8034.  Training acc: 40.81%.
[ Tue Jun 27 16:39:06 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 16:39:06 2023 ] Eval epoch: 4
[ Tue Jun 27 16:39:07 2023 ] 	Mean test loss of 625 batches: 5.738342.
[ Tue Jun 27 16:39:07 2023 ] 	Top1: 38.60%
[ Tue Jun 27 16:39:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:07 2023 ] Training epoch: 5
[ Tue Jun 27 16:39:09 2023 ] 	Training loss: 6.4375.  Training acc: 37.68%.
[ Tue Jun 27 16:39:09 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 16:39:09 2023 ] Eval epoch: 5
[ Tue Jun 27 16:39:10 2023 ] 	Mean test loss of 625 batches: 2.510940.
[ Tue Jun 27 16:39:10 2023 ] 	Top1: 38.60%
[ Tue Jun 27 16:39:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:10 2023 ] Training epoch: 6
[ Tue Jun 27 16:39:12 2023 ] 	Training loss: 4.8917.  Training acc: 35.20%.
[ Tue Jun 27 16:39:12 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 16:39:12 2023 ] Eval epoch: 6
[ Tue Jun 27 16:39:13 2023 ] 	Mean test loss of 625 batches: 1.281090.
[ Tue Jun 27 16:39:13 2023 ] 	Top1: 38.60%
[ Tue Jun 27 16:39:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:13 2023 ] Training epoch: 7
[ Tue Jun 27 16:39:15 2023 ] 	Training loss: 4.4560.  Training acc: 30.88%.
[ Tue Jun 27 16:39:15 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 16:39:15 2023 ] Eval epoch: 7
[ Tue Jun 27 16:39:15 2023 ] 	Mean test loss of 625 batches: 2.851632.
[ Tue Jun 27 16:39:15 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:15 2023 ] Training epoch: 8
[ Tue Jun 27 16:39:18 2023 ] 	Training loss: 2.9468.  Training acc: 32.90%.
[ Tue Jun 27 16:39:18 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 16:39:18 2023 ] Eval epoch: 8
[ Tue Jun 27 16:39:18 2023 ] 	Mean test loss of 625 batches: 1.266245.
[ Tue Jun 27 16:39:18 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:18 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:18 2023 ] Training epoch: 9
[ Tue Jun 27 16:39:20 2023 ] 	Training loss: 2.0882.  Training acc: 33.55%.
[ Tue Jun 27 16:39:20 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 16:39:20 2023 ] Eval epoch: 9
[ Tue Jun 27 16:39:21 2023 ] 	Mean test loss of 625 batches: 1.109682.
[ Tue Jun 27 16:39:21 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:21 2023 ] Training epoch: 10
[ Tue Jun 27 16:39:23 2023 ] 	Training loss: 1.8727.  Training acc: 33.82%.
[ Tue Jun 27 16:39:23 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 16:39:23 2023 ] Eval epoch: 10
[ Tue Jun 27 16:39:24 2023 ] 	Mean test loss of 625 batches: 1.099651.
[ Tue Jun 27 16:39:24 2023 ] 	Top1: 29.82%
[ Tue Jun 27 16:39:24 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:24 2023 ] Training epoch: 11
[ Tue Jun 27 16:39:27 2023 ] 	Training loss: 1.6036.  Training acc: 33.92%.
[ Tue Jun 27 16:39:27 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:39:27 2023 ] Eval epoch: 11
[ Tue Jun 27 16:39:27 2023 ] 	Mean test loss of 625 batches: 1.117603.
[ Tue Jun 27 16:39:27 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:27 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:27 2023 ] Training epoch: 12
[ Tue Jun 27 16:39:30 2023 ] 	Training loss: 1.6132.  Training acc: 34.10%.
[ Tue Jun 27 16:39:30 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:39:30 2023 ] Eval epoch: 12
[ Tue Jun 27 16:39:30 2023 ] 	Mean test loss of 625 batches: 1.128681.
[ Tue Jun 27 16:39:30 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:30 2023 ] Training epoch: 13
[ Tue Jun 27 16:39:33 2023 ] 	Training loss: 1.5206.  Training acc: 33.55%.
[ Tue Jun 27 16:39:33 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 16:39:33 2023 ] Eval epoch: 13
[ Tue Jun 27 16:39:34 2023 ] 	Mean test loss of 625 batches: 1.112145.
[ Tue Jun 27 16:39:34 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:34 2023 ] Training epoch: 14
[ Tue Jun 27 16:39:37 2023 ] 	Training loss: 1.5975.  Training acc: 33.18%.
[ Tue Jun 27 16:39:37 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:39:37 2023 ] Eval epoch: 14
[ Tue Jun 27 16:39:37 2023 ] 	Mean test loss of 625 batches: 1.116946.
[ Tue Jun 27 16:39:37 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:37 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:37 2023 ] Training epoch: 15
[ Tue Jun 27 16:39:40 2023 ] 	Training loss: 1.5412.  Training acc: 34.01%.
[ Tue Jun 27 16:39:40 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:39:40 2023 ] Eval epoch: 15
[ Tue Jun 27 16:39:41 2023 ] 	Mean test loss of 625 batches: 1.115264.
[ Tue Jun 27 16:39:41 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:41 2023 ] Training epoch: 16
[ Tue Jun 27 16:39:43 2023 ] 	Training loss: 1.5013.  Training acc: 34.47%.
[ Tue Jun 27 16:39:43 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 16:39:43 2023 ] Eval epoch: 16
[ Tue Jun 27 16:39:44 2023 ] 	Mean test loss of 625 batches: 1.116938.
[ Tue Jun 27 16:39:44 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:44 2023 ] Training epoch: 17
[ Tue Jun 27 16:39:47 2023 ] 	Training loss: 1.4987.  Training acc: 33.92%.
[ Tue Jun 27 16:39:47 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 16:39:47 2023 ] Eval epoch: 17
[ Tue Jun 27 16:39:47 2023 ] 	Mean test loss of 625 batches: 1.113127.
[ Tue Jun 27 16:39:47 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:47 2023 ] Training epoch: 18
[ Tue Jun 27 16:39:50 2023 ] 	Training loss: 1.4604.  Training acc: 33.55%.
[ Tue Jun 27 16:39:50 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:39:50 2023 ] Eval epoch: 18
[ Tue Jun 27 16:39:51 2023 ] 	Mean test loss of 625 batches: 1.105438.
[ Tue Jun 27 16:39:51 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:51 2023 ] Training epoch: 19
[ Tue Jun 27 16:39:54 2023 ] 	Training loss: 1.4368.  Training acc: 34.93%.
[ Tue Jun 27 16:39:54 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 16:39:54 2023 ] Eval epoch: 19
[ Tue Jun 27 16:39:54 2023 ] 	Mean test loss of 625 batches: 1.117538.
[ Tue Jun 27 16:39:54 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:54 2023 ] Training epoch: 20
[ Tue Jun 27 16:39:57 2023 ] 	Training loss: 1.3810.  Training acc: 36.67%.
[ Tue Jun 27 16:39:57 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:39:57 2023 ] Eval epoch: 20
[ Tue Jun 27 16:39:58 2023 ] 	Mean test loss of 625 batches: 1.115069.
[ Tue Jun 27 16:39:58 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:39:58 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:39:58 2023 ] Training epoch: 21
[ Tue Jun 27 16:40:00 2023 ] 	Training loss: 1.3759.  Training acc: 35.94%.
[ Tue Jun 27 16:40:00 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 16:40:00 2023 ] Eval epoch: 21
[ Tue Jun 27 16:40:01 2023 ] 	Mean test loss of 625 batches: 1.113885.
[ Tue Jun 27 16:40:01 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:01 2023 ] Training epoch: 22
[ Tue Jun 27 16:40:04 2023 ] 	Training loss: 1.3633.  Training acc: 34.83%.
[ Tue Jun 27 16:40:04 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 16:40:04 2023 ] Eval epoch: 22
[ Tue Jun 27 16:40:04 2023 ] 	Mean test loss of 625 batches: 1.112991.
[ Tue Jun 27 16:40:04 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:04 2023 ] Training epoch: 23
[ Tue Jun 27 16:40:07 2023 ] 	Training loss: 1.3563.  Training acc: 36.95%.
[ Tue Jun 27 16:40:07 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:40:07 2023 ] Eval epoch: 23
[ Tue Jun 27 16:40:07 2023 ] 	Mean test loss of 625 batches: 1.111542.
[ Tue Jun 27 16:40:07 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:07 2023 ] Training epoch: 24
[ Tue Jun 27 16:40:10 2023 ] 	Training loss: 1.3624.  Training acc: 35.02%.
[ Tue Jun 27 16:40:10 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:40:10 2023 ] Eval epoch: 24
[ Tue Jun 27 16:40:11 2023 ] 	Mean test loss of 625 batches: 1.111578.
[ Tue Jun 27 16:40:11 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:11 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:11 2023 ] Training epoch: 25
[ Tue Jun 27 16:40:13 2023 ] 	Training loss: 1.3783.  Training acc: 34.01%.
[ Tue Jun 27 16:40:13 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 16:40:13 2023 ] Eval epoch: 25
[ Tue Jun 27 16:40:14 2023 ] 	Mean test loss of 625 batches: 1.113083.
[ Tue Jun 27 16:40:14 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:14 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:14 2023 ] Training epoch: 26
[ Tue Jun 27 16:40:17 2023 ] 	Training loss: 1.3659.  Training acc: 36.31%.
[ Tue Jun 27 16:40:17 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 16:40:17 2023 ] Eval epoch: 26
[ Tue Jun 27 16:40:17 2023 ] 	Mean test loss of 625 batches: 1.112188.
[ Tue Jun 27 16:40:17 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:17 2023 ] Training epoch: 27
[ Tue Jun 27 16:40:20 2023 ] 	Training loss: 1.4055.  Training acc: 32.90%.
[ Tue Jun 27 16:40:20 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Tue Jun 27 16:40:20 2023 ] Eval epoch: 27
[ Tue Jun 27 16:40:21 2023 ] 	Mean test loss of 625 batches: 1.111092.
[ Tue Jun 27 16:40:21 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:21 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:21 2023 ] Training epoch: 28
[ Tue Jun 27 16:40:24 2023 ] 	Training loss: 1.3367.  Training acc: 35.20%.
[ Tue Jun 27 16:40:24 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:40:24 2023 ] Eval epoch: 28
[ Tue Jun 27 16:40:24 2023 ] 	Mean test loss of 625 batches: 1.112015.
[ Tue Jun 27 16:40:24 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:24 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:24 2023 ] Training epoch: 29
[ Tue Jun 27 16:40:27 2023 ] 	Training loss: 1.3614.  Training acc: 36.12%.
[ Tue Jun 27 16:40:27 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 16:40:27 2023 ] Eval epoch: 29
[ Tue Jun 27 16:40:28 2023 ] 	Mean test loss of 625 batches: 1.111970.
[ Tue Jun 27 16:40:28 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:28 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:28 2023 ] Training epoch: 30
[ Tue Jun 27 16:40:30 2023 ] 	Training loss: 1.3282.  Training acc: 35.11%.
[ Tue Jun 27 16:40:30 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:40:30 2023 ] Eval epoch: 30
[ Tue Jun 27 16:40:31 2023 ] 	Mean test loss of 625 batches: 1.113564.
[ Tue Jun 27 16:40:31 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:31 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:31 2023 ] Training epoch: 31
[ Tue Jun 27 16:40:34 2023 ] 	Training loss: 1.3830.  Training acc: 34.19%.
[ Tue Jun 27 16:40:34 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 16:40:34 2023 ] Eval epoch: 31
[ Tue Jun 27 16:40:34 2023 ] 	Mean test loss of 625 batches: 1.112845.
[ Tue Jun 27 16:40:34 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:34 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:34 2023 ] Training epoch: 32
[ Tue Jun 27 16:40:37 2023 ] 	Training loss: 1.3601.  Training acc: 34.93%.
[ Tue Jun 27 16:40:37 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 16:40:37 2023 ] Eval epoch: 32
[ Tue Jun 27 16:40:38 2023 ] 	Mean test loss of 625 batches: 1.112254.
[ Tue Jun 27 16:40:38 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:38 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:38 2023 ] Training epoch: 33
[ Tue Jun 27 16:40:40 2023 ] 	Training loss: 1.3180.  Training acc: 36.12%.
[ Tue Jun 27 16:40:40 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:40:40 2023 ] Eval epoch: 33
[ Tue Jun 27 16:40:41 2023 ] 	Mean test loss of 625 batches: 1.112147.
[ Tue Jun 27 16:40:41 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:41 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:41 2023 ] Training epoch: 34
[ Tue Jun 27 16:40:44 2023 ] 	Training loss: 1.3534.  Training acc: 32.17%.
[ Tue Jun 27 16:40:44 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 16:40:44 2023 ] Eval epoch: 34
[ Tue Jun 27 16:40:45 2023 ] 	Mean test loss of 625 batches: 1.110738.
[ Tue Jun 27 16:40:45 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:45 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:45 2023 ] Training epoch: 35
[ Tue Jun 27 16:40:47 2023 ] 	Training loss: 1.3361.  Training acc: 34.28%.
[ Tue Jun 27 16:40:47 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:40:47 2023 ] Eval epoch: 35
[ Tue Jun 27 16:40:48 2023 ] 	Mean test loss of 625 batches: 1.109112.
[ Tue Jun 27 16:40:48 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:48 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:48 2023 ] Training epoch: 36
[ Tue Jun 27 16:40:50 2023 ] 	Training loss: 1.3477.  Training acc: 34.83%.
[ Tue Jun 27 16:40:50 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:40:50 2023 ] Eval epoch: 36
[ Tue Jun 27 16:40:51 2023 ] 	Mean test loss of 625 batches: 1.109347.
[ Tue Jun 27 16:40:51 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:51 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:51 2023 ] Training epoch: 37
[ Tue Jun 27 16:40:53 2023 ] 	Training loss: 1.3673.  Training acc: 33.92%.
[ Tue Jun 27 16:40:53 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:40:53 2023 ] Eval epoch: 37
[ Tue Jun 27 16:40:54 2023 ] 	Mean test loss of 625 batches: 1.108706.
[ Tue Jun 27 16:40:54 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:54 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:54 2023 ] Training epoch: 38
[ Tue Jun 27 16:40:57 2023 ] 	Training loss: 1.3137.  Training acc: 37.22%.
[ Tue Jun 27 16:40:57 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 16:40:57 2023 ] Eval epoch: 38
[ Tue Jun 27 16:40:57 2023 ] 	Mean test loss of 625 batches: 1.107911.
[ Tue Jun 27 16:40:57 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:40:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:40:57 2023 ] Training epoch: 39
[ Tue Jun 27 16:41:00 2023 ] 	Training loss: 1.3351.  Training acc: 35.29%.
[ Tue Jun 27 16:41:00 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:41:00 2023 ] Eval epoch: 39
[ Tue Jun 27 16:41:01 2023 ] 	Mean test loss of 625 batches: 1.108959.
[ Tue Jun 27 16:41:01 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:41:01 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:41:01 2023 ] Training epoch: 40
[ Tue Jun 27 16:41:03 2023 ] 	Training loss: 1.3692.  Training acc: 32.63%.
[ Tue Jun 27 16:41:03 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:41:03 2023 ] Eval epoch: 40
[ Tue Jun 27 16:41:04 2023 ] 	Mean test loss of 625 batches: 1.110316.
[ Tue Jun 27 16:41:04 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:41:04 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:41:05 2023 ] Best accuracy: 0.38596491228070173
[ Tue Jun 27 16:41:05 2023 ] Epoch number: 4
[ Tue Jun 27 16:41:05 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 16:41:05 2023 ] Weight decay: 0.0005
[ Tue Jun 27 16:41:05 2023 ] Base LR: 0.1
[ Tue Jun 27 16:41:05 2023 ] Batch Size: 64
[ Tue Jun 27 16:41:05 2023 ] Test Batch Size: 64
[ Tue Jun 27 16:41:05 2023 ] seed: 1
[ Tue Jun 27 16:41:05 2023 ] Start training Corrector
[ Tue Jun 27 16:41:06 2023 ] Training epoch: 1
[ Tue Jun 27 16:41:14 2023 ] 	Training loss: 137.9819.  Training acc: 33.20%.
[ Tue Jun 27 16:41:14 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Jun 27 16:41:15 2023 ] Training epoch: 2
[ Tue Jun 27 16:41:22 2023 ] 	Training loss: 95.9971.  Training acc: 33.20%.
[ Tue Jun 27 16:41:22 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Tue Jun 27 16:41:22 2023 ] Training epoch: 3
[ Tue Jun 27 16:41:28 2023 ] 	Training loss: 74.1226.  Training acc: 33.20%.
[ Tue Jun 27 16:41:28 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Jun 27 16:41:29 2023 ] Training epoch: 4
[ Tue Jun 27 16:41:34 2023 ] 	Training loss: 63.3482.  Training acc: 32.94%.
[ Tue Jun 27 16:41:34 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 27 16:41:35 2023 ] Training epoch: 5
[ Tue Jun 27 16:41:41 2023 ] 	Training loss: 59.9819.  Training acc: 33.07%.
[ Tue Jun 27 16:41:41 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:41:41 2023 ] Training epoch: 6
[ Tue Jun 27 16:41:47 2023 ] 	Training loss: 59.2924.  Training acc: 33.07%.
[ Tue Jun 27 16:41:47 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 16:41:47 2023 ] Training epoch: 7
[ Tue Jun 27 16:41:54 2023 ] 	Training loss: 57.8502.  Training acc: 33.20%.
[ Tue Jun 27 16:41:54 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:41:54 2023 ] Training epoch: 8
[ Tue Jun 27 16:42:01 2023 ] 	Training loss: 58.0435.  Training acc: 33.20%.
[ Tue Jun 27 16:42:01 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:42:02 2023 ] Training epoch: 9
[ Tue Jun 27 16:42:08 2023 ] 	Training loss: 58.0429.  Training acc: 33.20%.
[ Tue Jun 27 16:42:08 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:42:09 2023 ] Training epoch: 10
[ Tue Jun 27 16:42:16 2023 ] 	Training loss: 56.2364.  Training acc: 33.20%.
[ Tue Jun 27 16:42:16 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:42:16 2023 ] Training epoch: 11
[ Tue Jun 27 16:42:23 2023 ] 	Training loss: 55.9647.  Training acc: 33.20%.
[ Tue Jun 27 16:42:23 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Tue Jun 27 16:42:24 2023 ] Training epoch: 12
[ Tue Jun 27 16:42:30 2023 ] 	Training loss: 55.9594.  Training acc: 33.20%.
[ Tue Jun 27 16:42:30 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:42:31 2023 ] Training epoch: 13
[ Tue Jun 27 16:42:38 2023 ] 	Training loss: 55.5630.  Training acc: 33.20%.
[ Tue Jun 27 16:42:38 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:42:38 2023 ] Training epoch: 14
[ Tue Jun 27 16:42:45 2023 ] 	Training loss: 55.6177.  Training acc: 33.20%.
[ Tue Jun 27 16:42:45 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:42:46 2023 ] Training epoch: 15
[ Tue Jun 27 16:42:53 2023 ] 	Training loss: 57.0349.  Training acc: 33.20%.
[ Tue Jun 27 16:42:53 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:42:53 2023 ] Training epoch: 16
[ Tue Jun 27 16:43:00 2023 ] 	Training loss: 55.4454.  Training acc: 33.07%.
[ Tue Jun 27 16:43:00 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:43:01 2023 ] Training epoch: 17
[ Tue Jun 27 16:43:07 2023 ] 	Training loss: 54.9703.  Training acc: 33.07%.
[ Tue Jun 27 16:43:07 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:43:08 2023 ] Training epoch: 18
[ Tue Jun 27 16:43:14 2023 ] 	Training loss: 55.8560.  Training acc: 33.07%.
[ Tue Jun 27 16:43:14 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:43:15 2023 ] Training epoch: 19
[ Tue Jun 27 16:43:22 2023 ] 	Training loss: 54.4661.  Training acc: 33.20%.
[ Tue Jun 27 16:43:22 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:43:22 2023 ] Training epoch: 20
[ Tue Jun 27 16:43:29 2023 ] 	Training loss: 55.6122.  Training acc: 33.07%.
[ Tue Jun 27 16:43:29 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:43:29 2023 ] Training epoch: 21
[ Tue Jun 27 16:43:35 2023 ] 	Training loss: 56.0763.  Training acc: 33.07%.
[ Tue Jun 27 16:43:35 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:43:36 2023 ] Training epoch: 22
[ Tue Jun 27 16:43:41 2023 ] 	Training loss: 54.4800.  Training acc: 33.07%.
[ Tue Jun 27 16:43:41 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:43:42 2023 ] Training epoch: 23
[ Tue Jun 27 16:43:48 2023 ] 	Training loss: 55.7496.  Training acc: 33.20%.
[ Tue Jun 27 16:43:48 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:43:48 2023 ] Training epoch: 24
[ Tue Jun 27 16:43:54 2023 ] 	Training loss: 54.7143.  Training acc: 32.94%.
[ Tue Jun 27 16:43:54 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:43:55 2023 ] Training epoch: 25
[ Tue Jun 27 16:44:01 2023 ] 	Training loss: 56.8142.  Training acc: 32.94%.
[ Tue Jun 27 16:44:01 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:44:02 2023 ] Training epoch: 26
[ Tue Jun 27 16:44:09 2023 ] 	Training loss: 55.7227.  Training acc: 33.20%.
[ Tue Jun 27 16:44:09 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:44:09 2023 ] Training epoch: 27
[ Tue Jun 27 16:44:16 2023 ] using warm up, epoch: 5
[ Tue Jun 27 16:44:16 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 40, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Tue Jun 27 16:44:16 2023 ] # Parameters Predictor: 1538958
[ Tue Jun 27 16:44:16 2023 ] Start training Predictor
[ Tue Jun 27 16:44:16 2023 ] Training epoch: 1
[ Tue Jun 27 16:44:22 2023 ] 	Training loss: 108.2082.  Training acc: 35.94%.
[ Tue Jun 27 16:44:22 2023 ] 	Time consumption: [Data]05%, [Network]94%
[ Tue Jun 27 16:44:22 2023 ] Eval epoch: 1
[ Tue Jun 27 16:44:23 2023 ] 	Mean test loss of 625 batches: 302.542288.
[ Tue Jun 27 16:44:23 2023 ] 	Top1: 29.82%
[ Tue Jun 27 16:44:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:23 2023 ] Training epoch: 2
[ Tue Jun 27 16:44:25 2023 ] 	Training loss: 8.9051.  Training acc: 36.58%.
[ Tue Jun 27 16:44:25 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:44:25 2023 ] Eval epoch: 2
[ Tue Jun 27 16:44:26 2023 ] 	Mean test loss of 625 batches: 1.563980.
[ Tue Jun 27 16:44:26 2023 ] 	Top1: 31.58%
[ Tue Jun 27 16:44:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:26 2023 ] Training epoch: 3
[ Tue Jun 27 16:44:29 2023 ] 	Training loss: 7.0752.  Training acc: 38.88%.
[ Tue Jun 27 16:44:29 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:44:29 2023 ] Eval epoch: 3
[ Tue Jun 27 16:44:29 2023 ] 	Mean test loss of 625 batches: 3.136811.
[ Tue Jun 27 16:44:29 2023 ] 	Top1: 33.33%
[ Tue Jun 27 16:44:29 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:29 2023 ] Training epoch: 4
[ Tue Jun 27 16:44:32 2023 ] 	Training loss: 6.0475.  Training acc: 42.10%.
[ Tue Jun 27 16:44:32 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:44:32 2023 ] Eval epoch: 4
[ Tue Jun 27 16:44:33 2023 ] 	Mean test loss of 625 batches: 1.228071.
[ Tue Jun 27 16:44:33 2023 ] 	Top1: 64.91%
[ Tue Jun 27 16:44:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:33 2023 ] Training epoch: 5
[ Tue Jun 27 16:44:35 2023 ] 	Training loss: 3.6124.  Training acc: 52.57%.
[ Tue Jun 27 16:44:35 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:44:35 2023 ] Eval epoch: 5
[ Tue Jun 27 16:44:36 2023 ] 	Mean test loss of 625 batches: 1.357995.
[ Tue Jun 27 16:44:36 2023 ] 	Top1: 73.68%
[ Tue Jun 27 16:44:36 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:36 2023 ] Training epoch: 6
[ Tue Jun 27 16:44:39 2023 ] 	Training loss: 3.0785.  Training acc: 57.81%.
[ Tue Jun 27 16:44:39 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 16:44:39 2023 ] Eval epoch: 6
[ Tue Jun 27 16:44:39 2023 ] 	Mean test loss of 625 batches: 1.704206.
[ Tue Jun 27 16:44:39 2023 ] 	Top1: 66.67%
[ Tue Jun 27 16:44:39 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:39 2023 ] Training epoch: 7
[ Tue Jun 27 16:44:42 2023 ] 	Training loss: 2.3870.  Training acc: 57.35%.
[ Tue Jun 27 16:44:42 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 16:44:42 2023 ] Eval epoch: 7
[ Tue Jun 27 16:44:43 2023 ] 	Mean test loss of 625 batches: 4.069230.
[ Tue Jun 27 16:44:43 2023 ] 	Top1: 57.89%
[ Tue Jun 27 16:44:43 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:43 2023 ] Training epoch: 8
[ Tue Jun 27 16:44:45 2023 ] 	Training loss: 1.9207.  Training acc: 62.96%.
[ Tue Jun 27 16:44:45 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:44:45 2023 ] Eval epoch: 8
[ Tue Jun 27 16:44:46 2023 ] 	Mean test loss of 625 batches: 1.633154.
[ Tue Jun 27 16:44:46 2023 ] 	Top1: 52.63%
[ Tue Jun 27 16:44:46 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:46 2023 ] Training epoch: 9
[ Tue Jun 27 16:44:48 2023 ] 	Training loss: 1.2680.  Training acc: 67.28%.
[ Tue Jun 27 16:44:48 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 16:44:48 2023 ] Eval epoch: 9
[ Tue Jun 27 16:44:49 2023 ] 	Mean test loss of 625 batches: 1.120150.
[ Tue Jun 27 16:44:49 2023 ] 	Top1: 66.67%
[ Tue Jun 27 16:44:49 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:49 2023 ] Training epoch: 10
[ Tue Jun 27 16:44:52 2023 ] 	Training loss: 1.2430.  Training acc: 66.54%.
[ Tue Jun 27 16:44:52 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 16:44:52 2023 ] Eval epoch: 10
[ Tue Jun 27 16:44:53 2023 ] 	Mean test loss of 625 batches: 0.637863.
[ Tue Jun 27 16:44:53 2023 ] 	Top1: 82.46%
[ Tue Jun 27 16:44:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:53 2023 ] Training epoch: 11
[ Tue Jun 27 16:44:55 2023 ] 	Training loss: 0.9849.  Training acc: 64.71%.
[ Tue Jun 27 16:44:55 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:44:55 2023 ] Eval epoch: 11
[ Tue Jun 27 16:44:56 2023 ] 	Mean test loss of 625 batches: 0.732453.
[ Tue Jun 27 16:44:56 2023 ] 	Top1: 52.63%
[ Tue Jun 27 16:44:56 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:44:56 2023 ] Training epoch: 12
[ Tue Jun 27 16:44:59 2023 ] 	Training loss: 0.8976.  Training acc: 68.29%.
[ Tue Jun 27 16:44:59 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:44:59 2023 ] Eval epoch: 12
[ Tue Jun 27 16:44:59 2023 ] 	Mean test loss of 625 batches: 0.623756.
[ Tue Jun 27 16:44:59 2023 ] 	Top1: 89.47%
[ Tue Jun 27 16:44:59 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:00 2023 ] Training epoch: 13
[ Tue Jun 27 16:45:02 2023 ] 	Training loss: 0.8146.  Training acc: 76.65%.
[ Tue Jun 27 16:45:02 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 27 16:45:02 2023 ] Eval epoch: 13
[ Tue Jun 27 16:45:03 2023 ] 	Mean test loss of 625 batches: 0.589568.
[ Tue Jun 27 16:45:03 2023 ] 	Top1: 91.23%
[ Tue Jun 27 16:45:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:03 2023 ] Training epoch: 14
[ Tue Jun 27 16:45:06 2023 ] 	Training loss: 0.7634.  Training acc: 79.04%.
[ Tue Jun 27 16:45:06 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 16:45:06 2023 ] Eval epoch: 14
[ Tue Jun 27 16:45:07 2023 ] 	Mean test loss of 625 batches: 0.540452.
[ Tue Jun 27 16:45:07 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:07 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:07 2023 ] Training epoch: 15
[ Tue Jun 27 16:45:09 2023 ] 	Training loss: 0.7508.  Training acc: 79.04%.
[ Tue Jun 27 16:45:09 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:45:09 2023 ] Eval epoch: 15
[ Tue Jun 27 16:45:10 2023 ] 	Mean test loss of 625 batches: 0.519865.
[ Tue Jun 27 16:45:10 2023 ] 	Top1: 98.25%
[ Tue Jun 27 16:45:10 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:10 2023 ] Training epoch: 16
[ Tue Jun 27 16:45:13 2023 ] 	Training loss: 0.7471.  Training acc: 79.87%.
[ Tue Jun 27 16:45:13 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 16:45:13 2023 ] Eval epoch: 16
[ Tue Jun 27 16:45:13 2023 ] 	Mean test loss of 625 batches: 0.515033.
[ Tue Jun 27 16:45:13 2023 ] 	Top1: 94.74%
[ Tue Jun 27 16:45:13 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:13 2023 ] Training epoch: 17
[ Tue Jun 27 16:45:16 2023 ] 	Training loss: 0.7137.  Training acc: 81.43%.
[ Tue Jun 27 16:45:16 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:45:16 2023 ] Eval epoch: 17
[ Tue Jun 27 16:45:17 2023 ] 	Mean test loss of 625 batches: 0.496435.
[ Tue Jun 27 16:45:17 2023 ] 	Top1: 94.74%
[ Tue Jun 27 16:45:17 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:17 2023 ] Training epoch: 18
[ Tue Jun 27 16:45:19 2023 ] 	Training loss: 0.7120.  Training acc: 81.25%.
[ Tue Jun 27 16:45:19 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:45:19 2023 ] Eval epoch: 18
[ Tue Jun 27 16:45:20 2023 ] 	Mean test loss of 625 batches: 0.482237.
[ Tue Jun 27 16:45:20 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:20 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:20 2023 ] Training epoch: 19
[ Tue Jun 27 16:45:23 2023 ] 	Training loss: 0.7164.  Training acc: 82.72%.
[ Tue Jun 27 16:45:23 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:45:23 2023 ] Eval epoch: 19
[ Tue Jun 27 16:45:23 2023 ] 	Mean test loss of 625 batches: 0.477510.
[ Tue Jun 27 16:45:23 2023 ] 	Top1: 98.25%
[ Tue Jun 27 16:45:23 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:23 2023 ] Training epoch: 20
[ Tue Jun 27 16:45:26 2023 ] 	Training loss: 0.6704.  Training acc: 85.02%.
[ Tue Jun 27 16:45:26 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:45:26 2023 ] Eval epoch: 20
[ Tue Jun 27 16:45:26 2023 ] 	Mean test loss of 625 batches: 0.485883.
[ Tue Jun 27 16:45:26 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:26 2023 ] Training epoch: 21
[ Tue Jun 27 16:45:29 2023 ] 	Training loss: 0.6490.  Training acc: 87.68%.
[ Tue Jun 27 16:45:29 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 16:45:29 2023 ] Eval epoch: 21
[ Tue Jun 27 16:45:30 2023 ] 	Mean test loss of 625 batches: 0.490056.
[ Tue Jun 27 16:45:30 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:30 2023 ] Training epoch: 22
[ Tue Jun 27 16:45:33 2023 ] 	Training loss: 0.6632.  Training acc: 85.39%.
[ Tue Jun 27 16:45:33 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:45:33 2023 ] Eval epoch: 22
[ Tue Jun 27 16:45:33 2023 ] 	Mean test loss of 625 batches: 0.491727.
[ Tue Jun 27 16:45:33 2023 ] 	Top1: 98.25%
[ Tue Jun 27 16:45:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:33 2023 ] Training epoch: 23
[ Tue Jun 27 16:45:36 2023 ] 	Training loss: 0.6436.  Training acc: 86.31%.
[ Tue Jun 27 16:45:36 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 27 16:45:36 2023 ] Eval epoch: 23
[ Tue Jun 27 16:45:37 2023 ] 	Mean test loss of 625 batches: 0.492929.
[ Tue Jun 27 16:45:37 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:37 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:37 2023 ] Training epoch: 24
[ Tue Jun 27 16:45:40 2023 ] 	Training loss: 0.6116.  Training acc: 89.61%.
[ Tue Jun 27 16:45:40 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 27 16:45:40 2023 ] Eval epoch: 24
[ Tue Jun 27 16:45:40 2023 ] 	Mean test loss of 625 batches: 0.494638.
[ Tue Jun 27 16:45:40 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:40 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:40 2023 ] Training epoch: 25
[ Tue Jun 27 16:45:43 2023 ] 	Training loss: 0.6249.  Training acc: 87.68%.
[ Tue Jun 27 16:45:43 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 27 16:45:43 2023 ] Eval epoch: 25
[ Tue Jun 27 16:45:44 2023 ] 	Mean test loss of 625 batches: 0.494019.
[ Tue Jun 27 16:45:44 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:44 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:44 2023 ] Training epoch: 26
[ Tue Jun 27 16:45:46 2023 ] 	Training loss: 0.6429.  Training acc: 87.50%.
[ Tue Jun 27 16:45:46 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 16:45:46 2023 ] Eval epoch: 26
[ Tue Jun 27 16:45:47 2023 ] 	Mean test loss of 625 batches: 0.485808.
[ Tue Jun 27 16:45:47 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:47 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:47 2023 ] Training epoch: 27
[ Tue Jun 27 16:45:50 2023 ] 	Training loss: 0.6099.  Training acc: 89.71%.
[ Tue Jun 27 16:45:50 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 16:45:50 2023 ] Eval epoch: 27
[ Tue Jun 27 16:45:50 2023 ] 	Mean test loss of 625 batches: 0.494132.
[ Tue Jun 27 16:45:50 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:50 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:50 2023 ] Training epoch: 28
[ Tue Jun 27 16:45:53 2023 ] 	Training loss: 0.5895.  Training acc: 90.81%.
[ Tue Jun 27 16:45:53 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 27 16:45:53 2023 ] Eval epoch: 28
[ Tue Jun 27 16:45:53 2023 ] 	Mean test loss of 625 batches: 0.476396.
[ Tue Jun 27 16:45:53 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:53 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:53 2023 ] Training epoch: 29
[ Tue Jun 27 16:45:56 2023 ] 	Training loss: 0.5962.  Training acc: 89.71%.
[ Tue Jun 27 16:45:56 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 16:45:56 2023 ] Eval epoch: 29
[ Tue Jun 27 16:45:57 2023 ] 	Mean test loss of 625 batches: 0.480111.
[ Tue Jun 27 16:45:57 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:45:57 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:45:57 2023 ] Training epoch: 30
[ Tue Jun 27 16:45:59 2023 ] 	Training loss: 0.5940.  Training acc: 90.44%.
[ Tue Jun 27 16:45:59 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 27 16:45:59 2023 ] Eval epoch: 30
[ Tue Jun 27 16:46:00 2023 ] 	Mean test loss of 625 batches: 0.491217.
[ Tue Jun 27 16:46:00 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:46:00 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:00 2023 ] Training epoch: 31
[ Tue Jun 27 16:46:02 2023 ] 	Training loss: 0.5860.  Training acc: 89.89%.
[ Tue Jun 27 16:46:02 2023 ] 	Time consumption: [Data]22%, [Network]77%
[ Tue Jun 27 16:46:02 2023 ] Eval epoch: 31
[ Tue Jun 27 16:46:03 2023 ] 	Mean test loss of 625 batches: 0.484751.
[ Tue Jun 27 16:46:03 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:46:03 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:03 2023 ] Training epoch: 32
[ Tue Jun 27 16:46:05 2023 ] 	Training loss: 0.6075.  Training acc: 88.33%.
[ Tue Jun 27 16:46:05 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Tue Jun 27 16:46:05 2023 ] Eval epoch: 32
[ Tue Jun 27 16:46:06 2023 ] 	Mean test loss of 625 batches: 0.492199.
[ Tue Jun 27 16:46:06 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:46:06 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:06 2023 ] Training epoch: 33
[ Tue Jun 27 16:46:09 2023 ] 	Training loss: 0.5733.  Training acc: 91.08%.
[ Tue Jun 27 16:46:09 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 16:46:09 2023 ] Eval epoch: 33
[ Tue Jun 27 16:46:09 2023 ] 	Mean test loss of 625 batches: 0.482159.
[ Tue Jun 27 16:46:09 2023 ] 	Top1: 98.25%
[ Tue Jun 27 16:46:09 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:09 2023 ] Training epoch: 34
[ Tue Jun 27 16:46:12 2023 ] 	Training loss: 0.5816.  Training acc: 90.99%.
[ Tue Jun 27 16:46:12 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 16:46:12 2023 ] Eval epoch: 34
[ Tue Jun 27 16:46:12 2023 ] 	Mean test loss of 625 batches: 0.471858.
[ Tue Jun 27 16:46:12 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:46:12 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:12 2023 ] Training epoch: 35
[ Tue Jun 27 16:46:15 2023 ] 	Training loss: 0.5772.  Training acc: 91.45%.
[ Tue Jun 27 16:46:15 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 27 16:46:15 2023 ] Eval epoch: 35
[ Tue Jun 27 16:46:15 2023 ] 	Mean test loss of 625 batches: 0.479939.
[ Tue Jun 27 16:46:15 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:46:15 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:15 2023 ] Training epoch: 36
[ Tue Jun 27 16:46:18 2023 ] 	Training loss: 0.5778.  Training acc: 91.36%.
[ Tue Jun 27 16:46:18 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 27 16:46:18 2023 ] Eval epoch: 36
[ Tue Jun 27 16:46:19 2023 ] 	Mean test loss of 625 batches: 0.484988.
[ Tue Jun 27 16:46:19 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:46:19 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:19 2023 ] Training epoch: 37
[ Tue Jun 27 16:46:22 2023 ] 	Training loss: 0.5800.  Training acc: 91.82%.
[ Tue Jun 27 16:46:22 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 16:46:22 2023 ] Eval epoch: 37
[ Tue Jun 27 16:46:22 2023 ] 	Mean test loss of 625 batches: 0.475576.
[ Tue Jun 27 16:46:22 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:46:22 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:22 2023 ] Training epoch: 38
[ Tue Jun 27 16:46:25 2023 ] 	Training loss: 0.5862.  Training acc: 90.62%.
[ Tue Jun 27 16:46:25 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 27 16:46:25 2023 ] Eval epoch: 38
[ Tue Jun 27 16:46:26 2023 ] 	Mean test loss of 625 batches: 0.475372.
[ Tue Jun 27 16:46:26 2023 ] 	Top1: 96.49%
[ Tue Jun 27 16:46:26 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:26 2023 ] Training epoch: 39
[ Tue Jun 27 16:46:29 2023 ] 	Training loss: 0.5889.  Training acc: 90.99%.
[ Tue Jun 27 16:46:29 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 16:46:29 2023 ] Eval epoch: 39
[ Tue Jun 27 16:46:30 2023 ] 	Mean test loss of 625 batches: 0.476237.
[ Tue Jun 27 16:46:30 2023 ] 	Top1: 98.25%
[ Tue Jun 27 16:46:30 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:30 2023 ] Training epoch: 40
[ Tue Jun 27 16:46:32 2023 ] 	Training loss: 0.5982.  Training acc: 89.80%.
[ Tue Jun 27 16:46:32 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 27 16:46:32 2023 ] Eval epoch: 40
[ Tue Jun 27 16:46:33 2023 ] 	Mean test loss of 625 batches: 0.488101.
[ Tue Jun 27 16:46:33 2023 ] 	Top1: 98.25%
[ Tue Jun 27 16:46:33 2023 ] 	Top5: 100.00%
[ Tue Jun 27 16:46:34 2023 ] Best accuracy: 0.9824561403508771
[ Tue Jun 27 16:46:34 2023 ] Epoch number: 15
[ Tue Jun 27 16:46:34 2023 ] Model name: results/ec3d_EC3D
[ Tue Jun 27 16:46:34 2023 ] Weight decay: 0.0005
[ Tue Jun 27 16:46:34 2023 ] Base LR: 0.1
[ Tue Jun 27 16:46:34 2023 ] Batch Size: 64
[ Tue Jun 27 16:46:34 2023 ] Test Batch Size: 64
[ Tue Jun 27 16:46:34 2023 ] seed: 1
[ Tue Jun 27 16:46:34 2023 ] Start training Corrector
[ Tue Jun 27 16:46:36 2023 ] Training epoch: 1
[ Tue Jun 27 16:46:45 2023 ] 	Training loss: 136.7540.  Training acc: 38.28%.
[ Tue Jun 27 16:46:45 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Jun 27 16:46:45 2023 ] Training epoch: 2
[ Tue Jun 27 16:46:52 2023 ] 	Training loss: 98.3876.  Training acc: 25.52%.
[ Tue Jun 27 16:46:52 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:46:53 2023 ] Training epoch: 3
[ Tue Jun 27 16:47:00 2023 ] 	Training loss: 71.0875.  Training acc: 38.15%.
[ Tue Jun 27 16:47:00 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:47:01 2023 ] Training epoch: 4
[ Tue Jun 27 16:47:08 2023 ] 	Training loss: 60.9122.  Training acc: 45.18%.
[ Tue Jun 27 16:47:08 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:47:09 2023 ] Training epoch: 5
[ Tue Jun 27 16:47:16 2023 ] 	Training loss: 59.0259.  Training acc: 57.29%.
[ Tue Jun 27 16:47:16 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:47:16 2023 ] Training epoch: 6
[ Tue Jun 27 16:47:23 2023 ] 	Training loss: 58.2735.  Training acc: 71.61%.
[ Tue Jun 27 16:47:23 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:47:24 2023 ] Training epoch: 7
[ Tue Jun 27 16:47:31 2023 ] 	Training loss: 57.1343.  Training acc: 68.62%.
[ Tue Jun 27 16:47:31 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:47:32 2023 ] Training epoch: 8
[ Tue Jun 27 16:47:39 2023 ] 	Training loss: 55.2864.  Training acc: 67.71%.
[ Tue Jun 27 16:47:39 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:47:40 2023 ] Training epoch: 9
[ Tue Jun 27 16:47:46 2023 ] 	Training loss: 56.0683.  Training acc: 61.85%.
[ Tue Jun 27 16:47:46 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:47:47 2023 ] Training epoch: 10
[ Tue Jun 27 16:47:54 2023 ] 	Training loss: 55.0072.  Training acc: 65.36%.
[ Tue Jun 27 16:47:54 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 27 16:47:55 2023 ] Training epoch: 11
[ Tue Jun 27 16:48:01 2023 ] 	Training loss: 54.6783.  Training acc: 76.43%.
[ Tue Jun 27 16:48:01 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:48:02 2023 ] Training epoch: 12
[ Tue Jun 27 16:48:08 2023 ] 	Training loss: 54.0312.  Training acc: 78.78%.
[ Tue Jun 27 16:48:08 2023 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Jun 27 16:48:09 2023 ] Training epoch: 13
[ Tue Jun 27 16:48:15 2023 ] 	Training loss: 53.4197.  Training acc: 86.85%.
[ Tue Jun 27 16:48:15 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 16:48:15 2023 ] Training epoch: 14
[ Tue Jun 27 16:48:21 2023 ] 	Training loss: 54.4341.  Training acc: 84.77%.
[ Tue Jun 27 16:48:21 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:48:22 2023 ] Training epoch: 15
[ Tue Jun 27 16:48:29 2023 ] 	Training loss: 54.7670.  Training acc: 80.60%.
[ Tue Jun 27 16:48:29 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Jun 27 16:48:30 2023 ] Training epoch: 16
[ Tue Jun 27 16:48:37 2023 ] 	Training loss: 53.8731.  Training acc: 81.51%.
[ Tue Jun 27 16:48:37 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:48:38 2023 ] Training epoch: 17
[ Tue Jun 27 16:48:45 2023 ] 	Training loss: 53.5563.  Training acc: 82.55%.
[ Tue Jun 27 16:48:45 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:48:45 2023 ] Training epoch: 18
[ Tue Jun 27 16:48:52 2023 ] 	Training loss: 54.5901.  Training acc: 81.64%.
[ Tue Jun 27 16:48:52 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:48:53 2023 ] Training epoch: 19
[ Tue Jun 27 16:49:00 2023 ] 	Training loss: 53.0476.  Training acc: 83.20%.
[ Tue Jun 27 16:49:00 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:49:01 2023 ] Training epoch: 20
[ Tue Jun 27 16:49:08 2023 ] 	Training loss: 54.4973.  Training acc: 79.82%.
[ Tue Jun 27 16:49:08 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:49:09 2023 ] Training epoch: 21
[ Tue Jun 27 16:49:16 2023 ] 	Training loss: 54.4466.  Training acc: 81.90%.
[ Tue Jun 27 16:49:16 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:49:16 2023 ] Training epoch: 22
[ Tue Jun 27 16:49:24 2023 ] 	Training loss: 52.5354.  Training acc: 79.56%.
[ Tue Jun 27 16:49:24 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:49:24 2023 ] Training epoch: 23
[ Tue Jun 27 16:49:32 2023 ] 	Training loss: 53.5847.  Training acc: 80.86%.
[ Tue Jun 27 16:49:32 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:49:32 2023 ] Training epoch: 24
[ Tue Jun 27 16:49:40 2023 ] 	Training loss: 52.6156.  Training acc: 82.94%.
[ Tue Jun 27 16:49:40 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:49:40 2023 ] Training epoch: 25
[ Tue Jun 27 16:49:48 2023 ] 	Training loss: 53.7918.  Training acc: 85.03%.
[ Tue Jun 27 16:49:48 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:49:48 2023 ] Training epoch: 26
[ Tue Jun 27 16:49:56 2023 ] 	Training loss: 53.9902.  Training acc: 85.94%.
[ Tue Jun 27 16:49:56 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:49:56 2023 ] Training epoch: 27
[ Tue Jun 27 16:50:03 2023 ] 	Training loss: 54.7478.  Training acc: 84.77%.
[ Tue Jun 27 16:50:03 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:50:04 2023 ] Training epoch: 28
[ Tue Jun 27 16:50:10 2023 ] 	Training loss: 53.2491.  Training acc: 86.33%.
[ Tue Jun 27 16:50:10 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 16:50:11 2023 ] Training epoch: 29
[ Tue Jun 27 16:50:17 2023 ] 	Training loss: 52.8424.  Training acc: 83.72%.
[ Tue Jun 27 16:50:17 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 27 16:50:18 2023 ] Training epoch: 30
[ Tue Jun 27 16:50:24 2023 ] 	Training loss: 53.7882.  Training acc: 84.90%.
[ Tue Jun 27 16:50:24 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:50:25 2023 ] Training epoch: 31
[ Tue Jun 27 16:50:32 2023 ] 	Training loss: 52.4508.  Training acc: 83.07%.
[ Tue Jun 27 16:50:32 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:50:32 2023 ] Training epoch: 32
[ Tue Jun 27 16:50:40 2023 ] 	Training loss: 53.5582.  Training acc: 84.51%.
[ Tue Jun 27 16:50:40 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:50:40 2023 ] Training epoch: 33
[ Tue Jun 27 16:50:48 2023 ] 	Training loss: 54.0900.  Training acc: 87.37%.
[ Tue Jun 27 16:50:48 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:50:48 2023 ] Training epoch: 34
[ Tue Jun 27 16:50:55 2023 ] 	Training loss: 51.8644.  Training acc: 85.16%.
[ Tue Jun 27 16:50:55 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:50:56 2023 ] Training epoch: 35
[ Tue Jun 27 16:51:03 2023 ] 	Training loss: 52.7906.  Training acc: 84.51%.
[ Tue Jun 27 16:51:03 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:51:04 2023 ] Training epoch: 36
[ Tue Jun 27 16:51:11 2023 ] 	Training loss: 51.8439.  Training acc: 83.85%.
[ Tue Jun 27 16:51:11 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 27 16:51:12 2023 ] Training epoch: 37
[ Tue Jun 27 16:51:19 2023 ] 	Training loss: 54.1384.  Training acc: 83.72%.
[ Tue Jun 27 16:51:19 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:51:20 2023 ] Training epoch: 38
[ Tue Jun 27 16:51:27 2023 ] 	Training loss: 54.2299.  Training acc: 79.30%.
[ Tue Jun 27 16:51:27 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Tue Jun 27 16:51:27 2023 ] Training epoch: 39
[ Tue Jun 27 16:51:34 2023 ] 	Training loss: 54.5294.  Training acc: 79.95%.
[ Tue Jun 27 16:51:34 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 27 16:51:35 2023 ] Training epoch: 40
[ Tue Jun 27 16:51:42 2023 ] 	Training loss: 52.7714.  Training acc: 79.82%.
[ Tue Jun 27 16:51:42 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 04:56:57 2023 ] using warm up, epoch: 5
[ Wed Jun 28 04:56:57 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 04:56:57 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 04:56:57 2023 ] Start training Predictor
[ Wed Jun 28 04:56:57 2023 ] Training epoch: 1
[ Wed Jun 28 04:57:03 2023 ] 	Training loss: 114.8588.  Training acc: 34.19%.
[ Wed Jun 28 04:57:03 2023 ] 	Time consumption: [Data]04%, [Network]96%
[ Wed Jun 28 04:57:03 2023 ] Eval epoch: 1
[ Wed Jun 28 04:57:03 2023 ] 	Mean test loss of 625 batches: 2368.378223.
[ Wed Jun 28 04:57:03 2023 ] 	Top1: 29.82%
[ Wed Jun 28 04:57:03 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:57:03 2023 ] Training epoch: 2
[ Wed Jun 28 04:57:06 2023 ] 	Training loss: 12.3848.  Training acc: 34.74%.
[ Wed Jun 28 04:57:06 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 04:57:06 2023 ] Eval epoch: 2
[ Wed Jun 28 04:57:07 2023 ] 	Mean test loss of 625 batches: 2.914329.
[ Wed Jun 28 04:57:07 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:57:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:57:07 2023 ] Training epoch: 3
[ Wed Jun 28 04:57:09 2023 ] 	Training loss: 7.3267.  Training acc: 34.38%.
[ Wed Jun 28 04:57:09 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Jun 28 04:57:09 2023 ] Eval epoch: 3
[ Wed Jun 28 04:57:10 2023 ] 	Mean test loss of 625 batches: 2.483660.
[ Wed Jun 28 04:57:10 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:57:10 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:57:10 2023 ] Training epoch: 4
[ Wed Jun 28 04:57:12 2023 ] 	Training loss: 6.0648.  Training acc: 32.81%.
[ Wed Jun 28 04:57:12 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Jun 28 04:57:12 2023 ] Eval epoch: 4
[ Wed Jun 28 04:57:13 2023 ] 	Mean test loss of 625 batches: 1.791131.
[ Wed Jun 28 04:57:13 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:57:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:57:13 2023 ] Training epoch: 5
[ Wed Jun 28 04:57:15 2023 ] 	Training loss: 5.1312.  Training acc: 35.94%.
[ Wed Jun 28 04:57:15 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 04:57:15 2023 ] Eval epoch: 5
[ Wed Jun 28 04:57:16 2023 ] 	Mean test loss of 625 batches: 1.351008.
[ Wed Jun 28 04:57:16 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:57:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:57:16 2023 ] Training epoch: 6
[ Wed Jun 28 04:57:18 2023 ] 	Training loss: 5.9520.  Training acc: 34.10%.
[ Wed Jun 28 04:57:18 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 04:57:18 2023 ] Eval epoch: 6
[ Wed Jun 28 04:57:19 2023 ] 	Mean test loss of 625 batches: 3.318626.
[ Wed Jun 28 04:57:19 2023 ] 	Top1: 29.82%
[ Wed Jun 28 04:57:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:57:19 2023 ] Training epoch: 7
[ Wed Jun 28 04:57:21 2023 ] 	Training loss: 3.2652.  Training acc: 35.29%.
[ Wed Jun 28 04:57:21 2023 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Jun 28 04:57:21 2023 ] Eval epoch: 7
[ Wed Jun 28 04:57:22 2023 ] 	Mean test loss of 625 batches: 3.322996.
[ Wed Jun 28 04:57:22 2023 ] 	Top1: 38.60%
[ Wed Jun 28 04:57:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:57:22 2023 ] Training epoch: 8
[ Wed Jun 28 04:57:24 2023 ] 	Training loss: 3.0307.  Training acc: 33.18%.
[ Wed Jun 28 04:57:24 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 04:57:24 2023 ] Eval epoch: 8
[ Wed Jun 28 04:57:24 2023 ] 	Mean test loss of 625 batches: 1.273648.
[ Wed Jun 28 04:57:24 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:57:24 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:57:24 2023 ] Training epoch: 9
[ Wed Jun 28 04:57:27 2023 ] 	Training loss: 2.1325.  Training acc: 33.92%.
[ Wed Jun 28 04:57:27 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 04:57:27 2023 ] Eval epoch: 9
[ Wed Jun 28 04:57:27 2023 ] 	Mean test loss of 625 batches: 1.121354.
[ Wed Jun 28 04:57:27 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:57:27 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:57:27 2023 ] Training epoch: 10
[ Wed Jun 28 04:57:30 2023 ] 	Training loss: 1.9619.  Training acc: 34.19%.
[ Wed Jun 28 04:57:30 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Jun 28 04:57:30 2023 ] Eval epoch: 10
[ Wed Jun 28 04:57:30 2023 ] 	Mean test loss of 625 batches: 1.196259.
[ Wed Jun 28 04:57:30 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:57:30 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:57:30 2023 ] Training epoch: 11
[ Wed Jun 28 04:57:32 2023 ] 	Training loss: 1.7372.  Training acc: 32.90%.
[ Wed Jun 28 04:57:32 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 04:57:32 2023 ] Eval epoch: 11
[ Wed Jun 28 04:57:33 2023 ] 	Mean test loss of 625 batches: 1.124442.
[ Wed Jun 28 04:57:33 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:57:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:57:33 2023 ] Training epoch: 12
[ Wed Jun 28 04:57:35 2023 ] 	Training loss: 1.7276.  Training acc: 33.92%.
[ Wed Jun 28 04:57:35 2023 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Jun 28 04:57:35 2023 ] Eval epoch: 12
[ Wed Jun 28 04:57:35 2023 ] 	Mean test loss of 625 batches: 1.120034.
[ Wed Jun 28 04:57:35 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:57:35 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:57:35 2023 ] Training epoch: 13
[ Wed Jun 28 04:57:37 2023 ] 	Training loss: 1.6074.  Training acc: 35.20%.
[ Wed Jun 28 04:57:37 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Wed Jun 28 04:57:37 2023 ] Eval epoch: 13
[ Wed Jun 28 04:57:38 2023 ] 	Mean test loss of 625 batches: 1.143818.
[ Wed Jun 28 04:57:38 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:57:38 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:57:38 2023 ] Training epoch: 14
[ Wed Jun 28 04:57:40 2023 ] 	Training loss: 1.6355.  Training acc: 35.29%.
[ Wed Jun 28 04:57:40 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 04:57:40 2023 ] Eval epoch: 14
[ Wed Jun 28 04:57:41 2023 ] 	Mean test loss of 625 batches: 1.117547.
[ Wed Jun 28 04:57:41 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:57:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:57:41 2023 ] Training epoch: 15
[ Wed Jun 28 04:57:43 2023 ] 	Training loss: 1.6423.  Training acc: 33.36%.
[ Wed Jun 28 04:57:43 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 04:57:43 2023 ] Eval epoch: 15
[ Wed Jun 28 04:57:43 2023 ] 	Mean test loss of 625 batches: 1.115166.
[ Wed Jun 28 04:57:43 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:57:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:57:43 2023 ] Training epoch: 16
[ Wed Jun 28 04:57:45 2023 ] 	Training loss: 1.5792.  Training acc: 34.74%.
[ Wed Jun 28 04:57:45 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Wed Jun 28 04:57:45 2023 ] Eval epoch: 16
[ Wed Jun 28 04:57:46 2023 ] 	Mean test loss of 625 batches: 1.126518.
[ Wed Jun 28 04:57:46 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:57:46 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:57:46 2023 ] Training epoch: 17
[ Wed Jun 28 04:57:48 2023 ] 	Training loss: 1.5927.  Training acc: 33.73%.
[ Wed Jun 28 04:57:48 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Wed Jun 28 04:57:48 2023 ] Eval epoch: 17
[ Wed Jun 28 04:57:48 2023 ] 	Mean test loss of 625 batches: 1.118294.
[ Wed Jun 28 04:57:48 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:57:48 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:57:48 2023 ] Training epoch: 18
[ Wed Jun 28 04:57:50 2023 ] 	Training loss: 1.5387.  Training acc: 35.75%.
[ Wed Jun 28 04:57:50 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Wed Jun 28 04:57:50 2023 ] Eval epoch: 18
[ Wed Jun 28 04:57:51 2023 ] 	Mean test loss of 625 batches: 1.110958.
[ Wed Jun 28 04:57:51 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:57:51 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:57:51 2023 ] Training epoch: 19
[ Wed Jun 28 04:57:53 2023 ] 	Training loss: 1.5355.  Training acc: 33.36%.
[ Wed Jun 28 04:57:53 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Wed Jun 28 04:57:53 2023 ] Eval epoch: 19
[ Wed Jun 28 04:57:53 2023 ] 	Mean test loss of 625 batches: 1.137441.
[ Wed Jun 28 04:57:53 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:57:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:57:54 2023 ] Training epoch: 20
[ Wed Jun 28 04:57:56 2023 ] 	Training loss: 1.4369.  Training acc: 36.49%.
[ Wed Jun 28 04:57:56 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Wed Jun 28 04:57:56 2023 ] Eval epoch: 20
[ Wed Jun 28 04:57:56 2023 ] 	Mean test loss of 625 batches: 1.120962.
[ Wed Jun 28 04:57:56 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:57:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:57:56 2023 ] Training epoch: 21
[ Wed Jun 28 04:57:58 2023 ] 	Training loss: 1.4780.  Training acc: 34.38%.
[ Wed Jun 28 04:57:58 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Wed Jun 28 04:57:58 2023 ] Eval epoch: 21
[ Wed Jun 28 04:57:59 2023 ] 	Mean test loss of 625 batches: 1.118418.
[ Wed Jun 28 04:57:59 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:57:59 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:57:59 2023 ] Training epoch: 22
[ Wed Jun 28 04:58:01 2023 ] 	Training loss: 1.4287.  Training acc: 33.92%.
[ Wed Jun 28 04:58:01 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Wed Jun 28 04:58:01 2023 ] Eval epoch: 22
[ Wed Jun 28 04:58:01 2023 ] 	Mean test loss of 625 batches: 1.113944.
[ Wed Jun 28 04:58:01 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:58:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:58:01 2023 ] Training epoch: 23
[ Wed Jun 28 04:58:04 2023 ] 	Training loss: 1.4345.  Training acc: 35.85%.
[ Wed Jun 28 04:58:04 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Wed Jun 28 04:58:04 2023 ] Eval epoch: 23
[ Wed Jun 28 04:58:04 2023 ] 	Mean test loss of 625 batches: 1.114212.
[ Wed Jun 28 04:58:04 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:58:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:58:04 2023 ] Training epoch: 24
[ Wed Jun 28 04:58:06 2023 ] 	Training loss: 1.4459.  Training acc: 32.81%.
[ Wed Jun 28 04:58:06 2023 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Jun 28 04:58:06 2023 ] Eval epoch: 24
[ Wed Jun 28 04:58:07 2023 ] 	Mean test loss of 625 batches: 1.118151.
[ Wed Jun 28 04:58:07 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:58:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:58:07 2023 ] Training epoch: 25
[ Wed Jun 28 04:58:09 2023 ] 	Training loss: 1.4867.  Training acc: 32.26%.
[ Wed Jun 28 04:58:09 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Wed Jun 28 04:58:09 2023 ] Eval epoch: 25
[ Wed Jun 28 04:58:10 2023 ] 	Mean test loss of 625 batches: 1.123657.
[ Wed Jun 28 04:58:10 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:58:10 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:58:10 2023 ] Training epoch: 26
[ Wed Jun 28 04:58:12 2023 ] 	Training loss: 1.4154.  Training acc: 38.24%.
[ Wed Jun 28 04:58:12 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 04:58:12 2023 ] Eval epoch: 26
[ Wed Jun 28 04:58:13 2023 ] 	Mean test loss of 625 batches: 1.120550.
[ Wed Jun 28 04:58:13 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:58:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:58:13 2023 ] Training epoch: 27
[ Wed Jun 28 04:58:15 2023 ] 	Training loss: 1.4851.  Training acc: 32.44%.
[ Wed Jun 28 04:58:15 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 04:58:15 2023 ] Eval epoch: 27
[ Wed Jun 28 04:58:16 2023 ] 	Mean test loss of 625 batches: 1.120085.
[ Wed Jun 28 04:58:16 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:58:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:58:16 2023 ] Training epoch: 28
[ Wed Jun 28 04:58:19 2023 ] 	Training loss: 1.4120.  Training acc: 37.22%.
[ Wed Jun 28 04:58:19 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 04:58:19 2023 ] Eval epoch: 28
[ Wed Jun 28 04:58:19 2023 ] 	Mean test loss of 625 batches: 1.123432.
[ Wed Jun 28 04:58:19 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:58:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:58:19 2023 ] Training epoch: 29
[ Wed Jun 28 04:58:21 2023 ] 	Training loss: 1.4454.  Training acc: 33.92%.
[ Wed Jun 28 04:58:21 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Jun 28 04:58:21 2023 ] Eval epoch: 29
[ Wed Jun 28 04:58:22 2023 ] 	Mean test loss of 625 batches: 1.122300.
[ Wed Jun 28 04:58:22 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:58:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:58:22 2023 ] Training epoch: 30
[ Wed Jun 28 04:58:24 2023 ] 	Training loss: 1.4054.  Training acc: 35.48%.
[ Wed Jun 28 04:58:24 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 04:58:24 2023 ] Eval epoch: 30
[ Wed Jun 28 04:58:25 2023 ] 	Mean test loss of 625 batches: 1.124576.
[ Wed Jun 28 04:58:25 2023 ] 	Top1: 31.58%
[ Wed Jun 28 04:58:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 04:58:26 2023 ] Best accuracy: 0.38596491228070173
[ Wed Jun 28 04:58:26 2023 ] Epoch number: 7
[ Wed Jun 28 04:58:26 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 04:58:26 2023 ] Weight decay: 0.0005
[ Wed Jun 28 04:58:26 2023 ] Base LR: 0.1
[ Wed Jun 28 04:58:26 2023 ] Batch Size: 64
[ Wed Jun 28 04:58:26 2023 ] Test Batch Size: 64
[ Wed Jun 28 04:58:26 2023 ] seed: 1
[ Wed Jun 28 04:58:26 2023 ] Start training Corrector
[ Wed Jun 28 04:58:27 2023 ] Training epoch: 1
[ Wed Jun 28 04:58:35 2023 ] 	Training loss: 567.5859.  Training acc: 32.94%.
[ Wed Jun 28 04:58:35 2023 ] 	Time consumption: [Data]04%, [Network]96%
[ Wed Jun 28 04:58:35 2023 ] Training epoch: 2
[ Wed Jun 28 04:58:42 2023 ] 	Training loss: 438.3389.  Training acc: 33.07%.
[ Wed Jun 28 04:58:42 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 04:58:42 2023 ] Training epoch: 3
[ Wed Jun 28 04:58:49 2023 ] 	Training loss: 341.7461.  Training acc: 33.07%.
[ Wed Jun 28 04:58:49 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 04:58:49 2023 ] Training epoch: 4
[ Wed Jun 28 04:58:57 2023 ] 	Training loss: 308.8277.  Training acc: 32.94%.
[ Wed Jun 28 04:58:57 2023 ] 	Time consumption: [Data]04%, [Network]96%
[ Wed Jun 28 04:58:57 2023 ] Training epoch: 5
[ Wed Jun 28 04:59:04 2023 ] 	Training loss: 303.8849.  Training acc: 33.20%.
[ Wed Jun 28 04:59:04 2023 ] 	Time consumption: [Data]05%, [Network]94%
[ Wed Jun 28 04:59:04 2023 ] Training epoch: 6
[ Wed Jun 28 04:59:10 2023 ] 	Training loss: 301.3755.  Training acc: 33.07%.
[ Wed Jun 28 04:59:10 2023 ] 	Time consumption: [Data]05%, [Network]94%
[ Wed Jun 28 04:59:11 2023 ] Training epoch: 7
[ Wed Jun 28 04:59:17 2023 ] 	Training loss: 291.3080.  Training acc: 33.20%.
[ Wed Jun 28 04:59:17 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 04:59:17 2023 ] Training epoch: 8
[ Wed Jun 28 04:59:24 2023 ] 	Training loss: 288.9583.  Training acc: 33.07%.
[ Wed Jun 28 04:59:24 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 04:59:24 2023 ] Training epoch: 9
[ Wed Jun 28 04:59:32 2023 ] 	Training loss: 296.9488.  Training acc: 33.07%.
[ Wed Jun 28 04:59:32 2023 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Jun 28 04:59:32 2023 ] Training epoch: 10
[ Wed Jun 28 04:59:39 2023 ] 	Training loss: 298.3924.  Training acc: 33.20%.
[ Wed Jun 28 04:59:39 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 04:59:39 2023 ] Training epoch: 11
[ Wed Jun 28 04:59:46 2023 ] 	Training loss: 293.1243.  Training acc: 33.20%.
[ Wed Jun 28 04:59:46 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 04:59:46 2023 ] Training epoch: 12
[ Wed Jun 28 04:59:52 2023 ] 	Training loss: 291.7962.  Training acc: 33.20%.
[ Wed Jun 28 04:59:52 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 04:59:52 2023 ] Training epoch: 13
[ Wed Jun 28 04:59:58 2023 ] 	Training loss: 285.7204.  Training acc: 33.20%.
[ Wed Jun 28 04:59:58 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 04:59:58 2023 ] Training epoch: 14
[ Wed Jun 28 05:00:04 2023 ] 	Training loss: 284.4077.  Training acc: 32.94%.
[ Wed Jun 28 05:00:04 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 05:00:04 2023 ] Training epoch: 15
[ Wed Jun 28 05:00:10 2023 ] 	Training loss: 286.6666.  Training acc: 33.07%.
[ Wed Jun 28 05:00:10 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 05:00:10 2023 ] Training epoch: 16
[ Wed Jun 28 05:00:15 2023 ] 	Training loss: 294.6952.  Training acc: 33.07%.
[ Wed Jun 28 05:00:15 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 05:00:16 2023 ] Training epoch: 17
[ Wed Jun 28 05:00:22 2023 ] 	Training loss: 292.3915.  Training acc: 33.20%.
[ Wed Jun 28 05:00:22 2023 ] 	Time consumption: [Data]05%, [Network]94%
[ Wed Jun 28 05:00:22 2023 ] Training epoch: 18
[ Wed Jun 28 05:00:29 2023 ] 	Training loss: 282.8513.  Training acc: 33.20%.
[ Wed Jun 28 05:00:29 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 05:00:29 2023 ] Training epoch: 19
[ Wed Jun 28 05:00:37 2023 ] 	Training loss: 288.4763.  Training acc: 33.20%.
[ Wed Jun 28 05:00:37 2023 ] 	Time consumption: [Data]04%, [Network]96%
[ Wed Jun 28 05:00:38 2023 ] Training epoch: 20
[ Wed Jun 28 05:00:44 2023 ] 	Training loss: 286.5962.  Training acc: 33.20%.
[ Wed Jun 28 05:00:44 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 05:00:45 2023 ] Training epoch: 21
[ Wed Jun 28 05:00:51 2023 ] 	Training loss: 288.9193.  Training acc: 33.20%.
[ Wed Jun 28 05:00:51 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 05:00:52 2023 ] Training epoch: 22
[ Wed Jun 28 05:00:58 2023 ] 	Training loss: 286.8067.  Training acc: 33.20%.
[ Wed Jun 28 05:00:58 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 05:00:59 2023 ] Training epoch: 23
[ Wed Jun 28 05:01:05 2023 ] 	Training loss: 284.7495.  Training acc: 33.20%.
[ Wed Jun 28 05:01:05 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 05:01:06 2023 ] Training epoch: 24
[ Wed Jun 28 05:01:14 2023 ] 	Training loss: 288.7772.  Training acc: 33.20%.
[ Wed Jun 28 05:01:14 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 05:01:14 2023 ] Training epoch: 25
[ Wed Jun 28 05:01:20 2023 ] 	Training loss: 290.8295.  Training acc: 33.20%.
[ Wed Jun 28 05:01:20 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 05:01:21 2023 ] Training epoch: 26
[ Wed Jun 28 05:01:27 2023 ] 	Training loss: 284.0035.  Training acc: 33.07%.
[ Wed Jun 28 05:01:27 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 05:01:28 2023 ] Training epoch: 27
[ Wed Jun 28 05:01:34 2023 ] 	Training loss: 283.8224.  Training acc: 33.07%.
[ Wed Jun 28 05:01:34 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 05:01:35 2023 ] Training epoch: 28
[ Wed Jun 28 05:01:42 2023 ] 	Training loss: 290.5157.  Training acc: 33.07%.
[ Wed Jun 28 05:01:42 2023 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Jun 28 05:01:42 2023 ] Training epoch: 29
[ Wed Jun 28 05:01:50 2023 ] 	Training loss: 284.7292.  Training acc: 33.20%.
[ Wed Jun 28 05:01:50 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 05:01:50 2023 ] Training epoch: 30
[ Wed Jun 28 05:01:57 2023 ] 	Training loss: 292.6900.  Training acc: 33.07%.
[ Wed Jun 28 05:01:57 2023 ] 	Time consumption: [Data]05%, [Network]94%
[ Wed Jun 28 05:07:05 2023 ] using warm up, epoch: 5
[ Wed Jun 28 05:07:05 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 05:07:05 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 05:07:05 2023 ] Start training Predictor
[ Wed Jun 28 05:07:05 2023 ] Training epoch: 1
[ Wed Jun 28 05:07:11 2023 ] 	Training loss: 96.4117.  Training acc: 34.74%.
[ Wed Jun 28 05:07:11 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 05:07:11 2023 ] Eval epoch: 1
[ Wed Jun 28 05:07:12 2023 ] 	Mean test loss of 625 batches: 225.669647.
[ Wed Jun 28 05:07:12 2023 ] 	Top1: 38.60%
[ Wed Jun 28 05:07:12 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:07:12 2023 ] Training epoch: 2
[ Wed Jun 28 05:07:14 2023 ] 	Training loss: 9.2096.  Training acc: 32.90%.
[ Wed Jun 28 05:07:14 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 05:07:14 2023 ] Eval epoch: 2
[ Wed Jun 28 05:07:15 2023 ] 	Mean test loss of 625 batches: 1.664725.
[ Wed Jun 28 05:07:15 2023 ] 	Top1: 38.60%
[ Wed Jun 28 05:07:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:07:15 2023 ] Training epoch: 3
[ Wed Jun 28 05:07:17 2023 ] 	Training loss: 7.5035.  Training acc: 35.66%.
[ Wed Jun 28 05:07:17 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 05:07:17 2023 ] Eval epoch: 3
[ Wed Jun 28 05:07:17 2023 ] 	Mean test loss of 625 batches: 1.368725.
[ Wed Jun 28 05:07:17 2023 ] 	Top1: 31.58%
[ Wed Jun 28 05:07:17 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:07:17 2023 ] Training epoch: 4
[ Wed Jun 28 05:07:19 2023 ] 	Training loss: 5.8930.  Training acc: 41.45%.
[ Wed Jun 28 05:07:19 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 05:07:19 2023 ] Eval epoch: 4
[ Wed Jun 28 05:07:20 2023 ] 	Mean test loss of 625 batches: 2.711487.
[ Wed Jun 28 05:07:20 2023 ] 	Top1: 38.60%
[ Wed Jun 28 05:07:20 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:07:20 2023 ] Training epoch: 5
[ Wed Jun 28 05:07:22 2023 ] 	Training loss: 3.4977.  Training acc: 55.51%.
[ Wed Jun 28 05:07:22 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 05:07:22 2023 ] Eval epoch: 5
[ Wed Jun 28 05:07:23 2023 ] 	Mean test loss of 625 batches: 2.942036.
[ Wed Jun 28 05:07:23 2023 ] 	Top1: 66.67%
[ Wed Jun 28 05:07:23 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:07:23 2023 ] Training epoch: 6
[ Wed Jun 28 05:07:25 2023 ] 	Training loss: 2.6907.  Training acc: 59.47%.
[ Wed Jun 28 05:07:25 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 05:07:25 2023 ] Eval epoch: 6
[ Wed Jun 28 05:07:26 2023 ] 	Mean test loss of 625 batches: 2.206701.
[ Wed Jun 28 05:07:26 2023 ] 	Top1: 70.18%
[ Wed Jun 28 05:07:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:07:26 2023 ] Training epoch: 7
[ Wed Jun 28 05:07:28 2023 ] 	Training loss: 1.3528.  Training acc: 69.03%.
[ Wed Jun 28 05:07:28 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 05:07:28 2023 ] Eval epoch: 7
[ Wed Jun 28 05:07:29 2023 ] 	Mean test loss of 625 batches: 0.719794.
[ Wed Jun 28 05:07:29 2023 ] 	Top1: 77.19%
[ Wed Jun 28 05:07:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:07:29 2023 ] Training epoch: 8
[ Wed Jun 28 05:07:31 2023 ] 	Training loss: 1.0566.  Training acc: 74.54%.
[ Wed Jun 28 05:07:31 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 05:07:31 2023 ] Eval epoch: 8
[ Wed Jun 28 05:07:31 2023 ] 	Mean test loss of 625 batches: 0.572862.
[ Wed Jun 28 05:07:31 2023 ] 	Top1: 98.25%
[ Wed Jun 28 05:07:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:07:31 2023 ] Training epoch: 9
[ Wed Jun 28 05:07:34 2023 ] 	Training loss: 0.7163.  Training acc: 86.31%.
[ Wed Jun 28 05:07:34 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 05:07:34 2023 ] Eval epoch: 9
[ Wed Jun 28 05:07:34 2023 ] 	Mean test loss of 625 batches: 0.638427.
[ Wed Jun 28 05:07:34 2023 ] 	Top1: 94.74%
[ Wed Jun 28 05:07:34 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:07:34 2023 ] Training epoch: 10
[ Wed Jun 28 05:07:37 2023 ] 	Training loss: 0.5937.  Training acc: 92.46%.
[ Wed Jun 28 05:07:37 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 05:07:37 2023 ] Eval epoch: 10
[ Wed Jun 28 05:07:37 2023 ] 	Mean test loss of 625 batches: 0.457470.
[ Wed Jun 28 05:07:37 2023 ] 	Top1: 100.00%
[ Wed Jun 28 05:07:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:07:38 2023 ] Training epoch: 11
[ Wed Jun 28 05:07:40 2023 ] 	Training loss: 0.5054.  Training acc: 95.77%.
[ Wed Jun 28 05:07:40 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 05:07:40 2023 ] Eval epoch: 11
[ Wed Jun 28 05:07:40 2023 ] 	Mean test loss of 625 batches: 0.440467.
[ Wed Jun 28 05:07:40 2023 ] 	Top1: 100.00%
[ Wed Jun 28 05:07:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:07:40 2023 ] Training epoch: 12
[ Wed Jun 28 05:07:43 2023 ] 	Training loss: 0.4676.  Training acc: 96.23%.
[ Wed Jun 28 05:07:43 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 05:07:43 2023 ] Eval epoch: 12
[ Wed Jun 28 05:07:43 2023 ] 	Mean test loss of 625 batches: 0.447333.
[ Wed Jun 28 05:07:43 2023 ] 	Top1: 100.00%
[ Wed Jun 28 05:07:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:07:43 2023 ] Training epoch: 13
[ Wed Jun 28 05:07:45 2023 ] 	Training loss: 0.4471.  Training acc: 96.78%.
[ Wed Jun 28 05:07:45 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 05:07:45 2023 ] Eval epoch: 13
[ Wed Jun 28 05:07:46 2023 ] 	Mean test loss of 625 batches: 0.443873.
[ Wed Jun 28 05:07:46 2023 ] 	Top1: 100.00%
[ Wed Jun 28 05:07:46 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:07:46 2023 ] Training epoch: 14
[ Wed Jun 28 05:07:49 2023 ] 	Training loss: 0.4286.  Training acc: 97.79%.
[ Wed Jun 28 05:07:49 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 05:07:49 2023 ] Eval epoch: 14
[ Wed Jun 28 05:07:49 2023 ] 	Mean test loss of 625 batches: 0.448046.
[ Wed Jun 28 05:07:49 2023 ] 	Top1: 100.00%
[ Wed Jun 28 05:07:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:07:49 2023 ] Training epoch: 15
[ Wed Jun 28 05:07:52 2023 ] 	Training loss: 0.4510.  Training acc: 97.43%.
[ Wed Jun 28 05:07:52 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 05:07:52 2023 ] Eval epoch: 15
[ Wed Jun 28 05:07:52 2023 ] 	Mean test loss of 625 batches: 0.449338.
[ Wed Jun 28 05:07:52 2023 ] 	Top1: 100.00%
[ Wed Jun 28 05:07:52 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:07:52 2023 ] Training epoch: 16
[ Wed Jun 28 05:07:55 2023 ] 	Training loss: 0.4559.  Training acc: 96.97%.
[ Wed Jun 28 05:07:55 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 05:07:55 2023 ] Eval epoch: 16
[ Wed Jun 28 05:07:55 2023 ] 	Mean test loss of 625 batches: 0.439442.
[ Wed Jun 28 05:07:55 2023 ] 	Top1: 100.00%
[ Wed Jun 28 05:07:55 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:07:55 2023 ] Training epoch: 17
[ Wed Jun 28 05:07:58 2023 ] 	Training loss: 0.4305.  Training acc: 98.07%.
[ Wed Jun 28 05:07:58 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 05:07:58 2023 ] Eval epoch: 17
[ Wed Jun 28 05:07:59 2023 ] 	Mean test loss of 625 batches: 0.425255.
[ Wed Jun 28 05:07:59 2023 ] 	Top1: 100.00%
[ Wed Jun 28 05:07:59 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:07:59 2023 ] Training epoch: 18
[ Wed Jun 28 05:08:01 2023 ] 	Training loss: 0.4123.  Training acc: 98.81%.
[ Wed Jun 28 05:08:01 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 05:08:01 2023 ] Eval epoch: 18
[ Wed Jun 28 05:08:02 2023 ] 	Mean test loss of 625 batches: 0.428150.
[ Wed Jun 28 05:08:02 2023 ] 	Top1: 100.00%
[ Wed Jun 28 05:08:02 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:08:02 2023 ] Training epoch: 19
[ Wed Jun 28 05:08:04 2023 ] 	Training loss: 0.4414.  Training acc: 98.07%.
[ Wed Jun 28 05:08:04 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Wed Jun 28 05:08:04 2023 ] Eval epoch: 19
[ Wed Jun 28 05:08:05 2023 ] 	Mean test loss of 625 batches: 0.407647.
[ Wed Jun 28 05:08:05 2023 ] 	Top1: 100.00%
[ Wed Jun 28 05:08:05 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:08:05 2023 ] Training epoch: 20
[ Wed Jun 28 05:08:08 2023 ] 	Training loss: 0.4083.  Training acc: 98.62%.
[ Wed Jun 28 05:08:08 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 05:08:08 2023 ] Eval epoch: 20
[ Wed Jun 28 05:08:08 2023 ] 	Mean test loss of 625 batches: 0.393404.
[ Wed Jun 28 05:08:08 2023 ] 	Top1: 100.00%
[ Wed Jun 28 05:08:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:08:08 2023 ] Training epoch: 21
[ Wed Jun 28 05:08:11 2023 ] 	Training loss: 0.3989.  Training acc: 98.90%.
[ Wed Jun 28 05:08:11 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Wed Jun 28 05:08:11 2023 ] Eval epoch: 21
[ Wed Jun 28 05:08:12 2023 ] 	Mean test loss of 625 batches: 0.388950.
[ Wed Jun 28 05:08:12 2023 ] 	Top1: 100.00%
[ Wed Jun 28 05:08:12 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:08:12 2023 ] Training epoch: 22
[ Wed Jun 28 05:08:15 2023 ] 	Training loss: 0.4032.  Training acc: 98.62%.
[ Wed Jun 28 05:08:15 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 05:08:15 2023 ] Eval epoch: 22
[ Wed Jun 28 05:08:15 2023 ] 	Mean test loss of 625 batches: 0.405685.
[ Wed Jun 28 05:08:15 2023 ] 	Top1: 100.00%
[ Wed Jun 28 05:08:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:08:15 2023 ] Training epoch: 23
[ Wed Jun 28 05:08:18 2023 ] 	Training loss: 0.4014.  Training acc: 98.71%.
[ Wed Jun 28 05:08:18 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 05:08:18 2023 ] Eval epoch: 23
[ Wed Jun 28 05:08:18 2023 ] 	Mean test loss of 625 batches: 0.376869.
[ Wed Jun 28 05:08:18 2023 ] 	Top1: 100.00%
[ Wed Jun 28 05:08:18 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:08:18 2023 ] Training epoch: 24
[ Wed Jun 28 05:08:21 2023 ] 	Training loss: 0.3904.  Training acc: 98.90%.
[ Wed Jun 28 05:08:21 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 05:08:21 2023 ] Eval epoch: 24
[ Wed Jun 28 05:08:21 2023 ] 	Mean test loss of 625 batches: 0.389738.
[ Wed Jun 28 05:08:21 2023 ] 	Top1: 100.00%
[ Wed Jun 28 05:08:21 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:08:21 2023 ] Training epoch: 25
[ Wed Jun 28 05:08:24 2023 ] 	Training loss: 0.3943.  Training acc: 98.35%.
[ Wed Jun 28 05:08:24 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Wed Jun 28 05:08:24 2023 ] Eval epoch: 25
[ Wed Jun 28 05:08:24 2023 ] 	Mean test loss of 625 batches: 0.403907.
[ Wed Jun 28 05:08:24 2023 ] 	Top1: 100.00%
[ Wed Jun 28 05:08:24 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:08:24 2023 ] Training epoch: 26
[ Wed Jun 28 05:08:27 2023 ] 	Training loss: 0.4042.  Training acc: 99.08%.
[ Wed Jun 28 05:08:27 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 05:08:27 2023 ] Eval epoch: 26
[ Wed Jun 28 05:08:27 2023 ] 	Mean test loss of 625 batches: 0.398762.
[ Wed Jun 28 05:08:27 2023 ] 	Top1: 100.00%
[ Wed Jun 28 05:08:27 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:08:27 2023 ] Training epoch: 27
[ Wed Jun 28 05:08:30 2023 ] 	Training loss: 0.3894.  Training acc: 98.81%.
[ Wed Jun 28 05:08:30 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 05:08:30 2023 ] Eval epoch: 27
[ Wed Jun 28 05:08:31 2023 ] 	Mean test loss of 625 batches: 0.389777.
[ Wed Jun 28 05:08:31 2023 ] 	Top1: 100.00%
[ Wed Jun 28 05:08:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:08:31 2023 ] Training epoch: 28
[ Wed Jun 28 05:08:33 2023 ] 	Training loss: 0.3807.  Training acc: 98.81%.
[ Wed Jun 28 05:08:33 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 05:08:33 2023 ] Eval epoch: 28
[ Wed Jun 28 05:08:34 2023 ] 	Mean test loss of 625 batches: 0.393093.
[ Wed Jun 28 05:08:34 2023 ] 	Top1: 100.00%
[ Wed Jun 28 05:08:34 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:08:34 2023 ] Training epoch: 29
[ Wed Jun 28 05:08:36 2023 ] 	Training loss: 0.4142.  Training acc: 98.35%.
[ Wed Jun 28 05:08:36 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 05:08:36 2023 ] Eval epoch: 29
[ Wed Jun 28 05:08:37 2023 ] 	Mean test loss of 625 batches: 0.398383.
[ Wed Jun 28 05:08:37 2023 ] 	Top1: 100.00%
[ Wed Jun 28 05:08:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:08:37 2023 ] Training epoch: 30
[ Wed Jun 28 05:08:40 2023 ] 	Training loss: 0.3933.  Training acc: 98.16%.
[ Wed Jun 28 05:08:40 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 05:08:40 2023 ] Eval epoch: 30
[ Wed Jun 28 05:08:40 2023 ] 	Mean test loss of 625 batches: 0.372530.
[ Wed Jun 28 05:08:40 2023 ] 	Top1: 100.00%
[ Wed Jun 28 05:08:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:08:41 2023 ] Best accuracy: 1.0
[ Wed Jun 28 05:08:41 2023 ] Epoch number: 10
[ Wed Jun 28 05:08:41 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 05:08:41 2023 ] Weight decay: 0.0005
[ Wed Jun 28 05:08:41 2023 ] Base LR: 0.1
[ Wed Jun 28 05:08:41 2023 ] Batch Size: 64
[ Wed Jun 28 05:08:41 2023 ] Test Batch Size: 64
[ Wed Jun 28 05:08:41 2023 ] seed: 1
[ Wed Jun 28 05:08:41 2023 ] Start training Corrector
[ Wed Jun 28 05:08:42 2023 ] Training epoch: 1
[ Wed Jun 28 05:08:52 2023 ] 	Training loss: 689.6569.  Training acc: 33.20%.
[ Wed Jun 28 05:08:52 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 05:08:52 2023 ] Training epoch: 2
[ Wed Jun 28 05:08:59 2023 ] 	Training loss: 465.6788.  Training acc: 36.98%.
[ Wed Jun 28 05:08:59 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 05:08:59 2023 ] Training epoch: 3
[ Wed Jun 28 05:09:06 2023 ] 	Training loss: 381.2900.  Training acc: 30.47%.
[ Wed Jun 28 05:09:06 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 05:09:06 2023 ] Training epoch: 4
[ Wed Jun 28 05:09:13 2023 ] 	Training loss: 318.1941.  Training acc: 44.40%.
[ Wed Jun 28 05:09:13 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 05:09:14 2023 ] Training epoch: 5
[ Wed Jun 28 05:09:22 2023 ] 	Training loss: 299.0815.  Training acc: 31.90%.
[ Wed Jun 28 05:09:22 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 05:09:22 2023 ] Training epoch: 6
[ Wed Jun 28 05:09:29 2023 ] 	Training loss: 290.6832.  Training acc: 31.90%.
[ Wed Jun 28 05:09:29 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 05:09:29 2023 ] Training epoch: 7
[ Wed Jun 28 05:09:35 2023 ] 	Training loss: 278.7173.  Training acc: 40.10%.
[ Wed Jun 28 05:09:35 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 05:09:36 2023 ] Training epoch: 8
[ Wed Jun 28 05:09:42 2023 ] 	Training loss: 269.9714.  Training acc: 32.94%.
[ Wed Jun 28 05:09:42 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 05:09:42 2023 ] Training epoch: 9
[ Wed Jun 28 05:09:48 2023 ] 	Training loss: 283.8835.  Training acc: 34.90%.
[ Wed Jun 28 05:09:48 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 05:09:48 2023 ] Training epoch: 10
[ Wed Jun 28 05:09:54 2023 ] 	Training loss: 285.2696.  Training acc: 38.93%.
[ Wed Jun 28 05:09:54 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 05:09:55 2023 ] Training epoch: 11
[ Wed Jun 28 05:10:00 2023 ] 	Training loss: 273.9065.  Training acc: 37.89%.
[ Wed Jun 28 05:10:00 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 05:10:01 2023 ] Training epoch: 12
[ Wed Jun 28 05:10:07 2023 ] 	Training loss: 270.7472.  Training acc: 39.06%.
[ Wed Jun 28 05:10:07 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 05:10:08 2023 ] Training epoch: 13
[ Wed Jun 28 05:10:14 2023 ] 	Training loss: 265.4787.  Training acc: 43.36%.
[ Wed Jun 28 05:10:14 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 05:10:15 2023 ] Training epoch: 14
[ Wed Jun 28 05:10:21 2023 ] 	Training loss: 261.4522.  Training acc: 42.06%.
[ Wed Jun 28 05:10:21 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 05:10:22 2023 ] Training epoch: 15
[ Wed Jun 28 05:10:30 2023 ] 	Training loss: 264.0725.  Training acc: 40.49%.
[ Wed Jun 28 05:10:30 2023 ] 	Time consumption: [Data]05%, [Network]94%
[ Wed Jun 28 05:10:30 2023 ] Training epoch: 16
[ Wed Jun 28 05:10:37 2023 ] 	Training loss: 273.2457.  Training acc: 39.45%.
[ Wed Jun 28 05:10:37 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 05:10:37 2023 ] Training epoch: 17
[ Wed Jun 28 05:10:44 2023 ] 	Training loss: 270.2211.  Training acc: 45.31%.
[ Wed Jun 28 05:10:44 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 05:10:45 2023 ] Training epoch: 18
[ Wed Jun 28 05:10:51 2023 ] 	Training loss: 260.8120.  Training acc: 40.10%.
[ Wed Jun 28 05:10:51 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 05:10:52 2023 ] Training epoch: 19
[ Wed Jun 28 05:10:58 2023 ] 	Training loss: 264.1603.  Training acc: 42.06%.
[ Wed Jun 28 05:10:58 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 05:10:59 2023 ] Training epoch: 20
[ Wed Jun 28 05:11:07 2023 ] 	Training loss: 262.7786.  Training acc: 44.53%.
[ Wed Jun 28 05:11:07 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 05:11:08 2023 ] Training epoch: 21
[ Wed Jun 28 05:11:14 2023 ] 	Training loss: 263.3164.  Training acc: 40.76%.
[ Wed Jun 28 05:11:14 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 05:11:15 2023 ] Training epoch: 22
[ Wed Jun 28 05:11:21 2023 ] 	Training loss: 260.8698.  Training acc: 39.84%.
[ Wed Jun 28 05:11:21 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 05:11:21 2023 ] Training epoch: 23
[ Wed Jun 28 05:11:28 2023 ] 	Training loss: 261.1025.  Training acc: 42.06%.
[ Wed Jun 28 05:11:28 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 05:11:29 2023 ] Training epoch: 24
[ Wed Jun 28 05:11:35 2023 ] 	Training loss: 265.5253.  Training acc: 42.58%.
[ Wed Jun 28 05:11:35 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 05:11:36 2023 ] Training epoch: 25
[ Wed Jun 28 05:11:42 2023 ] 	Training loss: 266.8745.  Training acc: 44.14%.
[ Wed Jun 28 05:11:42 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 05:11:43 2023 ] Training epoch: 26
[ Wed Jun 28 05:11:48 2023 ] 	Training loss: 262.7218.  Training acc: 44.92%.
[ Wed Jun 28 05:11:48 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 05:11:49 2023 ] Training epoch: 27
[ Wed Jun 28 05:11:54 2023 ] 	Training loss: 261.1123.  Training acc: 45.57%.
[ Wed Jun 28 05:11:54 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 05:11:55 2023 ] Training epoch: 28
[ Wed Jun 28 05:12:01 2023 ] 	Training loss: 268.6746.  Training acc: 43.88%.
[ Wed Jun 28 05:12:01 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 05:12:01 2023 ] Training epoch: 29
[ Wed Jun 28 05:12:07 2023 ] 	Training loss: 260.2110.  Training acc: 43.62%.
[ Wed Jun 28 05:12:07 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 05:12:08 2023 ] Training epoch: 30
[ Wed Jun 28 05:12:17 2023 ] 	Training loss: 268.1518.  Training acc: 43.62%.
[ Wed Jun 28 05:12:17 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 05:28:29 2023 ] using warm up, epoch: 5
[ Wed Jun 28 05:28:29 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 05:28:29 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 05:28:29 2023 ] Start training Predictor
[ Wed Jun 28 05:28:29 2023 ] Training epoch: 1
[ Wed Jun 28 05:28:35 2023 ] 	Training loss: 103.5098.  Training acc: 34.74%.
[ Wed Jun 28 05:28:35 2023 ] 	Time consumption: [Data]05%, [Network]94%
[ Wed Jun 28 05:28:35 2023 ] Eval epoch: 1
[ Wed Jun 28 05:28:36 2023 ] 	Mean test loss of 625 batches: 957.840820.
[ Wed Jun 28 05:28:36 2023 ] 	Top1: 29.82%
[ Wed Jun 28 05:28:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:28:36 2023 ] Training epoch: 2
[ Wed Jun 28 05:28:38 2023 ] 	Training loss: 19.9491.  Training acc: 38.60%.
[ Wed Jun 28 05:28:38 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Wed Jun 28 05:28:38 2023 ] Eval epoch: 2
[ Wed Jun 28 05:28:39 2023 ] 	Mean test loss of 625 batches: 28.167355.
[ Wed Jun 28 05:28:39 2023 ] 	Top1: 29.82%
[ Wed Jun 28 05:28:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:28:39 2023 ] Training epoch: 3
[ Wed Jun 28 05:28:41 2023 ] 	Training loss: 9.7117.  Training acc: 38.60%.
[ Wed Jun 28 05:28:41 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Wed Jun 28 05:28:41 2023 ] Eval epoch: 3
[ Wed Jun 28 05:28:42 2023 ] 	Mean test loss of 625 batches: 2.884848.
[ Wed Jun 28 05:28:42 2023 ] 	Top1: 31.58%
[ Wed Jun 28 05:28:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:28:42 2023 ] Training epoch: 4
[ Wed Jun 28 05:28:44 2023 ] 	Training loss: 7.4502.  Training acc: 33.82%.
[ Wed Jun 28 05:28:44 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Wed Jun 28 05:28:44 2023 ] Eval epoch: 4
[ Wed Jun 28 05:28:45 2023 ] 	Mean test loss of 625 batches: 3.120108.
[ Wed Jun 28 05:28:45 2023 ] 	Top1: 38.60%
[ Wed Jun 28 05:28:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:28:45 2023 ] Training epoch: 5
[ Wed Jun 28 05:28:48 2023 ] 	Training loss: 4.8345.  Training acc: 35.57%.
[ Wed Jun 28 05:28:48 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Wed Jun 28 05:28:48 2023 ] Eval epoch: 5
[ Wed Jun 28 05:28:48 2023 ] 	Mean test loss of 625 batches: 1.797571.
[ Wed Jun 28 05:28:48 2023 ] 	Top1: 31.58%
[ Wed Jun 28 05:28:48 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:28:48 2023 ] Training epoch: 6
[ Wed Jun 28 05:28:51 2023 ] 	Training loss: 3.5938.  Training acc: 36.95%.
[ Wed Jun 28 05:28:51 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Wed Jun 28 05:28:51 2023 ] Eval epoch: 6
[ Wed Jun 28 05:28:51 2023 ] 	Mean test loss of 625 batches: 1.094476.
[ Wed Jun 28 05:28:51 2023 ] 	Top1: 54.39%
[ Wed Jun 28 05:28:51 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:28:51 2023 ] Training epoch: 7
[ Wed Jun 28 05:28:54 2023 ] 	Training loss: 2.7525.  Training acc: 41.82%.
[ Wed Jun 28 05:28:54 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Jun 28 05:28:54 2023 ] Eval epoch: 7
[ Wed Jun 28 05:28:55 2023 ] 	Mean test loss of 625 batches: 1.422109.
[ Wed Jun 28 05:28:55 2023 ] 	Top1: 42.11%
[ Wed Jun 28 05:28:55 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:28:55 2023 ] Training epoch: 8
[ Wed Jun 28 05:28:57 2023 ] 	Training loss: 2.2526.  Training acc: 48.25%.
[ Wed Jun 28 05:28:57 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Wed Jun 28 05:28:57 2023 ] Eval epoch: 8
[ Wed Jun 28 05:28:58 2023 ] 	Mean test loss of 625 batches: 1.443109.
[ Wed Jun 28 05:28:58 2023 ] 	Top1: 54.39%
[ Wed Jun 28 05:28:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:28:58 2023 ] Training epoch: 9
[ Wed Jun 28 05:29:00 2023 ] 	Training loss: 1.9145.  Training acc: 47.79%.
[ Wed Jun 28 05:29:00 2023 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Jun 28 05:29:00 2023 ] Eval epoch: 9
[ Wed Jun 28 05:29:01 2023 ] 	Mean test loss of 625 batches: 5.491090.
[ Wed Jun 28 05:29:01 2023 ] 	Top1: 29.82%
[ Wed Jun 28 05:29:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:29:01 2023 ] Training epoch: 10
[ Wed Jun 28 05:29:03 2023 ] 	Training loss: 2.0335.  Training acc: 40.07%.
[ Wed Jun 28 05:29:03 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Wed Jun 28 05:29:03 2023 ] Eval epoch: 10
[ Wed Jun 28 05:29:04 2023 ] 	Mean test loss of 625 batches: 1.385161.
[ Wed Jun 28 05:29:04 2023 ] 	Top1: 31.58%
[ Wed Jun 28 05:29:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:29:04 2023 ] Training epoch: 11
[ Wed Jun 28 05:29:06 2023 ] 	Training loss: 1.5980.  Training acc: 43.20%.
[ Wed Jun 28 05:29:06 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Wed Jun 28 05:29:06 2023 ] Eval epoch: 11
[ Wed Jun 28 05:29:07 2023 ] 	Mean test loss of 625 batches: 1.078083.
[ Wed Jun 28 05:29:07 2023 ] 	Top1: 36.84%
[ Wed Jun 28 05:29:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:29:07 2023 ] Training epoch: 12
[ Wed Jun 28 05:29:09 2023 ] 	Training loss: 1.6214.  Training acc: 41.82%.
[ Wed Jun 28 05:29:09 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 05:29:09 2023 ] Eval epoch: 12
[ Wed Jun 28 05:29:10 2023 ] 	Mean test loss of 625 batches: 0.956189.
[ Wed Jun 28 05:29:10 2023 ] 	Top1: 43.86%
[ Wed Jun 28 05:29:10 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:29:10 2023 ] Training epoch: 13
[ Wed Jun 28 05:29:12 2023 ] 	Training loss: 1.4441.  Training acc: 46.14%.
[ Wed Jun 28 05:29:12 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Wed Jun 28 05:29:12 2023 ] Eval epoch: 13
[ Wed Jun 28 05:29:13 2023 ] 	Mean test loss of 625 batches: 0.928138.
[ Wed Jun 28 05:29:13 2023 ] 	Top1: 50.88%
[ Wed Jun 28 05:29:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:29:13 2023 ] Training epoch: 14
[ Wed Jun 28 05:29:15 2023 ] 	Training loss: 1.4995.  Training acc: 45.22%.
[ Wed Jun 28 05:29:15 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Wed Jun 28 05:29:15 2023 ] Eval epoch: 14
[ Wed Jun 28 05:29:16 2023 ] 	Mean test loss of 625 batches: 0.864013.
[ Wed Jun 28 05:29:16 2023 ] 	Top1: 63.16%
[ Wed Jun 28 05:29:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:29:16 2023 ] Training epoch: 15
[ Wed Jun 28 05:29:19 2023 ] 	Training loss: 1.3276.  Training acc: 47.70%.
[ Wed Jun 28 05:29:19 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Wed Jun 28 05:29:19 2023 ] Eval epoch: 15
[ Wed Jun 28 05:29:19 2023 ] 	Mean test loss of 625 batches: 0.779373.
[ Wed Jun 28 05:29:19 2023 ] 	Top1: 75.44%
[ Wed Jun 28 05:29:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:29:19 2023 ] Training epoch: 16
[ Wed Jun 28 05:29:22 2023 ] 	Training loss: 1.2308.  Training acc: 52.57%.
[ Wed Jun 28 05:29:22 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Wed Jun 28 05:29:22 2023 ] Eval epoch: 16
[ Wed Jun 28 05:29:22 2023 ] 	Mean test loss of 625 batches: 0.658641.
[ Wed Jun 28 05:29:22 2023 ] 	Top1: 87.72%
[ Wed Jun 28 05:29:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:29:22 2023 ] Training epoch: 17
[ Wed Jun 28 05:29:25 2023 ] 	Training loss: 1.1372.  Training acc: 55.88%.
[ Wed Jun 28 05:29:25 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Wed Jun 28 05:29:25 2023 ] Eval epoch: 17
[ Wed Jun 28 05:29:25 2023 ] 	Mean test loss of 625 batches: 0.678077.
[ Wed Jun 28 05:29:25 2023 ] 	Top1: 73.68%
[ Wed Jun 28 05:29:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:29:25 2023 ] Training epoch: 18
[ Wed Jun 28 05:29:28 2023 ] 	Training loss: 1.0496.  Training acc: 60.66%.
[ Wed Jun 28 05:29:28 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Jun 28 05:29:28 2023 ] Eval epoch: 18
[ Wed Jun 28 05:29:29 2023 ] 	Mean test loss of 625 batches: 0.576462.
[ Wed Jun 28 05:29:29 2023 ] 	Top1: 91.23%
[ Wed Jun 28 05:29:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:29:29 2023 ] Training epoch: 19
[ Wed Jun 28 05:29:32 2023 ] 	Training loss: 1.0463.  Training acc: 63.05%.
[ Wed Jun 28 05:29:32 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 05:29:32 2023 ] Eval epoch: 19
[ Wed Jun 28 05:29:32 2023 ] 	Mean test loss of 625 batches: 0.638649.
[ Wed Jun 28 05:29:32 2023 ] 	Top1: 78.95%
[ Wed Jun 28 05:29:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:29:32 2023 ] Training epoch: 20
[ Wed Jun 28 05:29:35 2023 ] 	Training loss: 0.9609.  Training acc: 63.33%.
[ Wed Jun 28 05:29:35 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 05:29:35 2023 ] Eval epoch: 20
[ Wed Jun 28 05:29:35 2023 ] 	Mean test loss of 625 batches: 0.629447.
[ Wed Jun 28 05:29:35 2023 ] 	Top1: 85.96%
[ Wed Jun 28 05:29:35 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:29:35 2023 ] Training epoch: 21
[ Wed Jun 28 05:29:38 2023 ] 	Training loss: 0.8697.  Training acc: 68.66%.
[ Wed Jun 28 05:29:38 2023 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Jun 28 05:29:38 2023 ] Eval epoch: 21
[ Wed Jun 28 05:29:38 2023 ] 	Mean test loss of 625 batches: 0.592189.
[ Wed Jun 28 05:29:38 2023 ] 	Top1: 87.72%
[ Wed Jun 28 05:29:38 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:29:38 2023 ] Training epoch: 22
[ Wed Jun 28 05:29:41 2023 ] 	Training loss: 0.8523.  Training acc: 68.66%.
[ Wed Jun 28 05:29:41 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Wed Jun 28 05:29:41 2023 ] Eval epoch: 22
[ Wed Jun 28 05:29:41 2023 ] 	Mean test loss of 625 batches: 0.612244.
[ Wed Jun 28 05:29:41 2023 ] 	Top1: 84.21%
[ Wed Jun 28 05:29:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:29:41 2023 ] Training epoch: 23
[ Wed Jun 28 05:29:44 2023 ] 	Training loss: 0.8486.  Training acc: 68.20%.
[ Wed Jun 28 05:29:44 2023 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Jun 28 05:29:44 2023 ] Eval epoch: 23
[ Wed Jun 28 05:29:44 2023 ] 	Mean test loss of 625 batches: 0.611114.
[ Wed Jun 28 05:29:44 2023 ] 	Top1: 87.72%
[ Wed Jun 28 05:29:44 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:29:44 2023 ] Training epoch: 24
[ Wed Jun 28 05:29:47 2023 ] 	Training loss: 0.8409.  Training acc: 69.76%.
[ Wed Jun 28 05:29:47 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Wed Jun 28 05:29:47 2023 ] Eval epoch: 24
[ Wed Jun 28 05:29:47 2023 ] 	Mean test loss of 625 batches: 0.615019.
[ Wed Jun 28 05:29:47 2023 ] 	Top1: 84.21%
[ Wed Jun 28 05:29:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:29:47 2023 ] Training epoch: 25
[ Wed Jun 28 05:29:49 2023 ] 	Training loss: 0.8618.  Training acc: 68.84%.
[ Wed Jun 28 05:29:49 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 05:29:49 2023 ] Eval epoch: 25
[ Wed Jun 28 05:29:50 2023 ] 	Mean test loss of 625 batches: 0.626876.
[ Wed Jun 28 05:29:50 2023 ] 	Top1: 85.96%
[ Wed Jun 28 05:29:50 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:29:50 2023 ] Training epoch: 26
[ Wed Jun 28 05:29:52 2023 ] 	Training loss: 0.8084.  Training acc: 70.22%.
[ Wed Jun 28 05:29:52 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 05:29:52 2023 ] Eval epoch: 26
[ Wed Jun 28 05:29:53 2023 ] 	Mean test loss of 625 batches: 0.596069.
[ Wed Jun 28 05:29:53 2023 ] 	Top1: 85.96%
[ Wed Jun 28 05:29:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:29:53 2023 ] Training epoch: 27
[ Wed Jun 28 05:29:55 2023 ] 	Training loss: 0.8474.  Training acc: 69.49%.
[ Wed Jun 28 05:29:55 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 05:29:55 2023 ] Eval epoch: 27
[ Wed Jun 28 05:29:55 2023 ] 	Mean test loss of 625 batches: 0.574249.
[ Wed Jun 28 05:29:55 2023 ] 	Top1: 91.23%
[ Wed Jun 28 05:29:55 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:29:55 2023 ] Training epoch: 28
[ Wed Jun 28 05:29:58 2023 ] 	Training loss: 0.7839.  Training acc: 73.35%.
[ Wed Jun 28 05:29:58 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 05:29:58 2023 ] Eval epoch: 28
[ Wed Jun 28 05:29:58 2023 ] 	Mean test loss of 625 batches: 0.617721.
[ Wed Jun 28 05:29:58 2023 ] 	Top1: 89.47%
[ Wed Jun 28 05:29:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:29:58 2023 ] Training epoch: 29
[ Wed Jun 28 05:30:00 2023 ] 	Training loss: 0.7882.  Training acc: 74.08%.
[ Wed Jun 28 05:30:00 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 05:30:00 2023 ] Eval epoch: 29
[ Wed Jun 28 05:30:01 2023 ] 	Mean test loss of 625 batches: 0.631736.
[ Wed Jun 28 05:30:01 2023 ] 	Top1: 84.21%
[ Wed Jun 28 05:30:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:30:01 2023 ] Training epoch: 30
[ Wed Jun 28 05:30:04 2023 ] 	Training loss: 0.7710.  Training acc: 74.26%.
[ Wed Jun 28 05:30:04 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Wed Jun 28 05:30:04 2023 ] Eval epoch: 30
[ Wed Jun 28 05:30:04 2023 ] 	Mean test loss of 625 batches: 0.616853.
[ Wed Jun 28 05:30:04 2023 ] 	Top1: 87.72%
[ Wed Jun 28 05:30:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:30:05 2023 ] Best accuracy: 0.9122807017543859
[ Wed Jun 28 05:30:05 2023 ] Epoch number: 18
[ Wed Jun 28 05:30:05 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 05:30:05 2023 ] Weight decay: 0.0005
[ Wed Jun 28 05:30:05 2023 ] Base LR: 0.1
[ Wed Jun 28 05:30:05 2023 ] Batch Size: 64
[ Wed Jun 28 05:30:05 2023 ] Test Batch Size: 64
[ Wed Jun 28 05:30:05 2023 ] seed: 1
[ Wed Jun 28 05:30:05 2023 ] Start training Corrector
[ Wed Jun 28 05:30:06 2023 ] Training epoch: 1
[ Wed Jun 28 05:56:38 2023 ] using warm up, epoch: 5
[ Wed Jun 28 05:56:38 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 05:56:38 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 05:56:38 2023 ] Start training Predictor
[ Wed Jun 28 05:56:38 2023 ] Training epoch: 1
[ Wed Jun 28 05:56:43 2023 ] 	Training loss: 104.3968.  Training acc: 34.83%.
[ Wed Jun 28 05:56:43 2023 ] 	Time consumption: [Data]04%, [Network]96%
[ Wed Jun 28 05:56:43 2023 ] Eval epoch: 1
[ Wed Jun 28 05:56:44 2023 ] 	Mean test loss of 625 batches: 384.192010.
[ Wed Jun 28 05:56:44 2023 ] 	Top1: 29.82%
[ Wed Jun 28 05:56:44 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:56:44 2023 ] Training epoch: 2
[ Wed Jun 28 05:56:47 2023 ] 	Training loss: 9.0638.  Training acc: 35.39%.
[ Wed Jun 28 05:56:47 2023 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Jun 28 05:56:47 2023 ] Eval epoch: 2
[ Wed Jun 28 05:56:47 2023 ] 	Mean test loss of 625 batches: 2.751508.
[ Wed Jun 28 05:56:47 2023 ] 	Top1: 31.58%
[ Wed Jun 28 05:56:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:56:47 2023 ] Training epoch: 3
[ Wed Jun 28 05:56:50 2023 ] 	Training loss: 5.9293.  Training acc: 50.28%.
[ Wed Jun 28 05:56:50 2023 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Jun 28 05:56:50 2023 ] Eval epoch: 3
[ Wed Jun 28 05:56:50 2023 ] 	Mean test loss of 625 batches: 19.625386.
[ Wed Jun 28 05:56:50 2023 ] 	Top1: 38.60%
[ Wed Jun 28 05:56:50 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:56:50 2023 ] Training epoch: 4
[ Wed Jun 28 05:56:53 2023 ] 	Training loss: 4.1884.  Training acc: 64.25%.
[ Wed Jun 28 05:56:53 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Wed Jun 28 05:56:53 2023 ] Eval epoch: 4
[ Wed Jun 28 05:56:53 2023 ] 	Mean test loss of 625 batches: 2.457432.
[ Wed Jun 28 05:56:53 2023 ] 	Top1: 57.89%
[ Wed Jun 28 05:56:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:56:54 2023 ] Training epoch: 5
[ Wed Jun 28 05:56:56 2023 ] 	Training loss: 7.1214.  Training acc: 51.38%.
[ Wed Jun 28 05:56:56 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Wed Jun 28 05:56:56 2023 ] Eval epoch: 5
[ Wed Jun 28 05:56:57 2023 ] 	Mean test loss of 625 batches: 4.747120.
[ Wed Jun 28 05:56:57 2023 ] 	Top1: 38.60%
[ Wed Jun 28 05:56:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:56:57 2023 ] Training epoch: 6
[ Wed Jun 28 05:56:59 2023 ] 	Training loss: 5.1422.  Training acc: 34.93%.
[ Wed Jun 28 05:56:59 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Wed Jun 28 05:56:59 2023 ] Eval epoch: 6
[ Wed Jun 28 05:56:59 2023 ] 	Mean test loss of 625 batches: 38.536942.
[ Wed Jun 28 05:56:59 2023 ] 	Top1: 38.60%
[ Wed Jun 28 05:56:59 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:56:59 2023 ] Training epoch: 7
[ Wed Jun 28 05:57:02 2023 ] 	Training loss: 4.1129.  Training acc: 35.29%.
[ Wed Jun 28 05:57:02 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Wed Jun 28 05:57:02 2023 ] Eval epoch: 7
[ Wed Jun 28 05:57:02 2023 ] 	Mean test loss of 625 batches: 1.505023.
[ Wed Jun 28 05:57:02 2023 ] 	Top1: 38.60%
[ Wed Jun 28 05:57:02 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:57:02 2023 ] Training epoch: 8
[ Wed Jun 28 05:57:05 2023 ] 	Training loss: 2.9707.  Training acc: 33.82%.
[ Wed Jun 28 05:57:05 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Wed Jun 28 05:57:05 2023 ] Eval epoch: 8
[ Wed Jun 28 05:57:05 2023 ] 	Mean test loss of 625 batches: 1.301040.
[ Wed Jun 28 05:57:05 2023 ] 	Top1: 38.60%
[ Wed Jun 28 05:57:05 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:57:05 2023 ] Training epoch: 9
[ Wed Jun 28 05:57:08 2023 ] 	Training loss: 2.2312.  Training acc: 33.73%.
[ Wed Jun 28 05:57:08 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 05:57:08 2023 ] Eval epoch: 9
[ Wed Jun 28 05:57:09 2023 ] 	Mean test loss of 625 batches: 1.086546.
[ Wed Jun 28 05:57:09 2023 ] 	Top1: 50.88%
[ Wed Jun 28 05:57:09 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:57:09 2023 ] Training epoch: 10
[ Wed Jun 28 05:57:11 2023 ] 	Training loss: 1.8607.  Training acc: 39.80%.
[ Wed Jun 28 05:57:11 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Wed Jun 28 05:57:11 2023 ] Eval epoch: 10
[ Wed Jun 28 05:57:11 2023 ] 	Mean test loss of 625 batches: 2.466675.
[ Wed Jun 28 05:57:11 2023 ] 	Top1: 47.37%
[ Wed Jun 28 05:57:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:57:11 2023 ] Training epoch: 11
[ Wed Jun 28 05:57:14 2023 ] 	Training loss: 1.4375.  Training acc: 49.36%.
[ Wed Jun 28 05:57:14 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Wed Jun 28 05:57:14 2023 ] Eval epoch: 11
[ Wed Jun 28 05:57:15 2023 ] 	Mean test loss of 625 batches: 1.064850.
[ Wed Jun 28 05:57:15 2023 ] 	Top1: 40.35%
[ Wed Jun 28 05:57:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:57:15 2023 ] Training epoch: 12
[ Wed Jun 28 05:57:17 2023 ] 	Training loss: 1.3694.  Training acc: 51.38%.
[ Wed Jun 28 05:57:17 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 05:57:17 2023 ] Eval epoch: 12
[ Wed Jun 28 05:57:17 2023 ] 	Mean test loss of 625 batches: 1.000579.
[ Wed Jun 28 05:57:17 2023 ] 	Top1: 38.60%
[ Wed Jun 28 05:57:17 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:57:17 2023 ] Training epoch: 13
[ Wed Jun 28 05:57:19 2023 ] 	Training loss: 1.2502.  Training acc: 53.68%.
[ Wed Jun 28 05:57:19 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 05:57:19 2023 ] Eval epoch: 13
[ Wed Jun 28 05:57:20 2023 ] 	Mean test loss of 625 batches: 0.910865.
[ Wed Jun 28 05:57:20 2023 ] 	Top1: 29.82%
[ Wed Jun 28 05:57:20 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:57:20 2023 ] Training epoch: 14
[ Wed Jun 28 05:57:22 2023 ] 	Training loss: 1.2089.  Training acc: 53.86%.
[ Wed Jun 28 05:57:22 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 05:57:22 2023 ] Eval epoch: 14
[ Wed Jun 28 05:57:23 2023 ] 	Mean test loss of 625 batches: 0.948023.
[ Wed Jun 28 05:57:23 2023 ] 	Top1: 66.67%
[ Wed Jun 28 05:57:23 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:57:23 2023 ] Training epoch: 15
[ Wed Jun 28 05:57:25 2023 ] 	Training loss: 1.1506.  Training acc: 56.71%.
[ Wed Jun 28 05:57:25 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 05:57:25 2023 ] Eval epoch: 15
[ Wed Jun 28 05:57:25 2023 ] 	Mean test loss of 625 batches: 0.890246.
[ Wed Jun 28 05:57:25 2023 ] 	Top1: 68.42%
[ Wed Jun 28 05:57:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:57:25 2023 ] Training epoch: 16
[ Wed Jun 28 05:57:28 2023 ] 	Training loss: 1.1111.  Training acc: 59.93%.
[ Wed Jun 28 05:57:28 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 05:57:28 2023 ] Eval epoch: 16
[ Wed Jun 28 05:57:28 2023 ] 	Mean test loss of 625 batches: 0.761457.
[ Wed Jun 28 05:57:28 2023 ] 	Top1: 66.67%
[ Wed Jun 28 05:57:28 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:57:28 2023 ] Training epoch: 17
[ Wed Jun 28 05:57:30 2023 ] 	Training loss: 1.1300.  Training acc: 59.65%.
[ Wed Jun 28 05:57:30 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 05:57:30 2023 ] Eval epoch: 17
[ Wed Jun 28 05:57:31 2023 ] 	Mean test loss of 625 batches: 0.880828.
[ Wed Jun 28 05:57:31 2023 ] 	Top1: 68.42%
[ Wed Jun 28 05:57:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:57:31 2023 ] Training epoch: 18
[ Wed Jun 28 05:57:33 2023 ] 	Training loss: 1.0532.  Training acc: 58.92%.
[ Wed Jun 28 05:57:33 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 05:57:33 2023 ] Eval epoch: 18
[ Wed Jun 28 05:57:33 2023 ] 	Mean test loss of 625 batches: 0.745175.
[ Wed Jun 28 05:57:33 2023 ] 	Top1: 66.67%
[ Wed Jun 28 05:57:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:57:33 2023 ] Training epoch: 19
[ Wed Jun 28 05:57:36 2023 ] 	Training loss: 1.1053.  Training acc: 59.93%.
[ Wed Jun 28 05:57:36 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 05:57:36 2023 ] Eval epoch: 19
[ Wed Jun 28 05:57:36 2023 ] 	Mean test loss of 625 batches: 0.770059.
[ Wed Jun 28 05:57:36 2023 ] 	Top1: 68.42%
[ Wed Jun 28 05:57:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:57:36 2023 ] Training epoch: 20
[ Wed Jun 28 05:57:38 2023 ] 	Training loss: 1.0280.  Training acc: 60.11%.
[ Wed Jun 28 05:57:38 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 05:57:38 2023 ] Eval epoch: 20
[ Wed Jun 28 05:57:39 2023 ] 	Mean test loss of 625 batches: 0.741912.
[ Wed Jun 28 05:57:39 2023 ] 	Top1: 70.18%
[ Wed Jun 28 05:57:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:57:39 2023 ] Training epoch: 21
[ Wed Jun 28 05:57:41 2023 ] 	Training loss: 1.0092.  Training acc: 60.75%.
[ Wed Jun 28 05:57:41 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 05:57:41 2023 ] Eval epoch: 21
[ Wed Jun 28 05:57:42 2023 ] 	Mean test loss of 625 batches: 0.775435.
[ Wed Jun 28 05:57:42 2023 ] 	Top1: 71.93%
[ Wed Jun 28 05:57:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:57:42 2023 ] Training epoch: 22
[ Wed Jun 28 05:57:44 2023 ] 	Training loss: 0.9935.  Training acc: 62.68%.
[ Wed Jun 28 05:57:44 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 05:57:44 2023 ] Eval epoch: 22
[ Wed Jun 28 05:57:45 2023 ] 	Mean test loss of 625 batches: 0.774263.
[ Wed Jun 28 05:57:45 2023 ] 	Top1: 75.44%
[ Wed Jun 28 05:57:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:57:45 2023 ] Training epoch: 23
[ Wed Jun 28 05:57:47 2023 ] 	Training loss: 0.9349.  Training acc: 65.62%.
[ Wed Jun 28 05:57:47 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 05:57:47 2023 ] Eval epoch: 23
[ Wed Jun 28 05:57:48 2023 ] 	Mean test loss of 625 batches: 0.726385.
[ Wed Jun 28 05:57:48 2023 ] 	Top1: 78.95%
[ Wed Jun 28 05:57:48 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:57:48 2023 ] Training epoch: 24
[ Wed Jun 28 05:57:50 2023 ] 	Training loss: 0.9734.  Training acc: 62.68%.
[ Wed Jun 28 05:57:50 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 05:57:50 2023 ] Eval epoch: 24
[ Wed Jun 28 05:57:50 2023 ] 	Mean test loss of 625 batches: 0.763601.
[ Wed Jun 28 05:57:50 2023 ] 	Top1: 80.70%
[ Wed Jun 28 05:57:50 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:57:50 2023 ] Training epoch: 25
[ Wed Jun 28 05:57:53 2023 ] 	Training loss: 0.9671.  Training acc: 63.14%.
[ Wed Jun 28 05:57:53 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 05:57:53 2023 ] Eval epoch: 25
[ Wed Jun 28 05:57:54 2023 ] 	Mean test loss of 625 batches: 0.773015.
[ Wed Jun 28 05:57:54 2023 ] 	Top1: 82.46%
[ Wed Jun 28 05:57:54 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:57:54 2023 ] Training epoch: 26
[ Wed Jun 28 05:57:56 2023 ] 	Training loss: 0.9541.  Training acc: 63.42%.
[ Wed Jun 28 05:57:56 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 05:57:56 2023 ] Eval epoch: 26
[ Wed Jun 28 05:57:57 2023 ] 	Mean test loss of 625 batches: 0.760177.
[ Wed Jun 28 05:57:57 2023 ] 	Top1: 80.70%
[ Wed Jun 28 05:57:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:57:57 2023 ] Training epoch: 27
[ Wed Jun 28 05:58:00 2023 ] 	Training loss: 0.9378.  Training acc: 64.25%.
[ Wed Jun 28 05:58:00 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Wed Jun 28 05:58:00 2023 ] Eval epoch: 27
[ Wed Jun 28 05:58:00 2023 ] 	Mean test loss of 625 batches: 0.739241.
[ Wed Jun 28 05:58:00 2023 ] 	Top1: 77.19%
[ Wed Jun 28 05:58:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:58:00 2023 ] Training epoch: 28
[ Wed Jun 28 05:58:03 2023 ] 	Training loss: 0.9169.  Training acc: 65.53%.
[ Wed Jun 28 05:58:03 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Wed Jun 28 05:58:03 2023 ] Eval epoch: 28
[ Wed Jun 28 05:58:03 2023 ] 	Mean test loss of 625 batches: 0.746695.
[ Wed Jun 28 05:58:03 2023 ] 	Top1: 78.95%
[ Wed Jun 28 05:58:03 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:58:03 2023 ] Training epoch: 29
[ Wed Jun 28 05:58:06 2023 ] 	Training loss: 0.9538.  Training acc: 64.61%.
[ Wed Jun 28 05:58:06 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Wed Jun 28 05:58:06 2023 ] Eval epoch: 29
[ Wed Jun 28 05:58:06 2023 ] 	Mean test loss of 625 batches: 0.730859.
[ Wed Jun 28 05:58:06 2023 ] 	Top1: 75.44%
[ Wed Jun 28 05:58:06 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:58:06 2023 ] Training epoch: 30
[ Wed Jun 28 05:58:09 2023 ] 	Training loss: 0.9083.  Training acc: 66.73%.
[ Wed Jun 28 05:58:09 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 05:58:09 2023 ] Eval epoch: 30
[ Wed Jun 28 05:58:10 2023 ] 	Mean test loss of 625 batches: 0.730786.
[ Wed Jun 28 05:58:10 2023 ] 	Top1: 80.70%
[ Wed Jun 28 05:58:10 2023 ] 	Top5: 100.00%
[ Wed Jun 28 05:58:11 2023 ] Best accuracy: 0.8245614035087719
[ Wed Jun 28 05:58:11 2023 ] Epoch number: 25
[ Wed Jun 28 05:58:11 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 05:58:11 2023 ] Weight decay: 0.0005
[ Wed Jun 28 05:58:11 2023 ] Base LR: 0.1
[ Wed Jun 28 05:58:11 2023 ] Batch Size: 64
[ Wed Jun 28 05:58:11 2023 ] Test Batch Size: 64
[ Wed Jun 28 05:58:11 2023 ] seed: 1
[ Wed Jun 28 05:58:11 2023 ] Start training Corrector
[ Wed Jun 28 05:58:12 2023 ] Training epoch: 1
[ Wed Jun 28 05:58:20 2023 ] 	Training loss: 13.3753.  Training acc: 36.33%.
[ Wed Jun 28 05:58:20 2023 ] 	Time consumption: [Data]04%, [Network]96%
[ Wed Jun 28 05:58:21 2023 ] Training epoch: 2
[ Wed Jun 28 05:58:27 2023 ] 	Training loss: 11.7826.  Training acc: 32.16%.
[ Wed Jun 28 05:58:27 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 05:58:28 2023 ] Training epoch: 3
[ Wed Jun 28 05:58:34 2023 ] 	Training loss: 9.9359.  Training acc: 33.20%.
[ Wed Jun 28 05:58:34 2023 ] 	Time consumption: [Data]05%, [Network]94%
[ Wed Jun 28 05:58:35 2023 ] Training epoch: 4
[ Wed Jun 28 05:58:42 2023 ] 	Training loss: 8.6077.  Training acc: 32.94%.
[ Wed Jun 28 05:58:42 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 05:58:42 2023 ] Training epoch: 5
[ Wed Jun 28 05:58:49 2023 ] 	Training loss: 7.4811.  Training acc: 33.33%.
[ Wed Jun 28 05:58:49 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 05:58:49 2023 ] Training epoch: 6
[ Wed Jun 28 05:58:56 2023 ] 	Training loss: 10.7111.  Training acc: 33.07%.
[ Wed Jun 28 05:58:56 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 05:58:56 2023 ] Training epoch: 7
[ Wed Jun 28 05:59:03 2023 ] 	Training loss: 9.0551.  Training acc: 33.20%.
[ Wed Jun 28 05:59:03 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 05:59:04 2023 ] Training epoch: 8
[ Wed Jun 28 05:59:10 2023 ] 	Training loss: 7.6725.  Training acc: 34.24%.
[ Wed Jun 28 05:59:10 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 05:59:11 2023 ] Training epoch: 9
[ Wed Jun 28 05:59:17 2023 ] 	Training loss: 13.4133.  Training acc: 33.07%.
[ Wed Jun 28 05:59:17 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 05:59:18 2023 ] Training epoch: 10
[ Wed Jun 28 05:59:25 2023 ] 	Training loss: 15.0004.  Training acc: 33.33%.
[ Wed Jun 28 05:59:25 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 05:59:25 2023 ] Training epoch: 11
[ Wed Jun 28 05:59:30 2023 ] 	Training loss: 27.1607.  Training acc: 33.20%.
[ Wed Jun 28 05:59:30 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 05:59:31 2023 ] Training epoch: 12
[ Wed Jun 28 05:59:36 2023 ] 	Training loss: 20.7787.  Training acc: 33.20%.
[ Wed Jun 28 05:59:36 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 05:59:37 2023 ] Training epoch: 13
[ Wed Jun 28 05:59:42 2023 ] 	Training loss: 16.3453.  Training acc: 33.20%.
[ Wed Jun 28 05:59:42 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 05:59:42 2023 ] Training epoch: 14
[ Wed Jun 28 05:59:48 2023 ] 	Training loss: 14.3452.  Training acc: 32.94%.
[ Wed Jun 28 05:59:48 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 05:59:48 2023 ] Training epoch: 15
[ Wed Jun 28 05:59:54 2023 ] 	Training loss: 13.2071.  Training acc: 33.07%.
[ Wed Jun 28 05:59:54 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 05:59:54 2023 ] Training epoch: 16
[ Wed Jun 28 06:00:00 2023 ] 	Training loss: 12.3697.  Training acc: 33.07%.
[ Wed Jun 28 06:00:00 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:00:01 2023 ] Training epoch: 17
[ Wed Jun 28 06:00:08 2023 ] 	Training loss: 11.5869.  Training acc: 33.20%.
[ Wed Jun 28 06:00:08 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 06:00:08 2023 ] Training epoch: 18
[ Wed Jun 28 06:00:15 2023 ] 	Training loss: 10.7809.  Training acc: 33.20%.
[ Wed Jun 28 06:00:15 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 06:00:15 2023 ] Training epoch: 19
[ Wed Jun 28 06:00:24 2023 ] using warm up, epoch: 5
[ Wed Jun 28 06:00:24 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 06:00:24 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 06:00:24 2023 ] Start training Predictor
[ Wed Jun 28 06:00:24 2023 ] Training epoch: 1
[ Wed Jun 28 06:00:30 2023 ] 	Training loss: 113.0724.  Training acc: 34.56%.
[ Wed Jun 28 06:00:30 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 06:00:30 2023 ] Eval epoch: 1
[ Wed Jun 28 06:00:31 2023 ] 	Mean test loss of 625 batches: 22.445303.
[ Wed Jun 28 06:00:31 2023 ] 	Top1: 29.82%
[ Wed Jun 28 06:00:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:00:31 2023 ] Training epoch: 2
[ Wed Jun 28 06:00:33 2023 ] 	Training loss: 8.6017.  Training acc: 33.55%.
[ Wed Jun 28 06:00:33 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 06:00:33 2023 ] Eval epoch: 2
[ Wed Jun 28 06:00:34 2023 ] 	Mean test loss of 625 batches: 6.730123.
[ Wed Jun 28 06:00:34 2023 ] 	Top1: 29.82%
[ Wed Jun 28 06:00:34 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:00:34 2023 ] Training epoch: 3
[ Wed Jun 28 06:00:36 2023 ] 	Training loss: 6.0488.  Training acc: 34.10%.
[ Wed Jun 28 06:00:36 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 06:00:36 2023 ] Eval epoch: 3
[ Wed Jun 28 06:00:37 2023 ] 	Mean test loss of 625 batches: 5.414620.
[ Wed Jun 28 06:00:37 2023 ] 	Top1: 31.58%
[ Wed Jun 28 06:00:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:00:37 2023 ] Training epoch: 4
[ Wed Jun 28 06:00:40 2023 ] 	Training loss: 5.6402.  Training acc: 36.31%.
[ Wed Jun 28 06:00:40 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 06:00:40 2023 ] Eval epoch: 4
[ Wed Jun 28 06:00:40 2023 ] 	Mean test loss of 625 batches: 31.016972.
[ Wed Jun 28 06:00:40 2023 ] 	Top1: 29.82%
[ Wed Jun 28 06:00:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:00:40 2023 ] Training epoch: 5
[ Wed Jun 28 06:00:43 2023 ] 	Training loss: 5.8311.  Training acc: 44.21%.
[ Wed Jun 28 06:00:43 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 06:00:43 2023 ] Eval epoch: 5
[ Wed Jun 28 06:00:44 2023 ] 	Mean test loss of 625 batches: 7.325535.
[ Wed Jun 28 06:00:44 2023 ] 	Top1: 38.60%
[ Wed Jun 28 06:00:44 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:00:44 2023 ] Training epoch: 6
[ Wed Jun 28 06:00:46 2023 ] 	Training loss: 2.7723.  Training acc: 62.41%.
[ Wed Jun 28 06:00:46 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 06:00:46 2023 ] Eval epoch: 6
[ Wed Jun 28 06:00:47 2023 ] 	Mean test loss of 625 batches: 1.120850.
[ Wed Jun 28 06:00:47 2023 ] 	Top1: 68.42%
[ Wed Jun 28 06:00:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:00:47 2023 ] Training epoch: 7
[ Wed Jun 28 06:00:49 2023 ] 	Training loss: 2.0551.  Training acc: 61.95%.
[ Wed Jun 28 06:00:49 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 06:00:49 2023 ] Eval epoch: 7
[ Wed Jun 28 06:00:50 2023 ] 	Mean test loss of 625 batches: 2.874670.
[ Wed Jun 28 06:00:50 2023 ] 	Top1: 57.89%
[ Wed Jun 28 06:00:50 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:00:50 2023 ] Training epoch: 8
[ Wed Jun 28 06:00:53 2023 ] 	Training loss: 1.8565.  Training acc: 59.47%.
[ Wed Jun 28 06:00:53 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 06:00:53 2023 ] Eval epoch: 8
[ Wed Jun 28 06:00:53 2023 ] 	Mean test loss of 625 batches: 0.948421.
[ Wed Jun 28 06:00:53 2023 ] 	Top1: 68.42%
[ Wed Jun 28 06:00:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:00:53 2023 ] Training epoch: 9
[ Wed Jun 28 06:00:56 2023 ] 	Training loss: 1.1709.  Training acc: 64.80%.
[ Wed Jun 28 06:00:56 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 06:00:56 2023 ] Eval epoch: 9
[ Wed Jun 28 06:00:56 2023 ] 	Mean test loss of 625 batches: 0.798255.
[ Wed Jun 28 06:00:56 2023 ] 	Top1: 68.42%
[ Wed Jun 28 06:00:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:00:56 2023 ] Training epoch: 10
[ Wed Jun 28 06:00:59 2023 ] 	Training loss: 1.3834.  Training acc: 64.34%.
[ Wed Jun 28 06:00:59 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 06:00:59 2023 ] Eval epoch: 10
[ Wed Jun 28 06:00:59 2023 ] 	Mean test loss of 625 batches: 0.848392.
[ Wed Jun 28 06:00:59 2023 ] 	Top1: 71.93%
[ Wed Jun 28 06:00:59 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:01:00 2023 ] Training epoch: 11
[ Wed Jun 28 06:01:02 2023 ] 	Training loss: 1.1056.  Training acc: 63.51%.
[ Wed Jun 28 06:01:02 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 06:01:02 2023 ] Eval epoch: 11
[ Wed Jun 28 06:01:03 2023 ] 	Mean test loss of 625 batches: 0.735914.
[ Wed Jun 28 06:01:03 2023 ] 	Top1: 73.68%
[ Wed Jun 28 06:01:03 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:01:03 2023 ] Training epoch: 12
[ Wed Jun 28 06:01:06 2023 ] 	Training loss: 1.0228.  Training acc: 66.45%.
[ Wed Jun 28 06:01:06 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 06:01:06 2023 ] Eval epoch: 12
[ Wed Jun 28 06:01:06 2023 ] 	Mean test loss of 625 batches: 0.808512.
[ Wed Jun 28 06:01:06 2023 ] 	Top1: 70.18%
[ Wed Jun 28 06:01:06 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:01:06 2023 ] Training epoch: 13
[ Wed Jun 28 06:01:09 2023 ] 	Training loss: 0.9587.  Training acc: 69.49%.
[ Wed Jun 28 06:01:09 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 06:01:09 2023 ] Eval epoch: 13
[ Wed Jun 28 06:01:10 2023 ] 	Mean test loss of 625 batches: 0.708357.
[ Wed Jun 28 06:01:10 2023 ] 	Top1: 75.44%
[ Wed Jun 28 06:01:10 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:01:10 2023 ] Training epoch: 14
[ Wed Jun 28 06:01:12 2023 ] 	Training loss: 0.9097.  Training acc: 68.47%.
[ Wed Jun 28 06:01:12 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 06:01:12 2023 ] Eval epoch: 14
[ Wed Jun 28 06:01:13 2023 ] 	Mean test loss of 625 batches: 0.726093.
[ Wed Jun 28 06:01:13 2023 ] 	Top1: 73.68%
[ Wed Jun 28 06:01:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:01:13 2023 ] Training epoch: 15
[ Wed Jun 28 06:01:15 2023 ] 	Training loss: 0.8726.  Training acc: 70.13%.
[ Wed Jun 28 06:01:15 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 06:01:15 2023 ] Eval epoch: 15
[ Wed Jun 28 06:01:16 2023 ] 	Mean test loss of 625 batches: 0.677937.
[ Wed Jun 28 06:01:16 2023 ] 	Top1: 91.23%
[ Wed Jun 28 06:01:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:01:16 2023 ] Training epoch: 16
[ Wed Jun 28 06:01:19 2023 ] 	Training loss: 0.8311.  Training acc: 73.90%.
[ Wed Jun 28 06:01:19 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 06:01:19 2023 ] Eval epoch: 16
[ Wed Jun 28 06:01:19 2023 ] 	Mean test loss of 625 batches: 0.663413.
[ Wed Jun 28 06:01:19 2023 ] 	Top1: 80.70%
[ Wed Jun 28 06:01:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:01:19 2023 ] Training epoch: 17
[ Wed Jun 28 06:01:22 2023 ] 	Training loss: 0.7912.  Training acc: 77.85%.
[ Wed Jun 28 06:01:22 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 06:01:22 2023 ] Eval epoch: 17
[ Wed Jun 28 06:01:22 2023 ] 	Mean test loss of 625 batches: 0.600835.
[ Wed Jun 28 06:01:22 2023 ] 	Top1: 94.74%
[ Wed Jun 28 06:01:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:01:23 2023 ] Training epoch: 18
[ Wed Jun 28 06:01:25 2023 ] 	Training loss: 0.7535.  Training acc: 78.68%.
[ Wed Jun 28 06:01:25 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 06:01:25 2023 ] Eval epoch: 18
[ Wed Jun 28 06:01:26 2023 ] 	Mean test loss of 625 batches: 0.571402.
[ Wed Jun 28 06:01:26 2023 ] 	Top1: 89.47%
[ Wed Jun 28 06:01:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:01:26 2023 ] Training epoch: 19
[ Wed Jun 28 06:01:29 2023 ] 	Training loss: 0.7000.  Training acc: 81.25%.
[ Wed Jun 28 06:01:29 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 06:01:29 2023 ] Eval epoch: 19
[ Wed Jun 28 06:01:29 2023 ] 	Mean test loss of 625 batches: 0.652053.
[ Wed Jun 28 06:01:29 2023 ] 	Top1: 75.44%
[ Wed Jun 28 06:01:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:01:29 2023 ] Training epoch: 20
[ Wed Jun 28 06:01:32 2023 ] 	Training loss: 0.6746.  Training acc: 84.93%.
[ Wed Jun 28 06:01:32 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 06:01:32 2023 ] Eval epoch: 20
[ Wed Jun 28 06:01:33 2023 ] 	Mean test loss of 625 batches: 0.586898.
[ Wed Jun 28 06:01:33 2023 ] 	Top1: 84.21%
[ Wed Jun 28 06:01:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:01:33 2023 ] Training epoch: 21
[ Wed Jun 28 06:01:35 2023 ] 	Training loss: 0.6654.  Training acc: 84.56%.
[ Wed Jun 28 06:01:35 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 06:01:35 2023 ] Eval epoch: 21
[ Wed Jun 28 06:01:36 2023 ] 	Mean test loss of 625 batches: 0.483706.
[ Wed Jun 28 06:01:36 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:01:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:01:36 2023 ] Training epoch: 22
[ Wed Jun 28 06:01:38 2023 ] 	Training loss: 0.6123.  Training acc: 88.79%.
[ Wed Jun 28 06:01:38 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 06:01:38 2023 ] Eval epoch: 22
[ Wed Jun 28 06:01:39 2023 ] 	Mean test loss of 625 batches: 0.501223.
[ Wed Jun 28 06:01:39 2023 ] 	Top1: 98.25%
[ Wed Jun 28 06:01:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:01:39 2023 ] Training epoch: 23
[ Wed Jun 28 06:01:42 2023 ] 	Training loss: 0.5855.  Training acc: 90.81%.
[ Wed Jun 28 06:01:42 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 06:01:42 2023 ] Eval epoch: 23
[ Wed Jun 28 06:01:42 2023 ] 	Mean test loss of 625 batches: 0.505160.
[ Wed Jun 28 06:01:42 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:01:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:01:42 2023 ] Training epoch: 24
[ Wed Jun 28 06:01:45 2023 ] 	Training loss: 0.6134.  Training acc: 88.60%.
[ Wed Jun 28 06:01:45 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 06:01:45 2023 ] Eval epoch: 24
[ Wed Jun 28 06:01:45 2023 ] 	Mean test loss of 625 batches: 0.477558.
[ Wed Jun 28 06:01:45 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:01:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:01:45 2023 ] Training epoch: 25
[ Wed Jun 28 06:01:48 2023 ] 	Training loss: 0.6014.  Training acc: 89.43%.
[ Wed Jun 28 06:01:48 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 06:01:48 2023 ] Eval epoch: 25
[ Wed Jun 28 06:01:48 2023 ] 	Mean test loss of 625 batches: 0.480963.
[ Wed Jun 28 06:01:48 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:01:48 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:01:48 2023 ] Training epoch: 26
[ Wed Jun 28 06:01:50 2023 ] 	Training loss: 0.6063.  Training acc: 90.17%.
[ Wed Jun 28 06:01:50 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 06:01:50 2023 ] Eval epoch: 26
[ Wed Jun 28 06:01:51 2023 ] 	Mean test loss of 625 batches: 0.485682.
[ Wed Jun 28 06:01:51 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:01:51 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:01:51 2023 ] Training epoch: 27
[ Wed Jun 28 06:01:53 2023 ] 	Training loss: 0.6106.  Training acc: 89.89%.
[ Wed Jun 28 06:01:53 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 06:01:53 2023 ] Eval epoch: 27
[ Wed Jun 28 06:01:54 2023 ] 	Mean test loss of 625 batches: 0.471729.
[ Wed Jun 28 06:01:54 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:01:54 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:01:54 2023 ] Training epoch: 28
[ Wed Jun 28 06:01:56 2023 ] 	Training loss: 0.5849.  Training acc: 90.90%.
[ Wed Jun 28 06:01:56 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Wed Jun 28 06:01:56 2023 ] Eval epoch: 28
[ Wed Jun 28 06:01:57 2023 ] 	Mean test loss of 625 batches: 0.471558.
[ Wed Jun 28 06:01:57 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:01:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:01:57 2023 ] Training epoch: 29
[ Wed Jun 28 06:01:59 2023 ] 	Training loss: 0.6025.  Training acc: 89.80%.
[ Wed Jun 28 06:01:59 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 06:01:59 2023 ] Eval epoch: 29
[ Wed Jun 28 06:02:00 2023 ] 	Mean test loss of 625 batches: 0.493769.
[ Wed Jun 28 06:02:00 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:02:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:02:00 2023 ] Training epoch: 30
[ Wed Jun 28 06:02:02 2023 ] 	Training loss: 0.5790.  Training acc: 90.99%.
[ Wed Jun 28 06:02:02 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 06:02:02 2023 ] Eval epoch: 30
[ Wed Jun 28 06:02:03 2023 ] 	Mean test loss of 625 batches: 0.464008.
[ Wed Jun 28 06:02:03 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:02:03 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:02:03 2023 ] Best accuracy: 1.0
[ Wed Jun 28 06:02:03 2023 ] Epoch number: 21
[ Wed Jun 28 06:02:03 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 06:02:03 2023 ] Weight decay: 0.0005
[ Wed Jun 28 06:02:03 2023 ] Base LR: 0.1
[ Wed Jun 28 06:02:03 2023 ] Batch Size: 64
[ Wed Jun 28 06:02:03 2023 ] Test Batch Size: 64
[ Wed Jun 28 06:02:03 2023 ] seed: 1
[ Wed Jun 28 06:02:03 2023 ] Start training Corrector
[ Wed Jun 28 06:02:04 2023 ] Training epoch: 1
[ Wed Jun 28 06:02:11 2023 ] 	Training loss: 11.6599.  Training acc: 76.56%.
[ Wed Jun 28 06:02:11 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 06:02:12 2023 ] Training epoch: 2
[ Wed Jun 28 06:02:17 2023 ] 	Training loss: 8.4403.  Training acc: 66.80%.
[ Wed Jun 28 06:02:17 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:02:18 2023 ] Training epoch: 3
[ Wed Jun 28 06:02:24 2023 ] 	Training loss: 12.3239.  Training acc: 36.20%.
[ Wed Jun 28 06:02:24 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:02:25 2023 ] Training epoch: 4
[ Wed Jun 28 06:02:31 2023 ] 	Training loss: 14.3585.  Training acc: 32.94%.
[ Wed Jun 28 06:02:31 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:02:32 2023 ] Training epoch: 5
[ Wed Jun 28 06:02:38 2023 ] 	Training loss: 12.5479.  Training acc: 33.20%.
[ Wed Jun 28 06:02:38 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:02:39 2023 ] Training epoch: 6
[ Wed Jun 28 06:02:46 2023 ] 	Training loss: 10.5594.  Training acc: 33.07%.
[ Wed Jun 28 06:02:46 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:02:46 2023 ] Training epoch: 7
[ Wed Jun 28 06:02:53 2023 ] 	Training loss: 10.3066.  Training acc: 34.64%.
[ Wed Jun 28 06:02:53 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:02:53 2023 ] Training epoch: 8
[ Wed Jun 28 06:03:00 2023 ] 	Training loss: 13.0991.  Training acc: 30.08%.
[ Wed Jun 28 06:03:00 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:03:01 2023 ] Training epoch: 9
[ Wed Jun 28 06:03:07 2023 ] 	Training loss: 11.6056.  Training acc: 33.07%.
[ Wed Jun 28 06:03:07 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 06:03:08 2023 ] Training epoch: 10
[ Wed Jun 28 06:03:15 2023 ] 	Training loss: 10.4540.  Training acc: 29.69%.
[ Wed Jun 28 06:03:15 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:03:15 2023 ] Training epoch: 11
[ Wed Jun 28 06:03:22 2023 ] 	Training loss: 11.0315.  Training acc: 36.72%.
[ Wed Jun 28 06:03:22 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 06:03:22 2023 ] Training epoch: 12
[ Wed Jun 28 06:03:29 2023 ] 	Training loss: 10.0480.  Training acc: 40.36%.
[ Wed Jun 28 06:03:29 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 06:03:30 2023 ] Training epoch: 13
[ Wed Jun 28 06:03:36 2023 ] 	Training loss: 9.1025.  Training acc: 31.64%.
[ Wed Jun 28 06:03:36 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:03:37 2023 ] Training epoch: 14
[ Wed Jun 28 06:03:43 2023 ] 	Training loss: 8.5615.  Training acc: 17.19%.
[ Wed Jun 28 06:03:43 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 06:03:44 2023 ] Training epoch: 15
[ Wed Jun 28 06:03:50 2023 ] 	Training loss: 8.1046.  Training acc: 26.56%.
[ Wed Jun 28 06:03:50 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 06:03:51 2023 ] Training epoch: 16
[ Wed Jun 28 06:03:56 2023 ] 	Training loss: 8.0624.  Training acc: 56.38%.
[ Wed Jun 28 06:03:56 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:03:57 2023 ] Training epoch: 17
[ Wed Jun 28 06:04:02 2023 ] 	Training loss: 7.9675.  Training acc: 49.35%.
[ Wed Jun 28 06:04:02 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:04:03 2023 ] Training epoch: 18
[ Wed Jun 28 06:04:09 2023 ] 	Training loss: 7.5464.  Training acc: 56.64%.
[ Wed Jun 28 06:04:09 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:04:09 2023 ] Training epoch: 19
[ Wed Jun 28 06:04:15 2023 ] 	Training loss: 7.4376.  Training acc: 58.46%.
[ Wed Jun 28 06:04:15 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:04:15 2023 ] Training epoch: 20
[ Wed Jun 28 06:04:22 2023 ] 	Training loss: 7.2743.  Training acc: 59.38%.
[ Wed Jun 28 06:04:22 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:04:22 2023 ] Training epoch: 21
[ Wed Jun 28 06:04:29 2023 ] 	Training loss: 7.2159.  Training acc: 61.07%.
[ Wed Jun 28 06:04:29 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 06:04:29 2023 ] Training epoch: 22
[ Wed Jun 28 06:04:36 2023 ] 	Training loss: 7.2016.  Training acc: 60.42%.
[ Wed Jun 28 06:04:36 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 06:04:37 2023 ] Training epoch: 23
[ Wed Jun 28 06:04:43 2023 ] 	Training loss: 7.1765.  Training acc: 60.03%.
[ Wed Jun 28 06:04:43 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:04:44 2023 ] Training epoch: 24
[ Wed Jun 28 06:04:50 2023 ] 	Training loss: 7.2032.  Training acc: 59.11%.
[ Wed Jun 28 06:04:50 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:04:51 2023 ] Training epoch: 25
[ Wed Jun 28 06:04:57 2023 ] 	Training loss: 7.2255.  Training acc: 59.38%.
[ Wed Jun 28 06:04:57 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 06:04:58 2023 ] Training epoch: 26
[ Wed Jun 28 06:05:05 2023 ] 	Training loss: 7.0694.  Training acc: 61.33%.
[ Wed Jun 28 06:05:05 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 06:05:05 2023 ] Training epoch: 27
[ Wed Jun 28 06:05:12 2023 ] 	Training loss: 7.0931.  Training acc: 60.03%.
[ Wed Jun 28 06:05:12 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:05:13 2023 ] Training epoch: 28
[ Wed Jun 28 06:05:19 2023 ] 	Training loss: 7.1525.  Training acc: 61.33%.
[ Wed Jun 28 06:05:19 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:05:20 2023 ] Training epoch: 29
[ Wed Jun 28 06:05:27 2023 ] 	Training loss: 7.0495.  Training acc: 61.33%.
[ Wed Jun 28 06:05:27 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:05:27 2023 ] Training epoch: 30
[ Wed Jun 28 06:05:34 2023 ] 	Training loss: 7.1157.  Training acc: 61.98%.
[ Wed Jun 28 06:05:34 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:08:23 2023 ] using warm up, epoch: 5
[ Wed Jun 28 06:08:23 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 06:08:23 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 06:08:23 2023 ] Start training Predictor
[ Wed Jun 28 06:08:23 2023 ] Training epoch: 1
[ Wed Jun 28 06:08:29 2023 ] 	Training loss: 102.3465.  Training acc: 36.31%.
[ Wed Jun 28 06:08:29 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 06:08:29 2023 ] Eval epoch: 1
[ Wed Jun 28 06:08:30 2023 ] 	Mean test loss of 625 batches: 9783.616406.
[ Wed Jun 28 06:08:30 2023 ] 	Top1: 29.82%
[ Wed Jun 28 06:08:30 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:08:30 2023 ] Training epoch: 2
[ Wed Jun 28 06:08:33 2023 ] 	Training loss: 12.9634.  Training acc: 42.37%.
[ Wed Jun 28 06:08:33 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 06:08:33 2023 ] Eval epoch: 2
[ Wed Jun 28 06:08:34 2023 ] 	Mean test loss of 625 batches: 33.350736.
[ Wed Jun 28 06:08:34 2023 ] 	Top1: 29.82%
[ Wed Jun 28 06:08:34 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:08:34 2023 ] Training epoch: 3
[ Wed Jun 28 06:08:36 2023 ] 	Training loss: 6.0730.  Training acc: 49.45%.
[ Wed Jun 28 06:08:36 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Wed Jun 28 06:08:36 2023 ] Eval epoch: 3
[ Wed Jun 28 06:08:37 2023 ] 	Mean test loss of 625 batches: 14.580107.
[ Wed Jun 28 06:08:37 2023 ] 	Top1: 29.82%
[ Wed Jun 28 06:08:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:08:37 2023 ] Training epoch: 4
[ Wed Jun 28 06:08:40 2023 ] 	Training loss: 4.0824.  Training acc: 60.57%.
[ Wed Jun 28 06:08:40 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 06:08:40 2023 ] Eval epoch: 4
[ Wed Jun 28 06:08:41 2023 ] 	Mean test loss of 625 batches: 1.756801.
[ Wed Jun 28 06:08:41 2023 ] 	Top1: 71.93%
[ Wed Jun 28 06:08:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:08:41 2023 ] Training epoch: 5
[ Wed Jun 28 06:08:43 2023 ] 	Training loss: 4.0767.  Training acc: 53.58%.
[ Wed Jun 28 06:08:43 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 06:08:43 2023 ] Eval epoch: 5
[ Wed Jun 28 06:08:44 2023 ] 	Mean test loss of 625 batches: 2.151626.
[ Wed Jun 28 06:08:44 2023 ] 	Top1: 56.14%
[ Wed Jun 28 06:08:44 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:08:44 2023 ] Training epoch: 6
[ Wed Jun 28 06:08:47 2023 ] 	Training loss: 2.9902.  Training acc: 63.79%.
[ Wed Jun 28 06:08:47 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 06:08:47 2023 ] Eval epoch: 6
[ Wed Jun 28 06:08:48 2023 ] 	Mean test loss of 625 batches: 0.873162.
[ Wed Jun 28 06:08:48 2023 ] 	Top1: 85.96%
[ Wed Jun 28 06:08:48 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:08:48 2023 ] Training epoch: 7
[ Wed Jun 28 06:08:50 2023 ] 	Training loss: 2.1514.  Training acc: 67.46%.
[ Wed Jun 28 06:08:50 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 06:08:50 2023 ] Eval epoch: 7
[ Wed Jun 28 06:08:51 2023 ] 	Mean test loss of 625 batches: 3.201539.
[ Wed Jun 28 06:08:51 2023 ] 	Top1: 71.93%
[ Wed Jun 28 06:08:51 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:08:51 2023 ] Training epoch: 8
[ Wed Jun 28 06:08:54 2023 ] 	Training loss: 1.5474.  Training acc: 78.31%.
[ Wed Jun 28 06:08:54 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Wed Jun 28 06:08:54 2023 ] Eval epoch: 8
[ Wed Jun 28 06:08:55 2023 ] 	Mean test loss of 625 batches: 1.339673.
[ Wed Jun 28 06:08:55 2023 ] 	Top1: 71.93%
[ Wed Jun 28 06:08:55 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:08:55 2023 ] Training epoch: 9
[ Wed Jun 28 06:08:57 2023 ] 	Training loss: 1.1585.  Training acc: 79.96%.
[ Wed Jun 28 06:08:57 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 06:08:57 2023 ] Eval epoch: 9
[ Wed Jun 28 06:08:58 2023 ] 	Mean test loss of 625 batches: 0.798488.
[ Wed Jun 28 06:08:58 2023 ] 	Top1: 92.98%
[ Wed Jun 28 06:08:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:08:58 2023 ] Training epoch: 10
[ Wed Jun 28 06:09:01 2023 ] 	Training loss: 1.0907.  Training acc: 79.32%.
[ Wed Jun 28 06:09:01 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 06:09:01 2023 ] Eval epoch: 10
[ Wed Jun 28 06:09:02 2023 ] 	Mean test loss of 625 batches: 0.870491.
[ Wed Jun 28 06:09:02 2023 ] 	Top1: 80.70%
[ Wed Jun 28 06:09:02 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:09:02 2023 ] Training epoch: 11
[ Wed Jun 28 06:09:04 2023 ] 	Training loss: 0.7054.  Training acc: 87.22%.
[ Wed Jun 28 06:09:04 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Wed Jun 28 06:09:04 2023 ] Eval epoch: 11
[ Wed Jun 28 06:09:05 2023 ] 	Mean test loss of 625 batches: 0.655788.
[ Wed Jun 28 06:09:05 2023 ] 	Top1: 87.72%
[ Wed Jun 28 06:09:05 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:09:05 2023 ] Training epoch: 12
[ Wed Jun 28 06:09:08 2023 ] 	Training loss: 0.7025.  Training acc: 87.22%.
[ Wed Jun 28 06:09:08 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Wed Jun 28 06:09:08 2023 ] Eval epoch: 12
[ Wed Jun 28 06:09:09 2023 ] 	Mean test loss of 625 batches: 0.591989.
[ Wed Jun 28 06:09:09 2023 ] 	Top1: 91.23%
[ Wed Jun 28 06:09:09 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:09:09 2023 ] Training epoch: 13
[ Wed Jun 28 06:09:11 2023 ] 	Training loss: 0.6190.  Training acc: 89.34%.
[ Wed Jun 28 06:09:11 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Wed Jun 28 06:09:11 2023 ] Eval epoch: 13
[ Wed Jun 28 06:09:12 2023 ] 	Mean test loss of 625 batches: 0.610952.
[ Wed Jun 28 06:09:12 2023 ] 	Top1: 91.23%
[ Wed Jun 28 06:09:12 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:09:12 2023 ] Training epoch: 14
[ Wed Jun 28 06:09:15 2023 ] 	Training loss: 0.5535.  Training acc: 91.54%.
[ Wed Jun 28 06:09:15 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Wed Jun 28 06:09:15 2023 ] Eval epoch: 14
[ Wed Jun 28 06:09:15 2023 ] 	Mean test loss of 625 batches: 0.494337.
[ Wed Jun 28 06:09:15 2023 ] 	Top1: 96.49%
[ Wed Jun 28 06:09:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:09:16 2023 ] Training epoch: 15
[ Wed Jun 28 06:09:18 2023 ] 	Training loss: 0.5356.  Training acc: 92.10%.
[ Wed Jun 28 06:09:18 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Wed Jun 28 06:09:18 2023 ] Eval epoch: 15
[ Wed Jun 28 06:09:19 2023 ] 	Mean test loss of 625 batches: 0.475388.
[ Wed Jun 28 06:09:19 2023 ] 	Top1: 98.25%
[ Wed Jun 28 06:09:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:09:19 2023 ] Training epoch: 16
[ Wed Jun 28 06:09:22 2023 ] 	Training loss: 0.5374.  Training acc: 92.46%.
[ Wed Jun 28 06:09:22 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Wed Jun 28 06:09:22 2023 ] Eval epoch: 16
[ Wed Jun 28 06:09:22 2023 ] 	Mean test loss of 625 batches: 0.391387.
[ Wed Jun 28 06:09:22 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:09:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:09:23 2023 ] Training epoch: 17
[ Wed Jun 28 06:09:25 2023 ] 	Training loss: 0.5012.  Training acc: 91.82%.
[ Wed Jun 28 06:09:25 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 06:09:25 2023 ] Eval epoch: 17
[ Wed Jun 28 06:09:26 2023 ] 	Mean test loss of 625 batches: 0.376357.
[ Wed Jun 28 06:09:26 2023 ] 	Top1: 96.49%
[ Wed Jun 28 06:09:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:09:26 2023 ] Training epoch: 18
[ Wed Jun 28 06:09:29 2023 ] 	Training loss: 0.4615.  Training acc: 94.21%.
[ Wed Jun 28 06:09:29 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Wed Jun 28 06:09:29 2023 ] Eval epoch: 18
[ Wed Jun 28 06:09:29 2023 ] 	Mean test loss of 625 batches: 0.365465.
[ Wed Jun 28 06:09:29 2023 ] 	Top1: 98.25%
[ Wed Jun 28 06:09:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:09:29 2023 ] Training epoch: 19
[ Wed Jun 28 06:09:32 2023 ] 	Training loss: 0.4480.  Training acc: 93.75%.
[ Wed Jun 28 06:09:32 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 06:09:32 2023 ] Eval epoch: 19
[ Wed Jun 28 06:09:33 2023 ] 	Mean test loss of 625 batches: 0.345798.
[ Wed Jun 28 06:09:33 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:09:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:09:33 2023 ] Training epoch: 20
[ Wed Jun 28 06:09:36 2023 ] 	Training loss: 0.4282.  Training acc: 96.14%.
[ Wed Jun 28 06:09:36 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Wed Jun 28 06:09:36 2023 ] Eval epoch: 20
[ Wed Jun 28 06:09:37 2023 ] 	Mean test loss of 625 batches: 0.401124.
[ Wed Jun 28 06:09:37 2023 ] 	Top1: 92.98%
[ Wed Jun 28 06:09:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:09:37 2023 ] Training epoch: 21
[ Wed Jun 28 06:09:39 2023 ] 	Training loss: 0.4397.  Training acc: 94.12%.
[ Wed Jun 28 06:09:39 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Wed Jun 28 06:09:39 2023 ] Eval epoch: 21
[ Wed Jun 28 06:09:40 2023 ] 	Mean test loss of 625 batches: 0.337367.
[ Wed Jun 28 06:09:40 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:09:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:09:40 2023 ] Training epoch: 22
[ Wed Jun 28 06:09:43 2023 ] 	Training loss: 0.4072.  Training acc: 96.23%.
[ Wed Jun 28 06:09:43 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Wed Jun 28 06:09:43 2023 ] Eval epoch: 22
[ Wed Jun 28 06:09:43 2023 ] 	Mean test loss of 625 batches: 0.334746.
[ Wed Jun 28 06:09:43 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:09:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:09:43 2023 ] Training epoch: 23
[ Wed Jun 28 06:09:46 2023 ] 	Training loss: 0.4012.  Training acc: 96.51%.
[ Wed Jun 28 06:09:46 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Wed Jun 28 06:09:46 2023 ] Eval epoch: 23
[ Wed Jun 28 06:09:46 2023 ] 	Mean test loss of 625 batches: 0.340394.
[ Wed Jun 28 06:09:46 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:09:46 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:09:46 2023 ] Training epoch: 24
[ Wed Jun 28 06:09:49 2023 ] 	Training loss: 0.4001.  Training acc: 97.15%.
[ Wed Jun 28 06:09:49 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Wed Jun 28 06:09:49 2023 ] Eval epoch: 24
[ Wed Jun 28 06:09:49 2023 ] 	Mean test loss of 625 batches: 0.328571.
[ Wed Jun 28 06:09:49 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:09:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:09:49 2023 ] Training epoch: 25
[ Wed Jun 28 06:09:52 2023 ] 	Training loss: 0.4118.  Training acc: 95.40%.
[ Wed Jun 28 06:09:52 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 06:09:52 2023 ] Eval epoch: 25
[ Wed Jun 28 06:09:53 2023 ] 	Mean test loss of 625 batches: 0.328872.
[ Wed Jun 28 06:09:53 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:09:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:09:53 2023 ] Training epoch: 26
[ Wed Jun 28 06:09:55 2023 ] 	Training loss: 0.4004.  Training acc: 95.96%.
[ Wed Jun 28 06:09:55 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Wed Jun 28 06:09:55 2023 ] Eval epoch: 26
[ Wed Jun 28 06:09:56 2023 ] 	Mean test loss of 625 batches: 0.324322.
[ Wed Jun 28 06:09:56 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:09:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:09:56 2023 ] Training epoch: 27
[ Wed Jun 28 06:09:58 2023 ] 	Training loss: 0.3890.  Training acc: 97.33%.
[ Wed Jun 28 06:09:58 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Wed Jun 28 06:09:58 2023 ] Eval epoch: 27
[ Wed Jun 28 06:09:59 2023 ] 	Mean test loss of 625 batches: 0.325506.
[ Wed Jun 28 06:09:59 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:09:59 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:09:59 2023 ] Training epoch: 28
[ Wed Jun 28 06:10:01 2023 ] 	Training loss: 0.3881.  Training acc: 97.15%.
[ Wed Jun 28 06:10:01 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Wed Jun 28 06:10:01 2023 ] Eval epoch: 28
[ Wed Jun 28 06:10:02 2023 ] 	Mean test loss of 625 batches: 0.326636.
[ Wed Jun 28 06:10:02 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:10:02 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:10:02 2023 ] Training epoch: 29
[ Wed Jun 28 06:10:04 2023 ] 	Training loss: 0.4111.  Training acc: 95.50%.
[ Wed Jun 28 06:10:04 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Jun 28 06:10:04 2023 ] Eval epoch: 29
[ Wed Jun 28 06:10:05 2023 ] 	Mean test loss of 625 batches: 0.325694.
[ Wed Jun 28 06:10:05 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:10:05 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:10:05 2023 ] Training epoch: 30
[ Wed Jun 28 06:10:07 2023 ] 	Training loss: 0.4129.  Training acc: 95.68%.
[ Wed Jun 28 06:10:07 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Wed Jun 28 06:10:07 2023 ] Eval epoch: 30
[ Wed Jun 28 06:10:08 2023 ] 	Mean test loss of 625 batches: 0.323907.
[ Wed Jun 28 06:10:08 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:10:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:10:09 2023 ] Best accuracy: 1.0
[ Wed Jun 28 06:10:09 2023 ] Epoch number: 16
[ Wed Jun 28 06:10:09 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 06:10:09 2023 ] Weight decay: 0.0005
[ Wed Jun 28 06:10:09 2023 ] Base LR: 0.1
[ Wed Jun 28 06:10:09 2023 ] Batch Size: 64
[ Wed Jun 28 06:10:09 2023 ] Test Batch Size: 64
[ Wed Jun 28 06:10:09 2023 ] seed: 1
[ Wed Jun 28 06:10:09 2023 ] Start training Corrector
[ Wed Jun 28 06:10:10 2023 ] Training epoch: 1
[ Wed Jun 28 06:10:17 2023 ] 	Training loss: 12.7388.  Training acc: 49.48%.
[ Wed Jun 28 06:10:17 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:10:18 2023 ] Training epoch: 2
[ Wed Jun 28 06:10:24 2023 ] 	Training loss: 8.7293.  Training acc: 34.51%.
[ Wed Jun 28 06:10:24 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:10:25 2023 ] Training epoch: 3
[ Wed Jun 28 06:10:32 2023 ] 	Training loss: 8.3478.  Training acc: 40.49%.
[ Wed Jun 28 06:10:32 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:10:33 2023 ] Training epoch: 4
[ Wed Jun 28 06:10:40 2023 ] 	Training loss: 8.0118.  Training acc: 52.34%.
[ Wed Jun 28 06:10:40 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:10:40 2023 ] Training epoch: 5
[ Wed Jun 28 06:10:47 2023 ] 	Training loss: 10.9840.  Training acc: 37.76%.
[ Wed Jun 28 06:10:47 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:10:48 2023 ] Training epoch: 6
[ Wed Jun 28 06:10:55 2023 ] 	Training loss: 10.7479.  Training acc: 31.90%.
[ Wed Jun 28 06:10:55 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 06:10:55 2023 ] Training epoch: 7
[ Wed Jun 28 06:11:02 2023 ] 	Training loss: 8.5970.  Training acc: 28.52%.
[ Wed Jun 28 06:11:02 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:11:03 2023 ] Training epoch: 8
[ Wed Jun 28 06:11:10 2023 ] 	Training loss: 7.6905.  Training acc: 37.76%.
[ Wed Jun 28 06:11:10 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:11:11 2023 ] Training epoch: 9
[ Wed Jun 28 06:11:18 2023 ] 	Training loss: 8.7399.  Training acc: 34.24%.
[ Wed Jun 28 06:11:18 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:11:19 2023 ] Training epoch: 10
[ Wed Jun 28 06:11:26 2023 ] 	Training loss: 8.7038.  Training acc: 29.43%.
[ Wed Jun 28 06:11:26 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:11:27 2023 ] Training epoch: 11
[ Wed Jun 28 06:11:34 2023 ] 	Training loss: 7.7812.  Training acc: 27.73%.
[ Wed Jun 28 06:11:34 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 06:11:35 2023 ] Training epoch: 12
[ Wed Jun 28 06:11:42 2023 ] 	Training loss: 7.4642.  Training acc: 26.95%.
[ Wed Jun 28 06:11:42 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:11:43 2023 ] Training epoch: 13
[ Wed Jun 28 06:11:50 2023 ] 	Training loss: 7.1376.  Training acc: 23.57%.
[ Wed Jun 28 06:11:50 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:11:51 2023 ] Training epoch: 14
[ Wed Jun 28 06:11:56 2023 ] 	Training loss: 6.9658.  Training acc: 25.39%.
[ Wed Jun 28 06:11:56 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:11:57 2023 ] Training epoch: 15
[ Wed Jun 28 06:12:03 2023 ] 	Training loss: 6.9287.  Training acc: 23.44%.
[ Wed Jun 28 06:12:03 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:12:04 2023 ] Training epoch: 16
[ Wed Jun 28 06:12:10 2023 ] 	Training loss: 6.9264.  Training acc: 27.99%.
[ Wed Jun 28 06:12:10 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:12:10 2023 ] Training epoch: 17
[ Wed Jun 28 06:12:16 2023 ] 	Training loss: 6.8338.  Training acc: 27.60%.
[ Wed Jun 28 06:12:16 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:12:17 2023 ] Training epoch: 18
[ Wed Jun 28 06:12:24 2023 ] 	Training loss: 6.7124.  Training acc: 27.86%.
[ Wed Jun 28 06:12:24 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:12:25 2023 ] Training epoch: 19
[ Wed Jun 28 06:12:32 2023 ] 	Training loss: 6.7289.  Training acc: 27.86%.
[ Wed Jun 28 06:12:32 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:12:33 2023 ] Training epoch: 20
[ Wed Jun 28 06:12:41 2023 ] 	Training loss: 6.6335.  Training acc: 28.52%.
[ Wed Jun 28 06:12:41 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:12:41 2023 ] Training epoch: 21
[ Wed Jun 28 06:12:48 2023 ] 	Training loss: 6.5042.  Training acc: 30.47%.
[ Wed Jun 28 06:12:48 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:12:49 2023 ] Training epoch: 22
[ Wed Jun 28 06:12:57 2023 ] 	Training loss: 6.4137.  Training acc: 28.39%.
[ Wed Jun 28 06:12:57 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:12:57 2023 ] Training epoch: 23
[ Wed Jun 28 06:13:04 2023 ] 	Training loss: 6.3656.  Training acc: 30.73%.
[ Wed Jun 28 06:13:04 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:13:05 2023 ] Training epoch: 24
[ Wed Jun 28 06:13:12 2023 ] 	Training loss: 6.3605.  Training acc: 35.55%.
[ Wed Jun 28 06:13:12 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:13:13 2023 ] Training epoch: 25
[ Wed Jun 28 06:13:20 2023 ] 	Training loss: 6.4120.  Training acc: 33.72%.
[ Wed Jun 28 06:13:20 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:13:21 2023 ] Training epoch: 26
[ Wed Jun 28 06:13:28 2023 ] 	Training loss: 6.2979.  Training acc: 36.85%.
[ Wed Jun 28 06:13:28 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:13:29 2023 ] Training epoch: 27
[ Wed Jun 28 06:13:36 2023 ] 	Training loss: 6.2825.  Training acc: 36.85%.
[ Wed Jun 28 06:13:36 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:13:37 2023 ] Training epoch: 28
[ Wed Jun 28 06:13:44 2023 ] 	Training loss: 6.3689.  Training acc: 40.89%.
[ Wed Jun 28 06:13:44 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:13:45 2023 ] Training epoch: 29
[ Wed Jun 28 06:13:51 2023 ] 	Training loss: 6.2848.  Training acc: 42.71%.
[ Wed Jun 28 06:13:51 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:13:52 2023 ] Training epoch: 30
[ Wed Jun 28 06:13:58 2023 ] 	Training loss: 6.3970.  Training acc: 38.28%.
[ Wed Jun 28 06:13:58 2023 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Jun 28 06:16:04 2023 ] using warm up, epoch: 5
[ Wed Jun 28 06:16:04 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 06:16:04 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 06:16:04 2023 ] Start training Predictor
[ Wed Jun 28 06:16:04 2023 ] Training epoch: 1
[ Wed Jun 28 06:16:09 2023 ] 	Training loss: 151.8596.  Training acc: 33.09%.
[ Wed Jun 28 06:16:09 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 06:16:09 2023 ] Eval epoch: 1
[ Wed Jun 28 06:16:10 2023 ] 	Mean test loss of 625 batches: 795.231348.
[ Wed Jun 28 06:16:10 2023 ] 	Top1: 38.60%
[ Wed Jun 28 06:16:10 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:16:10 2023 ] Training epoch: 2
[ Wed Jun 28 06:16:13 2023 ] 	Training loss: 14.5782.  Training acc: 34.47%.
[ Wed Jun 28 06:16:13 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 06:16:13 2023 ] Eval epoch: 2
[ Wed Jun 28 06:16:13 2023 ] 	Mean test loss of 625 batches: 1.470764.
[ Wed Jun 28 06:16:13 2023 ] 	Top1: 31.58%
[ Wed Jun 28 06:16:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:16:13 2023 ] Training epoch: 3
[ Wed Jun 28 06:16:16 2023 ] 	Training loss: 6.9616.  Training acc: 34.65%.
[ Wed Jun 28 06:16:16 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 06:16:16 2023 ] Eval epoch: 3
[ Wed Jun 28 06:16:17 2023 ] 	Mean test loss of 625 batches: 2.150444.
[ Wed Jun 28 06:16:17 2023 ] 	Top1: 31.58%
[ Wed Jun 28 06:16:17 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:16:17 2023 ] Training epoch: 4
[ Wed Jun 28 06:16:20 2023 ] 	Training loss: 5.9284.  Training acc: 32.54%.
[ Wed Jun 28 06:16:20 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 06:16:20 2023 ] Eval epoch: 4
[ Wed Jun 28 06:16:20 2023 ] 	Mean test loss of 625 batches: 1.987746.
[ Wed Jun 28 06:16:20 2023 ] 	Top1: 31.58%
[ Wed Jun 28 06:16:20 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:16:20 2023 ] Training epoch: 5
[ Wed Jun 28 06:16:23 2023 ] 	Training loss: 4.6613.  Training acc: 33.27%.
[ Wed Jun 28 06:16:23 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 06:16:23 2023 ] Eval epoch: 5
[ Wed Jun 28 06:16:24 2023 ] 	Mean test loss of 625 batches: 1.756843.
[ Wed Jun 28 06:16:24 2023 ] 	Top1: 31.58%
[ Wed Jun 28 06:16:24 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:16:24 2023 ] Training epoch: 6
[ Wed Jun 28 06:16:26 2023 ] 	Training loss: 4.1385.  Training acc: 36.31%.
[ Wed Jun 28 06:16:26 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 06:16:26 2023 ] Eval epoch: 6
[ Wed Jun 28 06:16:27 2023 ] 	Mean test loss of 625 batches: 1.117259.
[ Wed Jun 28 06:16:27 2023 ] 	Top1: 29.82%
[ Wed Jun 28 06:16:27 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:16:27 2023 ] Training epoch: 7
[ Wed Jun 28 06:16:29 2023 ] 	Training loss: 3.0410.  Training acc: 34.47%.
[ Wed Jun 28 06:16:29 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 06:16:29 2023 ] Eval epoch: 7
[ Wed Jun 28 06:16:30 2023 ] 	Mean test loss of 625 batches: 1.266355.
[ Wed Jun 28 06:16:30 2023 ] 	Top1: 36.84%
[ Wed Jun 28 06:16:30 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:16:30 2023 ] Training epoch: 8
[ Wed Jun 28 06:16:33 2023 ] 	Training loss: 2.5713.  Training acc: 37.32%.
[ Wed Jun 28 06:16:33 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 06:16:33 2023 ] Eval epoch: 8
[ Wed Jun 28 06:16:33 2023 ] 	Mean test loss of 625 batches: 0.737150.
[ Wed Jun 28 06:16:33 2023 ] 	Top1: 70.18%
[ Wed Jun 28 06:16:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:16:34 2023 ] Training epoch: 9
[ Wed Jun 28 06:16:36 2023 ] 	Training loss: 1.7159.  Training acc: 53.68%.
[ Wed Jun 28 06:16:36 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 06:16:36 2023 ] Eval epoch: 9
[ Wed Jun 28 06:16:37 2023 ] 	Mean test loss of 625 batches: 2.891091.
[ Wed Jun 28 06:16:37 2023 ] 	Top1: 33.33%
[ Wed Jun 28 06:16:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:16:37 2023 ] Training epoch: 10
[ Wed Jun 28 06:16:39 2023 ] 	Training loss: 1.4618.  Training acc: 56.80%.
[ Wed Jun 28 06:16:39 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 06:16:39 2023 ] Eval epoch: 10
[ Wed Jun 28 06:16:40 2023 ] 	Mean test loss of 625 batches: 0.911532.
[ Wed Jun 28 06:16:40 2023 ] 	Top1: 75.44%
[ Wed Jun 28 06:16:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:16:40 2023 ] Training epoch: 11
[ Wed Jun 28 06:16:43 2023 ] 	Training loss: 1.1902.  Training acc: 63.88%.
[ Wed Jun 28 06:16:43 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 06:16:43 2023 ] Eval epoch: 11
[ Wed Jun 28 06:16:44 2023 ] 	Mean test loss of 625 batches: 0.640945.
[ Wed Jun 28 06:16:44 2023 ] 	Top1: 80.70%
[ Wed Jun 28 06:16:44 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:16:44 2023 ] Training epoch: 12
[ Wed Jun 28 06:16:47 2023 ] 	Training loss: 1.2018.  Training acc: 64.52%.
[ Wed Jun 28 06:16:47 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 06:16:47 2023 ] Eval epoch: 12
[ Wed Jun 28 06:16:47 2023 ] 	Mean test loss of 625 batches: 0.619056.
[ Wed Jun 28 06:16:47 2023 ] 	Top1: 87.72%
[ Wed Jun 28 06:16:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:16:47 2023 ] Training epoch: 13
[ Wed Jun 28 06:16:50 2023 ] 	Training loss: 1.1065.  Training acc: 65.07%.
[ Wed Jun 28 06:16:50 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 06:16:50 2023 ] Eval epoch: 13
[ Wed Jun 28 06:16:51 2023 ] 	Mean test loss of 625 batches: 0.620236.
[ Wed Jun 28 06:16:51 2023 ] 	Top1: 89.47%
[ Wed Jun 28 06:16:51 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:16:51 2023 ] Training epoch: 14
[ Wed Jun 28 06:16:53 2023 ] 	Training loss: 1.0705.  Training acc: 67.74%.
[ Wed Jun 28 06:16:53 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 06:16:53 2023 ] Eval epoch: 14
[ Wed Jun 28 06:16:54 2023 ] 	Mean test loss of 625 batches: 0.551048.
[ Wed Jun 28 06:16:54 2023 ] 	Top1: 94.74%
[ Wed Jun 28 06:16:54 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:16:54 2023 ] Training epoch: 15
[ Wed Jun 28 06:16:57 2023 ] 	Training loss: 1.0344.  Training acc: 69.12%.
[ Wed Jun 28 06:16:57 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 06:16:57 2023 ] Eval epoch: 15
[ Wed Jun 28 06:16:57 2023 ] 	Mean test loss of 625 batches: 0.522848.
[ Wed Jun 28 06:16:57 2023 ] 	Top1: 96.49%
[ Wed Jun 28 06:16:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:16:57 2023 ] Training epoch: 16
[ Wed Jun 28 06:17:00 2023 ] 	Training loss: 0.9953.  Training acc: 69.58%.
[ Wed Jun 28 06:17:00 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 06:17:00 2023 ] Eval epoch: 16
[ Wed Jun 28 06:17:01 2023 ] 	Mean test loss of 625 batches: 0.522507.
[ Wed Jun 28 06:17:01 2023 ] 	Top1: 94.74%
[ Wed Jun 28 06:17:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:17:01 2023 ] Training epoch: 17
[ Wed Jun 28 06:17:03 2023 ] 	Training loss: 0.9532.  Training acc: 73.25%.
[ Wed Jun 28 06:17:03 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 06:17:03 2023 ] Eval epoch: 17
[ Wed Jun 28 06:17:04 2023 ] 	Mean test loss of 625 batches: 0.503927.
[ Wed Jun 28 06:17:04 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:17:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:17:04 2023 ] Training epoch: 18
[ Wed Jun 28 06:17:07 2023 ] 	Training loss: 0.9117.  Training acc: 72.43%.
[ Wed Jun 28 06:17:07 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 06:17:07 2023 ] Eval epoch: 18
[ Wed Jun 28 06:17:07 2023 ] 	Mean test loss of 625 batches: 0.486669.
[ Wed Jun 28 06:17:07 2023 ] 	Top1: 98.25%
[ Wed Jun 28 06:17:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:17:07 2023 ] Training epoch: 19
[ Wed Jun 28 06:17:10 2023 ] 	Training loss: 0.8539.  Training acc: 75.92%.
[ Wed Jun 28 06:17:10 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 06:17:10 2023 ] Eval epoch: 19
[ Wed Jun 28 06:17:11 2023 ] 	Mean test loss of 625 batches: 0.487843.
[ Wed Jun 28 06:17:11 2023 ] 	Top1: 100.00%
[ Wed Jun 28 06:17:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:17:11 2023 ] Training epoch: 20
[ Wed Jun 28 06:17:13 2023 ] 	Training loss: 0.7738.  Training acc: 79.78%.
[ Wed Jun 28 06:17:13 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 06:17:13 2023 ] Eval epoch: 20
[ Wed Jun 28 06:17:14 2023 ] 	Mean test loss of 625 batches: 0.491477.
[ Wed Jun 28 06:17:14 2023 ] 	Top1: 96.49%
[ Wed Jun 28 06:17:14 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:17:14 2023 ] Training epoch: 21
[ Wed Jun 28 06:17:17 2023 ] 	Training loss: 0.7386.  Training acc: 79.32%.
[ Wed Jun 28 06:17:17 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 06:17:17 2023 ] Eval epoch: 21
[ Wed Jun 28 06:17:17 2023 ] 	Mean test loss of 625 batches: 0.493649.
[ Wed Jun 28 06:17:17 2023 ] 	Top1: 98.25%
[ Wed Jun 28 06:17:17 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:17:17 2023 ] Training epoch: 22
[ Wed Jun 28 06:17:20 2023 ] 	Training loss: 0.7269.  Training acc: 80.79%.
[ Wed Jun 28 06:17:20 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 06:17:20 2023 ] Eval epoch: 22
[ Wed Jun 28 06:17:21 2023 ] 	Mean test loss of 625 batches: 0.488646.
[ Wed Jun 28 06:17:21 2023 ] 	Top1: 98.25%
[ Wed Jun 28 06:17:21 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:17:21 2023 ] Training epoch: 23
[ Wed Jun 28 06:17:23 2023 ] 	Training loss: 0.7060.  Training acc: 83.00%.
[ Wed Jun 28 06:17:23 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 06:17:23 2023 ] Eval epoch: 23
[ Wed Jun 28 06:17:24 2023 ] 	Mean test loss of 625 batches: 0.494308.
[ Wed Jun 28 06:17:24 2023 ] 	Top1: 98.25%
[ Wed Jun 28 06:17:24 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:17:24 2023 ] Training epoch: 24
[ Wed Jun 28 06:17:27 2023 ] 	Training loss: 0.7084.  Training acc: 81.07%.
[ Wed Jun 28 06:17:27 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 06:17:27 2023 ] Eval epoch: 24
[ Wed Jun 28 06:17:28 2023 ] 	Mean test loss of 625 batches: 0.491587.
[ Wed Jun 28 06:17:28 2023 ] 	Top1: 98.25%
[ Wed Jun 28 06:17:28 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:17:28 2023 ] Training epoch: 25
[ Wed Jun 28 06:17:30 2023 ] 	Training loss: 0.7283.  Training acc: 81.43%.
[ Wed Jun 28 06:17:30 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 06:17:30 2023 ] Eval epoch: 25
[ Wed Jun 28 06:17:31 2023 ] 	Mean test loss of 625 batches: 0.498319.
[ Wed Jun 28 06:17:31 2023 ] 	Top1: 98.25%
[ Wed Jun 28 06:17:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:17:31 2023 ] Training epoch: 26
[ Wed Jun 28 06:17:33 2023 ] 	Training loss: 0.7384.  Training acc: 80.88%.
[ Wed Jun 28 06:17:33 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 06:17:33 2023 ] Eval epoch: 26
[ Wed Jun 28 06:17:34 2023 ] 	Mean test loss of 625 batches: 0.478801.
[ Wed Jun 28 06:17:34 2023 ] 	Top1: 98.25%
[ Wed Jun 28 06:17:34 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:17:34 2023 ] Training epoch: 27
[ Wed Jun 28 06:17:37 2023 ] 	Training loss: 0.7367.  Training acc: 79.69%.
[ Wed Jun 28 06:17:37 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 06:17:37 2023 ] Eval epoch: 27
[ Wed Jun 28 06:17:37 2023 ] 	Mean test loss of 625 batches: 0.486459.
[ Wed Jun 28 06:17:37 2023 ] 	Top1: 98.25%
[ Wed Jun 28 06:17:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:17:37 2023 ] Training epoch: 28
[ Wed Jun 28 06:17:40 2023 ] 	Training loss: 0.7046.  Training acc: 83.00%.
[ Wed Jun 28 06:17:40 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 06:17:40 2023 ] Eval epoch: 28
[ Wed Jun 28 06:17:41 2023 ] 	Mean test loss of 625 batches: 0.497862.
[ Wed Jun 28 06:17:41 2023 ] 	Top1: 98.25%
[ Wed Jun 28 06:17:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:17:41 2023 ] Training epoch: 29
[ Wed Jun 28 06:17:43 2023 ] 	Training loss: 0.7462.  Training acc: 80.15%.
[ Wed Jun 28 06:17:43 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 06:17:43 2023 ] Eval epoch: 29
[ Wed Jun 28 06:17:44 2023 ] 	Mean test loss of 625 batches: 0.481743.
[ Wed Jun 28 06:17:44 2023 ] 	Top1: 98.25%
[ Wed Jun 28 06:17:44 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:17:44 2023 ] Training epoch: 30
[ Wed Jun 28 06:17:47 2023 ] 	Training loss: 0.6976.  Training acc: 83.27%.
[ Wed Jun 28 06:17:47 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 06:17:47 2023 ] Eval epoch: 30
[ Wed Jun 28 06:17:47 2023 ] 	Mean test loss of 625 batches: 0.486908.
[ Wed Jun 28 06:17:47 2023 ] 	Top1: 98.25%
[ Wed Jun 28 06:17:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 06:17:48 2023 ] Best accuracy: 1.0
[ Wed Jun 28 06:17:48 2023 ] Epoch number: 17
[ Wed Jun 28 06:17:48 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 06:17:48 2023 ] Weight decay: 0.0005
[ Wed Jun 28 06:17:48 2023 ] Base LR: 0.1
[ Wed Jun 28 06:17:48 2023 ] Batch Size: 64
[ Wed Jun 28 06:17:48 2023 ] Test Batch Size: 64
[ Wed Jun 28 06:17:48 2023 ] seed: 1
[ Wed Jun 28 06:17:48 2023 ] Start training Corrector
[ Wed Jun 28 06:17:50 2023 ] Training epoch: 1
[ Wed Jun 28 06:17:58 2023 ] 	Training loss: 11.7243.  Training acc: 36.07%.
[ Wed Jun 28 06:17:58 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 06:17:59 2023 ] Training epoch: 2
[ Wed Jun 28 06:18:05 2023 ] 	Training loss: 8.3437.  Training acc: 42.71%.
[ Wed Jun 28 06:18:05 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:18:05 2023 ] Training epoch: 3
[ Wed Jun 28 06:18:11 2023 ] 	Training loss: 7.4830.  Training acc: 41.54%.
[ Wed Jun 28 06:18:11 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:18:11 2023 ] Training epoch: 4
[ Wed Jun 28 06:18:17 2023 ] 	Training loss: 10.1708.  Training acc: 32.94%.
[ Wed Jun 28 06:18:17 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:18:18 2023 ] Training epoch: 5
[ Wed Jun 28 06:18:23 2023 ] 	Training loss: 8.1568.  Training acc: 30.99%.
[ Wed Jun 28 06:18:23 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:18:24 2023 ] Training epoch: 6
[ Wed Jun 28 06:18:30 2023 ] 	Training loss: 6.6491.  Training acc: 33.33%.
[ Wed Jun 28 06:18:30 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 06:18:30 2023 ] Training epoch: 7
[ Wed Jun 28 06:18:37 2023 ] 	Training loss: 6.5724.  Training acc: 34.90%.
[ Wed Jun 28 06:18:37 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:18:38 2023 ] Training epoch: 8
[ Wed Jun 28 06:18:45 2023 ] 	Training loss: 7.4164.  Training acc: 57.16%.
[ Wed Jun 28 06:18:45 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 06:18:45 2023 ] Training epoch: 9
[ Wed Jun 28 06:18:52 2023 ] 	Training loss: 6.6813.  Training acc: 60.68%.
[ Wed Jun 28 06:18:52 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:18:53 2023 ] Training epoch: 10
[ Wed Jun 28 06:19:00 2023 ] 	Training loss: 5.8269.  Training acc: 73.44%.
[ Wed Jun 28 06:19:00 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:19:00 2023 ] Training epoch: 11
[ Wed Jun 28 06:19:08 2023 ] 	Training loss: 5.4935.  Training acc: 87.37%.
[ Wed Jun 28 06:19:08 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 06:19:08 2023 ] Training epoch: 12
[ Wed Jun 28 06:19:15 2023 ] 	Training loss: 5.3432.  Training acc: 89.19%.
[ Wed Jun 28 06:19:15 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:19:16 2023 ] Training epoch: 13
[ Wed Jun 28 06:19:22 2023 ] 	Training loss: 5.2154.  Training acc: 87.76%.
[ Wed Jun 28 06:19:22 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:19:23 2023 ] Training epoch: 14
[ Wed Jun 28 06:19:30 2023 ] 	Training loss: 5.2197.  Training acc: 88.41%.
[ Wed Jun 28 06:19:30 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 06:19:30 2023 ] Training epoch: 15
[ Wed Jun 28 06:19:38 2023 ] 	Training loss: 5.2067.  Training acc: 89.19%.
[ Wed Jun 28 06:19:38 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 06:19:38 2023 ] Training epoch: 16
[ Wed Jun 28 06:19:45 2023 ] 	Training loss: 5.3035.  Training acc: 86.46%.
[ Wed Jun 28 06:19:45 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 06:19:46 2023 ] Training epoch: 17
[ Wed Jun 28 06:19:53 2023 ] 	Training loss: 5.2230.  Training acc: 85.16%.
[ Wed Jun 28 06:19:53 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:19:53 2023 ] Training epoch: 18
[ Wed Jun 28 06:20:00 2023 ] 	Training loss: 5.0791.  Training acc: 90.49%.
[ Wed Jun 28 06:20:00 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:20:01 2023 ] Training epoch: 19
[ Wed Jun 28 06:20:07 2023 ] 	Training loss: 5.2080.  Training acc: 81.12%.
[ Wed Jun 28 06:20:07 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:20:08 2023 ] Training epoch: 20
[ Wed Jun 28 06:20:13 2023 ] 	Training loss: 5.1484.  Training acc: 87.24%.
[ Wed Jun 28 06:20:13 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:20:14 2023 ] Training epoch: 21
[ Wed Jun 28 06:20:20 2023 ] 	Training loss: 5.2341.  Training acc: 86.20%.
[ Wed Jun 28 06:20:20 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:20:21 2023 ] Training epoch: 22
[ Wed Jun 28 06:20:27 2023 ] 	Training loss: 5.0959.  Training acc: 88.15%.
[ Wed Jun 28 06:20:27 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:20:28 2023 ] Training epoch: 23
[ Wed Jun 28 06:20:35 2023 ] 	Training loss: 5.0680.  Training acc: 87.63%.
[ Wed Jun 28 06:20:35 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 06:20:36 2023 ] Training epoch: 24
[ Wed Jun 28 06:20:43 2023 ] 	Training loss: 5.1143.  Training acc: 86.59%.
[ Wed Jun 28 06:20:43 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:20:44 2023 ] Training epoch: 25
[ Wed Jun 28 06:20:51 2023 ] 	Training loss: 5.1283.  Training acc: 87.11%.
[ Wed Jun 28 06:20:51 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:20:52 2023 ] Training epoch: 26
[ Wed Jun 28 06:20:59 2023 ] 	Training loss: 5.0265.  Training acc: 88.54%.
[ Wed Jun 28 06:20:59 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:21:00 2023 ] Training epoch: 27
[ Wed Jun 28 06:21:07 2023 ] 	Training loss: 5.0605.  Training acc: 87.50%.
[ Wed Jun 28 06:21:07 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:21:08 2023 ] Training epoch: 28
[ Wed Jun 28 06:21:16 2023 ] 	Training loss: 5.1631.  Training acc: 86.07%.
[ Wed Jun 28 06:21:16 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 06:21:17 2023 ] Training epoch: 29
[ Wed Jun 28 06:21:24 2023 ] 	Training loss: 5.0516.  Training acc: 88.93%.
[ Wed Jun 28 06:21:24 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:21:25 2023 ] Training epoch: 30
[ Wed Jun 28 06:21:32 2023 ] 	Training loss: 5.1950.  Training acc: 86.46%.
[ Wed Jun 28 06:21:32 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 06:21:33 2023 ] Training epoch: 31
[ Wed Jun 28 06:21:40 2023 ] 	Training loss: 5.1321.  Training acc: 89.84%.
[ Wed Jun 28 06:21:40 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 06:21:41 2023 ] Training epoch: 32
[ Wed Jun 28 06:21:48 2023 ] 	Training loss: 4.9935.  Training acc: 88.80%.
[ Wed Jun 28 06:21:48 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:21:49 2023 ] Training epoch: 33
[ Wed Jun 28 06:21:56 2023 ] 	Training loss: 5.0828.  Training acc: 90.36%.
[ Wed Jun 28 06:21:56 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:21:57 2023 ] Training epoch: 34
[ Wed Jun 28 06:22:03 2023 ] 	Training loss: 5.0405.  Training acc: 89.84%.
[ Wed Jun 28 06:22:03 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:22:04 2023 ] Training epoch: 35
[ Wed Jun 28 06:22:10 2023 ] 	Training loss: 5.1072.  Training acc: 88.80%.
[ Wed Jun 28 06:22:10 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:22:11 2023 ] Training epoch: 36
[ Wed Jun 28 06:22:17 2023 ] 	Training loss: 5.0941.  Training acc: 88.67%.
[ Wed Jun 28 06:22:17 2023 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Jun 28 06:22:17 2023 ] Training epoch: 37
[ Wed Jun 28 06:22:23 2023 ] 	Training loss: 5.1970.  Training acc: 86.07%.
[ Wed Jun 28 06:22:23 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:22:24 2023 ] Training epoch: 38
[ Wed Jun 28 06:22:31 2023 ] 	Training loss: 5.1593.  Training acc: 89.06%.
[ Wed Jun 28 06:22:31 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:22:32 2023 ] Training epoch: 39
[ Wed Jun 28 06:22:39 2023 ] 	Training loss: 5.0436.  Training acc: 88.28%.
[ Wed Jun 28 06:22:39 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:22:40 2023 ] Training epoch: 40
[ Wed Jun 28 06:22:47 2023 ] 	Training loss: 5.0977.  Training acc: 88.80%.
[ Wed Jun 28 06:22:47 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:22:48 2023 ] Training epoch: 41
[ Wed Jun 28 06:22:55 2023 ] 	Training loss: 5.0146.  Training acc: 89.97%.
[ Wed Jun 28 06:22:55 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:22:56 2023 ] Training epoch: 42
[ Wed Jun 28 06:23:03 2023 ] 	Training loss: 5.0088.  Training acc: 89.32%.
[ Wed Jun 28 06:23:03 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:23:04 2023 ] Training epoch: 43
[ Wed Jun 28 06:23:11 2023 ] 	Training loss: 5.1264.  Training acc: 90.76%.
[ Wed Jun 28 06:23:11 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:23:12 2023 ] Training epoch: 44
[ Wed Jun 28 06:23:19 2023 ] 	Training loss: 4.9900.  Training acc: 88.54%.
[ Wed Jun 28 06:23:19 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:23:20 2023 ] Training epoch: 45
[ Wed Jun 28 06:23:27 2023 ] 	Training loss: 5.0552.  Training acc: 89.19%.
[ Wed Jun 28 06:23:27 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 06:23:28 2023 ] Training epoch: 46
[ Wed Jun 28 06:23:36 2023 ] 	Training loss: 4.9265.  Training acc: 89.71%.
[ Wed Jun 28 06:23:36 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:23:36 2023 ] Training epoch: 47
[ Wed Jun 28 06:23:44 2023 ] 	Training loss: 5.1848.  Training acc: 88.02%.
[ Wed Jun 28 06:23:44 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:23:45 2023 ] Training epoch: 48
[ Wed Jun 28 06:23:52 2023 ] 	Training loss: 5.1517.  Training acc: 90.62%.
[ Wed Jun 28 06:23:52 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:23:53 2023 ] Training epoch: 49
[ Wed Jun 28 06:23:59 2023 ] 	Training loss: 5.2114.  Training acc: 90.10%.
[ Wed Jun 28 06:23:59 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:24:00 2023 ] Training epoch: 50
[ Wed Jun 28 06:24:05 2023 ] 	Training loss: 5.0177.  Training acc: 88.93%.
[ Wed Jun 28 06:24:05 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:24:06 2023 ] Training epoch: 51
[ Wed Jun 28 06:24:12 2023 ] 	Training loss: 5.0162.  Training acc: 88.80%.
[ Wed Jun 28 06:24:12 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:24:13 2023 ] Training epoch: 52
[ Wed Jun 28 06:24:19 2023 ] 	Training loss: 4.9388.  Training acc: 92.45%.
[ Wed Jun 28 06:24:19 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:24:19 2023 ] Training epoch: 53
[ Wed Jun 28 06:24:25 2023 ] 	Training loss: 4.9328.  Training acc: 90.62%.
[ Wed Jun 28 06:24:25 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:24:26 2023 ] Training epoch: 54
[ Wed Jun 28 06:24:33 2023 ] 	Training loss: 4.9706.  Training acc: 90.10%.
[ Wed Jun 28 06:24:33 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:24:34 2023 ] Training epoch: 55
[ Wed Jun 28 06:24:41 2023 ] 	Training loss: 5.0649.  Training acc: 88.67%.
[ Wed Jun 28 06:24:41 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:24:42 2023 ] Training epoch: 56
[ Wed Jun 28 06:24:49 2023 ] 	Training loss: 5.0131.  Training acc: 90.36%.
[ Wed Jun 28 06:24:49 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:24:50 2023 ] Training epoch: 57
[ Wed Jun 28 06:24:57 2023 ] 	Training loss: 5.0215.  Training acc: 88.93%.
[ Wed Jun 28 06:24:57 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:24:58 2023 ] Training epoch: 58
[ Wed Jun 28 06:25:05 2023 ] 	Training loss: 5.1067.  Training acc: 88.80%.
[ Wed Jun 28 06:25:05 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:25:05 2023 ] Training epoch: 59
[ Wed Jun 28 06:25:13 2023 ] 	Training loss: 4.9821.  Training acc: 90.49%.
[ Wed Jun 28 06:25:13 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:25:13 2023 ] Training epoch: 60
[ Wed Jun 28 06:25:20 2023 ] 	Training loss: 5.0580.  Training acc: 89.71%.
[ Wed Jun 28 06:25:20 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:25:21 2023 ] Training epoch: 61
[ Wed Jun 28 06:25:28 2023 ] 	Training loss: 4.9873.  Training acc: 90.49%.
[ Wed Jun 28 06:25:28 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:25:29 2023 ] Training epoch: 62
[ Wed Jun 28 06:25:37 2023 ] 	Training loss: 4.8743.  Training acc: 91.15%.
[ Wed Jun 28 06:25:37 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:25:37 2023 ] Training epoch: 63
[ Wed Jun 28 06:25:45 2023 ] 	Training loss: 5.0830.  Training acc: 90.62%.
[ Wed Jun 28 06:25:45 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:25:45 2023 ] Training epoch: 64
[ Wed Jun 28 06:25:52 2023 ] 	Training loss: 5.0186.  Training acc: 90.23%.
[ Wed Jun 28 06:25:52 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:25:53 2023 ] Training epoch: 65
[ Wed Jun 28 06:26:00 2023 ] 	Training loss: 4.9911.  Training acc: 88.54%.
[ Wed Jun 28 06:26:00 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:26:00 2023 ] Training epoch: 66
[ Wed Jun 28 06:26:06 2023 ] 	Training loss: 4.9197.  Training acc: 91.67%.
[ Wed Jun 28 06:26:06 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:26:07 2023 ] Training epoch: 67
[ Wed Jun 28 06:26:13 2023 ] 	Training loss: 5.1086.  Training acc: 89.71%.
[ Wed Jun 28 06:26:13 2023 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Jun 28 06:26:13 2023 ] Training epoch: 68
[ Wed Jun 28 06:26:19 2023 ] 	Training loss: 4.9944.  Training acc: 91.67%.
[ Wed Jun 28 06:26:19 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:26:20 2023 ] Training epoch: 69
[ Wed Jun 28 06:26:26 2023 ] 	Training loss: 5.1040.  Training acc: 89.71%.
[ Wed Jun 28 06:26:26 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:26:27 2023 ] Training epoch: 70
[ Wed Jun 28 06:26:34 2023 ] 	Training loss: 4.9924.  Training acc: 91.02%.
[ Wed Jun 28 06:26:34 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 06:26:35 2023 ] Training epoch: 71
[ Wed Jun 28 06:26:42 2023 ] 	Training loss: 4.9507.  Training acc: 89.71%.
[ Wed Jun 28 06:26:42 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:26:43 2023 ] Training epoch: 72
[ Wed Jun 28 06:26:50 2023 ] 	Training loss: 5.0026.  Training acc: 90.23%.
[ Wed Jun 28 06:26:50 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:26:51 2023 ] Training epoch: 73
[ Wed Jun 28 06:26:59 2023 ] 	Training loss: 5.0076.  Training acc: 91.15%.
[ Wed Jun 28 06:26:59 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:26:59 2023 ] Training epoch: 74
[ Wed Jun 28 06:27:07 2023 ] 	Training loss: 5.0777.  Training acc: 89.58%.
[ Wed Jun 28 06:27:07 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:27:07 2023 ] Training epoch: 75
[ Wed Jun 28 06:27:15 2023 ] 	Training loss: 5.0867.  Training acc: 89.58%.
[ Wed Jun 28 06:27:15 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:27:16 2023 ] Training epoch: 76
[ Wed Jun 28 06:27:23 2023 ] 	Training loss: 4.9163.  Training acc: 89.97%.
[ Wed Jun 28 06:27:23 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:27:23 2023 ] Training epoch: 77
[ Wed Jun 28 06:27:31 2023 ] 	Training loss: 4.9856.  Training acc: 90.36%.
[ Wed Jun 28 06:27:31 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:27:32 2023 ] Training epoch: 78
[ Wed Jun 28 06:27:39 2023 ] 	Training loss: 5.0316.  Training acc: 90.36%.
[ Wed Jun 28 06:27:39 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:27:39 2023 ] Training epoch: 79
[ Wed Jun 28 06:27:47 2023 ] 	Training loss: 4.8948.  Training acc: 89.32%.
[ Wed Jun 28 06:27:47 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:27:47 2023 ] Training epoch: 80
[ Wed Jun 28 06:27:55 2023 ] 	Training loss: 5.0012.  Training acc: 91.41%.
[ Wed Jun 28 06:27:55 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 06:27:56 2023 ] Training epoch: 81
[ Wed Jun 28 06:28:01 2023 ] 	Training loss: 4.9579.  Training acc: 91.15%.
[ Wed Jun 28 06:28:01 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:28:02 2023 ] Training epoch: 82
[ Wed Jun 28 06:28:08 2023 ] 	Training loss: 5.0830.  Training acc: 88.41%.
[ Wed Jun 28 06:28:08 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 06:28:09 2023 ] Training epoch: 83
[ Wed Jun 28 06:28:15 2023 ] 	Training loss: 4.9258.  Training acc: 89.84%.
[ Wed Jun 28 06:28:15 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:28:15 2023 ] Training epoch: 84
[ Wed Jun 28 06:28:21 2023 ] 	Training loss: 5.0345.  Training acc: 88.02%.
[ Wed Jun 28 06:28:21 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:28:22 2023 ] Training epoch: 85
[ Wed Jun 28 06:28:29 2023 ] 	Training loss: 4.9837.  Training acc: 90.89%.
[ Wed Jun 28 06:28:29 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:28:30 2023 ] Training epoch: 86
[ Wed Jun 28 06:28:37 2023 ] 	Training loss: 4.8776.  Training acc: 92.06%.
[ Wed Jun 28 06:28:37 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:28:38 2023 ] Training epoch: 87
[ Wed Jun 28 06:28:45 2023 ] 	Training loss: 4.9891.  Training acc: 88.93%.
[ Wed Jun 28 06:28:45 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:28:46 2023 ] Training epoch: 88
[ Wed Jun 28 06:28:53 2023 ] 	Training loss: 5.0823.  Training acc: 90.23%.
[ Wed Jun 28 06:28:53 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:28:54 2023 ] Training epoch: 89
[ Wed Jun 28 06:29:01 2023 ] 	Training loss: 4.9956.  Training acc: 90.76%.
[ Wed Jun 28 06:29:01 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:29:02 2023 ] Training epoch: 90
[ Wed Jun 28 06:29:09 2023 ] 	Training loss: 5.0639.  Training acc: 89.71%.
[ Wed Jun 28 06:29:09 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:29:10 2023 ] Training epoch: 91
[ Wed Jun 28 06:29:17 2023 ] 	Training loss: 4.9848.  Training acc: 91.02%.
[ Wed Jun 28 06:29:17 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:29:18 2023 ] Training epoch: 92
[ Wed Jun 28 06:29:26 2023 ] 	Training loss: 4.9957.  Training acc: 91.67%.
[ Wed Jun 28 06:29:26 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:29:26 2023 ] Training epoch: 93
[ Wed Jun 28 06:29:34 2023 ] 	Training loss: 4.9238.  Training acc: 89.97%.
[ Wed Jun 28 06:29:34 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:29:34 2023 ] Training epoch: 94
[ Wed Jun 28 06:29:41 2023 ] 	Training loss: 4.8313.  Training acc: 91.15%.
[ Wed Jun 28 06:29:41 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:29:42 2023 ] Training epoch: 95
[ Wed Jun 28 06:29:49 2023 ] 	Training loss: 4.9356.  Training acc: 92.97%.
[ Wed Jun 28 06:29:49 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 06:29:50 2023 ] Training epoch: 96
[ Wed Jun 28 06:29:57 2023 ] 	Training loss: 4.9896.  Training acc: 90.89%.
[ Wed Jun 28 06:29:57 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 06:29:58 2023 ] Training epoch: 97
[ Wed Jun 28 06:30:03 2023 ] 	Training loss: 5.0280.  Training acc: 89.45%.
[ Wed Jun 28 06:30:03 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:30:04 2023 ] Training epoch: 98
[ Wed Jun 28 06:30:10 2023 ] 	Training loss: 4.8868.  Training acc: 90.62%.
[ Wed Jun 28 06:30:10 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:30:11 2023 ] Training epoch: 99
[ Wed Jun 28 06:30:16 2023 ] 	Training loss: 4.9927.  Training acc: 89.71%.
[ Wed Jun 28 06:30:16 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:30:17 2023 ] Training epoch: 100
[ Wed Jun 28 06:30:23 2023 ] 	Training loss: 5.0088.  Training acc: 91.28%.
[ Wed Jun 28 06:30:23 2023 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Jun 28 06:30:24 2023 ] Training epoch: 101
[ Wed Jun 28 06:30:31 2023 ] 	Training loss: 5.0060.  Training acc: 89.19%.
[ Wed Jun 28 06:30:31 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:30:32 2023 ] Training epoch: 102
[ Wed Jun 28 06:30:39 2023 ] 	Training loss: 4.9728.  Training acc: 90.76%.
[ Wed Jun 28 06:30:39 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:30:40 2023 ] Training epoch: 103
[ Wed Jun 28 06:30:48 2023 ] 	Training loss: 5.0034.  Training acc: 90.62%.
[ Wed Jun 28 06:30:48 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:30:49 2023 ] Training epoch: 104
[ Wed Jun 28 06:30:56 2023 ] 	Training loss: 5.0240.  Training acc: 90.36%.
[ Wed Jun 28 06:30:56 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:30:57 2023 ] Training epoch: 105
[ Wed Jun 28 06:31:04 2023 ] 	Training loss: 4.9445.  Training acc: 91.41%.
[ Wed Jun 28 06:31:04 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 06:31:05 2023 ] Training epoch: 106
[ Wed Jun 28 06:31:12 2023 ] 	Training loss: 4.9105.  Training acc: 91.54%.
[ Wed Jun 28 06:31:12 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:31:13 2023 ] Training epoch: 107
[ Wed Jun 28 06:31:20 2023 ] 	Training loss: 4.9526.  Training acc: 91.41%.
[ Wed Jun 28 06:31:20 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:31:21 2023 ] Training epoch: 108
[ Wed Jun 28 06:31:28 2023 ] 	Training loss: 5.0038.  Training acc: 89.32%.
[ Wed Jun 28 06:31:28 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:31:29 2023 ] Training epoch: 109
[ Wed Jun 28 06:31:36 2023 ] 	Training loss: 5.0920.  Training acc: 89.19%.
[ Wed Jun 28 06:31:36 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:31:37 2023 ] Training epoch: 110
[ Wed Jun 28 06:31:44 2023 ] 	Training loss: 5.0624.  Training acc: 89.45%.
[ Wed Jun 28 06:31:44 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:31:45 2023 ] Training epoch: 111
[ Wed Jun 28 06:31:52 2023 ] 	Training loss: 4.8315.  Training acc: 90.89%.
[ Wed Jun 28 06:31:52 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:31:53 2023 ] Training epoch: 112
[ Wed Jun 28 06:31:59 2023 ] 	Training loss: 4.9587.  Training acc: 89.97%.
[ Wed Jun 28 06:31:59 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 06:31:59 2023 ] Training epoch: 113
[ Wed Jun 28 06:32:05 2023 ] 	Training loss: 4.9327.  Training acc: 91.67%.
[ Wed Jun 28 06:32:05 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:32:06 2023 ] Training epoch: 114
[ Wed Jun 28 06:32:12 2023 ] 	Training loss: 4.8437.  Training acc: 89.84%.
[ Wed Jun 28 06:32:12 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:32:13 2023 ] Training epoch: 115
[ Wed Jun 28 06:32:18 2023 ] 	Training loss: 4.9437.  Training acc: 90.49%.
[ Wed Jun 28 06:32:18 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:32:19 2023 ] Training epoch: 116
[ Wed Jun 28 06:32:26 2023 ] 	Training loss: 4.9759.  Training acc: 90.49%.
[ Wed Jun 28 06:32:26 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 06:32:27 2023 ] Training epoch: 117
[ Wed Jun 28 06:32:34 2023 ] 	Training loss: 4.9212.  Training acc: 90.36%.
[ Wed Jun 28 06:32:34 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 06:32:35 2023 ] Training epoch: 118
[ Wed Jun 28 06:32:42 2023 ] 	Training loss: 4.8475.  Training acc: 92.06%.
[ Wed Jun 28 06:32:42 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:32:42 2023 ] Training epoch: 119
[ Wed Jun 28 06:32:50 2023 ] 	Training loss: 4.9233.  Training acc: 91.15%.
[ Wed Jun 28 06:32:50 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:32:50 2023 ] Training epoch: 120
[ Wed Jun 28 06:32:57 2023 ] 	Training loss: 4.8072.  Training acc: 88.28%.
[ Wed Jun 28 06:32:57 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:32:58 2023 ] Training epoch: 121
[ Wed Jun 28 06:33:05 2023 ] 	Training loss: 4.9185.  Training acc: 90.10%.
[ Wed Jun 28 06:33:05 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:33:06 2023 ] Training epoch: 122
[ Wed Jun 28 06:33:13 2023 ] 	Training loss: 4.8918.  Training acc: 91.15%.
[ Wed Jun 28 06:33:13 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:33:14 2023 ] Training epoch: 123
[ Wed Jun 28 06:33:21 2023 ] 	Training loss: 4.9358.  Training acc: 90.36%.
[ Wed Jun 28 06:33:21 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:33:22 2023 ] Training epoch: 124
[ Wed Jun 28 06:33:30 2023 ] 	Training loss: 4.9004.  Training acc: 89.84%.
[ Wed Jun 28 06:33:30 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:33:30 2023 ] Training epoch: 125
[ Wed Jun 28 06:33:38 2023 ] 	Training loss: 4.8752.  Training acc: 91.54%.
[ Wed Jun 28 06:33:38 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:33:38 2023 ] Training epoch: 126
[ Wed Jun 28 06:33:46 2023 ] 	Training loss: 4.9673.  Training acc: 92.19%.
[ Wed Jun 28 06:33:46 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:33:47 2023 ] Training epoch: 127
[ Wed Jun 28 06:33:54 2023 ] 	Training loss: 4.8503.  Training acc: 88.54%.
[ Wed Jun 28 06:33:54 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:33:54 2023 ] Training epoch: 128
[ Wed Jun 28 06:34:00 2023 ] 	Training loss: 4.8440.  Training acc: 89.45%.
[ Wed Jun 28 06:34:00 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 06:34:01 2023 ] Training epoch: 129
[ Wed Jun 28 06:34:07 2023 ] 	Training loss: 4.8422.  Training acc: 91.02%.
[ Wed Jun 28 06:34:07 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 06:34:07 2023 ] Training epoch: 130
[ Wed Jun 28 06:34:13 2023 ] 	Training loss: 4.9745.  Training acc: 90.89%.
[ Wed Jun 28 06:34:13 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:34:14 2023 ] Training epoch: 131
[ Wed Jun 28 06:34:20 2023 ] 	Training loss: 4.9370.  Training acc: 90.23%.
[ Wed Jun 28 06:34:20 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:34:21 2023 ] Training epoch: 132
[ Wed Jun 28 06:34:28 2023 ] 	Training loss: 4.8454.  Training acc: 91.28%.
[ Wed Jun 28 06:34:28 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:34:29 2023 ] Training epoch: 133
[ Wed Jun 28 06:34:36 2023 ] 	Training loss: 4.9150.  Training acc: 89.19%.
[ Wed Jun 28 06:34:36 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:34:37 2023 ] Training epoch: 134
[ Wed Jun 28 06:34:44 2023 ] 	Training loss: 4.9460.  Training acc: 91.02%.
[ Wed Jun 28 06:34:44 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:34:45 2023 ] Training epoch: 135
[ Wed Jun 28 06:34:52 2023 ] 	Training loss: 5.0027.  Training acc: 88.15%.
[ Wed Jun 28 06:34:52 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:34:53 2023 ] Training epoch: 136
[ Wed Jun 28 06:35:00 2023 ] 	Training loss: 4.9658.  Training acc: 90.76%.
[ Wed Jun 28 06:35:00 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:35:01 2023 ] Training epoch: 137
[ Wed Jun 28 06:35:09 2023 ] 	Training loss: 4.9231.  Training acc: 91.80%.
[ Wed Jun 28 06:35:09 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:35:09 2023 ] Training epoch: 138
[ Wed Jun 28 06:35:16 2023 ] 	Training loss: 4.9543.  Training acc: 90.23%.
[ Wed Jun 28 06:35:16 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:35:17 2023 ] Training epoch: 139
[ Wed Jun 28 06:35:24 2023 ] 	Training loss: 4.8762.  Training acc: 89.06%.
[ Wed Jun 28 06:35:24 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 06:35:25 2023 ] Training epoch: 140
[ Wed Jun 28 06:35:32 2023 ] 	Training loss: 4.9363.  Training acc: 92.06%.
[ Wed Jun 28 06:35:32 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:35:33 2023 ] Training epoch: 141
[ Wed Jun 28 06:35:40 2023 ] 	Training loss: 4.8033.  Training acc: 90.89%.
[ Wed Jun 28 06:35:40 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:35:41 2023 ] Training epoch: 142
[ Wed Jun 28 06:35:48 2023 ] 	Training loss: 4.8694.  Training acc: 89.58%.
[ Wed Jun 28 06:35:48 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:35:49 2023 ] Training epoch: 143
[ Wed Jun 28 06:35:55 2023 ] 	Training loss: 4.7987.  Training acc: 92.58%.
[ Wed Jun 28 06:35:55 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:35:56 2023 ] Training epoch: 144
[ Wed Jun 28 06:36:02 2023 ] 	Training loss: 4.9592.  Training acc: 91.28%.
[ Wed Jun 28 06:36:02 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:36:03 2023 ] Training epoch: 145
[ Wed Jun 28 06:36:08 2023 ] 	Training loss: 4.9063.  Training acc: 90.62%.
[ Wed Jun 28 06:36:08 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:36:09 2023 ] Training epoch: 146
[ Wed Jun 28 06:36:15 2023 ] 	Training loss: 5.0064.  Training acc: 87.37%.
[ Wed Jun 28 06:36:15 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 06:36:15 2023 ] Training epoch: 147
[ Wed Jun 28 06:36:21 2023 ] 	Training loss: 4.8443.  Training acc: 91.41%.
[ Wed Jun 28 06:36:21 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 06:36:22 2023 ] Training epoch: 148
[ Wed Jun 28 06:36:29 2023 ] 	Training loss: 4.9058.  Training acc: 91.41%.
[ Wed Jun 28 06:36:29 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:36:30 2023 ] Training epoch: 149
[ Wed Jun 28 06:36:37 2023 ] 	Training loss: 4.8475.  Training acc: 89.58%.
[ Wed Jun 28 06:36:37 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 06:36:38 2023 ] Training epoch: 150
[ Wed Jun 28 06:36:45 2023 ] 	Training loss: 4.9588.  Training acc: 90.76%.
[ Wed Jun 28 06:36:45 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 13:56:42 2023 ] using warm up, epoch: 5
[ Wed Jun 28 13:56:43 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 13:56:43 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 13:56:43 2023 ] Start training Predictor
[ Wed Jun 28 13:56:43 2023 ] Training epoch: 1
[ Wed Jun 28 13:56:49 2023 ] 	Training loss: 110.2151.  Training acc: 33.92%.
[ Wed Jun 28 13:56:49 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 13:56:49 2023 ] Eval epoch: 1
[ Wed Jun 28 13:56:50 2023 ] 	Mean test loss of 625 batches: 640.762415.
[ Wed Jun 28 13:56:50 2023 ] 	Top1: 38.60%
[ Wed Jun 28 13:56:50 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:56:50 2023 ] Training epoch: 2
[ Wed Jun 28 13:56:53 2023 ] 	Training loss: 8.5336.  Training acc: 42.10%.
[ Wed Jun 28 13:56:53 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 13:56:53 2023 ] Eval epoch: 2
[ Wed Jun 28 13:56:53 2023 ] 	Mean test loss of 625 batches: 8.147614.
[ Wed Jun 28 13:56:53 2023 ] 	Top1: 66.67%
[ Wed Jun 28 13:56:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:56:53 2023 ] Training epoch: 3
[ Wed Jun 28 13:56:56 2023 ] 	Training loss: 5.8293.  Training acc: 55.88%.
[ Wed Jun 28 13:56:56 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 13:56:56 2023 ] Eval epoch: 3
[ Wed Jun 28 13:56:57 2023 ] 	Mean test loss of 625 batches: 28.915521.
[ Wed Jun 28 13:56:57 2023 ] 	Top1: 38.60%
[ Wed Jun 28 13:56:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:56:57 2023 ] Training epoch: 4
[ Wed Jun 28 13:57:02 2023 ] 	Training loss: 5.0450.  Training acc: 70.59%.
[ Wed Jun 28 13:57:02 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Jun 28 13:57:02 2023 ] Eval epoch: 4
[ Wed Jun 28 13:57:02 2023 ] 	Mean test loss of 625 batches: 8.469791.
[ Wed Jun 28 13:57:02 2023 ] 	Top1: 50.88%
[ Wed Jun 28 13:57:02 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:57:02 2023 ] Training epoch: 5
[ Wed Jun 28 13:57:05 2023 ] 	Training loss: 3.2021.  Training acc: 66.54%.
[ Wed Jun 28 13:57:05 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 13:57:05 2023 ] Eval epoch: 5
[ Wed Jun 28 13:57:06 2023 ] 	Mean test loss of 625 batches: 5.716123.
[ Wed Jun 28 13:57:06 2023 ] 	Top1: 35.09%
[ Wed Jun 28 13:57:06 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:57:06 2023 ] Training epoch: 6
[ Wed Jun 28 13:57:09 2023 ] 	Training loss: 3.2102.  Training acc: 59.65%.
[ Wed Jun 28 13:57:09 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 13:57:09 2023 ] Eval epoch: 6
[ Wed Jun 28 13:57:10 2023 ] 	Mean test loss of 625 batches: 5.944531.
[ Wed Jun 28 13:57:10 2023 ] 	Top1: 38.60%
[ Wed Jun 28 13:57:10 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:57:10 2023 ] Training epoch: 7
[ Wed Jun 28 13:57:13 2023 ] 	Training loss: 2.3144.  Training acc: 60.57%.
[ Wed Jun 28 13:57:13 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Wed Jun 28 13:57:13 2023 ] Eval epoch: 7
[ Wed Jun 28 13:57:14 2023 ] 	Mean test loss of 625 batches: 6.588255.
[ Wed Jun 28 13:57:14 2023 ] 	Top1: 38.60%
[ Wed Jun 28 13:57:14 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:57:14 2023 ] Training epoch: 8
[ Wed Jun 28 13:57:19 2023 ] 	Training loss: 2.1851.  Training acc: 62.87%.
[ Wed Jun 28 13:57:19 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Jun 28 13:57:19 2023 ] Eval epoch: 8
[ Wed Jun 28 13:57:19 2023 ] 	Mean test loss of 625 batches: 5.827849.
[ Wed Jun 28 13:57:19 2023 ] 	Top1: 38.60%
[ Wed Jun 28 13:57:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:57:19 2023 ] Training epoch: 9
[ Wed Jun 28 13:57:22 2023 ] 	Training loss: 1.4279.  Training acc: 67.10%.
[ Wed Jun 28 13:57:22 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 13:57:22 2023 ] Eval epoch: 9
[ Wed Jun 28 13:57:23 2023 ] 	Mean test loss of 625 batches: 0.759097.
[ Wed Jun 28 13:57:23 2023 ] 	Top1: 73.68%
[ Wed Jun 28 13:57:23 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:57:23 2023 ] Training epoch: 10
[ Wed Jun 28 13:57:26 2023 ] 	Training loss: 1.3207.  Training acc: 65.62%.
[ Wed Jun 28 13:57:26 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 13:57:26 2023 ] Eval epoch: 10
[ Wed Jun 28 13:57:27 2023 ] 	Mean test loss of 625 batches: 5.190646.
[ Wed Jun 28 13:57:27 2023 ] 	Top1: 38.60%
[ Wed Jun 28 13:57:27 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:57:27 2023 ] Training epoch: 11
[ Wed Jun 28 13:57:30 2023 ] 	Training loss: 1.4234.  Training acc: 64.43%.
[ Wed Jun 28 13:57:30 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 13:57:30 2023 ] Eval epoch: 11
[ Wed Jun 28 13:57:31 2023 ] 	Mean test loss of 625 batches: 0.504511.
[ Wed Jun 28 13:57:31 2023 ] 	Top1: 96.49%
[ Wed Jun 28 13:57:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:57:31 2023 ] Training epoch: 12
[ Wed Jun 28 13:57:34 2023 ] 	Training loss: 1.1107.  Training acc: 70.22%.
[ Wed Jun 28 13:57:34 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 13:57:34 2023 ] Eval epoch: 12
[ Wed Jun 28 13:57:35 2023 ] 	Mean test loss of 625 batches: 0.574481.
[ Wed Jun 28 13:57:35 2023 ] 	Top1: 87.72%
[ Wed Jun 28 13:57:35 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:57:35 2023 ] Training epoch: 13
[ Wed Jun 28 13:57:39 2023 ] 	Training loss: 0.9527.  Training acc: 73.25%.
[ Wed Jun 28 13:57:39 2023 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Jun 28 13:57:39 2023 ] Eval epoch: 13
[ Wed Jun 28 13:57:40 2023 ] 	Mean test loss of 625 batches: 0.648788.
[ Wed Jun 28 13:57:40 2023 ] 	Top1: 80.70%
[ Wed Jun 28 13:57:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:57:40 2023 ] Training epoch: 14
[ Wed Jun 28 13:57:44 2023 ] 	Training loss: 0.9031.  Training acc: 76.01%.
[ Wed Jun 28 13:57:44 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Jun 28 13:57:44 2023 ] Eval epoch: 14
[ Wed Jun 28 13:57:45 2023 ] 	Mean test loss of 625 batches: 0.465044.
[ Wed Jun 28 13:57:45 2023 ] 	Top1: 98.25%
[ Wed Jun 28 13:57:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:57:45 2023 ] Training epoch: 15
[ Wed Jun 28 13:57:49 2023 ] 	Training loss: 0.8310.  Training acc: 77.39%.
[ Wed Jun 28 13:57:49 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Jun 28 13:57:49 2023 ] Eval epoch: 15
[ Wed Jun 28 13:57:50 2023 ] 	Mean test loss of 625 batches: 0.434091.
[ Wed Jun 28 13:57:50 2023 ] 	Top1: 100.00%
[ Wed Jun 28 13:57:50 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:57:50 2023 ] Training epoch: 16
[ Wed Jun 28 13:57:53 2023 ] 	Training loss: 0.8394.  Training acc: 75.28%.
[ Wed Jun 28 13:57:53 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 13:57:53 2023 ] Eval epoch: 16
[ Wed Jun 28 13:57:54 2023 ] 	Mean test loss of 625 batches: 0.435748.
[ Wed Jun 28 13:57:54 2023 ] 	Top1: 100.00%
[ Wed Jun 28 13:57:54 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:57:54 2023 ] Training epoch: 17
[ Wed Jun 28 13:57:57 2023 ] 	Training loss: 0.7633.  Training acc: 81.25%.
[ Wed Jun 28 13:57:57 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 13:57:57 2023 ] Eval epoch: 17
[ Wed Jun 28 13:57:58 2023 ] 	Mean test loss of 625 batches: 0.419744.
[ Wed Jun 28 13:57:58 2023 ] 	Top1: 98.25%
[ Wed Jun 28 13:57:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:57:58 2023 ] Training epoch: 18
[ Wed Jun 28 13:58:01 2023 ] 	Training loss: 0.7178.  Training acc: 80.24%.
[ Wed Jun 28 13:58:01 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 13:58:01 2023 ] Eval epoch: 18
[ Wed Jun 28 13:58:01 2023 ] 	Mean test loss of 625 batches: 0.505442.
[ Wed Jun 28 13:58:01 2023 ] 	Top1: 89.47%
[ Wed Jun 28 13:58:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:58:01 2023 ] Training epoch: 19
[ Wed Jun 28 13:58:04 2023 ] 	Training loss: 0.7329.  Training acc: 79.41%.
[ Wed Jun 28 13:58:04 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 13:58:04 2023 ] Eval epoch: 19
[ Wed Jun 28 13:58:05 2023 ] 	Mean test loss of 625 batches: 0.446940.
[ Wed Jun 28 13:58:05 2023 ] 	Top1: 98.25%
[ Wed Jun 28 13:58:05 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:58:05 2023 ] Training epoch: 20
[ Wed Jun 28 13:58:08 2023 ] 	Training loss: 0.6362.  Training acc: 84.01%.
[ Wed Jun 28 13:58:08 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Jun 28 13:58:08 2023 ] Eval epoch: 20
[ Wed Jun 28 13:58:09 2023 ] 	Mean test loss of 625 batches: 0.390734.
[ Wed Jun 28 13:58:09 2023 ] 	Top1: 98.25%
[ Wed Jun 28 13:58:09 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:58:09 2023 ] Training epoch: 21
[ Wed Jun 28 13:58:12 2023 ] 	Training loss: 0.6065.  Training acc: 86.40%.
[ Wed Jun 28 13:58:12 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Wed Jun 28 13:58:12 2023 ] Eval epoch: 21
[ Wed Jun 28 13:58:13 2023 ] 	Mean test loss of 625 batches: 0.393373.
[ Wed Jun 28 13:58:13 2023 ] 	Top1: 100.00%
[ Wed Jun 28 13:58:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:58:13 2023 ] Training epoch: 22
[ Wed Jun 28 13:58:16 2023 ] 	Training loss: 0.6071.  Training acc: 86.03%.
[ Wed Jun 28 13:58:16 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 13:58:16 2023 ] Eval epoch: 22
[ Wed Jun 28 13:58:17 2023 ] 	Mean test loss of 625 batches: 0.402307.
[ Wed Jun 28 13:58:17 2023 ] 	Top1: 98.25%
[ Wed Jun 28 13:58:17 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:58:17 2023 ] Training epoch: 23
[ Wed Jun 28 13:58:20 2023 ] 	Training loss: 0.6115.  Training acc: 87.04%.
[ Wed Jun 28 13:58:20 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 13:58:20 2023 ] Eval epoch: 23
[ Wed Jun 28 13:58:20 2023 ] 	Mean test loss of 625 batches: 0.401721.
[ Wed Jun 28 13:58:20 2023 ] 	Top1: 98.25%
[ Wed Jun 28 13:58:20 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:58:20 2023 ] Training epoch: 24
[ Wed Jun 28 13:58:25 2023 ] 	Training loss: 0.6044.  Training acc: 85.66%.
[ Wed Jun 28 13:58:25 2023 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Jun 28 13:58:25 2023 ] Eval epoch: 24
[ Wed Jun 28 13:58:26 2023 ] 	Mean test loss of 625 batches: 0.390450.
[ Wed Jun 28 13:58:26 2023 ] 	Top1: 100.00%
[ Wed Jun 28 13:58:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:58:26 2023 ] Training epoch: 25
[ Wed Jun 28 13:58:30 2023 ] 	Training loss: 0.6108.  Training acc: 86.31%.
[ Wed Jun 28 13:58:30 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Jun 28 13:58:30 2023 ] Eval epoch: 25
[ Wed Jun 28 13:58:31 2023 ] 	Mean test loss of 625 batches: 0.393730.
[ Wed Jun 28 13:58:31 2023 ] 	Top1: 100.00%
[ Wed Jun 28 13:58:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:58:31 2023 ] Training epoch: 26
[ Wed Jun 28 13:58:34 2023 ] 	Training loss: 0.6076.  Training acc: 85.02%.
[ Wed Jun 28 13:58:34 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 13:58:34 2023 ] Eval epoch: 26
[ Wed Jun 28 13:58:35 2023 ] 	Mean test loss of 625 batches: 0.396564.
[ Wed Jun 28 13:58:35 2023 ] 	Top1: 100.00%
[ Wed Jun 28 13:58:35 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:58:35 2023 ] Training epoch: 27
[ Wed Jun 28 13:58:38 2023 ] 	Training loss: 0.5913.  Training acc: 86.86%.
[ Wed Jun 28 13:58:38 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 13:58:38 2023 ] Eval epoch: 27
[ Wed Jun 28 13:58:39 2023 ] 	Mean test loss of 625 batches: 0.400616.
[ Wed Jun 28 13:58:39 2023 ] 	Top1: 100.00%
[ Wed Jun 28 13:58:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:58:39 2023 ] Training epoch: 28
[ Wed Jun 28 13:58:42 2023 ] 	Training loss: 0.5798.  Training acc: 87.50%.
[ Wed Jun 28 13:58:42 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 13:58:42 2023 ] Eval epoch: 28
[ Wed Jun 28 13:58:43 2023 ] 	Mean test loss of 625 batches: 0.389636.
[ Wed Jun 28 13:58:43 2023 ] 	Top1: 100.00%
[ Wed Jun 28 13:58:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:58:43 2023 ] Training epoch: 29
[ Wed Jun 28 13:58:46 2023 ] 	Training loss: 0.5819.  Training acc: 86.12%.
[ Wed Jun 28 13:58:46 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 13:58:46 2023 ] Eval epoch: 29
[ Wed Jun 28 13:58:46 2023 ] 	Mean test loss of 625 batches: 0.402307.
[ Wed Jun 28 13:58:46 2023 ] 	Top1: 100.00%
[ Wed Jun 28 13:58:46 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:58:46 2023 ] Training epoch: 30
[ Wed Jun 28 13:58:49 2023 ] 	Training loss: 0.5580.  Training acc: 87.78%.
[ Wed Jun 28 13:58:49 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 13:58:49 2023 ] Eval epoch: 30
[ Wed Jun 28 13:58:50 2023 ] 	Mean test loss of 625 batches: 0.394907.
[ Wed Jun 28 13:58:50 2023 ] 	Top1: 100.00%
[ Wed Jun 28 13:58:50 2023 ] 	Top5: 100.00%
[ Wed Jun 28 13:58:51 2023 ] Best accuracy: 1.0
[ Wed Jun 28 13:58:51 2023 ] Epoch number: 15
[ Wed Jun 28 13:58:51 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 13:58:51 2023 ] Weight decay: 0.0005
[ Wed Jun 28 13:58:51 2023 ] Base LR: 0.1
[ Wed Jun 28 13:58:51 2023 ] Batch Size: 64
[ Wed Jun 28 13:58:51 2023 ] Test Batch Size: 64
[ Wed Jun 28 13:58:51 2023 ] seed: 1
[ Wed Jun 28 13:58:51 2023 ] Start training Corrector
[ Wed Jun 28 13:58:53 2023 ] Training epoch: 1
[ Wed Jun 28 13:59:02 2023 ] 	Training loss: 23.6496.  Training acc: 34.24%.
[ Wed Jun 28 13:59:02 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 13:59:02 2023 ] Training epoch: 2
[ Wed Jun 28 13:59:13 2023 ] 	Training loss: 25.0396.  Training acc: 28.91%.
[ Wed Jun 28 13:59:13 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 13:59:14 2023 ] Training epoch: 3
[ Wed Jun 28 13:59:23 2023 ] 	Training loss: 35.6149.  Training acc: 27.73%.
[ Wed Jun 28 13:59:23 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 13:59:24 2023 ] Training epoch: 4
[ Wed Jun 28 13:59:31 2023 ] 	Training loss: 34.1731.  Training acc: 26.43%.
[ Wed Jun 28 13:59:31 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 13:59:32 2023 ] Training epoch: 5
[ Wed Jun 28 13:59:39 2023 ] 	Training loss: 36.1102.  Training acc: 31.77%.
[ Wed Jun 28 13:59:39 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 13:59:39 2023 ] Training epoch: 6
[ Wed Jun 28 13:59:47 2023 ] 	Training loss: 35.6927.  Training acc: 33.07%.
[ Wed Jun 28 13:59:47 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 13:59:47 2023 ] Training epoch: 7
[ Wed Jun 28 13:59:56 2023 ] 	Training loss: 41.5285.  Training acc: 28.12%.
[ Wed Jun 28 13:59:56 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 13:59:57 2023 ] Training epoch: 8
[ Wed Jun 28 14:00:05 2023 ] 	Training loss: 47.8802.  Training acc: 27.86%.
[ Wed Jun 28 14:00:05 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:00:06 2023 ] Training epoch: 9
[ Wed Jun 28 14:00:13 2023 ] 	Training loss: 38.7080.  Training acc: 30.34%.
[ Wed Jun 28 14:00:13 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:00:14 2023 ] Training epoch: 10
[ Wed Jun 28 14:00:22 2023 ] 	Training loss: 34.4275.  Training acc: 35.68%.
[ Wed Jun 28 14:00:22 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:00:23 2023 ] Training epoch: 11
[ Wed Jun 28 14:00:31 2023 ] 	Training loss: 36.5344.  Training acc: 33.33%.
[ Wed Jun 28 14:00:31 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:00:31 2023 ] Training epoch: 12
[ Wed Jun 28 14:00:42 2023 ] 	Training loss: 36.1119.  Training acc: 36.59%.
[ Wed Jun 28 14:00:42 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:00:43 2023 ] Training epoch: 13
[ Wed Jun 28 14:00:54 2023 ] 	Training loss: 35.9352.  Training acc: 33.72%.
[ Wed Jun 28 14:00:54 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:00:54 2023 ] Training epoch: 14
[ Wed Jun 28 14:01:02 2023 ] 	Training loss: 35.2484.  Training acc: 33.59%.
[ Wed Jun 28 14:01:02 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:01:03 2023 ] Training epoch: 15
[ Wed Jun 28 14:01:10 2023 ] 	Training loss: 34.6744.  Training acc: 31.12%.
[ Wed Jun 28 14:01:10 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:01:11 2023 ] Training epoch: 16
[ Wed Jun 28 14:01:19 2023 ] 	Training loss: 35.0434.  Training acc: 30.86%.
[ Wed Jun 28 14:01:19 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:01:19 2023 ] Training epoch: 17
[ Wed Jun 28 14:01:29 2023 ] 	Training loss: 35.1285.  Training acc: 32.29%.
[ Wed Jun 28 14:01:29 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:01:29 2023 ] Training epoch: 18
[ Wed Jun 28 14:01:38 2023 ] 	Training loss: 35.0453.  Training acc: 30.86%.
[ Wed Jun 28 14:01:38 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:01:39 2023 ] Training epoch: 19
[ Wed Jun 28 14:01:47 2023 ] 	Training loss: 33.8219.  Training acc: 31.25%.
[ Wed Jun 28 14:01:47 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:01:48 2023 ] Training epoch: 20
[ Wed Jun 28 14:01:55 2023 ] 	Training loss: 33.4010.  Training acc: 31.38%.
[ Wed Jun 28 14:01:55 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:01:56 2023 ] Training epoch: 21
[ Wed Jun 28 14:02:03 2023 ] 	Training loss: 33.3350.  Training acc: 35.03%.
[ Wed Jun 28 14:02:03 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:02:04 2023 ] Training epoch: 22
[ Wed Jun 28 14:02:17 2023 ] 	Training loss: 33.3160.  Training acc: 32.29%.
[ Wed Jun 28 14:02:17 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 14:02:18 2023 ] Training epoch: 23
[ Wed Jun 28 14:02:29 2023 ] 	Training loss: 33.2240.  Training acc: 33.98%.
[ Wed Jun 28 14:02:29 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:02:30 2023 ] Training epoch: 24
[ Wed Jun 28 14:02:38 2023 ] 	Training loss: 33.2401.  Training acc: 31.51%.
[ Wed Jun 28 14:02:38 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:02:38 2023 ] Training epoch: 25
[ Wed Jun 28 14:02:46 2023 ] 	Training loss: 33.2465.  Training acc: 32.94%.
[ Wed Jun 28 14:02:46 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:02:47 2023 ] Training epoch: 26
[ Wed Jun 28 14:02:55 2023 ] 	Training loss: 33.1404.  Training acc: 30.21%.
[ Wed Jun 28 14:02:55 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:02:56 2023 ] Training epoch: 27
[ Wed Jun 28 14:03:04 2023 ] 	Training loss: 33.2144.  Training acc: 31.38%.
[ Wed Jun 28 14:03:04 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:03:04 2023 ] Training epoch: 28
[ Wed Jun 28 14:03:13 2023 ] 	Training loss: 33.2227.  Training acc: 32.81%.
[ Wed Jun 28 14:03:13 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:03:14 2023 ] Training epoch: 29
[ Wed Jun 28 14:03:22 2023 ] 	Training loss: 33.1241.  Training acc: 33.72%.
[ Wed Jun 28 14:03:22 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:03:22 2023 ] Training epoch: 30
[ Wed Jun 28 14:03:31 2023 ] 	Training loss: 33.3397.  Training acc: 30.99%.
[ Wed Jun 28 14:03:31 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:03:32 2023 ] Training epoch: 31
[ Wed Jun 28 14:03:39 2023 ] 	Training loss: 32.8455.  Training acc: 31.90%.
[ Wed Jun 28 14:03:39 2023 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Jun 28 14:03:40 2023 ] Training epoch: 32
[ Wed Jun 28 14:03:51 2023 ] 	Training loss: 33.0745.  Training acc: 33.59%.
[ Wed Jun 28 14:03:51 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:03:52 2023 ] Training epoch: 33
[ Wed Jun 28 14:04:03 2023 ] 	Training loss: 32.9063.  Training acc: 30.60%.
[ Wed Jun 28 14:04:03 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:04:04 2023 ] Training epoch: 34
[ Wed Jun 28 14:04:15 2023 ] 	Training loss: 32.3968.  Training acc: 33.72%.
[ Wed Jun 28 14:04:15 2023 ] 	Time consumption: [Data]05%, [Network]94%
[ Wed Jun 28 14:04:16 2023 ] Training epoch: 35
[ Wed Jun 28 14:04:24 2023 ] 	Training loss: 32.7851.  Training acc: 31.77%.
[ Wed Jun 28 14:04:24 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:04:25 2023 ] Training epoch: 36
[ Wed Jun 28 14:04:32 2023 ] 	Training loss: 32.7454.  Training acc: 32.29%.
[ Wed Jun 28 14:04:32 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:04:33 2023 ] Training epoch: 37
[ Wed Jun 28 14:04:40 2023 ] 	Training loss: 32.7819.  Training acc: 34.77%.
[ Wed Jun 28 14:04:40 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:04:41 2023 ] Training epoch: 38
[ Wed Jun 28 14:04:51 2023 ] 	Training loss: 32.8083.  Training acc: 32.94%.
[ Wed Jun 28 14:04:51 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:04:52 2023 ] Training epoch: 39
[ Wed Jun 28 14:04:59 2023 ] 	Training loss: 32.3020.  Training acc: 33.59%.
[ Wed Jun 28 14:04:59 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:05:00 2023 ] Training epoch: 40
[ Wed Jun 28 14:05:07 2023 ] 	Training loss: 32.5546.  Training acc: 30.60%.
[ Wed Jun 28 14:05:07 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:05:08 2023 ] Training epoch: 41
[ Wed Jun 28 14:05:16 2023 ] 	Training loss: 31.9952.  Training acc: 35.03%.
[ Wed Jun 28 14:05:16 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:05:16 2023 ] Training epoch: 42
[ Wed Jun 28 14:05:28 2023 ] 	Training loss: 32.0523.  Training acc: 32.81%.
[ Wed Jun 28 14:05:28 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:05:29 2023 ] Training epoch: 43
[ Wed Jun 28 14:05:39 2023 ] 	Training loss: 32.3990.  Training acc: 32.03%.
[ Wed Jun 28 14:05:39 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:05:40 2023 ] Training epoch: 44
[ Wed Jun 28 14:05:51 2023 ] 	Training loss: 31.9743.  Training acc: 34.90%.
[ Wed Jun 28 14:05:51 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:05:52 2023 ] Training epoch: 45
[ Wed Jun 28 14:06:04 2023 ] 	Training loss: 32.3878.  Training acc: 30.99%.
[ Wed Jun 28 14:06:04 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:06:05 2023 ] Training epoch: 46
[ Wed Jun 28 14:06:13 2023 ] 	Training loss: 31.8802.  Training acc: 31.64%.
[ Wed Jun 28 14:06:13 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:06:13 2023 ] Training epoch: 47
[ Wed Jun 28 14:06:21 2023 ] 	Training loss: 32.4345.  Training acc: 32.42%.
[ Wed Jun 28 14:06:21 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:06:22 2023 ] Training epoch: 48
[ Wed Jun 28 14:06:30 2023 ] 	Training loss: 32.4529.  Training acc: 30.47%.
[ Wed Jun 28 14:06:30 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:06:31 2023 ] Training epoch: 49
[ Wed Jun 28 14:06:38 2023 ] 	Training loss: 32.5499.  Training acc: 33.20%.
[ Wed Jun 28 14:06:38 2023 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Jun 28 14:06:38 2023 ] Training epoch: 50
[ Wed Jun 28 14:06:47 2023 ] 	Training loss: 32.4567.  Training acc: 31.38%.
[ Wed Jun 28 14:06:47 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:06:48 2023 ] Training epoch: 51
[ Wed Jun 28 14:06:55 2023 ] 	Training loss: 32.0663.  Training acc: 33.46%.
[ Wed Jun 28 14:06:55 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:06:56 2023 ] Training epoch: 52
[ Wed Jun 28 14:07:04 2023 ] 	Training loss: 32.0294.  Training acc: 32.81%.
[ Wed Jun 28 14:07:04 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 14:07:04 2023 ] Training epoch: 53
[ Wed Jun 28 14:07:15 2023 ] 	Training loss: 32.2408.  Training acc: 31.51%.
[ Wed Jun 28 14:07:15 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 14:07:16 2023 ] Training epoch: 54
[ Wed Jun 28 14:07:30 2023 ] 	Training loss: 32.3172.  Training acc: 31.51%.
[ Wed Jun 28 14:07:30 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 14:07:31 2023 ] Training epoch: 55
[ Wed Jun 28 14:07:42 2023 ] 	Training loss: 32.2120.  Training acc: 32.29%.
[ Wed Jun 28 14:07:42 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:07:43 2023 ] Training epoch: 56
[ Wed Jun 28 14:07:54 2023 ] 	Training loss: 32.1417.  Training acc: 31.77%.
[ Wed Jun 28 14:07:54 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:07:55 2023 ] Training epoch: 57
[ Wed Jun 28 14:08:06 2023 ] 	Training loss: 32.0689.  Training acc: 33.20%.
[ Wed Jun 28 14:08:06 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:08:06 2023 ] Training epoch: 58
[ Wed Jun 28 14:08:14 2023 ] 	Training loss: 32.5243.  Training acc: 30.99%.
[ Wed Jun 28 14:08:14 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:08:15 2023 ] Training epoch: 59
[ Wed Jun 28 14:08:22 2023 ] 	Training loss: 32.0543.  Training acc: 32.55%.
[ Wed Jun 28 14:08:22 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:08:23 2023 ] Training epoch: 60
[ Wed Jun 28 14:08:29 2023 ] 	Training loss: 32.1890.  Training acc: 34.11%.
[ Wed Jun 28 14:08:29 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 14:08:30 2023 ] Training epoch: 61
[ Wed Jun 28 14:08:36 2023 ] 	Training loss: 32.0849.  Training acc: 31.51%.
[ Wed Jun 28 14:08:36 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:08:37 2023 ] Training epoch: 62
[ Wed Jun 28 14:08:45 2023 ] 	Training loss: 32.2917.  Training acc: 31.12%.
[ Wed Jun 28 14:08:45 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:08:46 2023 ] Training epoch: 63
[ Wed Jun 28 14:08:55 2023 ] 	Training loss: 32.4041.  Training acc: 31.51%.
[ Wed Jun 28 14:08:55 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:08:55 2023 ] Training epoch: 64
[ Wed Jun 28 14:09:03 2023 ] 	Training loss: 32.2094.  Training acc: 33.20%.
[ Wed Jun 28 14:09:03 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:09:04 2023 ] Training epoch: 65
[ Wed Jun 28 14:09:12 2023 ] 	Training loss: 32.1135.  Training acc: 32.42%.
[ Wed Jun 28 14:09:12 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:09:13 2023 ] Training epoch: 66
[ Wed Jun 28 14:09:20 2023 ] 	Training loss: 32.2961.  Training acc: 34.11%.
[ Wed Jun 28 14:09:20 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:09:21 2023 ] Training epoch: 67
[ Wed Jun 28 14:09:31 2023 ] 	Training loss: 32.3115.  Training acc: 30.47%.
[ Wed Jun 28 14:09:31 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:09:32 2023 ] Training epoch: 68
[ Wed Jun 28 14:09:41 2023 ] 	Training loss: 32.2152.  Training acc: 30.08%.
[ Wed Jun 28 14:09:41 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:09:42 2023 ] Training epoch: 69
[ Wed Jun 28 14:09:49 2023 ] 	Training loss: 32.2729.  Training acc: 32.68%.
[ Wed Jun 28 14:09:49 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:09:50 2023 ] Training epoch: 70
[ Wed Jun 28 14:09:58 2023 ] 	Training loss: 31.9969.  Training acc: 31.25%.
[ Wed Jun 28 14:09:58 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:09:58 2023 ] Training epoch: 71
[ Wed Jun 28 14:10:05 2023 ] 	Training loss: 32.0062.  Training acc: 32.29%.
[ Wed Jun 28 14:10:05 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:10:06 2023 ] Training epoch: 72
[ Wed Jun 28 14:10:15 2023 ] 	Training loss: 32.0777.  Training acc: 32.16%.
[ Wed Jun 28 14:10:15 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 14:10:15 2023 ] Training epoch: 73
[ Wed Jun 28 14:10:22 2023 ] 	Training loss: 32.0335.  Training acc: 31.51%.
[ Wed Jun 28 14:10:22 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:10:23 2023 ] Training epoch: 74
[ Wed Jun 28 14:10:29 2023 ] 	Training loss: 32.1642.  Training acc: 31.12%.
[ Wed Jun 28 14:10:29 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Jun 28 14:10:30 2023 ] Training epoch: 75
[ Wed Jun 28 14:10:37 2023 ] 	Training loss: 32.4008.  Training acc: 32.42%.
[ Wed Jun 28 14:10:37 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:10:38 2023 ] Training epoch: 76
[ Wed Jun 28 14:10:45 2023 ] 	Training loss: 32.2838.  Training acc: 30.73%.
[ Wed Jun 28 14:10:45 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:10:46 2023 ] Training epoch: 77
[ Wed Jun 28 14:10:55 2023 ] 	Training loss: 32.1854.  Training acc: 30.34%.
[ Wed Jun 28 14:10:55 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:10:56 2023 ] Training epoch: 78
[ Wed Jun 28 14:11:06 2023 ] 	Training loss: 32.2252.  Training acc: 32.68%.
[ Wed Jun 28 14:11:06 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:11:07 2023 ] Training epoch: 79
[ Wed Jun 28 14:11:15 2023 ] 	Training loss: 31.9041.  Training acc: 32.16%.
[ Wed Jun 28 14:11:15 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 14:11:15 2023 ] Training epoch: 80
[ Wed Jun 28 14:11:23 2023 ] 	Training loss: 32.3022.  Training acc: 30.34%.
[ Wed Jun 28 14:11:23 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:11:24 2023 ] Training epoch: 81
[ Wed Jun 28 14:11:32 2023 ] 	Training loss: 32.1054.  Training acc: 33.98%.
[ Wed Jun 28 14:11:32 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 14:11:32 2023 ] Training epoch: 82
[ Wed Jun 28 14:11:42 2023 ] 	Training loss: 32.4348.  Training acc: 30.60%.
[ Wed Jun 28 14:11:42 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:11:42 2023 ] Training epoch: 83
[ Wed Jun 28 14:11:53 2023 ] 	Training loss: 32.2521.  Training acc: 30.34%.
[ Wed Jun 28 14:11:53 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:11:54 2023 ] Training epoch: 84
[ Wed Jun 28 14:12:03 2023 ] 	Training loss: 32.3129.  Training acc: 32.03%.
[ Wed Jun 28 14:12:03 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:12:03 2023 ] Training epoch: 85
[ Wed Jun 28 14:12:10 2023 ] 	Training loss: 32.2243.  Training acc: 30.47%.
[ Wed Jun 28 14:12:10 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:12:10 2023 ] Training epoch: 86
[ Wed Jun 28 14:12:17 2023 ] 	Training loss: 32.0596.  Training acc: 33.72%.
[ Wed Jun 28 14:12:17 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:12:18 2023 ] Training epoch: 87
[ Wed Jun 28 14:12:24 2023 ] 	Training loss: 32.3376.  Training acc: 31.12%.
[ Wed Jun 28 14:12:24 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 14:12:24 2023 ] Training epoch: 88
[ Wed Jun 28 14:12:31 2023 ] 	Training loss: 32.3299.  Training acc: 32.16%.
[ Wed Jun 28 14:12:31 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:12:32 2023 ] Training epoch: 89
[ Wed Jun 28 14:12:41 2023 ] 	Training loss: 32.2434.  Training acc: 33.33%.
[ Wed Jun 28 14:12:41 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:12:42 2023 ] Training epoch: 90
[ Wed Jun 28 14:12:52 2023 ] 	Training loss: 32.2311.  Training acc: 31.38%.
[ Wed Jun 28 14:12:52 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 14:12:53 2023 ] Training epoch: 91
[ Wed Jun 28 14:13:00 2023 ] 	Training loss: 32.0328.  Training acc: 31.25%.
[ Wed Jun 28 14:13:00 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:13:01 2023 ] Training epoch: 92
[ Wed Jun 28 14:13:08 2023 ] 	Training loss: 32.2839.  Training acc: 31.64%.
[ Wed Jun 28 14:13:08 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:13:09 2023 ] Training epoch: 93
[ Wed Jun 28 14:13:16 2023 ] 	Training loss: 32.3639.  Training acc: 32.55%.
[ Wed Jun 28 14:13:16 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:13:17 2023 ] Training epoch: 94
[ Wed Jun 28 14:13:25 2023 ] 	Training loss: 32.0722.  Training acc: 33.07%.
[ Wed Jun 28 14:13:25 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:13:26 2023 ] Training epoch: 95
[ Wed Jun 28 14:13:36 2023 ] 	Training loss: 32.1486.  Training acc: 31.90%.
[ Wed Jun 28 14:13:36 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:13:37 2023 ] Training epoch: 96
[ Wed Jun 28 14:13:49 2023 ] 	Training loss: 32.3825.  Training acc: 35.29%.
[ Wed Jun 28 14:13:49 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:13:50 2023 ] Training epoch: 97
[ Wed Jun 28 14:13:57 2023 ] 	Training loss: 32.2317.  Training acc: 31.12%.
[ Wed Jun 28 14:13:57 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:13:58 2023 ] Training epoch: 98
[ Wed Jun 28 14:14:06 2023 ] 	Training loss: 32.4150.  Training acc: 34.64%.
[ Wed Jun 28 14:14:06 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 14:14:06 2023 ] Training epoch: 99
[ Wed Jun 28 14:14:15 2023 ] 	Training loss: 32.2006.  Training acc: 33.33%.
[ Wed Jun 28 14:14:15 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:14:15 2023 ] Training epoch: 100
[ Wed Jun 28 14:14:22 2023 ] 	Training loss: 32.2923.  Training acc: 30.47%.
[ Wed Jun 28 14:14:22 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:14:23 2023 ] Training epoch: 101
[ Wed Jun 28 14:14:30 2023 ] 	Training loss: 32.6168.  Training acc: 33.85%.
[ Wed Jun 28 14:14:30 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 14:14:31 2023 ] Training epoch: 102
[ Wed Jun 28 14:14:42 2023 ] using warm up, epoch: 5
[ Wed Jun 28 14:14:42 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 14:14:42 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 14:14:42 2023 ] Start training Predictor
[ Wed Jun 28 14:14:42 2023 ] Training epoch: 1
[ Wed Jun 28 14:14:48 2023 ] 	Training loss: 109.2523.  Training acc: 36.21%.
[ Wed Jun 28 14:14:48 2023 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Jun 28 14:14:48 2023 ] Eval epoch: 1
[ Wed Jun 28 14:14:50 2023 ] 	Mean test loss of 625 batches: 265.394376.
[ Wed Jun 28 14:14:50 2023 ] 	Top1: 38.60%
[ Wed Jun 28 14:14:50 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:14:50 2023 ] Training epoch: 2
[ Wed Jun 28 14:14:53 2023 ] 	Training loss: 9.4322.  Training acc: 37.68%.
[ Wed Jun 28 14:14:53 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 14:14:53 2023 ] Eval epoch: 2
[ Wed Jun 28 14:14:54 2023 ] 	Mean test loss of 625 batches: 3.580214.
[ Wed Jun 28 14:14:54 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:14:54 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:14:54 2023 ] Training epoch: 3
[ Wed Jun 28 14:14:57 2023 ] 	Training loss: 5.2047.  Training acc: 53.31%.
[ Wed Jun 28 14:14:57 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 14:14:57 2023 ] Eval epoch: 3
[ Wed Jun 28 14:14:57 2023 ] 	Mean test loss of 625 batches: 1.313132.
[ Wed Jun 28 14:14:57 2023 ] 	Top1: 64.91%
[ Wed Jun 28 14:14:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:14:57 2023 ] Training epoch: 4
[ Wed Jun 28 14:15:00 2023 ] 	Training loss: 3.2584.  Training acc: 68.93%.
[ Wed Jun 28 14:15:00 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 14:15:00 2023 ] Eval epoch: 4
[ Wed Jun 28 14:15:01 2023 ] 	Mean test loss of 625 batches: 1.648657.
[ Wed Jun 28 14:15:01 2023 ] 	Top1: 80.70%
[ Wed Jun 28 14:15:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:15:01 2023 ] Training epoch: 5
[ Wed Jun 28 14:15:04 2023 ] 	Training loss: 5.0196.  Training acc: 59.28%.
[ Wed Jun 28 14:15:04 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 14:15:04 2023 ] Eval epoch: 5
[ Wed Jun 28 14:15:05 2023 ] 	Mean test loss of 625 batches: 28.544445.
[ Wed Jun 28 14:15:05 2023 ] 	Top1: 29.82%
[ Wed Jun 28 14:15:05 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:15:05 2023 ] Training epoch: 6
[ Wed Jun 28 14:15:08 2023 ] 	Training loss: 5.6699.  Training acc: 43.75%.
[ Wed Jun 28 14:15:08 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 14:15:08 2023 ] Eval epoch: 6
[ Wed Jun 28 14:15:08 2023 ] 	Mean test loss of 625 batches: 1.832576.
[ Wed Jun 28 14:15:08 2023 ] 	Top1: 28.07%
[ Wed Jun 28 14:15:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:15:08 2023 ] Training epoch: 7
[ Wed Jun 28 14:15:11 2023 ] 	Training loss: 2.0141.  Training acc: 58.27%.
[ Wed Jun 28 14:15:11 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 14:15:11 2023 ] Eval epoch: 7
[ Wed Jun 28 14:15:12 2023 ] 	Mean test loss of 625 batches: 4.764469.
[ Wed Jun 28 14:15:12 2023 ] 	Top1: 43.86%
[ Wed Jun 28 14:15:12 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:15:12 2023 ] Training epoch: 8
[ Wed Jun 28 14:15:15 2023 ] 	Training loss: 2.1273.  Training acc: 58.09%.
[ Wed Jun 28 14:15:15 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 14:15:15 2023 ] Eval epoch: 8
[ Wed Jun 28 14:15:15 2023 ] 	Mean test loss of 625 batches: 1.290485.
[ Wed Jun 28 14:15:15 2023 ] 	Top1: 64.91%
[ Wed Jun 28 14:15:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:15:15 2023 ] Training epoch: 9
[ Wed Jun 28 14:15:18 2023 ] 	Training loss: 1.1901.  Training acc: 62.32%.
[ Wed Jun 28 14:15:18 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 14:15:18 2023 ] Eval epoch: 9
[ Wed Jun 28 14:15:19 2023 ] 	Mean test loss of 625 batches: 1.533724.
[ Wed Jun 28 14:15:19 2023 ] 	Top1: 45.61%
[ Wed Jun 28 14:15:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:15:19 2023 ] Training epoch: 10
[ Wed Jun 28 14:15:23 2023 ] 	Training loss: 1.2980.  Training acc: 62.13%.
[ Wed Jun 28 14:15:23 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Wed Jun 28 14:15:23 2023 ] Eval epoch: 10
[ Wed Jun 28 14:15:23 2023 ] 	Mean test loss of 625 batches: 0.911546.
[ Wed Jun 28 14:15:23 2023 ] 	Top1: 61.40%
[ Wed Jun 28 14:15:23 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:15:23 2023 ] Training epoch: 11
[ Wed Jun 28 14:15:29 2023 ] 	Training loss: 1.0180.  Training acc: 67.46%.
[ Wed Jun 28 14:15:29 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 14:15:29 2023 ] Eval epoch: 11
[ Wed Jun 28 14:15:30 2023 ] 	Mean test loss of 625 batches: 0.648471.
[ Wed Jun 28 14:15:30 2023 ] 	Top1: 78.95%
[ Wed Jun 28 14:15:30 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:15:30 2023 ] Training epoch: 12
[ Wed Jun 28 14:15:34 2023 ] 	Training loss: 0.8247.  Training acc: 72.98%.
[ Wed Jun 28 14:15:34 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Jun 28 14:15:34 2023 ] Eval epoch: 12
[ Wed Jun 28 14:15:35 2023 ] 	Mean test loss of 625 batches: 0.599615.
[ Wed Jun 28 14:15:35 2023 ] 	Top1: 84.21%
[ Wed Jun 28 14:15:35 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:15:35 2023 ] Training epoch: 13
[ Wed Jun 28 14:15:40 2023 ] 	Training loss: 0.7357.  Training acc: 77.67%.
[ Wed Jun 28 14:15:40 2023 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Jun 28 14:15:40 2023 ] Eval epoch: 13
[ Wed Jun 28 14:15:41 2023 ] 	Mean test loss of 625 batches: 0.534734.
[ Wed Jun 28 14:15:41 2023 ] 	Top1: 89.47%
[ Wed Jun 28 14:15:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:15:41 2023 ] Training epoch: 14
[ Wed Jun 28 14:15:45 2023 ] 	Training loss: 0.6620.  Training acc: 80.79%.
[ Wed Jun 28 14:15:45 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Jun 28 14:15:45 2023 ] Eval epoch: 14
[ Wed Jun 28 14:15:46 2023 ] 	Mean test loss of 625 batches: 0.562488.
[ Wed Jun 28 14:15:46 2023 ] 	Top1: 85.96%
[ Wed Jun 28 14:15:46 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:15:46 2023 ] Training epoch: 15
[ Wed Jun 28 14:15:51 2023 ] 	Training loss: 0.5877.  Training acc: 86.49%.
[ Wed Jun 28 14:15:51 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Jun 28 14:15:51 2023 ] Eval epoch: 15
[ Wed Jun 28 14:15:52 2023 ] 	Mean test loss of 625 batches: 0.477562.
[ Wed Jun 28 14:15:52 2023 ] 	Top1: 94.74%
[ Wed Jun 28 14:15:52 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:15:52 2023 ] Training epoch: 16
[ Wed Jun 28 14:15:56 2023 ] 	Training loss: 0.5834.  Training acc: 86.31%.
[ Wed Jun 28 14:15:56 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Jun 28 14:15:56 2023 ] Eval epoch: 16
[ Wed Jun 28 14:15:57 2023 ] 	Mean test loss of 625 batches: 0.500300.
[ Wed Jun 28 14:15:57 2023 ] 	Top1: 92.98%
[ Wed Jun 28 14:15:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:15:57 2023 ] Training epoch: 17
[ Wed Jun 28 14:16:00 2023 ] 	Training loss: 0.5105.  Training acc: 91.36%.
[ Wed Jun 28 14:16:00 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 14:16:00 2023 ] Eval epoch: 17
[ Wed Jun 28 14:16:01 2023 ] 	Mean test loss of 625 batches: 0.427624.
[ Wed Jun 28 14:16:01 2023 ] 	Top1: 94.74%
[ Wed Jun 28 14:16:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:16:01 2023 ] Training epoch: 18
[ Wed Jun 28 14:16:04 2023 ] 	Training loss: 0.5091.  Training acc: 90.07%.
[ Wed Jun 28 14:16:04 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 14:16:04 2023 ] Eval epoch: 18
[ Wed Jun 28 14:16:05 2023 ] 	Mean test loss of 625 batches: 0.382351.
[ Wed Jun 28 14:16:05 2023 ] 	Top1: 98.25%
[ Wed Jun 28 14:16:05 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:16:05 2023 ] Training epoch: 19
[ Wed Jun 28 14:16:08 2023 ] 	Training loss: 0.4899.  Training acc: 92.37%.
[ Wed Jun 28 14:16:08 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Wed Jun 28 14:16:08 2023 ] Eval epoch: 19
[ Wed Jun 28 14:16:09 2023 ] 	Mean test loss of 625 batches: 0.363165.
[ Wed Jun 28 14:16:09 2023 ] 	Top1: 98.25%
[ Wed Jun 28 14:16:09 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:16:09 2023 ] Training epoch: 20
[ Wed Jun 28 14:16:12 2023 ] 	Training loss: 0.4586.  Training acc: 94.67%.
[ Wed Jun 28 14:16:12 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 14:16:12 2023 ] Eval epoch: 20
[ Wed Jun 28 14:16:13 2023 ] 	Mean test loss of 625 batches: 0.368442.
[ Wed Jun 28 14:16:13 2023 ] 	Top1: 98.25%
[ Wed Jun 28 14:16:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:16:13 2023 ] Training epoch: 21
[ Wed Jun 28 14:16:16 2023 ] 	Training loss: 0.4522.  Training acc: 94.30%.
[ Wed Jun 28 14:16:16 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 14:16:16 2023 ] Eval epoch: 21
[ Wed Jun 28 14:16:16 2023 ] 	Mean test loss of 625 batches: 0.381061.
[ Wed Jun 28 14:16:16 2023 ] 	Top1: 98.25%
[ Wed Jun 28 14:16:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:16:16 2023 ] Training epoch: 22
[ Wed Jun 28 14:16:19 2023 ] 	Training loss: 0.4362.  Training acc: 94.94%.
[ Wed Jun 28 14:16:19 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 14:16:19 2023 ] Eval epoch: 22
[ Wed Jun 28 14:16:20 2023 ] 	Mean test loss of 625 batches: 0.369625.
[ Wed Jun 28 14:16:20 2023 ] 	Top1: 98.25%
[ Wed Jun 28 14:16:20 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:16:20 2023 ] Training epoch: 23
[ Wed Jun 28 14:16:23 2023 ] 	Training loss: 0.4238.  Training acc: 95.86%.
[ Wed Jun 28 14:16:23 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Wed Jun 28 14:16:23 2023 ] Eval epoch: 23
[ Wed Jun 28 14:16:24 2023 ] 	Mean test loss of 625 batches: 0.372592.
[ Wed Jun 28 14:16:24 2023 ] 	Top1: 98.25%
[ Wed Jun 28 14:16:24 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:16:24 2023 ] Training epoch: 24
[ Wed Jun 28 14:16:27 2023 ] 	Training loss: 0.4353.  Training acc: 95.59%.
[ Wed Jun 28 14:16:27 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 14:16:27 2023 ] Eval epoch: 24
[ Wed Jun 28 14:16:28 2023 ] 	Mean test loss of 625 batches: 0.365229.
[ Wed Jun 28 14:16:28 2023 ] 	Top1: 98.25%
[ Wed Jun 28 14:16:28 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:16:28 2023 ] Training epoch: 25
[ Wed Jun 28 14:16:32 2023 ] 	Training loss: 0.4399.  Training acc: 94.76%.
[ Wed Jun 28 14:16:32 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Jun 28 14:16:32 2023 ] Eval epoch: 25
[ Wed Jun 28 14:16:32 2023 ] 	Mean test loss of 625 batches: 0.359157.
[ Wed Jun 28 14:16:32 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:16:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:16:32 2023 ] Training epoch: 26
[ Wed Jun 28 14:16:37 2023 ] 	Training loss: 0.4372.  Training acc: 95.04%.
[ Wed Jun 28 14:16:37 2023 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Jun 28 14:16:37 2023 ] Eval epoch: 26
[ Wed Jun 28 14:16:37 2023 ] 	Mean test loss of 625 batches: 0.357253.
[ Wed Jun 28 14:16:37 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:16:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:16:37 2023 ] Training epoch: 27
[ Wed Jun 28 14:16:40 2023 ] 	Training loss: 0.4291.  Training acc: 95.59%.
[ Wed Jun 28 14:16:40 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 14:16:40 2023 ] Eval epoch: 27
[ Wed Jun 28 14:16:41 2023 ] 	Mean test loss of 625 batches: 0.361403.
[ Wed Jun 28 14:16:41 2023 ] 	Top1: 98.25%
[ Wed Jun 28 14:16:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:16:41 2023 ] Training epoch: 28
[ Wed Jun 28 14:16:45 2023 ] 	Training loss: 0.4223.  Training acc: 95.50%.
[ Wed Jun 28 14:16:45 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Wed Jun 28 14:16:45 2023 ] Eval epoch: 28
[ Wed Jun 28 14:16:46 2023 ] 	Mean test loss of 625 batches: 0.359630.
[ Wed Jun 28 14:16:46 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:16:46 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:16:46 2023 ] Training epoch: 29
[ Wed Jun 28 14:16:49 2023 ] 	Training loss: 0.4412.  Training acc: 94.58%.
[ Wed Jun 28 14:16:49 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 14:16:49 2023 ] Eval epoch: 29
[ Wed Jun 28 14:16:49 2023 ] 	Mean test loss of 625 batches: 0.352361.
[ Wed Jun 28 14:16:49 2023 ] 	Top1: 98.25%
[ Wed Jun 28 14:16:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:16:49 2023 ] Training epoch: 30
[ Wed Jun 28 14:16:52 2023 ] 	Training loss: 0.4166.  Training acc: 96.32%.
[ Wed Jun 28 14:16:52 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 14:16:52 2023 ] Eval epoch: 30
[ Wed Jun 28 14:16:53 2023 ] 	Mean test loss of 625 batches: 0.352052.
[ Wed Jun 28 14:16:53 2023 ] 	Top1: 98.25%
[ Wed Jun 28 14:16:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:16:54 2023 ] Best accuracy: 1.0
[ Wed Jun 28 14:16:54 2023 ] Epoch number: 25
[ Wed Jun 28 14:16:54 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 14:16:54 2023 ] Weight decay: 0.0005
[ Wed Jun 28 14:16:54 2023 ] Base LR: 0.1
[ Wed Jun 28 14:16:54 2023 ] Batch Size: 64
[ Wed Jun 28 14:16:54 2023 ] Test Batch Size: 64
[ Wed Jun 28 14:16:54 2023 ] seed: 1
[ Wed Jun 28 14:16:54 2023 ] Start training Corrector
[ Wed Jun 28 14:16:55 2023 ] Training epoch: 1
[ Wed Jun 28 14:17:03 2023 ] 	Training loss: 16.7114.  Training acc: 38.28%.
[ Wed Jun 28 14:17:03 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:17:04 2023 ] Training epoch: 2
[ Wed Jun 28 14:17:09 2023 ] 	Training loss: 16.9543.  Training acc: 26.56%.
[ Wed Jun 28 14:17:09 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:17:10 2023 ] Training epoch: 3
[ Wed Jun 28 14:17:16 2023 ] 	Training loss: 16.6400.  Training acc: 34.24%.
[ Wed Jun 28 14:17:16 2023 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Jun 28 14:17:16 2023 ] Training epoch: 4
[ Wed Jun 28 14:17:22 2023 ] 	Training loss: 31.6944.  Training acc: 35.55%.
[ Wed Jun 28 14:17:22 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:17:22 2023 ] Training epoch: 5
[ Wed Jun 28 14:17:28 2023 ] 	Training loss: 40.4143.  Training acc: 33.59%.
[ Wed Jun 28 14:17:28 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:17:29 2023 ] Training epoch: 6
[ Wed Jun 28 14:17:34 2023 ] 	Training loss: 41.3640.  Training acc: 22.14%.
[ Wed Jun 28 14:17:34 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Wed Jun 28 14:17:35 2023 ] Training epoch: 7
[ Wed Jun 28 14:17:41 2023 ] 	Training loss: 42.0734.  Training acc: 16.28%.
[ Wed Jun 28 14:17:41 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:17:41 2023 ] Training epoch: 8
[ Wed Jun 28 14:17:49 2023 ] 	Training loss: 41.0436.  Training acc: 22.53%.
[ Wed Jun 28 14:17:49 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:17:50 2023 ] Training epoch: 9
[ Wed Jun 28 14:17:58 2023 ] 	Training loss: 40.4123.  Training acc: 26.17%.
[ Wed Jun 28 14:17:58 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:17:58 2023 ] Training epoch: 10
[ Wed Jun 28 14:18:06 2023 ] 	Training loss: 40.4396.  Training acc: 24.22%.
[ Wed Jun 28 14:18:06 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:18:07 2023 ] Training epoch: 11
[ Wed Jun 28 14:18:14 2023 ] 	Training loss: 40.6966.  Training acc: 24.48%.
[ Wed Jun 28 14:18:14 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:18:14 2023 ] Training epoch: 12
[ Wed Jun 28 14:18:21 2023 ] 	Training loss: 40.7442.  Training acc: 24.35%.
[ Wed Jun 28 14:18:21 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 14:18:21 2023 ] Training epoch: 13
[ Wed Jun 28 14:18:27 2023 ] 	Training loss: 40.2410.  Training acc: 24.48%.
[ Wed Jun 28 14:18:27 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:18:27 2023 ] Training epoch: 14
[ Wed Jun 28 14:18:34 2023 ] 	Training loss: 40.3056.  Training acc: 25.52%.
[ Wed Jun 28 14:18:34 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:18:35 2023 ] Training epoch: 15
[ Wed Jun 28 14:18:42 2023 ] 	Training loss: 40.3697.  Training acc: 24.87%.
[ Wed Jun 28 14:18:42 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:18:43 2023 ] Training epoch: 16
[ Wed Jun 28 14:18:48 2023 ] 	Training loss: 39.8678.  Training acc: 24.87%.
[ Wed Jun 28 14:18:48 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:18:49 2023 ] Training epoch: 17
[ Wed Jun 28 14:18:54 2023 ] 	Training loss: 39.9754.  Training acc: 26.30%.
[ Wed Jun 28 14:18:54 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:18:55 2023 ] Training epoch: 18
[ Wed Jun 28 14:19:02 2023 ] 	Training loss: 40.0908.  Training acc: 25.26%.
[ Wed Jun 28 14:19:02 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 14:19:02 2023 ] Training epoch: 19
[ Wed Jun 28 14:19:09 2023 ] 	Training loss: 40.5381.  Training acc: 25.00%.
[ Wed Jun 28 14:19:09 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:19:10 2023 ] Training epoch: 20
[ Wed Jun 28 14:19:19 2023 ] 	Training loss: 40.5118.  Training acc: 25.00%.
[ Wed Jun 28 14:19:19 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:19:19 2023 ] Training epoch: 21
[ Wed Jun 28 14:19:31 2023 ] 	Training loss: 40.3405.  Training acc: 24.61%.
[ Wed Jun 28 14:19:31 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 14:19:32 2023 ] Training epoch: 22
[ Wed Jun 28 14:19:39 2023 ] 	Training loss: 40.2993.  Training acc: 25.13%.
[ Wed Jun 28 14:19:39 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:19:39 2023 ] Training epoch: 23
[ Wed Jun 28 14:19:44 2023 ] 	Training loss: 40.2133.  Training acc: 25.13%.
[ Wed Jun 28 14:19:44 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:19:45 2023 ] Training epoch: 24
[ Wed Jun 28 14:19:50 2023 ] 	Training loss: 40.4447.  Training acc: 24.74%.
[ Wed Jun 28 14:19:50 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:19:51 2023 ] Training epoch: 25
[ Wed Jun 28 14:19:56 2023 ] 	Training loss: 40.2160.  Training acc: 24.09%.
[ Wed Jun 28 14:19:56 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 14:19:56 2023 ] Training epoch: 26
[ Wed Jun 28 14:20:03 2023 ] 	Training loss: 40.4415.  Training acc: 25.26%.
[ Wed Jun 28 14:20:03 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 14:20:03 2023 ] Training epoch: 27
[ Wed Jun 28 14:20:10 2023 ] 	Training loss: 40.4776.  Training acc: 24.61%.
[ Wed Jun 28 14:20:10 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:20:10 2023 ] Training epoch: 28
[ Wed Jun 28 14:20:19 2023 ] 	Training loss: 40.2449.  Training acc: 24.61%.
[ Wed Jun 28 14:20:19 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:20:20 2023 ] Training epoch: 29
[ Wed Jun 28 14:20:30 2023 ] 	Training loss: 40.1500.  Training acc: 25.26%.
[ Wed Jun 28 14:20:30 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 14:20:30 2023 ] Training epoch: 30
[ Wed Jun 28 14:20:37 2023 ] 	Training loss: 40.4827.  Training acc: 24.74%.
[ Wed Jun 28 14:20:37 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 14:20:38 2023 ] Training epoch: 31
[ Wed Jun 28 14:20:46 2023 ] 	Training loss: 40.5620.  Training acc: 25.00%.
[ Wed Jun 28 14:20:46 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 14:20:46 2023 ] Training epoch: 32
[ Wed Jun 28 14:20:53 2023 ] 	Training loss: 39.8203.  Training acc: 26.17%.
[ Wed Jun 28 14:20:53 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:20:54 2023 ] Training epoch: 33
[ Wed Jun 28 14:21:00 2023 ] 	Training loss: 40.1510.  Training acc: 25.91%.
[ Wed Jun 28 14:21:00 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:21:01 2023 ] Training epoch: 34
[ Wed Jun 28 14:21:08 2023 ] 	Training loss: 40.4446.  Training acc: 25.13%.
[ Wed Jun 28 14:21:08 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:21:09 2023 ] Training epoch: 35
[ Wed Jun 28 14:21:15 2023 ] 	Training loss: 40.0846.  Training acc: 25.52%.
[ Wed Jun 28 14:21:15 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:21:16 2023 ] Training epoch: 36
[ Wed Jun 28 14:21:23 2023 ] 	Training loss: 40.2739.  Training acc: 26.43%.
[ Wed Jun 28 14:21:23 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:21:24 2023 ] Training epoch: 37
[ Wed Jun 28 14:21:31 2023 ] 	Training loss: 40.5396.  Training acc: 25.39%.
[ Wed Jun 28 14:21:31 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:21:31 2023 ] Training epoch: 38
[ Wed Jun 28 14:21:38 2023 ] 	Training loss: 39.7289.  Training acc: 25.00%.
[ Wed Jun 28 14:21:38 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:21:39 2023 ] Training epoch: 39
[ Wed Jun 28 14:21:45 2023 ] 	Training loss: 39.9595.  Training acc: 25.78%.
[ Wed Jun 28 14:21:45 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:21:46 2023 ] Training epoch: 40
[ Wed Jun 28 14:21:53 2023 ] 	Training loss: 39.8253.  Training acc: 25.52%.
[ Wed Jun 28 14:21:53 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:21:53 2023 ] Training epoch: 41
[ Wed Jun 28 14:22:00 2023 ] 	Training loss: 40.4181.  Training acc: 25.39%.
[ Wed Jun 28 14:22:00 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:22:00 2023 ] Training epoch: 42
[ Wed Jun 28 14:22:10 2023 ] 	Training loss: 40.5818.  Training acc: 25.78%.
[ Wed Jun 28 14:22:10 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:22:10 2023 ] Training epoch: 43
[ Wed Jun 28 14:22:19 2023 ] 	Training loss: 40.0435.  Training acc: 25.52%.
[ Wed Jun 28 14:22:19 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:22:20 2023 ] Training epoch: 44
[ Wed Jun 28 14:22:29 2023 ] 	Training loss: 40.5351.  Training acc: 25.52%.
[ Wed Jun 28 14:22:29 2023 ] 	Time consumption: [Data]05%, [Network]94%
[ Wed Jun 28 14:22:30 2023 ] Training epoch: 45
[ Wed Jun 28 14:22:36 2023 ] 	Training loss: 39.8301.  Training acc: 25.00%.
[ Wed Jun 28 14:22:36 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:22:37 2023 ] Training epoch: 46
[ Wed Jun 28 14:22:45 2023 ] 	Training loss: 40.4435.  Training acc: 25.26%.
[ Wed Jun 28 14:22:45 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:22:45 2023 ] Training epoch: 47
[ Wed Jun 28 14:22:51 2023 ] 	Training loss: 40.1556.  Training acc: 25.65%.
[ Wed Jun 28 14:22:51 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:22:52 2023 ] Training epoch: 48
[ Wed Jun 28 14:22:57 2023 ] 	Training loss: 39.9886.  Training acc: 23.96%.
[ Wed Jun 28 14:22:57 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:22:58 2023 ] Training epoch: 49
[ Wed Jun 28 14:23:15 2023 ] using warm up, epoch: 5
[ Wed Jun 28 14:23:16 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 14:23:16 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 14:23:16 2023 ] Start training Predictor
[ Wed Jun 28 14:23:16 2023 ] Training epoch: 1
[ Wed Jun 28 14:23:24 2023 ] 	Training loss: 113.3834.  Training acc: 35.66%.
[ Wed Jun 28 14:23:24 2023 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Jun 28 14:23:24 2023 ] Eval epoch: 1
[ Wed Jun 28 14:23:26 2023 ] 	Mean test loss of 625 batches: 388.677478.
[ Wed Jun 28 14:23:26 2023 ] 	Top1: 38.60%
[ Wed Jun 28 14:23:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:23:26 2023 ] Training epoch: 2
[ Wed Jun 28 14:23:30 2023 ] 	Training loss: 9.9459.  Training acc: 33.18%.
[ Wed Jun 28 14:23:30 2023 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Jun 28 14:23:30 2023 ] Eval epoch: 2
[ Wed Jun 28 14:23:31 2023 ] 	Mean test loss of 625 batches: 6.757801.
[ Wed Jun 28 14:23:31 2023 ] 	Top1: 38.60%
[ Wed Jun 28 14:23:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:23:31 2023 ] Training epoch: 3
[ Wed Jun 28 14:23:35 2023 ] 	Training loss: 6.8676.  Training acc: 35.85%.
[ Wed Jun 28 14:23:35 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Jun 28 14:23:35 2023 ] Eval epoch: 3
[ Wed Jun 28 14:23:36 2023 ] 	Mean test loss of 625 batches: 1.309290.
[ Wed Jun 28 14:23:36 2023 ] 	Top1: 45.61%
[ Wed Jun 28 14:23:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:23:36 2023 ] Training epoch: 4
[ Wed Jun 28 14:23:41 2023 ] 	Training loss: 5.0781.  Training acc: 44.30%.
[ Wed Jun 28 14:23:41 2023 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Jun 28 14:23:41 2023 ] Eval epoch: 4
[ Wed Jun 28 14:23:42 2023 ] 	Mean test loss of 625 batches: 4.987321.
[ Wed Jun 28 14:23:42 2023 ] 	Top1: 29.82%
[ Wed Jun 28 14:23:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:23:42 2023 ] Training epoch: 5
[ Wed Jun 28 14:23:46 2023 ] 	Training loss: 3.2461.  Training acc: 63.88%.
[ Wed Jun 28 14:23:46 2023 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Jun 28 14:23:46 2023 ] Eval epoch: 5
[ Wed Jun 28 14:23:47 2023 ] 	Mean test loss of 625 batches: 6.776851.
[ Wed Jun 28 14:23:47 2023 ] 	Top1: 38.60%
[ Wed Jun 28 14:23:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:23:47 2023 ] Training epoch: 6
[ Wed Jun 28 14:23:52 2023 ] 	Training loss: 3.7937.  Training acc: 66.36%.
[ Wed Jun 28 14:23:52 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Jun 28 14:23:52 2023 ] Eval epoch: 6
[ Wed Jun 28 14:23:52 2023 ] 	Mean test loss of 625 batches: 1.088806.
[ Wed Jun 28 14:23:52 2023 ] 	Top1: 80.70%
[ Wed Jun 28 14:23:52 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:23:53 2023 ] Training epoch: 7
[ Wed Jun 28 14:23:57 2023 ] 	Training loss: 2.0611.  Training acc: 71.78%.
[ Wed Jun 28 14:23:57 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:23:57 2023 ] Eval epoch: 7
[ Wed Jun 28 14:23:58 2023 ] 	Mean test loss of 625 batches: 1.198329.
[ Wed Jun 28 14:23:58 2023 ] 	Top1: 89.47%
[ Wed Jun 28 14:23:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:23:58 2023 ] Training epoch: 8
[ Wed Jun 28 14:24:01 2023 ] 	Training loss: 1.1920.  Training acc: 81.07%.
[ Wed Jun 28 14:24:01 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 14:24:01 2023 ] Eval epoch: 8
[ Wed Jun 28 14:24:01 2023 ] 	Mean test loss of 625 batches: 2.969774.
[ Wed Jun 28 14:24:01 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:24:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:24:01 2023 ] Training epoch: 9
[ Wed Jun 28 14:24:03 2023 ] 	Training loss: 1.1131.  Training acc: 78.12%.
[ Wed Jun 28 14:24:03 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 14:24:03 2023 ] Eval epoch: 9
[ Wed Jun 28 14:24:04 2023 ] 	Mean test loss of 625 batches: 2.636654.
[ Wed Jun 28 14:24:04 2023 ] 	Top1: 29.82%
[ Wed Jun 28 14:24:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:24:04 2023 ] Training epoch: 10
[ Wed Jun 28 14:24:06 2023 ] 	Training loss: 1.0636.  Training acc: 79.50%.
[ Wed Jun 28 14:24:06 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Wed Jun 28 14:24:06 2023 ] Eval epoch: 10
[ Wed Jun 28 14:24:07 2023 ] 	Mean test loss of 625 batches: 0.498583.
[ Wed Jun 28 14:24:07 2023 ] 	Top1: 96.49%
[ Wed Jun 28 14:24:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:24:07 2023 ] Training epoch: 11
[ Wed Jun 28 14:24:09 2023 ] 	Training loss: 0.7924.  Training acc: 88.24%.
[ Wed Jun 28 14:24:09 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 14:24:09 2023 ] Eval epoch: 11
[ Wed Jun 28 14:24:10 2023 ] 	Mean test loss of 625 batches: 0.489694.
[ Wed Jun 28 14:24:10 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:24:10 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:24:10 2023 ] Training epoch: 12
[ Wed Jun 28 14:24:12 2023 ] 	Training loss: 0.6598.  Training acc: 90.99%.
[ Wed Jun 28 14:24:12 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Jun 28 14:24:12 2023 ] Eval epoch: 12
[ Wed Jun 28 14:24:13 2023 ] 	Mean test loss of 625 batches: 0.442156.
[ Wed Jun 28 14:24:13 2023 ] 	Top1: 98.25%
[ Wed Jun 28 14:24:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:24:13 2023 ] Training epoch: 13
[ Wed Jun 28 14:24:15 2023 ] 	Training loss: 0.6446.  Training acc: 90.81%.
[ Wed Jun 28 14:24:15 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Jun 28 14:24:15 2023 ] Eval epoch: 13
[ Wed Jun 28 14:24:16 2023 ] 	Mean test loss of 625 batches: 0.394631.
[ Wed Jun 28 14:24:16 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:24:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:24:16 2023 ] Training epoch: 14
[ Wed Jun 28 14:24:18 2023 ] 	Training loss: 0.5658.  Training acc: 93.20%.
[ Wed Jun 28 14:24:18 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Wed Jun 28 14:24:18 2023 ] Eval epoch: 14
[ Wed Jun 28 14:24:19 2023 ] 	Mean test loss of 625 batches: 0.401038.
[ Wed Jun 28 14:24:19 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:24:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:24:19 2023 ] Training epoch: 15
[ Wed Jun 28 14:24:21 2023 ] 	Training loss: 0.5473.  Training acc: 92.56%.
[ Wed Jun 28 14:24:21 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 14:24:21 2023 ] Eval epoch: 15
[ Wed Jun 28 14:24:22 2023 ] 	Mean test loss of 625 batches: 0.362842.
[ Wed Jun 28 14:24:22 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:24:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:24:22 2023 ] Training epoch: 16
[ Wed Jun 28 14:24:24 2023 ] 	Training loss: 0.5241.  Training acc: 94.21%.
[ Wed Jun 28 14:24:24 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 14:24:24 2023 ] Eval epoch: 16
[ Wed Jun 28 14:24:25 2023 ] 	Mean test loss of 625 batches: 0.366109.
[ Wed Jun 28 14:24:25 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:24:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:24:25 2023 ] Training epoch: 17
[ Wed Jun 28 14:24:27 2023 ] 	Training loss: 0.5209.  Training acc: 94.21%.
[ Wed Jun 28 14:24:27 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 14:24:27 2023 ] Eval epoch: 17
[ Wed Jun 28 14:24:28 2023 ] 	Mean test loss of 625 batches: 0.369695.
[ Wed Jun 28 14:24:28 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:24:28 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:24:28 2023 ] Training epoch: 18
[ Wed Jun 28 14:24:30 2023 ] 	Training loss: 0.5001.  Training acc: 94.67%.
[ Wed Jun 28 14:24:30 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 14:24:30 2023 ] Eval epoch: 18
[ Wed Jun 28 14:24:31 2023 ] 	Mean test loss of 625 batches: 0.360893.
[ Wed Jun 28 14:24:31 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:24:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:24:31 2023 ] Training epoch: 19
[ Wed Jun 28 14:24:35 2023 ] 	Training loss: 0.4945.  Training acc: 94.30%.
[ Wed Jun 28 14:24:35 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Jun 28 14:24:35 2023 ] Eval epoch: 19
[ Wed Jun 28 14:24:36 2023 ] 	Mean test loss of 625 batches: 0.352725.
[ Wed Jun 28 14:24:36 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:24:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:24:36 2023 ] Training epoch: 20
[ Wed Jun 28 14:24:40 2023 ] 	Training loss: 0.4493.  Training acc: 96.42%.
[ Wed Jun 28 14:24:40 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Jun 28 14:24:40 2023 ] Eval epoch: 20
[ Wed Jun 28 14:24:41 2023 ] 	Mean test loss of 625 batches: 0.342837.
[ Wed Jun 28 14:24:41 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:24:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:24:41 2023 ] Training epoch: 21
[ Wed Jun 28 14:24:46 2023 ] 	Training loss: 0.4418.  Training acc: 96.32%.
[ Wed Jun 28 14:24:46 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Jun 28 14:24:46 2023 ] Eval epoch: 21
[ Wed Jun 28 14:24:47 2023 ] 	Mean test loss of 625 batches: 0.342508.
[ Wed Jun 28 14:24:47 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:24:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:24:47 2023 ] Training epoch: 22
[ Wed Jun 28 14:24:51 2023 ] 	Training loss: 0.4312.  Training acc: 96.69%.
[ Wed Jun 28 14:24:51 2023 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Jun 28 14:24:51 2023 ] Eval epoch: 22
[ Wed Jun 28 14:24:52 2023 ] 	Mean test loss of 625 batches: 0.340719.
[ Wed Jun 28 14:24:52 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:24:52 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:24:52 2023 ] Training epoch: 23
[ Wed Jun 28 14:24:57 2023 ] 	Training loss: 0.4436.  Training acc: 96.23%.
[ Wed Jun 28 14:24:57 2023 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Jun 28 14:24:57 2023 ] Eval epoch: 23
[ Wed Jun 28 14:24:58 2023 ] 	Mean test loss of 625 batches: 0.353642.
[ Wed Jun 28 14:24:58 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:24:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:24:58 2023 ] Training epoch: 24
[ Wed Jun 28 14:25:02 2023 ] 	Training loss: 0.4209.  Training acc: 97.89%.
[ Wed Jun 28 14:25:02 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Jun 28 14:25:02 2023 ] Eval epoch: 24
[ Wed Jun 28 14:25:03 2023 ] 	Mean test loss of 625 batches: 0.343662.
[ Wed Jun 28 14:25:03 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:25:03 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:25:03 2023 ] Training epoch: 25
[ Wed Jun 28 14:25:07 2023 ] 	Training loss: 0.4300.  Training acc: 97.33%.
[ Wed Jun 28 14:25:07 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Jun 28 14:25:07 2023 ] Eval epoch: 25
[ Wed Jun 28 14:25:08 2023 ] 	Mean test loss of 625 batches: 0.345207.
[ Wed Jun 28 14:25:08 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:25:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:25:08 2023 ] Training epoch: 26
[ Wed Jun 28 14:25:13 2023 ] 	Training loss: 0.4448.  Training acc: 95.96%.
[ Wed Jun 28 14:25:13 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:25:13 2023 ] Eval epoch: 26
[ Wed Jun 28 14:25:14 2023 ] 	Mean test loss of 625 batches: 0.349926.
[ Wed Jun 28 14:25:14 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:25:14 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:25:14 2023 ] Training epoch: 27
[ Wed Jun 28 14:25:19 2023 ] 	Training loss: 0.4235.  Training acc: 97.89%.
[ Wed Jun 28 14:25:19 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:25:19 2023 ] Eval epoch: 27
[ Wed Jun 28 14:25:19 2023 ] 	Mean test loss of 625 batches: 0.347000.
[ Wed Jun 28 14:25:19 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:25:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:25:19 2023 ] Training epoch: 28
[ Wed Jun 28 14:25:23 2023 ] 	Training loss: 0.4297.  Training acc: 97.06%.
[ Wed Jun 28 14:25:23 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 14:25:23 2023 ] Eval epoch: 28
[ Wed Jun 28 14:25:23 2023 ] 	Mean test loss of 625 batches: 0.342398.
[ Wed Jun 28 14:25:23 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:25:23 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:25:23 2023 ] Training epoch: 29
[ Wed Jun 28 14:25:26 2023 ] 	Training loss: 0.4177.  Training acc: 97.89%.
[ Wed Jun 28 14:25:26 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 14:25:26 2023 ] Eval epoch: 29
[ Wed Jun 28 14:25:27 2023 ] 	Mean test loss of 625 batches: 0.338425.
[ Wed Jun 28 14:25:27 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:25:27 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:25:27 2023 ] Training epoch: 30
[ Wed Jun 28 14:25:30 2023 ] 	Training loss: 0.4176.  Training acc: 97.52%.
[ Wed Jun 28 14:25:30 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 14:25:30 2023 ] Eval epoch: 30
[ Wed Jun 28 14:25:31 2023 ] 	Mean test loss of 625 batches: 0.341410.
[ Wed Jun 28 14:25:31 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:25:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:25:32 2023 ] Best accuracy: 1.0
[ Wed Jun 28 14:25:32 2023 ] Epoch number: 11
[ Wed Jun 28 14:25:32 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 14:25:32 2023 ] Weight decay: 0.0005
[ Wed Jun 28 14:25:32 2023 ] Base LR: 0.1
[ Wed Jun 28 14:25:32 2023 ] Batch Size: 64
[ Wed Jun 28 14:25:32 2023 ] Test Batch Size: 64
[ Wed Jun 28 14:25:32 2023 ] seed: 1
[ Wed Jun 28 14:25:32 2023 ] Start training Corrector
[ Wed Jun 28 14:25:33 2023 ] Training epoch: 1
[ Wed Jun 28 14:25:40 2023 ] 	Training loss: 17.5968.  Training acc: 36.07%.
[ Wed Jun 28 14:25:40 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:25:40 2023 ] Training epoch: 2
[ Wed Jun 28 14:25:46 2023 ] 	Training loss: 14.8075.  Training acc: 35.29%.
[ Wed Jun 28 14:25:46 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:25:46 2023 ] Training epoch: 3
[ Wed Jun 28 14:25:51 2023 ] 	Training loss: 17.1017.  Training acc: 37.89%.
[ Wed Jun 28 14:25:51 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:25:52 2023 ] Training epoch: 4
[ Wed Jun 28 14:25:59 2023 ] 	Training loss: 15.7671.  Training acc: 42.97%.
[ Wed Jun 28 14:25:59 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:25:59 2023 ] Training epoch: 5
[ Wed Jun 28 14:26:06 2023 ] 	Training loss: 13.7836.  Training acc: 51.56%.
[ Wed Jun 28 14:26:06 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:26:06 2023 ] Training epoch: 6
[ Wed Jun 28 14:26:15 2023 ] 	Training loss: 24.8006.  Training acc: 33.46%.
[ Wed Jun 28 14:26:15 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:26:16 2023 ] Training epoch: 7
[ Wed Jun 28 14:26:26 2023 ] 	Training loss: 25.5287.  Training acc: 36.20%.
[ Wed Jun 28 14:26:26 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 14:26:27 2023 ] Training epoch: 8
[ Wed Jun 28 14:26:38 2023 ] 	Training loss: 18.6036.  Training acc: 39.71%.
[ Wed Jun 28 14:26:38 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 14:26:39 2023 ] Training epoch: 9
[ Wed Jun 28 14:26:47 2023 ] 	Training loss: 13.6668.  Training acc: 57.81%.
[ Wed Jun 28 14:26:47 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:26:48 2023 ] Training epoch: 10
[ Wed Jun 28 14:26:55 2023 ] 	Training loss: 10.8949.  Training acc: 64.32%.
[ Wed Jun 28 14:26:55 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:26:55 2023 ] Training epoch: 11
[ Wed Jun 28 14:27:02 2023 ] 	Training loss: 9.9459.  Training acc: 49.48%.
[ Wed Jun 28 14:27:02 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:27:02 2023 ] Training epoch: 12
[ Wed Jun 28 14:27:09 2023 ] 	Training loss: 9.7106.  Training acc: 53.52%.
[ Wed Jun 28 14:27:09 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 14:27:10 2023 ] Training epoch: 13
[ Wed Jun 28 14:27:16 2023 ] 	Training loss: 9.4885.  Training acc: 55.21%.
[ Wed Jun 28 14:27:16 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:27:17 2023 ] Training epoch: 14
[ Wed Jun 28 14:27:23 2023 ] 	Training loss: 9.4141.  Training acc: 53.52%.
[ Wed Jun 28 14:27:23 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:27:24 2023 ] Training epoch: 15
[ Wed Jun 28 14:27:30 2023 ] 	Training loss: 9.3319.  Training acc: 57.03%.
[ Wed Jun 28 14:27:30 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:27:31 2023 ] Training epoch: 16
[ Wed Jun 28 14:27:38 2023 ] 	Training loss: 9.2935.  Training acc: 60.42%.
[ Wed Jun 28 14:27:38 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:27:38 2023 ] Training epoch: 17
[ Wed Jun 28 14:27:45 2023 ] 	Training loss: 9.0464.  Training acc: 59.77%.
[ Wed Jun 28 14:27:45 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:27:45 2023 ] Training epoch: 18
[ Wed Jun 28 14:27:53 2023 ] 	Training loss: 8.8296.  Training acc: 59.51%.
[ Wed Jun 28 14:27:53 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:27:54 2023 ] Training epoch: 19
[ Wed Jun 28 14:28:04 2023 ] 	Training loss: 8.7910.  Training acc: 61.46%.
[ Wed Jun 28 14:28:04 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:28:04 2023 ] Training epoch: 20
[ Wed Jun 28 14:28:14 2023 ] 	Training loss: 8.6392.  Training acc: 60.81%.
[ Wed Jun 28 14:28:14 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 14:28:15 2023 ] Training epoch: 21
[ Wed Jun 28 14:28:22 2023 ] 	Training loss: 8.6599.  Training acc: 64.06%.
[ Wed Jun 28 14:28:22 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:28:23 2023 ] Training epoch: 22
[ Wed Jun 28 14:28:29 2023 ] 	Training loss: 8.6174.  Training acc: 63.28%.
[ Wed Jun 28 14:28:29 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:28:30 2023 ] Training epoch: 23
[ Wed Jun 28 14:28:36 2023 ] 	Training loss: 8.5449.  Training acc: 62.11%.
[ Wed Jun 28 14:28:36 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:28:37 2023 ] Training epoch: 24
[ Wed Jun 28 14:28:44 2023 ] 	Training loss: 8.5695.  Training acc: 65.62%.
[ Wed Jun 28 14:28:44 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:28:44 2023 ] Training epoch: 25
[ Wed Jun 28 14:28:52 2023 ] 	Training loss: 8.6118.  Training acc: 62.63%.
[ Wed Jun 28 14:28:52 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:28:52 2023 ] Training epoch: 26
[ Wed Jun 28 14:29:01 2023 ] 	Training loss: 8.4753.  Training acc: 65.62%.
[ Wed Jun 28 14:29:01 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:29:02 2023 ] Training epoch: 27
[ Wed Jun 28 14:29:09 2023 ] 	Training loss: 8.5234.  Training acc: 66.41%.
[ Wed Jun 28 14:29:09 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:29:10 2023 ] Training epoch: 28
[ Wed Jun 28 14:29:17 2023 ] 	Training loss: 8.5996.  Training acc: 65.49%.
[ Wed Jun 28 14:29:17 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:29:17 2023 ] Training epoch: 29
[ Wed Jun 28 14:29:24 2023 ] 	Training loss: 8.5147.  Training acc: 69.14%.
[ Wed Jun 28 14:29:24 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:29:25 2023 ] Training epoch: 30
[ Wed Jun 28 14:29:32 2023 ] 	Training loss: 8.5495.  Training acc: 65.10%.
[ Wed Jun 28 14:29:32 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:29:33 2023 ] Training epoch: 31
[ Wed Jun 28 14:29:44 2023 ] 	Training loss: 8.5304.  Training acc: 66.15%.
[ Wed Jun 28 14:29:44 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:29:45 2023 ] Training epoch: 32
[ Wed Jun 28 14:29:55 2023 ] 	Training loss: 8.4513.  Training acc: 67.45%.
[ Wed Jun 28 14:29:55 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:29:56 2023 ] Training epoch: 33
[ Wed Jun 28 14:30:03 2023 ] 	Training loss: 8.4748.  Training acc: 67.97%.
[ Wed Jun 28 14:30:03 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:30:04 2023 ] Training epoch: 34
[ Wed Jun 28 14:30:11 2023 ] 	Training loss: 8.4392.  Training acc: 68.88%.
[ Wed Jun 28 14:30:11 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:30:12 2023 ] Training epoch: 35
[ Wed Jun 28 14:30:18 2023 ] 	Training loss: 8.4692.  Training acc: 69.14%.
[ Wed Jun 28 14:30:18 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:30:19 2023 ] Training epoch: 36
[ Wed Jun 28 14:30:27 2023 ] 	Training loss: 8.4532.  Training acc: 67.19%.
[ Wed Jun 28 14:30:27 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:30:28 2023 ] Training epoch: 37
[ Wed Jun 28 14:30:39 2023 ] 	Training loss: 8.4857.  Training acc: 68.75%.
[ Wed Jun 28 14:30:39 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:30:40 2023 ] Training epoch: 38
[ Wed Jun 28 14:30:49 2023 ] 	Training loss: 8.5231.  Training acc: 68.62%.
[ Wed Jun 28 14:30:49 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:30:50 2023 ] Training epoch: 39
[ Wed Jun 28 14:30:57 2023 ] 	Training loss: 8.4013.  Training acc: 68.49%.
[ Wed Jun 28 14:30:57 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:30:58 2023 ] Training epoch: 40
[ Wed Jun 28 14:31:05 2023 ] 	Training loss: 8.4237.  Training acc: 68.88%.
[ Wed Jun 28 14:31:05 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:31:06 2023 ] Training epoch: 41
[ Wed Jun 28 14:31:13 2023 ] 	Training loss: 8.3331.  Training acc: 72.79%.
[ Wed Jun 28 14:31:13 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:31:14 2023 ] Training epoch: 42
[ Wed Jun 28 14:31:23 2023 ] 	Training loss: 8.2942.  Training acc: 72.14%.
[ Wed Jun 28 14:31:23 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:31:24 2023 ] Training epoch: 43
[ Wed Jun 28 14:31:34 2023 ] 	Training loss: 8.4483.  Training acc: 66.80%.
[ Wed Jun 28 14:31:34 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:31:35 2023 ] Training epoch: 44
[ Wed Jun 28 14:31:42 2023 ] 	Training loss: 8.2630.  Training acc: 71.22%.
[ Wed Jun 28 14:31:42 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:31:43 2023 ] Training epoch: 45
[ Wed Jun 28 14:31:50 2023 ] 	Training loss: 8.3241.  Training acc: 67.45%.
[ Wed Jun 28 14:31:50 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:31:51 2023 ] Training epoch: 46
[ Wed Jun 28 14:31:58 2023 ] 	Training loss: 8.2478.  Training acc: 65.10%.
[ Wed Jun 28 14:31:58 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:31:59 2023 ] Training epoch: 47
[ Wed Jun 28 14:32:06 2023 ] 	Training loss: 8.3725.  Training acc: 70.57%.
[ Wed Jun 28 14:32:06 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:32:07 2023 ] Training epoch: 48
[ Wed Jun 28 14:32:18 2023 ] 	Training loss: 8.3508.  Training acc: 68.88%.
[ Wed Jun 28 14:32:18 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:32:19 2023 ] Training epoch: 49
[ Wed Jun 28 14:32:30 2023 ] 	Training loss: 8.4494.  Training acc: 70.05%.
[ Wed Jun 28 14:32:30 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:32:31 2023 ] Training epoch: 50
[ Wed Jun 28 14:32:39 2023 ] 	Training loss: 8.3020.  Training acc: 67.84%.
[ Wed Jun 28 14:32:39 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:32:40 2023 ] Training epoch: 51
[ Wed Jun 28 14:32:47 2023 ] 	Training loss: 8.2454.  Training acc: 68.75%.
[ Wed Jun 28 14:32:47 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:32:48 2023 ] Training epoch: 52
[ Wed Jun 28 14:32:55 2023 ] 	Training loss: 8.1942.  Training acc: 68.62%.
[ Wed Jun 28 14:32:55 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:32:56 2023 ] Training epoch: 53
[ Wed Jun 28 14:33:03 2023 ] 	Training loss: 8.1857.  Training acc: 67.71%.
[ Wed Jun 28 14:33:03 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:33:04 2023 ] Training epoch: 54
[ Wed Jun 28 14:33:12 2023 ] 	Training loss: 8.1599.  Training acc: 68.62%.
[ Wed Jun 28 14:33:12 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:33:12 2023 ] Training epoch: 55
[ Wed Jun 28 14:33:19 2023 ] 	Training loss: 8.2261.  Training acc: 72.27%.
[ Wed Jun 28 14:33:19 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:33:20 2023 ] Training epoch: 56
[ Wed Jun 28 14:33:27 2023 ] 	Training loss: 8.1465.  Training acc: 69.92%.
[ Wed Jun 28 14:33:27 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:33:28 2023 ] Training epoch: 57
[ Wed Jun 28 14:33:34 2023 ] 	Training loss: 8.1810.  Training acc: 65.49%.
[ Wed Jun 28 14:33:34 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:33:34 2023 ] Training epoch: 58
[ Wed Jun 28 14:33:40 2023 ] 	Training loss: 8.2924.  Training acc: 71.48%.
[ Wed Jun 28 14:33:40 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 14:33:41 2023 ] Training epoch: 59
[ Wed Jun 28 14:33:48 2023 ] 	Training loss: 8.1265.  Training acc: 69.27%.
[ Wed Jun 28 14:33:48 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:33:49 2023 ] Training epoch: 60
[ Wed Jun 28 14:33:55 2023 ] 	Training loss: 8.1794.  Training acc: 68.75%.
[ Wed Jun 28 14:33:55 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:33:56 2023 ] Training epoch: 61
[ Wed Jun 28 14:34:02 2023 ] 	Training loss: 8.1483.  Training acc: 68.36%.
[ Wed Jun 28 14:34:02 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:34:03 2023 ] Training epoch: 62
[ Wed Jun 28 14:34:10 2023 ] 	Training loss: 8.0074.  Training acc: 73.05%.
[ Wed Jun 28 14:34:10 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:34:11 2023 ] Training epoch: 63
[ Wed Jun 28 14:34:18 2023 ] 	Training loss: 8.1839.  Training acc: 69.14%.
[ Wed Jun 28 14:34:18 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:34:19 2023 ] Training epoch: 64
[ Wed Jun 28 14:34:29 2023 ] 	Training loss: 8.0543.  Training acc: 72.01%.
[ Wed Jun 28 14:34:29 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:34:30 2023 ] Training epoch: 65
[ Wed Jun 28 14:34:37 2023 ] 	Training loss: 8.1015.  Training acc: 71.88%.
[ Wed Jun 28 14:34:37 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 14:34:38 2023 ] Training epoch: 66
[ Wed Jun 28 14:34:45 2023 ] 	Training loss: 7.9954.  Training acc: 71.74%.
[ Wed Jun 28 14:34:45 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:34:46 2023 ] Training epoch: 67
[ Wed Jun 28 14:34:53 2023 ] 	Training loss: 8.1375.  Training acc: 70.05%.
[ Wed Jun 28 14:34:53 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:34:54 2023 ] Training epoch: 68
[ Wed Jun 28 14:35:01 2023 ] 	Training loss: 8.0212.  Training acc: 72.27%.
[ Wed Jun 28 14:35:01 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:35:02 2023 ] Training epoch: 69
[ Wed Jun 28 14:35:13 2023 ] 	Training loss: 8.0932.  Training acc: 67.32%.
[ Wed Jun 28 14:35:13 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:35:14 2023 ] Training epoch: 70
[ Wed Jun 28 14:35:20 2023 ] 	Training loss: 7.9827.  Training acc: 71.88%.
[ Wed Jun 28 14:35:20 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:35:21 2023 ] Training epoch: 71
[ Wed Jun 28 14:35:27 2023 ] 	Training loss: 7.9007.  Training acc: 68.62%.
[ Wed Jun 28 14:35:27 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:35:28 2023 ] Training epoch: 72
[ Wed Jun 28 14:35:34 2023 ] 	Training loss: 7.9789.  Training acc: 67.58%.
[ Wed Jun 28 14:35:34 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:35:35 2023 ] Training epoch: 73
[ Wed Jun 28 14:35:41 2023 ] 	Training loss: 8.0156.  Training acc: 67.19%.
[ Wed Jun 28 14:35:41 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:35:42 2023 ] Training epoch: 74
[ Wed Jun 28 14:35:48 2023 ] 	Training loss: 8.0019.  Training acc: 72.27%.
[ Wed Jun 28 14:35:48 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:35:48 2023 ] Training epoch: 75
[ Wed Jun 28 14:35:59 2023 ] 	Training loss: 8.0111.  Training acc: 70.83%.
[ Wed Jun 28 14:35:59 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:36:00 2023 ] Training epoch: 76
[ Wed Jun 28 14:36:09 2023 ] 	Training loss: 7.8998.  Training acc: 75.78%.
[ Wed Jun 28 14:36:09 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:36:09 2023 ] Training epoch: 77
[ Wed Jun 28 14:36:17 2023 ] 	Training loss: 7.9017.  Training acc: 74.09%.
[ Wed Jun 28 14:36:17 2023 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Jun 28 14:36:17 2023 ] Training epoch: 78
[ Wed Jun 28 14:36:25 2023 ] 	Training loss: 7.9276.  Training acc: 76.43%.
[ Wed Jun 28 14:36:25 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:36:25 2023 ] Training epoch: 79
[ Wed Jun 28 14:36:33 2023 ] 	Training loss: 7.8189.  Training acc: 74.48%.
[ Wed Jun 28 14:36:33 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:36:33 2023 ] Training epoch: 80
[ Wed Jun 28 14:36:42 2023 ] 	Training loss: 7.9094.  Training acc: 75.91%.
[ Wed Jun 28 14:36:42 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:36:43 2023 ] Training epoch: 81
[ Wed Jun 28 14:36:54 2023 ] 	Training loss: 7.8684.  Training acc: 77.86%.
[ Wed Jun 28 14:36:54 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:36:55 2023 ] Training epoch: 82
[ Wed Jun 28 14:37:03 2023 ] 	Training loss: 7.9767.  Training acc: 75.65%.
[ Wed Jun 28 14:37:03 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:37:04 2023 ] Training epoch: 83
[ Wed Jun 28 14:37:11 2023 ] 	Training loss: 7.7961.  Training acc: 78.26%.
[ Wed Jun 28 14:37:11 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:37:12 2023 ] Training epoch: 84
[ Wed Jun 28 14:37:18 2023 ] 	Training loss: 7.8151.  Training acc: 80.60%.
[ Wed Jun 28 14:37:18 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 14:37:19 2023 ] Training epoch: 85
[ Wed Jun 28 14:37:25 2023 ] 	Training loss: 7.8580.  Training acc: 76.69%.
[ Wed Jun 28 14:37:25 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 14:37:25 2023 ] Training epoch: 86
[ Wed Jun 28 14:37:31 2023 ] 	Training loss: 7.7432.  Training acc: 79.95%.
[ Wed Jun 28 14:37:31 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Jun 28 14:37:32 2023 ] Training epoch: 87
[ Wed Jun 28 14:37:39 2023 ] 	Training loss: 7.8413.  Training acc: 77.21%.
[ Wed Jun 28 14:37:39 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:37:40 2023 ] Training epoch: 88
[ Wed Jun 28 14:37:49 2023 ] 	Training loss: 7.9287.  Training acc: 75.65%.
[ Wed Jun 28 14:37:49 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:37:49 2023 ] Training epoch: 89
[ Wed Jun 28 14:38:00 2023 ] 	Training loss: 7.8668.  Training acc: 74.48%.
[ Wed Jun 28 14:38:00 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:38:00 2023 ] Training epoch: 90
[ Wed Jun 28 14:38:08 2023 ] 	Training loss: 7.8753.  Training acc: 75.52%.
[ Wed Jun 28 14:38:08 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:38:08 2023 ] Training epoch: 91
[ Wed Jun 28 14:38:15 2023 ] 	Training loss: 7.7883.  Training acc: 76.17%.
[ Wed Jun 28 14:38:15 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:38:16 2023 ] Training epoch: 92
[ Wed Jun 28 14:38:23 2023 ] 	Training loss: 7.7950.  Training acc: 78.12%.
[ Wed Jun 28 14:38:23 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:38:24 2023 ] Training epoch: 93
[ Wed Jun 28 14:38:32 2023 ] 	Training loss: 7.7197.  Training acc: 77.60%.
[ Wed Jun 28 14:38:32 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 14:38:33 2023 ] Training epoch: 94
[ Wed Jun 28 14:38:43 2023 ] 	Training loss: 7.6396.  Training acc: 77.47%.
[ Wed Jun 28 14:38:43 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:38:44 2023 ] Training epoch: 95
[ Wed Jun 28 14:38:55 2023 ] 	Training loss: 7.7373.  Training acc: 76.43%.
[ Wed Jun 28 14:38:55 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:38:55 2023 ] Training epoch: 96
[ Wed Jun 28 14:39:04 2023 ] 	Training loss: 7.7285.  Training acc: 79.69%.
[ Wed Jun 28 14:39:04 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:39:05 2023 ] Training epoch: 97
[ Wed Jun 28 14:39:12 2023 ] 	Training loss: 7.7456.  Training acc: 82.03%.
[ Wed Jun 28 14:39:12 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:39:13 2023 ] Training epoch: 98
[ Wed Jun 28 14:39:19 2023 ] 	Training loss: 7.6586.  Training acc: 79.82%.
[ Wed Jun 28 14:39:19 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Jun 28 14:39:19 2023 ] Training epoch: 99
[ Wed Jun 28 14:39:25 2023 ] 	Training loss: 7.7246.  Training acc: 83.20%.
[ Wed Jun 28 14:39:25 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 14:39:26 2023 ] Training epoch: 100
[ Wed Jun 28 14:39:32 2023 ] 	Training loss: 7.7492.  Training acc: 80.73%.
[ Wed Jun 28 14:39:32 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Wed Jun 28 14:39:33 2023 ] Training epoch: 101
[ Wed Jun 28 14:39:40 2023 ] 	Training loss: 7.7253.  Training acc: 80.08%.
[ Wed Jun 28 14:39:40 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:39:40 2023 ] Training epoch: 102
[ Wed Jun 28 14:39:49 2023 ] 	Training loss: 7.6724.  Training acc: 85.68%.
[ Wed Jun 28 14:39:49 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:39:50 2023 ] Training epoch: 103
[ Wed Jun 28 14:40:00 2023 ] 	Training loss: 7.7594.  Training acc: 68.75%.
[ Wed Jun 28 14:40:00 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:40:01 2023 ] Training epoch: 104
[ Wed Jun 28 14:40:10 2023 ] 	Training loss: 7.7826.  Training acc: 66.28%.
[ Wed Jun 28 14:40:10 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:40:11 2023 ] Training epoch: 105
[ Wed Jun 28 14:40:18 2023 ] 	Training loss: 7.7115.  Training acc: 67.71%.
[ Wed Jun 28 14:40:18 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:40:19 2023 ] Training epoch: 106
[ Wed Jun 28 14:40:26 2023 ] 	Training loss: 7.6362.  Training acc: 70.96%.
[ Wed Jun 28 14:40:26 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:40:27 2023 ] Training epoch: 107
[ Wed Jun 28 14:40:35 2023 ] 	Training loss: 7.6745.  Training acc: 72.79%.
[ Wed Jun 28 14:40:35 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:40:35 2023 ] Training epoch: 108
[ Wed Jun 28 14:40:44 2023 ] 	Training loss: 7.7351.  Training acc: 75.65%.
[ Wed Jun 28 14:40:44 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:40:45 2023 ] Training epoch: 109
[ Wed Jun 28 14:40:56 2023 ] 	Training loss: 7.7484.  Training acc: 77.86%.
[ Wed Jun 28 14:40:56 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 14:40:57 2023 ] Training epoch: 110
[ Wed Jun 28 14:41:07 2023 ] 	Training loss: 7.7243.  Training acc: 80.73%.
[ Wed Jun 28 14:41:07 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:41:08 2023 ] Training epoch: 111
[ Wed Jun 28 14:41:18 2023 ] 	Training loss: 7.4773.  Training acc: 83.46%.
[ Wed Jun 28 14:41:18 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 14:41:19 2023 ] Training epoch: 112
[ Wed Jun 28 14:41:25 2023 ] 	Training loss: 7.5981.  Training acc: 82.94%.
[ Wed Jun 28 14:41:25 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 14:41:26 2023 ] Training epoch: 113
[ Wed Jun 28 14:41:32 2023 ] 	Training loss: 7.5661.  Training acc: 84.11%.
[ Wed Jun 28 14:41:32 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 14:41:32 2023 ] Training epoch: 114
[ Wed Jun 28 14:41:38 2023 ] 	Training loss: 7.4828.  Training acc: 83.46%.
[ Wed Jun 28 14:41:38 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:41:39 2023 ] Training epoch: 115
[ Wed Jun 28 14:41:45 2023 ] 	Training loss: 7.5817.  Training acc: 84.24%.
[ Wed Jun 28 14:41:45 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 14:41:46 2023 ] Training epoch: 116
[ Wed Jun 28 14:41:53 2023 ] 	Training loss: 7.5925.  Training acc: 86.07%.
[ Wed Jun 28 14:41:53 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:41:54 2023 ] Training epoch: 117
[ Wed Jun 28 14:42:04 2023 ] 	Training loss: 7.5421.  Training acc: 83.72%.
[ Wed Jun 28 14:42:04 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:42:05 2023 ] Training epoch: 118
[ Wed Jun 28 14:42:15 2023 ] 	Training loss: 7.4526.  Training acc: 84.90%.
[ Wed Jun 28 14:42:15 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:42:16 2023 ] Training epoch: 119
[ Wed Jun 28 14:42:26 2023 ] 	Training loss: 7.5424.  Training acc: 83.59%.
[ Wed Jun 28 14:42:26 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 14:42:27 2023 ] Training epoch: 120
[ Wed Jun 28 14:42:35 2023 ] 	Training loss: 7.3719.  Training acc: 86.46%.
[ Wed Jun 28 14:42:35 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:42:36 2023 ] Training epoch: 121
[ Wed Jun 28 14:42:43 2023 ] 	Training loss: 7.4742.  Training acc: 88.02%.
[ Wed Jun 28 14:42:43 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 14:42:44 2023 ] Training epoch: 122
[ Wed Jun 28 14:42:51 2023 ] 	Training loss: 7.4598.  Training acc: 88.93%.
[ Wed Jun 28 14:42:51 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:42:52 2023 ] Training epoch: 123
[ Wed Jun 28 14:43:00 2023 ] 	Training loss: 7.4876.  Training acc: 89.45%.
[ Wed Jun 28 14:43:00 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:43:01 2023 ] Training epoch: 124
[ Wed Jun 28 14:43:11 2023 ] 	Training loss: 7.4501.  Training acc: 86.46%.
[ Wed Jun 28 14:43:11 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:43:12 2023 ] Training epoch: 125
[ Wed Jun 28 14:43:22 2023 ] 	Training loss: 7.4510.  Training acc: 88.67%.
[ Wed Jun 28 14:43:22 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:43:23 2023 ] Training epoch: 126
[ Wed Jun 28 14:43:33 2023 ] 	Training loss: 7.5218.  Training acc: 87.76%.
[ Wed Jun 28 14:43:33 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:43:34 2023 ] Training epoch: 127
[ Wed Jun 28 14:43:41 2023 ] 	Training loss: 7.3598.  Training acc: 86.07%.
[ Wed Jun 28 14:43:41 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:43:42 2023 ] Training epoch: 128
[ Wed Jun 28 14:43:50 2023 ] 	Training loss: 7.3729.  Training acc: 86.07%.
[ Wed Jun 28 14:43:50 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:43:50 2023 ] Training epoch: 129
[ Wed Jun 28 14:43:56 2023 ] 	Training loss: 7.3195.  Training acc: 89.32%.
[ Wed Jun 28 14:43:56 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 14:43:57 2023 ] Training epoch: 130
[ Wed Jun 28 14:44:03 2023 ] 	Training loss: 7.4573.  Training acc: 89.32%.
[ Wed Jun 28 14:44:03 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 14:44:04 2023 ] Training epoch: 131
[ Wed Jun 28 14:44:11 2023 ] 	Training loss: 7.4396.  Training acc: 88.80%.
[ Wed Jun 28 14:44:11 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:44:12 2023 ] Training epoch: 132
[ Wed Jun 28 14:44:19 2023 ] 	Training loss: 7.3005.  Training acc: 88.28%.
[ Wed Jun 28 14:44:19 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:44:20 2023 ] Training epoch: 133
[ Wed Jun 28 14:44:31 2023 ] 	Training loss: 7.3673.  Training acc: 88.28%.
[ Wed Jun 28 14:44:31 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:44:32 2023 ] Training epoch: 134
[ Wed Jun 28 14:44:42 2023 ] 	Training loss: 7.4031.  Training acc: 87.50%.
[ Wed Jun 28 14:44:42 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:44:43 2023 ] Training epoch: 135
[ Wed Jun 28 14:44:53 2023 ] 	Training loss: 7.5190.  Training acc: 78.65%.
[ Wed Jun 28 14:44:53 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:44:54 2023 ] Training epoch: 136
[ Wed Jun 28 14:45:05 2023 ] 	Training loss: 7.4878.  Training acc: 81.90%.
[ Wed Jun 28 14:45:05 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:45:06 2023 ] Training epoch: 137
[ Wed Jun 28 14:45:14 2023 ] 	Training loss: 7.3890.  Training acc: 85.29%.
[ Wed Jun 28 14:45:14 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:45:15 2023 ] Training epoch: 138
[ Wed Jun 28 14:45:22 2023 ] 	Training loss: 7.3891.  Training acc: 87.50%.
[ Wed Jun 28 14:45:22 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 14:45:23 2023 ] Training epoch: 139
[ Wed Jun 28 14:45:30 2023 ] 	Training loss: 7.3195.  Training acc: 83.98%.
[ Wed Jun 28 14:45:30 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:45:31 2023 ] Training epoch: 140
[ Wed Jun 28 14:45:39 2023 ] 	Training loss: 7.5202.  Training acc: 77.99%.
[ Wed Jun 28 14:45:39 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:45:40 2023 ] Training epoch: 141
[ Wed Jun 28 14:45:49 2023 ] 	Training loss: 7.3819.  Training acc: 71.74%.
[ Wed Jun 28 14:45:49 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 14:45:50 2023 ] Training epoch: 142
[ Wed Jun 28 14:45:57 2023 ] 	Training loss: 7.3490.  Training acc: 81.12%.
[ Wed Jun 28 14:45:57 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:45:58 2023 ] Training epoch: 143
[ Wed Jun 28 14:46:05 2023 ] 	Training loss: 7.2878.  Training acc: 83.72%.
[ Wed Jun 28 14:46:05 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:46:06 2023 ] Training epoch: 144
[ Wed Jun 28 14:46:13 2023 ] 	Training loss: 7.3964.  Training acc: 85.16%.
[ Wed Jun 28 14:46:13 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:46:14 2023 ] Training epoch: 145
[ Wed Jun 28 14:46:22 2023 ] 	Training loss: 7.3554.  Training acc: 85.68%.
[ Wed Jun 28 14:46:22 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:46:22 2023 ] Training epoch: 146
[ Wed Jun 28 14:46:29 2023 ] 	Training loss: 7.3882.  Training acc: 86.07%.
[ Wed Jun 28 14:46:29 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 14:46:30 2023 ] Training epoch: 147
[ Wed Jun 28 14:46:37 2023 ] 	Training loss: 7.2142.  Training acc: 87.89%.
[ Wed Jun 28 14:46:37 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:46:37 2023 ] Training epoch: 148
[ Wed Jun 28 14:46:43 2023 ] 	Training loss: 7.3315.  Training acc: 88.28%.
[ Wed Jun 28 14:46:43 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:46:44 2023 ] Training epoch: 149
[ Wed Jun 28 14:46:49 2023 ] 	Training loss: 7.2612.  Training acc: 87.50%.
[ Wed Jun 28 14:46:49 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 14:46:49 2023 ] Training epoch: 150
[ Wed Jun 28 14:46:55 2023 ] 	Training loss: 7.3499.  Training acc: 85.16%.
[ Wed Jun 28 14:46:55 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 14:50:52 2023 ] using warm up, epoch: 5
[ Wed Jun 28 14:50:53 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 14:50:53 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 14:50:53 2023 ] Start training Predictor
[ Wed Jun 28 14:50:53 2023 ] Training epoch: 1
[ Wed Jun 28 14:51:35 2023 ] using warm up, epoch: 5
[ Wed Jun 28 14:51:35 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 14:51:35 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 14:51:35 2023 ] Start training Predictor
[ Wed Jun 28 14:51:35 2023 ] Training epoch: 1
[ Wed Jun 28 14:51:41 2023 ] 	Training loss: 123.8466.  Training acc: 34.01%.
[ Wed Jun 28 14:51:41 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:51:41 2023 ] Eval epoch: 1
[ Wed Jun 28 14:51:42 2023 ] 	Mean test loss of 625 batches: 1094.569177.
[ Wed Jun 28 14:51:42 2023 ] 	Top1: 38.60%
[ Wed Jun 28 14:51:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:51:42 2023 ] Training epoch: 2
[ Wed Jun 28 14:51:45 2023 ] 	Training loss: 13.7925.  Training acc: 33.64%.
[ Wed Jun 28 14:51:45 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 14:51:45 2023 ] Eval epoch: 2
[ Wed Jun 28 14:51:46 2023 ] 	Mean test loss of 625 batches: 1.671771.
[ Wed Jun 28 14:51:46 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:51:46 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:51:46 2023 ] Training epoch: 3
[ Wed Jun 28 14:51:49 2023 ] 	Training loss: 7.2998.  Training acc: 33.82%.
[ Wed Jun 28 14:51:49 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 14:51:49 2023 ] Eval epoch: 3
[ Wed Jun 28 14:51:50 2023 ] 	Mean test loss of 625 batches: 1.218922.
[ Wed Jun 28 14:51:50 2023 ] 	Top1: 57.89%
[ Wed Jun 28 14:51:50 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:51:50 2023 ] Training epoch: 4
[ Wed Jun 28 14:51:53 2023 ] 	Training loss: 8.1174.  Training acc: 32.81%.
[ Wed Jun 28 14:51:53 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 14:51:53 2023 ] Eval epoch: 4
[ Wed Jun 28 14:51:54 2023 ] 	Mean test loss of 625 batches: 1.508570.
[ Wed Jun 28 14:51:54 2023 ] 	Top1: 38.60%
[ Wed Jun 28 14:51:54 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:51:54 2023 ] Training epoch: 5
[ Wed Jun 28 14:51:56 2023 ] 	Training loss: 5.1194.  Training acc: 36.49%.
[ Wed Jun 28 14:51:56 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 14:51:56 2023 ] Eval epoch: 5
[ Wed Jun 28 14:51:57 2023 ] 	Mean test loss of 625 batches: 1.487538.
[ Wed Jun 28 14:51:57 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:51:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:51:57 2023 ] Training epoch: 6
[ Wed Jun 28 14:52:00 2023 ] 	Training loss: 4.1137.  Training acc: 35.94%.
[ Wed Jun 28 14:52:00 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 14:52:00 2023 ] Eval epoch: 6
[ Wed Jun 28 14:52:01 2023 ] 	Mean test loss of 625 batches: 1.134288.
[ Wed Jun 28 14:52:01 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:52:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:52:01 2023 ] Training epoch: 7
[ Wed Jun 28 14:52:04 2023 ] 	Training loss: 4.2823.  Training acc: 35.85%.
[ Wed Jun 28 14:52:04 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 14:52:04 2023 ] Eval epoch: 7
[ Wed Jun 28 14:52:05 2023 ] 	Mean test loss of 625 batches: 1.199513.
[ Wed Jun 28 14:52:05 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:52:05 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:52:05 2023 ] Training epoch: 8
[ Wed Jun 28 14:52:08 2023 ] 	Training loss: 3.0199.  Training acc: 32.44%.
[ Wed Jun 28 14:52:08 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Wed Jun 28 14:52:08 2023 ] Eval epoch: 8
[ Wed Jun 28 14:52:09 2023 ] 	Mean test loss of 625 batches: 1.302357.
[ Wed Jun 28 14:52:09 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:52:09 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:52:09 2023 ] Training epoch: 9
[ Wed Jun 28 14:52:12 2023 ] 	Training loss: 2.4344.  Training acc: 32.26%.
[ Wed Jun 28 14:52:12 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 14:52:12 2023 ] Eval epoch: 9
[ Wed Jun 28 14:52:13 2023 ] 	Mean test loss of 625 batches: 1.218542.
[ Wed Jun 28 14:52:13 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:52:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:52:13 2023 ] Training epoch: 10
[ Wed Jun 28 14:52:15 2023 ] 	Training loss: 2.1478.  Training acc: 33.55%.
[ Wed Jun 28 14:52:15 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Jun 28 14:52:15 2023 ] Eval epoch: 10
[ Wed Jun 28 14:52:16 2023 ] 	Mean test loss of 625 batches: 1.327706.
[ Wed Jun 28 14:52:16 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:52:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:52:16 2023 ] Training epoch: 11
[ Wed Jun 28 14:52:19 2023 ] 	Training loss: 1.9232.  Training acc: 34.28%.
[ Wed Jun 28 14:52:19 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Wed Jun 28 14:52:19 2023 ] Eval epoch: 11
[ Wed Jun 28 14:52:19 2023 ] 	Mean test loss of 625 batches: 1.112747.
[ Wed Jun 28 14:52:19 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:52:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:52:19 2023 ] Training epoch: 12
[ Wed Jun 28 14:52:22 2023 ] 	Training loss: 1.9518.  Training acc: 32.72%.
[ Wed Jun 28 14:52:22 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Wed Jun 28 14:52:22 2023 ] Eval epoch: 12
[ Wed Jun 28 14:52:23 2023 ] 	Mean test loss of 625 batches: 1.156674.
[ Wed Jun 28 14:52:23 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:52:23 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:52:23 2023 ] Training epoch: 13
[ Wed Jun 28 14:52:25 2023 ] 	Training loss: 1.8230.  Training acc: 33.46%.
[ Wed Jun 28 14:52:25 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Wed Jun 28 14:52:25 2023 ] Eval epoch: 13
[ Wed Jun 28 14:52:26 2023 ] 	Mean test loss of 625 batches: 1.155475.
[ Wed Jun 28 14:52:26 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:52:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:52:26 2023 ] Training epoch: 14
[ Wed Jun 28 14:52:28 2023 ] 	Training loss: 1.8551.  Training acc: 35.39%.
[ Wed Jun 28 14:52:28 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Wed Jun 28 14:52:28 2023 ] Eval epoch: 14
[ Wed Jun 28 14:52:29 2023 ] 	Mean test loss of 625 batches: 1.139376.
[ Wed Jun 28 14:52:29 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:52:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:52:29 2023 ] Training epoch: 15
[ Wed Jun 28 14:52:32 2023 ] 	Training loss: 1.8248.  Training acc: 32.90%.
[ Wed Jun 28 14:52:32 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Wed Jun 28 14:52:32 2023 ] Eval epoch: 15
[ Wed Jun 28 14:52:32 2023 ] 	Mean test loss of 625 batches: 1.143040.
[ Wed Jun 28 14:52:32 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:52:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:52:32 2023 ] Training epoch: 16
[ Wed Jun 28 14:52:35 2023 ] 	Training loss: 1.7780.  Training acc: 34.83%.
[ Wed Jun 28 14:52:35 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 14:52:35 2023 ] Eval epoch: 16
[ Wed Jun 28 14:52:36 2023 ] 	Mean test loss of 625 batches: 1.166105.
[ Wed Jun 28 14:52:36 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:52:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:52:36 2023 ] Training epoch: 17
[ Wed Jun 28 14:52:38 2023 ] 	Training loss: 1.7482.  Training acc: 35.29%.
[ Wed Jun 28 14:52:38 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Wed Jun 28 14:52:38 2023 ] Eval epoch: 17
[ Wed Jun 28 14:52:39 2023 ] 	Mean test loss of 625 batches: 1.118668.
[ Wed Jun 28 14:52:39 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:52:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:52:39 2023 ] Training epoch: 18
[ Wed Jun 28 14:52:41 2023 ] 	Training loss: 1.7336.  Training acc: 33.64%.
[ Wed Jun 28 14:52:41 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Wed Jun 28 14:52:41 2023 ] Eval epoch: 18
[ Wed Jun 28 14:52:42 2023 ] 	Mean test loss of 625 batches: 1.129194.
[ Wed Jun 28 14:52:42 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:52:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:52:42 2023 ] Training epoch: 19
[ Wed Jun 28 14:52:44 2023 ] 	Training loss: 1.6964.  Training acc: 34.38%.
[ Wed Jun 28 14:52:44 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Wed Jun 28 14:52:44 2023 ] Eval epoch: 19
[ Wed Jun 28 14:52:45 2023 ] 	Mean test loss of 625 batches: 1.160036.
[ Wed Jun 28 14:52:45 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:52:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:52:45 2023 ] Training epoch: 20
[ Wed Jun 28 14:52:48 2023 ] 	Training loss: 1.6387.  Training acc: 35.20%.
[ Wed Jun 28 14:52:48 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 14:52:48 2023 ] Eval epoch: 20
[ Wed Jun 28 14:52:49 2023 ] 	Mean test loss of 625 batches: 1.126713.
[ Wed Jun 28 14:52:49 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:52:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:52:49 2023 ] Training epoch: 21
[ Wed Jun 28 14:52:52 2023 ] 	Training loss: 1.6409.  Training acc: 35.20%.
[ Wed Jun 28 14:52:52 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 14:52:52 2023 ] Eval epoch: 21
[ Wed Jun 28 14:52:53 2023 ] 	Mean test loss of 625 batches: 1.124931.
[ Wed Jun 28 14:52:53 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:52:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:52:53 2023 ] Training epoch: 22
[ Wed Jun 28 14:52:56 2023 ] 	Training loss: 1.5850.  Training acc: 35.02%.
[ Wed Jun 28 14:52:56 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 14:52:56 2023 ] Eval epoch: 22
[ Wed Jun 28 14:52:56 2023 ] 	Mean test loss of 625 batches: 1.121275.
[ Wed Jun 28 14:52:56 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:52:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:52:56 2023 ] Training epoch: 23
[ Wed Jun 28 14:52:59 2023 ] 	Training loss: 1.5709.  Training acc: 36.86%.
[ Wed Jun 28 14:52:59 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 14:52:59 2023 ] Eval epoch: 23
[ Wed Jun 28 14:53:00 2023 ] 	Mean test loss of 625 batches: 1.126513.
[ Wed Jun 28 14:53:00 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:53:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:53:00 2023 ] Training epoch: 24
[ Wed Jun 28 14:53:03 2023 ] 	Training loss: 1.6135.  Training acc: 34.74%.
[ Wed Jun 28 14:53:03 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Wed Jun 28 14:53:03 2023 ] Eval epoch: 24
[ Wed Jun 28 14:53:04 2023 ] 	Mean test loss of 625 batches: 1.136911.
[ Wed Jun 28 14:53:04 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:53:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:53:04 2023 ] Training epoch: 25
[ Wed Jun 28 14:53:07 2023 ] 	Training loss: 1.6802.  Training acc: 31.99%.
[ Wed Jun 28 14:53:07 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 14:53:07 2023 ] Eval epoch: 25
[ Wed Jun 28 14:53:08 2023 ] 	Mean test loss of 625 batches: 1.144897.
[ Wed Jun 28 14:53:08 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:53:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:53:08 2023 ] Training epoch: 26
[ Wed Jun 28 14:53:17 2023 ] using warm up, epoch: 5
[ Wed Jun 28 14:53:17 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 14:53:17 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 14:53:17 2023 ] Start training Predictor
[ Wed Jun 28 14:53:17 2023 ] Training epoch: 1
[ Wed Jun 28 14:53:24 2023 ] 	Training loss: 107.1932.  Training acc: 35.02%.
[ Wed Jun 28 14:53:24 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 14:53:24 2023 ] Eval epoch: 1
[ Wed Jun 28 14:53:25 2023 ] 	Mean test loss of 625 batches: 645.540063.
[ Wed Jun 28 14:53:25 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:53:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:53:25 2023 ] Training epoch: 2
[ Wed Jun 28 14:53:28 2023 ] 	Training loss: 11.5237.  Training acc: 34.65%.
[ Wed Jun 28 14:53:28 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 14:53:28 2023 ] Eval epoch: 2
[ Wed Jun 28 14:53:29 2023 ] 	Mean test loss of 625 batches: 1.272029.
[ Wed Jun 28 14:53:29 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:53:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:53:29 2023 ] Training epoch: 3
[ Wed Jun 28 14:53:32 2023 ] 	Training loss: 7.3283.  Training acc: 38.14%.
[ Wed Jun 28 14:53:32 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 14:53:32 2023 ] Eval epoch: 3
[ Wed Jun 28 14:53:32 2023 ] 	Mean test loss of 625 batches: 2.311960.
[ Wed Jun 28 14:53:32 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:53:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:53:32 2023 ] Training epoch: 4
[ Wed Jun 28 14:53:35 2023 ] 	Training loss: 5.1765.  Training acc: 44.94%.
[ Wed Jun 28 14:53:35 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 14:53:35 2023 ] Eval epoch: 4
[ Wed Jun 28 14:53:36 2023 ] 	Mean test loss of 625 batches: 1.990890.
[ Wed Jun 28 14:53:36 2023 ] 	Top1: 70.18%
[ Wed Jun 28 14:53:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:53:36 2023 ] Training epoch: 5
[ Wed Jun 28 14:53:38 2023 ] 	Training loss: 5.8748.  Training acc: 57.44%.
[ Wed Jun 28 14:53:38 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Wed Jun 28 14:53:38 2023 ] Eval epoch: 5
[ Wed Jun 28 14:53:39 2023 ] 	Mean test loss of 625 batches: 13.592460.
[ Wed Jun 28 14:53:39 2023 ] 	Top1: 52.63%
[ Wed Jun 28 14:53:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:53:39 2023 ] Training epoch: 6
[ Wed Jun 28 14:53:41 2023 ] 	Training loss: 3.5766.  Training acc: 52.85%.
[ Wed Jun 28 14:53:41 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Wed Jun 28 14:53:41 2023 ] Eval epoch: 6
[ Wed Jun 28 14:53:42 2023 ] 	Mean test loss of 625 batches: 3.326470.
[ Wed Jun 28 14:53:42 2023 ] 	Top1: 29.82%
[ Wed Jun 28 14:53:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:53:42 2023 ] Training epoch: 7
[ Wed Jun 28 14:53:45 2023 ] 	Training loss: 2.5977.  Training acc: 56.25%.
[ Wed Jun 28 14:53:45 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 14:53:45 2023 ] Eval epoch: 7
[ Wed Jun 28 14:53:45 2023 ] 	Mean test loss of 625 batches: 2.808304.
[ Wed Jun 28 14:53:45 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:53:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:53:45 2023 ] Training epoch: 8
[ Wed Jun 28 14:53:48 2023 ] 	Training loss: 2.1998.  Training acc: 55.97%.
[ Wed Jun 28 14:53:48 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 14:53:48 2023 ] Eval epoch: 8
[ Wed Jun 28 14:53:48 2023 ] 	Mean test loss of 625 batches: 1.052649.
[ Wed Jun 28 14:53:48 2023 ] 	Top1: 70.18%
[ Wed Jun 28 14:53:48 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:53:48 2023 ] Training epoch: 9
[ Wed Jun 28 14:53:51 2023 ] 	Training loss: 1.5403.  Training acc: 63.05%.
[ Wed Jun 28 14:53:51 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Jun 28 14:53:51 2023 ] Eval epoch: 9
[ Wed Jun 28 14:53:52 2023 ] 	Mean test loss of 625 batches: 0.766217.
[ Wed Jun 28 14:53:52 2023 ] 	Top1: 85.96%
[ Wed Jun 28 14:53:52 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:53:52 2023 ] Training epoch: 10
[ Wed Jun 28 14:53:54 2023 ] 	Training loss: 1.6480.  Training acc: 57.35%.
[ Wed Jun 28 14:53:54 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Wed Jun 28 14:53:54 2023 ] Eval epoch: 10
[ Wed Jun 28 14:53:55 2023 ] 	Mean test loss of 625 batches: 1.570506.
[ Wed Jun 28 14:53:55 2023 ] 	Top1: 61.40%
[ Wed Jun 28 14:53:55 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:53:55 2023 ] Training epoch: 11
[ Wed Jun 28 14:53:57 2023 ] 	Training loss: 1.2566.  Training acc: 65.72%.
[ Wed Jun 28 14:53:57 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Jun 28 14:53:57 2023 ] Eval epoch: 11
[ Wed Jun 28 14:53:58 2023 ] 	Mean test loss of 625 batches: 0.856376.
[ Wed Jun 28 14:53:58 2023 ] 	Top1: 70.18%
[ Wed Jun 28 14:53:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:53:58 2023 ] Training epoch: 12
[ Wed Jun 28 14:54:00 2023 ] 	Training loss: 1.1899.  Training acc: 64.43%.
[ Wed Jun 28 14:54:00 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 14:54:00 2023 ] Eval epoch: 12
[ Wed Jun 28 14:54:01 2023 ] 	Mean test loss of 625 batches: 0.724111.
[ Wed Jun 28 14:54:01 2023 ] 	Top1: 73.68%
[ Wed Jun 28 14:54:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:54:01 2023 ] Training epoch: 13
[ Wed Jun 28 14:54:03 2023 ] 	Training loss: 1.0393.  Training acc: 66.18%.
[ Wed Jun 28 14:54:03 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Jun 28 14:54:03 2023 ] Eval epoch: 13
[ Wed Jun 28 14:54:04 2023 ] 	Mean test loss of 625 batches: 0.689851.
[ Wed Jun 28 14:54:04 2023 ] 	Top1: 73.68%
[ Wed Jun 28 14:54:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:54:04 2023 ] Training epoch: 14
[ Wed Jun 28 14:54:06 2023 ] 	Training loss: 0.9961.  Training acc: 69.49%.
[ Wed Jun 28 14:54:06 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Jun 28 14:54:06 2023 ] Eval epoch: 14
[ Wed Jun 28 14:54:07 2023 ] 	Mean test loss of 625 batches: 0.656807.
[ Wed Jun 28 14:54:07 2023 ] 	Top1: 77.19%
[ Wed Jun 28 14:54:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:54:07 2023 ] Training epoch: 15
[ Wed Jun 28 14:54:10 2023 ] 	Training loss: 0.9175.  Training acc: 71.78%.
[ Wed Jun 28 14:54:10 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 14:54:10 2023 ] Eval epoch: 15
[ Wed Jun 28 14:54:11 2023 ] 	Mean test loss of 625 batches: 0.657468.
[ Wed Jun 28 14:54:11 2023 ] 	Top1: 85.96%
[ Wed Jun 28 14:54:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:54:11 2023 ] Training epoch: 16
[ Wed Jun 28 14:54:14 2023 ] 	Training loss: 0.8419.  Training acc: 74.72%.
[ Wed Jun 28 14:54:14 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 14:54:14 2023 ] Eval epoch: 16
[ Wed Jun 28 14:54:15 2023 ] 	Mean test loss of 625 batches: 0.569704.
[ Wed Jun 28 14:54:15 2023 ] 	Top1: 75.44%
[ Wed Jun 28 14:54:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:54:15 2023 ] Training epoch: 17
[ Wed Jun 28 14:54:18 2023 ] 	Training loss: 0.7575.  Training acc: 78.12%.
[ Wed Jun 28 14:54:18 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 14:54:18 2023 ] Eval epoch: 17
[ Wed Jun 28 14:54:19 2023 ] 	Mean test loss of 625 batches: 0.532776.
[ Wed Jun 28 14:54:19 2023 ] 	Top1: 92.98%
[ Wed Jun 28 14:54:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:54:19 2023 ] Training epoch: 18
[ Wed Jun 28 14:54:22 2023 ] 	Training loss: 0.7271.  Training acc: 79.41%.
[ Wed Jun 28 14:54:22 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 14:54:22 2023 ] Eval epoch: 18
[ Wed Jun 28 14:54:23 2023 ] 	Mean test loss of 625 batches: 0.746837.
[ Wed Jun 28 14:54:23 2023 ] 	Top1: 70.18%
[ Wed Jun 28 14:54:23 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:54:23 2023 ] Training epoch: 19
[ Wed Jun 28 14:54:26 2023 ] 	Training loss: 0.6734.  Training acc: 81.53%.
[ Wed Jun 28 14:54:26 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 14:54:26 2023 ] Eval epoch: 19
[ Wed Jun 28 14:54:26 2023 ] 	Mean test loss of 625 batches: 0.446670.
[ Wed Jun 28 14:54:26 2023 ] 	Top1: 96.49%
[ Wed Jun 28 14:54:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:54:26 2023 ] Training epoch: 20
[ Wed Jun 28 14:54:29 2023 ] 	Training loss: 0.5339.  Training acc: 90.44%.
[ Wed Jun 28 14:54:29 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 14:54:29 2023 ] Eval epoch: 20
[ Wed Jun 28 14:54:30 2023 ] 	Mean test loss of 625 batches: 0.541232.
[ Wed Jun 28 14:54:30 2023 ] 	Top1: 87.72%
[ Wed Jun 28 14:54:30 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:54:30 2023 ] Training epoch: 21
[ Wed Jun 28 14:54:33 2023 ] 	Training loss: 0.5296.  Training acc: 89.06%.
[ Wed Jun 28 14:54:33 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 14:54:33 2023 ] Eval epoch: 21
[ Wed Jun 28 14:54:34 2023 ] 	Mean test loss of 625 batches: 0.398450.
[ Wed Jun 28 14:54:34 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:54:34 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:54:34 2023 ] Training epoch: 22
[ Wed Jun 28 14:54:37 2023 ] 	Training loss: 0.4943.  Training acc: 91.54%.
[ Wed Jun 28 14:54:37 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 14:54:37 2023 ] Eval epoch: 22
[ Wed Jun 28 14:54:38 2023 ] 	Mean test loss of 625 batches: 0.426031.
[ Wed Jun 28 14:54:38 2023 ] 	Top1: 96.49%
[ Wed Jun 28 14:54:38 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:54:38 2023 ] Training epoch: 23
[ Wed Jun 28 14:54:41 2023 ] 	Training loss: 0.4890.  Training acc: 92.37%.
[ Wed Jun 28 14:54:41 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 14:54:41 2023 ] Eval epoch: 23
[ Wed Jun 28 14:54:41 2023 ] 	Mean test loss of 625 batches: 0.410784.
[ Wed Jun 28 14:54:41 2023 ] 	Top1: 98.25%
[ Wed Jun 28 14:54:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:54:41 2023 ] Training epoch: 24
[ Wed Jun 28 14:54:44 2023 ] 	Training loss: 0.4864.  Training acc: 91.64%.
[ Wed Jun 28 14:54:44 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 14:54:44 2023 ] Eval epoch: 24
[ Wed Jun 28 14:54:45 2023 ] 	Mean test loss of 625 batches: 0.394523.
[ Wed Jun 28 14:54:45 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:54:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:54:45 2023 ] Training epoch: 25
[ Wed Jun 28 14:54:48 2023 ] 	Training loss: 0.4863.  Training acc: 91.18%.
[ Wed Jun 28 14:54:48 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 14:54:48 2023 ] Eval epoch: 25
[ Wed Jun 28 14:54:49 2023 ] 	Mean test loss of 625 batches: 0.402880.
[ Wed Jun 28 14:54:49 2023 ] 	Top1: 98.25%
[ Wed Jun 28 14:54:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:54:49 2023 ] Training epoch: 26
[ Wed Jun 28 14:54:52 2023 ] 	Training loss: 0.4704.  Training acc: 93.47%.
[ Wed Jun 28 14:54:52 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 14:54:52 2023 ] Eval epoch: 26
[ Wed Jun 28 14:54:53 2023 ] 	Mean test loss of 625 batches: 0.389481.
[ Wed Jun 28 14:54:53 2023 ] 	Top1: 98.25%
[ Wed Jun 28 14:54:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:54:53 2023 ] Training epoch: 27
[ Wed Jun 28 14:54:56 2023 ] 	Training loss: 0.4604.  Training acc: 94.21%.
[ Wed Jun 28 14:54:56 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 14:54:56 2023 ] Eval epoch: 27
[ Wed Jun 28 14:54:56 2023 ] 	Mean test loss of 625 batches: 0.394345.
[ Wed Jun 28 14:54:56 2023 ] 	Top1: 98.25%
[ Wed Jun 28 14:54:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:54:56 2023 ] Training epoch: 28
[ Wed Jun 28 14:54:59 2023 ] 	Training loss: 0.4633.  Training acc: 93.20%.
[ Wed Jun 28 14:54:59 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 14:54:59 2023 ] Eval epoch: 28
[ Wed Jun 28 14:55:00 2023 ] 	Mean test loss of 625 batches: 0.422866.
[ Wed Jun 28 14:55:00 2023 ] 	Top1: 94.74%
[ Wed Jun 28 14:55:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:55:00 2023 ] Training epoch: 29
[ Wed Jun 28 14:55:03 2023 ] 	Training loss: 0.4553.  Training acc: 94.39%.
[ Wed Jun 28 14:55:03 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 14:55:03 2023 ] Eval epoch: 29
[ Wed Jun 28 14:55:03 2023 ] 	Mean test loss of 625 batches: 0.402535.
[ Wed Jun 28 14:55:03 2023 ] 	Top1: 98.25%
[ Wed Jun 28 14:55:03 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:55:03 2023 ] Training epoch: 30
[ Wed Jun 28 14:55:06 2023 ] 	Training loss: 0.4555.  Training acc: 94.21%.
[ Wed Jun 28 14:55:06 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Wed Jun 28 14:55:06 2023 ] Eval epoch: 30
[ Wed Jun 28 14:55:07 2023 ] 	Mean test loss of 625 batches: 0.388068.
[ Wed Jun 28 14:55:07 2023 ] 	Top1: 100.00%
[ Wed Jun 28 14:55:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:55:07 2023 ] Best accuracy: 1.0
[ Wed Jun 28 14:55:07 2023 ] Epoch number: 21
[ Wed Jun 28 14:55:07 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 14:55:07 2023 ] Weight decay: 0.0005
[ Wed Jun 28 14:55:07 2023 ] Base LR: 0.1
[ Wed Jun 28 14:55:07 2023 ] Batch Size: 64
[ Wed Jun 28 14:55:07 2023 ] Test Batch Size: 64
[ Wed Jun 28 14:55:07 2023 ] seed: 1
[ Wed Jun 28 14:55:07 2023 ] Start training Corrector
[ Wed Jun 28 14:55:09 2023 ] Training epoch: 1
[ Wed Jun 28 14:55:17 2023 ] 	Training loss: 21.5138.  Training acc: 33.46%.
[ Wed Jun 28 14:55:17 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:55:17 2023 ] Training epoch: 2
[ Wed Jun 28 14:55:23 2023 ] 	Training loss: 20.7913.  Training acc: 26.30%.
[ Wed Jun 28 14:55:23 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:55:24 2023 ] Training epoch: 3
[ Wed Jun 28 14:55:30 2023 ] 	Training loss: 16.7648.  Training acc: 27.99%.
[ Wed Jun 28 14:55:30 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 14:55:30 2023 ] Training epoch: 4
[ Wed Jun 28 14:55:38 2023 ] 	Training loss: 15.5798.  Training acc: 28.12%.
[ Wed Jun 28 14:55:38 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:55:38 2023 ] Training epoch: 5
[ Wed Jun 28 14:55:46 2023 ] 	Training loss: 14.7548.  Training acc: 27.21%.
[ Wed Jun 28 14:55:46 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 14:55:46 2023 ] Training epoch: 6
[ Wed Jun 28 14:55:53 2023 ] 	Training loss: 13.8804.  Training acc: 27.73%.
[ Wed Jun 28 14:55:53 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:55:54 2023 ] Training epoch: 7
[ Wed Jun 28 14:56:01 2023 ] 	Training loss: 16.9578.  Training acc: 27.73%.
[ Wed Jun 28 14:56:01 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 14:56:01 2023 ] Training epoch: 8
[ Wed Jun 28 14:56:08 2023 ] 	Training loss: 21.5856.  Training acc: 27.86%.
[ Wed Jun 28 14:56:08 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 14:56:09 2023 ] Training epoch: 9
[ Wed Jun 28 14:56:16 2023 ] 	Training loss: 30.6462.  Training acc: 27.86%.
[ Wed Jun 28 14:56:16 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:56:17 2023 ] Training epoch: 10
[ Wed Jun 28 14:56:24 2023 ] 	Training loss: 43.5210.  Training acc: 27.86%.
[ Wed Jun 28 14:56:24 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:56:25 2023 ] Training epoch: 11
[ Wed Jun 28 14:56:31 2023 ] 	Training loss: 43.9879.  Training acc: 27.86%.
[ Wed Jun 28 14:56:31 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:56:32 2023 ] Training epoch: 12
[ Wed Jun 28 14:56:38 2023 ] 	Training loss: 42.4532.  Training acc: 27.99%.
[ Wed Jun 28 14:56:38 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:56:39 2023 ] Training epoch: 13
[ Wed Jun 28 14:56:45 2023 ] 	Training loss: 40.7382.  Training acc: 27.86%.
[ Wed Jun 28 14:56:45 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:56:46 2023 ] Training epoch: 14
[ Wed Jun 28 14:56:52 2023 ] 	Training loss: 39.1017.  Training acc: 27.99%.
[ Wed Jun 28 14:56:52 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:56:52 2023 ] Training epoch: 15
[ Wed Jun 28 14:56:58 2023 ] 	Training loss: 37.8734.  Training acc: 27.99%.
[ Wed Jun 28 14:56:58 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 14:56:59 2023 ] Training epoch: 16
[ Wed Jun 28 14:57:06 2023 ] 	Training loss: 36.7053.  Training acc: 27.99%.
[ Wed Jun 28 14:57:06 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 14:57:07 2023 ] Training epoch: 17
[ Wed Jun 28 14:57:16 2023 ] using warm up, epoch: 5
[ Wed Jun 28 14:57:16 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 14:57:16 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 14:57:16 2023 ] Start training Predictor
[ Wed Jun 28 14:57:16 2023 ] Training epoch: 1
[ Wed Jun 28 14:57:22 2023 ] 	Training loss: 107.6552.  Training acc: 35.02%.
[ Wed Jun 28 14:57:22 2023 ] 	Time consumption: [Data]04%, [Network]96%
[ Wed Jun 28 14:57:22 2023 ] Eval epoch: 1
[ Wed Jun 28 14:57:23 2023 ] 	Mean test loss of 625 batches: 307.068027.
[ Wed Jun 28 14:57:23 2023 ] 	Top1: 29.82%
[ Wed Jun 28 14:57:23 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:57:24 2023 ] Training epoch: 2
[ Wed Jun 28 14:57:26 2023 ] 	Training loss: 8.4986.  Training acc: 41.54%.
[ Wed Jun 28 14:57:26 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 14:57:26 2023 ] Eval epoch: 2
[ Wed Jun 28 14:57:27 2023 ] 	Mean test loss of 625 batches: 8.409660.
[ Wed Jun 28 14:57:27 2023 ] 	Top1: 40.35%
[ Wed Jun 28 14:57:27 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:57:27 2023 ] Training epoch: 3
[ Wed Jun 28 14:57:30 2023 ] 	Training loss: 6.7778.  Training acc: 45.77%.
[ Wed Jun 28 14:57:30 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 14:57:30 2023 ] Eval epoch: 3
[ Wed Jun 28 14:57:31 2023 ] 	Mean test loss of 625 batches: 19.689812.
[ Wed Jun 28 14:57:31 2023 ] 	Top1: 29.82%
[ Wed Jun 28 14:57:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:57:31 2023 ] Training epoch: 4
[ Wed Jun 28 14:57:34 2023 ] 	Training loss: 6.6981.  Training acc: 52.30%.
[ Wed Jun 28 14:57:34 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 14:57:34 2023 ] Eval epoch: 4
[ Wed Jun 28 14:57:35 2023 ] 	Mean test loss of 625 batches: 4.078158.
[ Wed Jun 28 14:57:35 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:57:35 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:57:35 2023 ] Training epoch: 5
[ Wed Jun 28 14:57:38 2023 ] 	Training loss: 4.2679.  Training acc: 53.86%.
[ Wed Jun 28 14:57:38 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 14:57:38 2023 ] Eval epoch: 5
[ Wed Jun 28 14:57:38 2023 ] 	Mean test loss of 625 batches: 2.213657.
[ Wed Jun 28 14:57:38 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:57:38 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:57:38 2023 ] Training epoch: 6
[ Wed Jun 28 14:57:41 2023 ] 	Training loss: 3.2510.  Training acc: 59.93%.
[ Wed Jun 28 14:57:41 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Wed Jun 28 14:57:41 2023 ] Eval epoch: 6
[ Wed Jun 28 14:57:42 2023 ] 	Mean test loss of 625 batches: 69.882800.
[ Wed Jun 28 14:57:42 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:57:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:57:42 2023 ] Training epoch: 7
[ Wed Jun 28 14:57:45 2023 ] 	Training loss: 6.5292.  Training acc: 50.64%.
[ Wed Jun 28 14:57:45 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Wed Jun 28 14:57:45 2023 ] Eval epoch: 7
[ Wed Jun 28 14:57:45 2023 ] 	Mean test loss of 625 batches: 1.308612.
[ Wed Jun 28 14:57:45 2023 ] 	Top1: 38.60%
[ Wed Jun 28 14:57:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:57:45 2023 ] Training epoch: 8
[ Wed Jun 28 14:57:48 2023 ] 	Training loss: 2.9951.  Training acc: 34.83%.
[ Wed Jun 28 14:57:48 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Wed Jun 28 14:57:48 2023 ] Eval epoch: 8
[ Wed Jun 28 14:57:49 2023 ] 	Mean test loss of 625 batches: 1.131194.
[ Wed Jun 28 14:57:49 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:57:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:57:49 2023 ] Training epoch: 9
[ Wed Jun 28 14:57:52 2023 ] 	Training loss: 2.3738.  Training acc: 33.55%.
[ Wed Jun 28 14:57:52 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Wed Jun 28 14:57:52 2023 ] Eval epoch: 9
[ Wed Jun 28 14:57:53 2023 ] 	Mean test loss of 625 batches: 1.122924.
[ Wed Jun 28 14:57:53 2023 ] 	Top1: 29.82%
[ Wed Jun 28 14:57:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:57:53 2023 ] Training epoch: 10
[ Wed Jun 28 14:57:56 2023 ] 	Training loss: 2.0599.  Training acc: 33.73%.
[ Wed Jun 28 14:57:56 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 14:57:56 2023 ] Eval epoch: 10
[ Wed Jun 28 14:57:56 2023 ] 	Mean test loss of 625 batches: 1.099761.
[ Wed Jun 28 14:57:56 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:57:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:57:56 2023 ] Training epoch: 11
[ Wed Jun 28 14:57:59 2023 ] 	Training loss: 1.7460.  Training acc: 33.00%.
[ Wed Jun 28 14:57:59 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 14:57:59 2023 ] Eval epoch: 11
[ Wed Jun 28 14:58:00 2023 ] 	Mean test loss of 625 batches: 1.153461.
[ Wed Jun 28 14:58:00 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:58:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:58:00 2023 ] Training epoch: 12
[ Wed Jun 28 14:58:03 2023 ] 	Training loss: 1.7559.  Training acc: 34.74%.
[ Wed Jun 28 14:58:03 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 14:58:03 2023 ] Eval epoch: 12
[ Wed Jun 28 14:58:04 2023 ] 	Mean test loss of 625 batches: 1.145786.
[ Wed Jun 28 14:58:04 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:58:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:58:04 2023 ] Training epoch: 13
[ Wed Jun 28 14:58:06 2023 ] 	Training loss: 1.6461.  Training acc: 34.74%.
[ Wed Jun 28 14:58:06 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Jun 28 14:58:06 2023 ] Eval epoch: 13
[ Wed Jun 28 14:58:07 2023 ] 	Mean test loss of 625 batches: 1.136131.
[ Wed Jun 28 14:58:07 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:58:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:58:07 2023 ] Training epoch: 14
[ Wed Jun 28 14:58:09 2023 ] 	Training loss: 1.6773.  Training acc: 33.92%.
[ Wed Jun 28 14:58:09 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Wed Jun 28 14:58:09 2023 ] Eval epoch: 14
[ Wed Jun 28 14:58:10 2023 ] 	Mean test loss of 625 batches: 1.138282.
[ Wed Jun 28 14:58:10 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:58:10 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:58:10 2023 ] Training epoch: 15
[ Wed Jun 28 14:58:13 2023 ] 	Training loss: 1.6499.  Training acc: 34.74%.
[ Wed Jun 28 14:58:13 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Wed Jun 28 14:58:13 2023 ] Eval epoch: 15
[ Wed Jun 28 14:58:13 2023 ] 	Mean test loss of 625 batches: 1.131230.
[ Wed Jun 28 14:58:13 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:58:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:58:13 2023 ] Training epoch: 16
[ Wed Jun 28 14:58:16 2023 ] 	Training loss: 1.6049.  Training acc: 36.03%.
[ Wed Jun 28 14:58:16 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 14:58:16 2023 ] Eval epoch: 16
[ Wed Jun 28 14:58:16 2023 ] 	Mean test loss of 625 batches: 1.134608.
[ Wed Jun 28 14:58:16 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:58:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:58:16 2023 ] Training epoch: 17
[ Wed Jun 28 14:58:19 2023 ] 	Training loss: 1.5989.  Training acc: 35.11%.
[ Wed Jun 28 14:58:19 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Wed Jun 28 14:58:19 2023 ] Eval epoch: 17
[ Wed Jun 28 14:58:19 2023 ] 	Mean test loss of 625 batches: 1.121330.
[ Wed Jun 28 14:58:19 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:58:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:58:19 2023 ] Training epoch: 18
[ Wed Jun 28 14:58:22 2023 ] 	Training loss: 1.5324.  Training acc: 35.11%.
[ Wed Jun 28 14:58:22 2023 ] 	Time consumption: [Data]22%, [Network]77%
[ Wed Jun 28 14:58:22 2023 ] Eval epoch: 18
[ Wed Jun 28 14:58:22 2023 ] 	Mean test loss of 625 batches: 1.116817.
[ Wed Jun 28 14:58:22 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:58:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:58:22 2023 ] Training epoch: 19
[ Wed Jun 28 14:58:25 2023 ] 	Training loss: 1.5272.  Training acc: 33.82%.
[ Wed Jun 28 14:58:25 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Wed Jun 28 14:58:25 2023 ] Eval epoch: 19
[ Wed Jun 28 14:58:26 2023 ] 	Mean test loss of 625 batches: 1.142873.
[ Wed Jun 28 14:58:26 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:58:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:58:26 2023 ] Training epoch: 20
[ Wed Jun 28 14:58:28 2023 ] 	Training loss: 1.4450.  Training acc: 35.29%.
[ Wed Jun 28 14:58:28 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Wed Jun 28 14:58:28 2023 ] Eval epoch: 20
[ Wed Jun 28 14:58:29 2023 ] 	Mean test loss of 625 batches: 1.127015.
[ Wed Jun 28 14:58:29 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:58:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:58:29 2023 ] Training epoch: 21
[ Wed Jun 28 14:58:31 2023 ] 	Training loss: 1.4749.  Training acc: 35.39%.
[ Wed Jun 28 14:58:31 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Wed Jun 28 14:58:31 2023 ] Eval epoch: 21
[ Wed Jun 28 14:58:32 2023 ] 	Mean test loss of 625 batches: 1.124726.
[ Wed Jun 28 14:58:32 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:58:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:58:32 2023 ] Training epoch: 22
[ Wed Jun 28 14:58:34 2023 ] 	Training loss: 1.4424.  Training acc: 35.85%.
[ Wed Jun 28 14:58:34 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Wed Jun 28 14:58:34 2023 ] Eval epoch: 22
[ Wed Jun 28 14:58:35 2023 ] 	Mean test loss of 625 batches: 1.121191.
[ Wed Jun 28 14:58:35 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:58:35 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:58:35 2023 ] Training epoch: 23
[ Wed Jun 28 14:58:37 2023 ] 	Training loss: 1.4062.  Training acc: 37.87%.
[ Wed Jun 28 14:58:37 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Wed Jun 28 14:58:37 2023 ] Eval epoch: 23
[ Wed Jun 28 14:58:38 2023 ] 	Mean test loss of 625 batches: 1.120787.
[ Wed Jun 28 14:58:38 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:58:38 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:58:38 2023 ] Training epoch: 24
[ Wed Jun 28 14:58:41 2023 ] 	Training loss: 1.4732.  Training acc: 31.25%.
[ Wed Jun 28 14:58:41 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Wed Jun 28 14:58:41 2023 ] Eval epoch: 24
[ Wed Jun 28 14:58:41 2023 ] 	Mean test loss of 625 batches: 1.123377.
[ Wed Jun 28 14:58:41 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:58:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:58:41 2023 ] Training epoch: 25
[ Wed Jun 28 14:58:44 2023 ] 	Training loss: 1.4802.  Training acc: 32.81%.
[ Wed Jun 28 14:58:44 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 14:58:44 2023 ] Eval epoch: 25
[ Wed Jun 28 14:58:45 2023 ] 	Mean test loss of 625 batches: 1.127343.
[ Wed Jun 28 14:58:45 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:58:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:58:45 2023 ] Training epoch: 26
[ Wed Jun 28 14:58:48 2023 ] 	Training loss: 1.4346.  Training acc: 36.49%.
[ Wed Jun 28 14:58:48 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 14:58:48 2023 ] Eval epoch: 26
[ Wed Jun 28 14:58:49 2023 ] 	Mean test loss of 625 batches: 1.125637.
[ Wed Jun 28 14:58:49 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:58:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:58:49 2023 ] Training epoch: 27
[ Wed Jun 28 14:58:52 2023 ] 	Training loss: 1.4906.  Training acc: 33.00%.
[ Wed Jun 28 14:58:52 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Wed Jun 28 14:58:52 2023 ] Eval epoch: 27
[ Wed Jun 28 14:58:53 2023 ] 	Mean test loss of 625 batches: 1.124885.
[ Wed Jun 28 14:58:53 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:58:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:58:53 2023 ] Training epoch: 28
[ Wed Jun 28 14:58:56 2023 ] 	Training loss: 1.4215.  Training acc: 34.74%.
[ Wed Jun 28 14:58:56 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 14:58:56 2023 ] Eval epoch: 28
[ Wed Jun 28 14:58:57 2023 ] 	Mean test loss of 625 batches: 1.127693.
[ Wed Jun 28 14:58:57 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:58:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:58:57 2023 ] Training epoch: 29
[ Wed Jun 28 14:59:00 2023 ] 	Training loss: 1.4597.  Training acc: 35.29%.
[ Wed Jun 28 14:59:00 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 14:59:00 2023 ] Eval epoch: 29
[ Wed Jun 28 14:59:01 2023 ] 	Mean test loss of 625 batches: 1.126897.
[ Wed Jun 28 14:59:01 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:59:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:59:01 2023 ] Training epoch: 30
[ Wed Jun 28 14:59:04 2023 ] 	Training loss: 1.4193.  Training acc: 34.47%.
[ Wed Jun 28 14:59:04 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 14:59:04 2023 ] Eval epoch: 30
[ Wed Jun 28 14:59:05 2023 ] 	Mean test loss of 625 batches: 1.129279.
[ Wed Jun 28 14:59:05 2023 ] 	Top1: 31.58%
[ Wed Jun 28 14:59:05 2023 ] 	Top5: 100.00%
[ Wed Jun 28 14:59:05 2023 ] Best accuracy: 0.7543859649122807
[ Wed Jun 28 14:59:05 2023 ] Epoch number: 1
[ Wed Jun 28 14:59:05 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 14:59:05 2023 ] Weight decay: 0.0005
[ Wed Jun 28 14:59:05 2023 ] Base LR: 0.1
[ Wed Jun 28 14:59:05 2023 ] Batch Size: 64
[ Wed Jun 28 14:59:05 2023 ] Test Batch Size: 64
[ Wed Jun 28 14:59:05 2023 ] seed: 1
[ Wed Jun 28 14:59:05 2023 ] Start training Corrector
[ Wed Jun 28 14:59:07 2023 ] Training epoch: 1
[ Wed Jun 28 14:59:16 2023 ] 	Training loss: 16.2427.  Training acc: 36.07%.
[ Wed Jun 28 14:59:16 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 14:59:17 2023 ] Training epoch: 2
[ Wed Jun 28 14:59:24 2023 ] 	Training loss: 12.4691.  Training acc: 34.38%.
[ Wed Jun 28 14:59:24 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:59:25 2023 ] Training epoch: 3
[ Wed Jun 28 14:59:32 2023 ] 	Training loss: 11.1119.  Training acc: 33.07%.
[ Wed Jun 28 14:59:32 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 14:59:32 2023 ] Training epoch: 4
[ Wed Jun 28 14:59:40 2023 ] 	Training loss: 10.2489.  Training acc: 36.72%.
[ Wed Jun 28 14:59:40 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 14:59:40 2023 ] Training epoch: 5
[ Wed Jun 28 14:59:46 2023 ] 	Training loss: 11.3674.  Training acc: 33.20%.
[ Wed Jun 28 14:59:46 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 14:59:47 2023 ] Training epoch: 6
[ Wed Jun 28 14:59:52 2023 ] 	Training loss: 9.4371.  Training acc: 33.46%.
[ Wed Jun 28 14:59:52 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 14:59:53 2023 ] Training epoch: 7
[ Wed Jun 28 14:59:59 2023 ] 	Training loss: 21.1922.  Training acc: 33.20%.
[ Wed Jun 28 14:59:59 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:00:00 2023 ] Training epoch: 8
[ Wed Jun 28 15:00:05 2023 ] 	Training loss: 16.2591.  Training acc: 33.07%.
[ Wed Jun 28 15:00:05 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:00:06 2023 ] Training epoch: 9
[ Wed Jun 28 15:00:12 2023 ] 	Training loss: 12.5544.  Training acc: 33.59%.
[ Wed Jun 28 15:00:12 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:00:13 2023 ] Training epoch: 10
[ Wed Jun 28 15:00:20 2023 ] 	Training loss: 32.3797.  Training acc: 33.20%.
[ Wed Jun 28 15:00:20 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:00:20 2023 ] Training epoch: 11
[ Wed Jun 28 15:00:27 2023 ] 	Training loss: 31.2858.  Training acc: 33.20%.
[ Wed Jun 28 15:00:27 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:00:28 2023 ] Training epoch: 12
[ Wed Jun 28 15:00:35 2023 ] 	Training loss: 29.3273.  Training acc: 33.20%.
[ Wed Jun 28 15:00:35 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:00:36 2023 ] Training epoch: 13
[ Wed Jun 28 15:00:43 2023 ] 	Training loss: 27.8717.  Training acc: 33.20%.
[ Wed Jun 28 15:00:43 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:00:43 2023 ] Training epoch: 14
[ Wed Jun 28 15:00:51 2023 ] 	Training loss: 29.3165.  Training acc: 32.94%.
[ Wed Jun 28 15:00:51 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:00:51 2023 ] Training epoch: 15
[ Wed Jun 28 15:00:58 2023 ] 	Training loss: 27.8034.  Training acc: 33.07%.
[ Wed Jun 28 15:00:58 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:00:59 2023 ] Training epoch: 16
[ Wed Jun 28 15:01:06 2023 ] 	Training loss: 26.2327.  Training acc: 33.07%.
[ Wed Jun 28 15:01:06 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:01:07 2023 ] Training epoch: 17
[ Wed Jun 28 15:01:14 2023 ] 	Training loss: 24.5665.  Training acc: 33.20%.
[ Wed Jun 28 15:01:14 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:01:15 2023 ] Training epoch: 18
[ Wed Jun 28 15:01:22 2023 ] 	Training loss: 22.6845.  Training acc: 33.20%.
[ Wed Jun 28 15:01:22 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 15:01:22 2023 ] Training epoch: 19
[ Wed Jun 28 15:01:28 2023 ] 	Training loss: 21.1472.  Training acc: 33.20%.
[ Wed Jun 28 15:01:28 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:01:29 2023 ] Training epoch: 20
[ Wed Jun 28 15:01:34 2023 ] 	Training loss: 19.6322.  Training acc: 33.20%.
[ Wed Jun 28 15:01:34 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:01:35 2023 ] Training epoch: 21
[ Wed Jun 28 15:01:40 2023 ] 	Training loss: 18.7408.  Training acc: 33.20%.
[ Wed Jun 28 15:01:40 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:01:41 2023 ] Training epoch: 22
[ Wed Jun 28 15:01:47 2023 ] 	Training loss: 18.3959.  Training acc: 33.20%.
[ Wed Jun 28 15:01:47 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:01:47 2023 ] Training epoch: 23
[ Wed Jun 28 15:01:53 2023 ] 	Training loss: 18.2437.  Training acc: 33.20%.
[ Wed Jun 28 15:01:53 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:01:54 2023 ] Training epoch: 24
[ Wed Jun 28 15:02:01 2023 ] 	Training loss: 18.1207.  Training acc: 33.20%.
[ Wed Jun 28 15:02:01 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:02:02 2023 ] Training epoch: 25
[ Wed Jun 28 15:02:09 2023 ] 	Training loss: 18.2100.  Training acc: 33.20%.
[ Wed Jun 28 15:02:09 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:02:09 2023 ] Training epoch: 26
[ Wed Jun 28 15:02:17 2023 ] 	Training loss: 17.9628.  Training acc: 33.07%.
[ Wed Jun 28 15:02:17 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:02:17 2023 ] Training epoch: 27
[ Wed Jun 28 15:02:25 2023 ] 	Training loss: 17.7523.  Training acc: 33.07%.
[ Wed Jun 28 15:02:25 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:02:25 2023 ] Training epoch: 28
[ Wed Jun 28 15:02:32 2023 ] 	Training loss: 17.6731.  Training acc: 33.07%.
[ Wed Jun 28 15:02:32 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:02:33 2023 ] Training epoch: 29
[ Wed Jun 28 15:02:40 2023 ] 	Training loss: 17.5227.  Training acc: 33.20%.
[ Wed Jun 28 15:02:40 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:02:41 2023 ] Training epoch: 30
[ Wed Jun 28 15:02:48 2023 ] 	Training loss: 17.3630.  Training acc: 33.07%.
[ Wed Jun 28 15:02:48 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:02:49 2023 ] Training epoch: 31
[ Wed Jun 28 15:02:56 2023 ] 	Training loss: 17.2656.  Training acc: 33.07%.
[ Wed Jun 28 15:02:56 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:02:56 2023 ] Training epoch: 32
[ Wed Jun 28 15:03:03 2023 ] 	Training loss: 16.9649.  Training acc: 33.07%.
[ Wed Jun 28 15:03:03 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:03:04 2023 ] Training epoch: 33
[ Wed Jun 28 15:03:10 2023 ] 	Training loss: 16.8896.  Training acc: 33.20%.
[ Wed Jun 28 15:03:10 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:03:11 2023 ] Training epoch: 34
[ Wed Jun 28 15:03:17 2023 ] 	Training loss: 16.5723.  Training acc: 32.94%.
[ Wed Jun 28 15:03:17 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:03:17 2023 ] Training epoch: 35
[ Wed Jun 28 15:03:23 2023 ] 	Training loss: 16.6688.  Training acc: 32.94%.
[ Wed Jun 28 15:03:23 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:03:23 2023 ] Training epoch: 36
[ Wed Jun 28 15:03:29 2023 ] 	Training loss: 16.4512.  Training acc: 33.20%.
[ Wed Jun 28 15:03:29 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:03:30 2023 ] Training epoch: 37
[ Wed Jun 28 15:03:35 2023 ] 	Training loss: 16.3604.  Training acc: 33.07%.
[ Wed Jun 28 15:03:35 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:03:36 2023 ] Training epoch: 38
[ Wed Jun 28 15:03:43 2023 ] 	Training loss: 16.2506.  Training acc: 33.20%.
[ Wed Jun 28 15:03:43 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:03:44 2023 ] Training epoch: 39
[ Wed Jun 28 15:03:51 2023 ] 	Training loss: 15.8116.  Training acc: 33.20%.
[ Wed Jun 28 15:03:51 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:03:52 2023 ] Training epoch: 40
[ Wed Jun 28 15:03:59 2023 ] 	Training loss: 15.9346.  Training acc: 33.20%.
[ Wed Jun 28 15:03:59 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:04:00 2023 ] Training epoch: 41
[ Wed Jun 28 15:04:07 2023 ] 	Training loss: 15.5225.  Training acc: 33.20%.
[ Wed Jun 28 15:04:07 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:04:22 2023 ] using warm up, epoch: 5
[ Wed Jun 28 15:04:22 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 15:04:22 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 15:04:22 2023 ] Start training Predictor
[ Wed Jun 28 15:04:22 2023 ] Training epoch: 1
[ Wed Jun 28 15:04:28 2023 ] 	Training loss: 111.3790.  Training acc: 34.56%.
[ Wed Jun 28 15:04:28 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 15:04:28 2023 ] Eval epoch: 1
[ Wed Jun 28 15:04:29 2023 ] 	Mean test loss of 625 batches: 661.913086.
[ Wed Jun 28 15:04:29 2023 ] 	Top1: 29.82%
[ Wed Jun 28 15:04:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:04:29 2023 ] Training epoch: 2
[ Wed Jun 28 15:04:32 2023 ] 	Training loss: 14.3552.  Training acc: 36.12%.
[ Wed Jun 28 15:04:32 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 15:04:32 2023 ] Eval epoch: 2
[ Wed Jun 28 15:04:32 2023 ] 	Mean test loss of 625 batches: 75.390434.
[ Wed Jun 28 15:04:32 2023 ] 	Top1: 38.60%
[ Wed Jun 28 15:04:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:04:32 2023 ] Training epoch: 3
[ Wed Jun 28 15:04:35 2023 ] 	Training loss: 6.3460.  Training acc: 47.43%.
[ Wed Jun 28 15:04:35 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 15:04:35 2023 ] Eval epoch: 3
[ Wed Jun 28 15:04:36 2023 ] 	Mean test loss of 625 batches: 5.571167.
[ Wed Jun 28 15:04:36 2023 ] 	Top1: 52.63%
[ Wed Jun 28 15:04:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:04:36 2023 ] Training epoch: 4
[ Wed Jun 28 15:04:39 2023 ] 	Training loss: 4.1194.  Training acc: 63.69%.
[ Wed Jun 28 15:04:39 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 15:04:39 2023 ] Eval epoch: 4
[ Wed Jun 28 15:04:39 2023 ] 	Mean test loss of 625 batches: 3.954479.
[ Wed Jun 28 15:04:39 2023 ] 	Top1: 61.40%
[ Wed Jun 28 15:04:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:04:40 2023 ] Training epoch: 5
[ Wed Jun 28 15:04:42 2023 ] 	Training loss: 2.6053.  Training acc: 69.39%.
[ Wed Jun 28 15:04:42 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 15:04:42 2023 ] Eval epoch: 5
[ Wed Jun 28 15:04:43 2023 ] 	Mean test loss of 625 batches: 1.523590.
[ Wed Jun 28 15:04:43 2023 ] 	Top1: 87.72%
[ Wed Jun 28 15:04:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:04:43 2023 ] Training epoch: 6
[ Wed Jun 28 15:04:46 2023 ] 	Training loss: 1.7853.  Training acc: 74.26%.
[ Wed Jun 28 15:04:46 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 15:04:46 2023 ] Eval epoch: 6
[ Wed Jun 28 15:04:47 2023 ] 	Mean test loss of 625 batches: 0.854729.
[ Wed Jun 28 15:04:47 2023 ] 	Top1: 96.49%
[ Wed Jun 28 15:04:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:04:47 2023 ] Training epoch: 7
[ Wed Jun 28 15:04:50 2023 ] 	Training loss: 1.7718.  Training acc: 79.60%.
[ Wed Jun 28 15:04:50 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 15:04:50 2023 ] Eval epoch: 7
[ Wed Jun 28 15:04:50 2023 ] 	Mean test loss of 625 batches: 1.673832.
[ Wed Jun 28 15:04:50 2023 ] 	Top1: 66.67%
[ Wed Jun 28 15:04:50 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:04:50 2023 ] Training epoch: 8
[ Wed Jun 28 15:04:53 2023 ] 	Training loss: 0.9404.  Training acc: 83.73%.
[ Wed Jun 28 15:04:53 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 15:04:53 2023 ] Eval epoch: 8
[ Wed Jun 28 15:04:53 2023 ] 	Mean test loss of 625 batches: 0.598749.
[ Wed Jun 28 15:04:53 2023 ] 	Top1: 91.23%
[ Wed Jun 28 15:04:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:04:53 2023 ] Training epoch: 9
[ Wed Jun 28 15:04:56 2023 ] 	Training loss: 0.7735.  Training acc: 86.31%.
[ Wed Jun 28 15:04:56 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Jun 28 15:04:56 2023 ] Eval epoch: 9
[ Wed Jun 28 15:04:56 2023 ] 	Mean test loss of 625 batches: 0.896714.
[ Wed Jun 28 15:04:56 2023 ] 	Top1: 71.93%
[ Wed Jun 28 15:04:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:04:56 2023 ] Training epoch: 10
[ Wed Jun 28 15:04:58 2023 ] 	Training loss: 0.7706.  Training acc: 87.96%.
[ Wed Jun 28 15:04:58 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Wed Jun 28 15:04:58 2023 ] Eval epoch: 10
[ Wed Jun 28 15:04:59 2023 ] 	Mean test loss of 625 batches: 0.778575.
[ Wed Jun 28 15:04:59 2023 ] 	Top1: 82.46%
[ Wed Jun 28 15:04:59 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:04:59 2023 ] Training epoch: 11
[ Wed Jun 28 15:05:01 2023 ] 	Training loss: 0.6374.  Training acc: 93.66%.
[ Wed Jun 28 15:05:01 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 15:05:01 2023 ] Eval epoch: 11
[ Wed Jun 28 15:05:02 2023 ] 	Mean test loss of 625 batches: 0.714683.
[ Wed Jun 28 15:05:02 2023 ] 	Top1: 91.23%
[ Wed Jun 28 15:05:02 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:05:02 2023 ] Training epoch: 12
[ Wed Jun 28 15:05:04 2023 ] 	Training loss: 0.6018.  Training acc: 93.75%.
[ Wed Jun 28 15:05:04 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 15:05:04 2023 ] Eval epoch: 12
[ Wed Jun 28 15:05:04 2023 ] 	Mean test loss of 625 batches: 0.508822.
[ Wed Jun 28 15:05:04 2023 ] 	Top1: 94.74%
[ Wed Jun 28 15:05:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:05:04 2023 ] Training epoch: 13
[ Wed Jun 28 15:05:06 2023 ] 	Training loss: 0.5261.  Training acc: 95.04%.
[ Wed Jun 28 15:05:06 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Jun 28 15:05:06 2023 ] Eval epoch: 13
[ Wed Jun 28 15:05:07 2023 ] 	Mean test loss of 625 batches: 0.408594.
[ Wed Jun 28 15:05:07 2023 ] 	Top1: 96.49%
[ Wed Jun 28 15:05:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:05:07 2023 ] Training epoch: 14
[ Wed Jun 28 15:05:09 2023 ] 	Training loss: 0.4771.  Training acc: 95.68%.
[ Wed Jun 28 15:05:09 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Wed Jun 28 15:05:09 2023 ] Eval epoch: 14
[ Wed Jun 28 15:05:10 2023 ] 	Mean test loss of 625 batches: 0.387766.
[ Wed Jun 28 15:05:10 2023 ] 	Top1: 94.74%
[ Wed Jun 28 15:05:10 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:05:10 2023 ] Training epoch: 15
[ Wed Jun 28 15:05:12 2023 ] 	Training loss: 0.4763.  Training acc: 95.59%.
[ Wed Jun 28 15:05:12 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Wed Jun 28 15:05:12 2023 ] Eval epoch: 15
[ Wed Jun 28 15:05:13 2023 ] 	Mean test loss of 625 batches: 0.423688.
[ Wed Jun 28 15:05:13 2023 ] 	Top1: 94.74%
[ Wed Jun 28 15:05:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:05:13 2023 ] Training epoch: 16
[ Wed Jun 28 15:05:15 2023 ] 	Training loss: 0.4530.  Training acc: 97.24%.
[ Wed Jun 28 15:05:15 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 15:05:15 2023 ] Eval epoch: 16
[ Wed Jun 28 15:05:15 2023 ] 	Mean test loss of 625 batches: 0.386236.
[ Wed Jun 28 15:05:15 2023 ] 	Top1: 94.74%
[ Wed Jun 28 15:05:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:05:15 2023 ] Training epoch: 17
[ Wed Jun 28 15:05:17 2023 ] 	Training loss: 0.4334.  Training acc: 97.33%.
[ Wed Jun 28 15:05:17 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Jun 28 15:05:17 2023 ] Eval epoch: 17
[ Wed Jun 28 15:05:18 2023 ] 	Mean test loss of 625 batches: 0.459799.
[ Wed Jun 28 15:05:18 2023 ] 	Top1: 92.98%
[ Wed Jun 28 15:05:18 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:05:18 2023 ] Training epoch: 18
[ Wed Jun 28 15:05:20 2023 ] 	Training loss: 0.4458.  Training acc: 95.50%.
[ Wed Jun 28 15:05:20 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Wed Jun 28 15:05:20 2023 ] Eval epoch: 18
[ Wed Jun 28 15:05:21 2023 ] 	Mean test loss of 625 batches: 0.385099.
[ Wed Jun 28 15:05:21 2023 ] 	Top1: 94.74%
[ Wed Jun 28 15:05:21 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:05:21 2023 ] Training epoch: 19
[ Wed Jun 28 15:05:23 2023 ] 	Training loss: 0.4136.  Training acc: 97.24%.
[ Wed Jun 28 15:05:23 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 15:05:23 2023 ] Eval epoch: 19
[ Wed Jun 28 15:05:24 2023 ] 	Mean test loss of 625 batches: 0.375961.
[ Wed Jun 28 15:05:24 2023 ] 	Top1: 94.74%
[ Wed Jun 28 15:05:24 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:05:24 2023 ] Training epoch: 20
[ Wed Jun 28 15:05:26 2023 ] 	Training loss: 0.3847.  Training acc: 98.25%.
[ Wed Jun 28 15:05:26 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 15:05:26 2023 ] Eval epoch: 20
[ Wed Jun 28 15:05:27 2023 ] 	Mean test loss of 625 batches: 0.394842.
[ Wed Jun 28 15:05:27 2023 ] 	Top1: 98.25%
[ Wed Jun 28 15:05:27 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:05:27 2023 ] Training epoch: 21
[ Wed Jun 28 15:05:29 2023 ] 	Training loss: 0.3723.  Training acc: 98.35%.
[ Wed Jun 28 15:05:29 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Wed Jun 28 15:05:29 2023 ] Eval epoch: 21
[ Wed Jun 28 15:05:30 2023 ] 	Mean test loss of 625 batches: 0.401114.
[ Wed Jun 28 15:05:30 2023 ] 	Top1: 94.74%
[ Wed Jun 28 15:05:30 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:05:30 2023 ] Training epoch: 22
[ Wed Jun 28 15:05:32 2023 ] 	Training loss: 0.3708.  Training acc: 97.70%.
[ Wed Jun 28 15:05:32 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Jun 28 15:05:32 2023 ] Eval epoch: 22
[ Wed Jun 28 15:05:33 2023 ] 	Mean test loss of 625 batches: 0.386930.
[ Wed Jun 28 15:05:33 2023 ] 	Top1: 94.74%
[ Wed Jun 28 15:05:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:05:33 2023 ] Training epoch: 23
[ Wed Jun 28 15:05:35 2023 ] 	Training loss: 0.3660.  Training acc: 98.53%.
[ Wed Jun 28 15:05:35 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 15:05:35 2023 ] Eval epoch: 23
[ Wed Jun 28 15:05:36 2023 ] 	Mean test loss of 625 batches: 0.394824.
[ Wed Jun 28 15:05:36 2023 ] 	Top1: 94.74%
[ Wed Jun 28 15:05:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:05:36 2023 ] Training epoch: 24
[ Wed Jun 28 15:05:38 2023 ] 	Training loss: 0.3617.  Training acc: 98.44%.
[ Wed Jun 28 15:05:38 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 15:05:38 2023 ] Eval epoch: 24
[ Wed Jun 28 15:05:39 2023 ] 	Mean test loss of 625 batches: 0.397027.
[ Wed Jun 28 15:05:39 2023 ] 	Top1: 94.74%
[ Wed Jun 28 15:05:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:05:39 2023 ] Training epoch: 25
[ Wed Jun 28 15:05:41 2023 ] 	Training loss: 0.3772.  Training acc: 97.61%.
[ Wed Jun 28 15:05:41 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 15:05:41 2023 ] Eval epoch: 25
[ Wed Jun 28 15:05:41 2023 ] 	Mean test loss of 625 batches: 0.381458.
[ Wed Jun 28 15:05:41 2023 ] 	Top1: 96.49%
[ Wed Jun 28 15:05:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:05:41 2023 ] Training epoch: 26
[ Wed Jun 28 15:05:44 2023 ] 	Training loss: 0.3651.  Training acc: 98.35%.
[ Wed Jun 28 15:05:44 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Wed Jun 28 15:05:44 2023 ] Eval epoch: 26
[ Wed Jun 28 15:05:44 2023 ] 	Mean test loss of 625 batches: 0.380904.
[ Wed Jun 28 15:05:44 2023 ] 	Top1: 94.74%
[ Wed Jun 28 15:05:44 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:05:44 2023 ] Training epoch: 27
[ Wed Jun 28 15:05:47 2023 ] 	Training loss: 0.3551.  Training acc: 98.99%.
[ Wed Jun 28 15:05:47 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 15:05:47 2023 ] Eval epoch: 27
[ Wed Jun 28 15:05:47 2023 ] 	Mean test loss of 625 batches: 0.393614.
[ Wed Jun 28 15:05:47 2023 ] 	Top1: 94.74%
[ Wed Jun 28 15:05:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:05:47 2023 ] Training epoch: 28
[ Wed Jun 28 15:05:49 2023 ] 	Training loss: 0.3563.  Training acc: 98.81%.
[ Wed Jun 28 15:05:49 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 15:05:49 2023 ] Eval epoch: 28
[ Wed Jun 28 15:05:50 2023 ] 	Mean test loss of 625 batches: 0.384541.
[ Wed Jun 28 15:05:50 2023 ] 	Top1: 94.74%
[ Wed Jun 28 15:05:50 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:05:50 2023 ] Training epoch: 29
[ Wed Jun 28 15:05:52 2023 ] 	Training loss: 0.3642.  Training acc: 98.16%.
[ Wed Jun 28 15:05:52 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 15:05:52 2023 ] Eval epoch: 29
[ Wed Jun 28 15:05:53 2023 ] 	Mean test loss of 625 batches: 0.373291.
[ Wed Jun 28 15:05:53 2023 ] 	Top1: 94.74%
[ Wed Jun 28 15:05:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:05:53 2023 ] Training epoch: 30
[ Wed Jun 28 15:05:56 2023 ] 	Training loss: 0.3625.  Training acc: 98.99%.
[ Wed Jun 28 15:05:56 2023 ] 	Time consumption: [Data]24%, [Network]76%
[ Wed Jun 28 15:05:56 2023 ] Eval epoch: 30
[ Wed Jun 28 15:05:56 2023 ] 	Mean test loss of 625 batches: 0.373829.
[ Wed Jun 28 15:05:56 2023 ] 	Top1: 94.74%
[ Wed Jun 28 15:05:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 15:05:57 2023 ] Best accuracy: 0.9824561403508771
[ Wed Jun 28 15:05:57 2023 ] Epoch number: 20
[ Wed Jun 28 15:05:57 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 15:05:57 2023 ] Weight decay: 0.0005
[ Wed Jun 28 15:05:57 2023 ] Base LR: 0.1
[ Wed Jun 28 15:05:57 2023 ] Batch Size: 64
[ Wed Jun 28 15:05:57 2023 ] Test Batch Size: 64
[ Wed Jun 28 15:05:57 2023 ] seed: 1
[ Wed Jun 28 15:05:57 2023 ] Start training Corrector
[ Wed Jun 28 15:05:58 2023 ] Training epoch: 1
[ Wed Jun 28 15:06:06 2023 ] 	Training loss: 16.5468.  Training acc: 40.62%.
[ Wed Jun 28 15:06:06 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 15:06:06 2023 ] Training epoch: 2
[ Wed Jun 28 15:06:12 2023 ] 	Training loss: 11.1831.  Training acc: 39.84%.
[ Wed Jun 28 15:06:12 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:06:12 2023 ] Training epoch: 3
[ Wed Jun 28 15:06:17 2023 ] 	Training loss: 8.9219.  Training acc: 51.56%.
[ Wed Jun 28 15:06:17 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:06:18 2023 ] Training epoch: 4
[ Wed Jun 28 15:06:23 2023 ] 	Training loss: 7.5859.  Training acc: 63.41%.
[ Wed Jun 28 15:06:23 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:06:23 2023 ] Training epoch: 5
[ Wed Jun 28 15:06:28 2023 ] 	Training loss: 7.4453.  Training acc: 46.61%.
[ Wed Jun 28 15:06:28 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:06:29 2023 ] Training epoch: 6
[ Wed Jun 28 15:06:34 2023 ] 	Training loss: 7.2426.  Training acc: 69.27%.
[ Wed Jun 28 15:06:34 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:06:35 2023 ] Training epoch: 7
[ Wed Jun 28 15:06:40 2023 ] 	Training loss: 6.6158.  Training acc: 84.90%.
[ Wed Jun 28 15:06:40 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:06:41 2023 ] Training epoch: 8
[ Wed Jun 28 15:06:47 2023 ] 	Training loss: 6.4724.  Training acc: 90.23%.
[ Wed Jun 28 15:06:47 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:06:48 2023 ] Training epoch: 9
[ Wed Jun 28 15:06:53 2023 ] 	Training loss: 6.3788.  Training acc: 91.54%.
[ Wed Jun 28 15:06:53 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:06:54 2023 ] Training epoch: 10
[ Wed Jun 28 15:06:59 2023 ] 	Training loss: 6.3198.  Training acc: 94.14%.
[ Wed Jun 28 15:06:59 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:06:59 2023 ] Training epoch: 11
[ Wed Jun 28 15:07:05 2023 ] 	Training loss: 6.1220.  Training acc: 95.70%.
[ Wed Jun 28 15:07:05 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:07:05 2023 ] Training epoch: 12
[ Wed Jun 28 15:07:10 2023 ] 	Training loss: 6.0476.  Training acc: 97.40%.
[ Wed Jun 28 15:07:10 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:07:11 2023 ] Training epoch: 13
[ Wed Jun 28 15:07:16 2023 ] 	Training loss: 5.9673.  Training acc: 96.88%.
[ Wed Jun 28 15:07:16 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:07:17 2023 ] Training epoch: 14
[ Wed Jun 28 15:07:22 2023 ] 	Training loss: 5.8824.  Training acc: 97.53%.
[ Wed Jun 28 15:07:22 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:07:23 2023 ] Training epoch: 15
[ Wed Jun 28 15:07:29 2023 ] 	Training loss: 5.9221.  Training acc: 98.44%.
[ Wed Jun 28 15:07:29 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:07:30 2023 ] Training epoch: 16
[ Wed Jun 28 15:07:36 2023 ] 	Training loss: 6.1090.  Training acc: 96.35%.
[ Wed Jun 28 15:07:36 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:07:37 2023 ] Training epoch: 17
[ Wed Jun 28 15:07:42 2023 ] 	Training loss: 6.0779.  Training acc: 96.61%.
[ Wed Jun 28 15:07:42 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:07:43 2023 ] Training epoch: 18
[ Wed Jun 28 15:07:48 2023 ] 	Training loss: 5.8464.  Training acc: 97.27%.
[ Wed Jun 28 15:07:48 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:07:48 2023 ] Training epoch: 19
[ Wed Jun 28 15:07:54 2023 ] 	Training loss: 5.9580.  Training acc: 96.88%.
[ Wed Jun 28 15:07:54 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:07:54 2023 ] Training epoch: 20
[ Wed Jun 28 15:07:59 2023 ] 	Training loss: 5.8818.  Training acc: 97.40%.
[ Wed Jun 28 15:07:59 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:08:00 2023 ] Training epoch: 21
[ Wed Jun 28 15:08:05 2023 ] 	Training loss: 5.9248.  Training acc: 96.88%.
[ Wed Jun 28 15:08:05 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:08:06 2023 ] Training epoch: 22
[ Wed Jun 28 15:08:12 2023 ] 	Training loss: 5.8681.  Training acc: 97.92%.
[ Wed Jun 28 15:08:12 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:08:13 2023 ] Training epoch: 23
[ Wed Jun 28 15:08:19 2023 ] 	Training loss: 5.8466.  Training acc: 98.31%.
[ Wed Jun 28 15:08:19 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:08:20 2023 ] Training epoch: 24
[ Wed Jun 28 15:08:26 2023 ] 	Training loss: 5.9620.  Training acc: 98.05%.
[ Wed Jun 28 15:08:26 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 15:08:27 2023 ] Training epoch: 25
[ Wed Jun 28 15:08:32 2023 ] 	Training loss: 5.9839.  Training acc: 97.66%.
[ Wed Jun 28 15:08:32 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:08:33 2023 ] Training epoch: 26
[ Wed Jun 28 15:08:38 2023 ] 	Training loss: 5.8949.  Training acc: 98.18%.
[ Wed Jun 28 15:08:38 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:08:38 2023 ] Training epoch: 27
[ Wed Jun 28 15:08:43 2023 ] 	Training loss: 5.8688.  Training acc: 98.05%.
[ Wed Jun 28 15:08:43 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:08:44 2023 ] Training epoch: 28
[ Wed Jun 28 15:08:49 2023 ] 	Training loss: 5.9897.  Training acc: 97.14%.
[ Wed Jun 28 15:08:49 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:08:50 2023 ] Training epoch: 29
[ Wed Jun 28 15:08:55 2023 ] 	Training loss: 5.8177.  Training acc: 98.44%.
[ Wed Jun 28 15:08:55 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:08:56 2023 ] Training epoch: 30
[ Wed Jun 28 15:09:01 2023 ] 	Training loss: 5.9886.  Training acc: 98.18%.
[ Wed Jun 28 15:09:01 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:09:02 2023 ] Training epoch: 31
[ Wed Jun 28 15:09:08 2023 ] 	Training loss: 5.9725.  Training acc: 98.44%.
[ Wed Jun 28 15:09:08 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:09:09 2023 ] Training epoch: 32
[ Wed Jun 28 15:09:16 2023 ] 	Training loss: 5.7615.  Training acc: 97.79%.
[ Wed Jun 28 15:09:16 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:09:16 2023 ] Training epoch: 33
[ Wed Jun 28 15:09:23 2023 ] 	Training loss: 5.8896.  Training acc: 98.44%.
[ Wed Jun 28 15:09:23 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:09:23 2023 ] Training epoch: 34
[ Wed Jun 28 15:09:29 2023 ] 	Training loss: 5.8033.  Training acc: 97.40%.
[ Wed Jun 28 15:09:29 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:09:30 2023 ] Training epoch: 35
[ Wed Jun 28 15:09:35 2023 ] 	Training loss: 5.9379.  Training acc: 98.05%.
[ Wed Jun 28 15:09:35 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Wed Jun 28 15:09:36 2023 ] Training epoch: 36
[ Wed Jun 28 15:09:42 2023 ] 	Training loss: 5.9506.  Training acc: 97.92%.
[ Wed Jun 28 15:09:42 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:09:43 2023 ] Training epoch: 37
[ Wed Jun 28 15:09:49 2023 ] 	Training loss: 6.0335.  Training acc: 97.14%.
[ Wed Jun 28 15:09:49 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Wed Jun 28 15:09:49 2023 ] Training epoch: 38
[ Wed Jun 28 15:09:56 2023 ] 	Training loss: 5.8580.  Training acc: 97.01%.
[ Wed Jun 28 15:09:56 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:09:56 2023 ] Training epoch: 39
[ Wed Jun 28 15:10:04 2023 ] 	Training loss: 5.8225.  Training acc: 97.66%.
[ Wed Jun 28 15:10:04 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:10:04 2023 ] Training epoch: 40
[ Wed Jun 28 15:10:12 2023 ] 	Training loss: 5.9323.  Training acc: 98.05%.
[ Wed Jun 28 15:10:12 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:10:12 2023 ] Training epoch: 41
[ Wed Jun 28 15:10:19 2023 ] 	Training loss: 5.7897.  Training acc: 98.44%.
[ Wed Jun 28 15:10:19 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:10:20 2023 ] Training epoch: 42
[ Wed Jun 28 15:10:26 2023 ] 	Training loss: 5.8933.  Training acc: 98.18%.
[ Wed Jun 28 15:10:26 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:10:27 2023 ] Training epoch: 43
[ Wed Jun 28 15:10:33 2023 ] 	Training loss: 5.9606.  Training acc: 97.92%.
[ Wed Jun 28 15:10:33 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:10:34 2023 ] Training epoch: 44
[ Wed Jun 28 15:10:39 2023 ] 	Training loss: 5.7279.  Training acc: 97.79%.
[ Wed Jun 28 15:10:39 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:10:40 2023 ] Training epoch: 45
[ Wed Jun 28 15:10:45 2023 ] 	Training loss: 5.8054.  Training acc: 97.40%.
[ Wed Jun 28 15:10:45 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Wed Jun 28 15:10:46 2023 ] Training epoch: 46
[ Wed Jun 28 15:10:52 2023 ] 	Training loss: 5.7174.  Training acc: 97.40%.
[ Wed Jun 28 15:10:52 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:10:52 2023 ] Training epoch: 47
[ Wed Jun 28 15:11:00 2023 ] 	Training loss: 5.9870.  Training acc: 97.27%.
[ Wed Jun 28 15:11:00 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:11:00 2023 ] Training epoch: 48
[ Wed Jun 28 15:11:07 2023 ] 	Training loss: 5.9887.  Training acc: 97.66%.
[ Wed Jun 28 15:11:07 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:11:08 2023 ] Training epoch: 49
[ Wed Jun 28 15:11:15 2023 ] 	Training loss: 5.9887.  Training acc: 96.35%.
[ Wed Jun 28 15:11:15 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:11:16 2023 ] Training epoch: 50
[ Wed Jun 28 15:11:23 2023 ] 	Training loss: 5.7807.  Training acc: 98.57%.
[ Wed Jun 28 15:11:23 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:11:24 2023 ] Training epoch: 51
[ Wed Jun 28 15:11:30 2023 ] 	Training loss: 5.9043.  Training acc: 96.61%.
[ Wed Jun 28 15:11:30 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Jun 28 15:11:30 2023 ] Training epoch: 52
[ Wed Jun 28 15:11:36 2023 ] 	Training loss: 5.7328.  Training acc: 97.79%.
[ Wed Jun 28 15:11:36 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:11:37 2023 ] Training epoch: 53
[ Wed Jun 28 15:11:43 2023 ] 	Training loss: 5.6752.  Training acc: 97.53%.
[ Wed Jun 28 15:11:43 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:11:44 2023 ] Training epoch: 54
[ Wed Jun 28 15:11:49 2023 ] 	Training loss: 5.7555.  Training acc: 98.18%.
[ Wed Jun 28 15:11:49 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:11:50 2023 ] Training epoch: 55
[ Wed Jun 28 15:11:57 2023 ] 	Training loss: 5.8371.  Training acc: 97.40%.
[ Wed Jun 28 15:11:57 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:11:57 2023 ] Training epoch: 56
[ Wed Jun 28 15:12:04 2023 ] 	Training loss: 5.8781.  Training acc: 97.53%.
[ Wed Jun 28 15:12:04 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:12:05 2023 ] Training epoch: 57
[ Wed Jun 28 15:12:12 2023 ] 	Training loss: 5.8158.  Training acc: 97.79%.
[ Wed Jun 28 15:12:12 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:12:13 2023 ] Training epoch: 58
[ Wed Jun 28 15:12:20 2023 ] 	Training loss: 5.9360.  Training acc: 97.53%.
[ Wed Jun 28 15:12:20 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:12:21 2023 ] Training epoch: 59
[ Wed Jun 28 15:12:28 2023 ] 	Training loss: 5.7593.  Training acc: 97.79%.
[ Wed Jun 28 15:12:28 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:12:28 2023 ] Training epoch: 60
[ Wed Jun 28 15:12:34 2023 ] 	Training loss: 5.8552.  Training acc: 97.66%.
[ Wed Jun 28 15:12:34 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:12:35 2023 ] Training epoch: 61
[ Wed Jun 28 15:12:41 2023 ] 	Training loss: 5.8110.  Training acc: 98.31%.
[ Wed Jun 28 15:12:41 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:12:42 2023 ] Training epoch: 62
[ Wed Jun 28 15:12:48 2023 ] 	Training loss: 5.6895.  Training acc: 98.57%.
[ Wed Jun 28 15:12:48 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:12:48 2023 ] Training epoch: 63
[ Wed Jun 28 15:12:54 2023 ] 	Training loss: 5.9621.  Training acc: 97.79%.
[ Wed Jun 28 15:12:54 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:12:55 2023 ] Training epoch: 64
[ Wed Jun 28 15:13:02 2023 ] 	Training loss: 5.9137.  Training acc: 98.57%.
[ Wed Jun 28 15:13:02 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:13:03 2023 ] Training epoch: 65
[ Wed Jun 28 15:13:10 2023 ] 	Training loss: 5.7512.  Training acc: 97.92%.
[ Wed Jun 28 15:13:10 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:13:11 2023 ] Training epoch: 66
[ Wed Jun 28 15:13:18 2023 ] 	Training loss: 5.7335.  Training acc: 97.79%.
[ Wed Jun 28 15:13:18 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:13:19 2023 ] Training epoch: 67
[ Wed Jun 28 15:13:26 2023 ] 	Training loss: 5.9338.  Training acc: 98.18%.
[ Wed Jun 28 15:13:26 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:13:27 2023 ] Training epoch: 68
[ Wed Jun 28 15:13:34 2023 ] 	Training loss: 5.7956.  Training acc: 97.92%.
[ Wed Jun 28 15:13:34 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:13:35 2023 ] Training epoch: 69
[ Wed Jun 28 15:13:40 2023 ] 	Training loss: 5.9628.  Training acc: 97.92%.
[ Wed Jun 28 15:13:40 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:13:41 2023 ] Training epoch: 70
[ Wed Jun 28 15:13:47 2023 ] 	Training loss: 5.8378.  Training acc: 98.57%.
[ Wed Jun 28 15:13:47 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:13:48 2023 ] Training epoch: 71
[ Wed Jun 28 15:13:53 2023 ] 	Training loss: 5.8673.  Training acc: 98.31%.
[ Wed Jun 28 15:13:53 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:13:54 2023 ] Training epoch: 72
[ Wed Jun 28 15:14:00 2023 ] 	Training loss: 5.8512.  Training acc: 98.05%.
[ Wed Jun 28 15:14:00 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:14:00 2023 ] Training epoch: 73
[ Wed Jun 28 15:14:06 2023 ] 	Training loss: 5.8290.  Training acc: 98.96%.
[ Wed Jun 28 15:14:06 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:14:07 2023 ] Training epoch: 74
[ Wed Jun 28 15:14:15 2023 ] 	Training loss: 5.9299.  Training acc: 98.05%.
[ Wed Jun 28 15:14:15 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:14:15 2023 ] Training epoch: 75
[ Wed Jun 28 15:14:23 2023 ] 	Training loss: 5.8817.  Training acc: 97.92%.
[ Wed Jun 28 15:14:23 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:14:24 2023 ] Training epoch: 76
[ Wed Jun 28 15:14:31 2023 ] 	Training loss: 5.6871.  Training acc: 98.31%.
[ Wed Jun 28 15:14:31 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 15:14:32 2023 ] Training epoch: 77
[ Wed Jun 28 15:14:39 2023 ] 	Training loss: 5.7261.  Training acc: 98.31%.
[ Wed Jun 28 15:14:39 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:14:39 2023 ] Training epoch: 78
[ Wed Jun 28 15:14:47 2023 ] 	Training loss: 5.8440.  Training acc: 98.83%.
[ Wed Jun 28 15:14:47 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:14:48 2023 ] Training epoch: 79
[ Wed Jun 28 15:14:53 2023 ] 	Training loss: 5.7839.  Training acc: 98.31%.
[ Wed Jun 28 15:14:53 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:14:54 2023 ] Training epoch: 80
[ Wed Jun 28 15:15:00 2023 ] 	Training loss: 5.8478.  Training acc: 98.57%.
[ Wed Jun 28 15:15:00 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Jun 28 15:15:01 2023 ] Training epoch: 81
[ Wed Jun 28 15:15:06 2023 ] 	Training loss: 5.7163.  Training acc: 98.57%.
[ Wed Jun 28 15:15:06 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:15:07 2023 ] Training epoch: 82
[ Wed Jun 28 15:15:13 2023 ] 	Training loss: 5.8826.  Training acc: 98.96%.
[ Wed Jun 28 15:15:13 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:15:14 2023 ] Training epoch: 83
[ Wed Jun 28 15:15:20 2023 ] 	Training loss: 5.7431.  Training acc: 98.05%.
[ Wed Jun 28 15:15:20 2023 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Jun 28 15:15:21 2023 ] Training epoch: 84
[ Wed Jun 28 15:15:28 2023 ] 	Training loss: 5.8566.  Training acc: 97.92%.
[ Wed Jun 28 15:15:28 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:15:29 2023 ] Training epoch: 85
[ Wed Jun 28 15:15:36 2023 ] 	Training loss: 5.7970.  Training acc: 98.83%.
[ Wed Jun 28 15:15:36 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:15:37 2023 ] Training epoch: 86
[ Wed Jun 28 15:15:44 2023 ] 	Training loss: 5.7075.  Training acc: 98.44%.
[ Wed Jun 28 15:15:44 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 15:15:45 2023 ] Training epoch: 87
[ Wed Jun 28 15:15:52 2023 ] 	Training loss: 5.7901.  Training acc: 98.57%.
[ Wed Jun 28 15:15:52 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:15:53 2023 ] Training epoch: 88
[ Wed Jun 28 15:16:00 2023 ] 	Training loss: 5.9314.  Training acc: 98.44%.
[ Wed Jun 28 15:16:00 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 15:16:01 2023 ] Training epoch: 89
[ Wed Jun 28 15:16:06 2023 ] 	Training loss: 5.8385.  Training acc: 98.70%.
[ Wed Jun 28 15:16:06 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:16:07 2023 ] Training epoch: 90
[ Wed Jun 28 15:16:13 2023 ] 	Training loss: 5.8848.  Training acc: 98.05%.
[ Wed Jun 28 15:16:13 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:16:14 2023 ] Training epoch: 91
[ Wed Jun 28 15:16:20 2023 ] 	Training loss: 5.8563.  Training acc: 98.70%.
[ Wed Jun 28 15:16:20 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:16:21 2023 ] Training epoch: 92
[ Wed Jun 28 15:16:26 2023 ] 	Training loss: 5.8170.  Training acc: 98.57%.
[ Wed Jun 28 15:16:26 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:16:27 2023 ] Training epoch: 93
[ Wed Jun 28 15:16:33 2023 ] 	Training loss: 5.7451.  Training acc: 98.31%.
[ Wed Jun 28 15:16:33 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:16:34 2023 ] Training epoch: 94
[ Wed Jun 28 15:16:41 2023 ] 	Training loss: 5.6105.  Training acc: 98.05%.
[ Wed Jun 28 15:16:41 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:16:41 2023 ] Training epoch: 95
[ Wed Jun 28 15:16:49 2023 ] 	Training loss: 5.7593.  Training acc: 98.70%.
[ Wed Jun 28 15:16:49 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:16:49 2023 ] Training epoch: 96
[ Wed Jun 28 15:16:56 2023 ] 	Training loss: 5.8110.  Training acc: 98.44%.
[ Wed Jun 28 15:16:56 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:16:57 2023 ] Training epoch: 97
[ Wed Jun 28 15:17:04 2023 ] 	Training loss: 5.8404.  Training acc: 98.70%.
[ Wed Jun 28 15:17:04 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:17:05 2023 ] Training epoch: 98
[ Wed Jun 28 15:17:12 2023 ] 	Training loss: 5.6809.  Training acc: 97.92%.
[ Wed Jun 28 15:17:12 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 15:17:13 2023 ] Training epoch: 99
[ Wed Jun 28 15:17:21 2023 ] 	Training loss: 5.7789.  Training acc: 96.22%.
[ Wed Jun 28 15:17:21 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:17:21 2023 ] Training epoch: 100
[ Wed Jun 28 15:17:27 2023 ] 	Training loss: 5.8503.  Training acc: 97.79%.
[ Wed Jun 28 15:17:27 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Wed Jun 28 15:17:28 2023 ] Training epoch: 101
[ Wed Jun 28 15:17:34 2023 ] 	Training loss: 5.7865.  Training acc: 98.96%.
[ Wed Jun 28 15:17:34 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:17:34 2023 ] Training epoch: 102
[ Wed Jun 28 15:17:40 2023 ] 	Training loss: 5.7567.  Training acc: 98.44%.
[ Wed Jun 28 15:17:40 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:17:41 2023 ] Training epoch: 103
[ Wed Jun 28 15:17:47 2023 ] 	Training loss: 5.8305.  Training acc: 97.27%.
[ Wed Jun 28 15:17:47 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:17:48 2023 ] Training epoch: 104
[ Wed Jun 28 15:17:53 2023 ] 	Training loss: 5.8944.  Training acc: 97.66%.
[ Wed Jun 28 15:17:53 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:17:54 2023 ] Training epoch: 105
[ Wed Jun 28 15:18:02 2023 ] 	Training loss: 5.7901.  Training acc: 97.92%.
[ Wed Jun 28 15:18:02 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:18:02 2023 ] Training epoch: 106
[ Wed Jun 28 15:18:10 2023 ] 	Training loss: 5.8619.  Training acc: 98.96%.
[ Wed Jun 28 15:18:10 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:18:10 2023 ] Training epoch: 107
[ Wed Jun 28 15:18:17 2023 ] 	Training loss: 5.7658.  Training acc: 98.70%.
[ Wed Jun 28 15:18:17 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:18:18 2023 ] Training epoch: 108
[ Wed Jun 28 15:18:25 2023 ] 	Training loss: 5.8133.  Training acc: 97.79%.
[ Wed Jun 28 15:18:25 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:18:26 2023 ] Training epoch: 109
[ Wed Jun 28 15:18:33 2023 ] 	Training loss: 5.8821.  Training acc: 98.57%.
[ Wed Jun 28 15:18:33 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:18:34 2023 ] Training epoch: 110
[ Wed Jun 28 15:18:41 2023 ] 	Training loss: 5.9164.  Training acc: 98.05%.
[ Wed Jun 28 15:18:41 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:18:42 2023 ] Training epoch: 111
[ Wed Jun 28 15:18:48 2023 ] 	Training loss: 5.7007.  Training acc: 97.92%.
[ Wed Jun 28 15:18:48 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:18:49 2023 ] Training epoch: 112
[ Wed Jun 28 15:18:55 2023 ] 	Training loss: 5.8048.  Training acc: 98.44%.
[ Wed Jun 28 15:18:55 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:18:56 2023 ] Training epoch: 113
[ Wed Jun 28 15:19:02 2023 ] 	Training loss: 5.7949.  Training acc: 97.92%.
[ Wed Jun 28 15:19:02 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:19:03 2023 ] Training epoch: 114
[ Wed Jun 28 15:19:08 2023 ] 	Training loss: 5.6415.  Training acc: 98.05%.
[ Wed Jun 28 15:19:08 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:19:09 2023 ] Training epoch: 115
[ Wed Jun 28 15:19:15 2023 ] 	Training loss: 5.7889.  Training acc: 98.05%.
[ Wed Jun 28 15:19:15 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:19:16 2023 ] Training epoch: 116
[ Wed Jun 28 15:19:23 2023 ] 	Training loss: 5.7421.  Training acc: 98.70%.
[ Wed Jun 28 15:19:23 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:19:23 2023 ] Training epoch: 117
[ Wed Jun 28 15:19:31 2023 ] 	Training loss: 5.7699.  Training acc: 97.66%.
[ Wed Jun 28 15:19:31 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 15:19:31 2023 ] Training epoch: 118
[ Wed Jun 28 15:19:39 2023 ] 	Training loss: 5.6275.  Training acc: 99.35%.
[ Wed Jun 28 15:19:39 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:19:40 2023 ] Training epoch: 119
[ Wed Jun 28 15:19:47 2023 ] 	Training loss: 5.7681.  Training acc: 98.05%.
[ Wed Jun 28 15:19:47 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:19:47 2023 ] Training epoch: 120
[ Wed Jun 28 15:19:54 2023 ] 	Training loss: 5.6511.  Training acc: 98.05%.
[ Wed Jun 28 15:19:54 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:19:55 2023 ] Training epoch: 121
[ Wed Jun 28 15:20:02 2023 ] 	Training loss: 5.7248.  Training acc: 98.96%.
[ Wed Jun 28 15:20:02 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:20:03 2023 ] Training epoch: 122
[ Wed Jun 28 15:20:10 2023 ] 	Training loss: 5.7213.  Training acc: 98.31%.
[ Wed Jun 28 15:20:10 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 15:20:11 2023 ] Training epoch: 123
[ Wed Jun 28 15:20:17 2023 ] 	Training loss: 5.7481.  Training acc: 99.09%.
[ Wed Jun 28 15:20:17 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 15:20:18 2023 ] Training epoch: 124
[ Wed Jun 28 15:20:24 2023 ] 	Training loss: 5.6935.  Training acc: 98.57%.
[ Wed Jun 28 15:20:24 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:20:24 2023 ] Training epoch: 125
[ Wed Jun 28 15:20:30 2023 ] 	Training loss: 5.6248.  Training acc: 99.22%.
[ Wed Jun 28 15:20:30 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:20:31 2023 ] Training epoch: 126
[ Wed Jun 28 15:20:37 2023 ] 	Training loss: 5.8129.  Training acc: 98.57%.
[ Wed Jun 28 15:20:37 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:20:38 2023 ] Training epoch: 127
[ Wed Jun 28 15:20:43 2023 ] 	Training loss: 5.6789.  Training acc: 97.66%.
[ Wed Jun 28 15:20:43 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Jun 28 15:20:44 2023 ] Training epoch: 128
[ Wed Jun 28 15:20:51 2023 ] 	Training loss: 5.6091.  Training acc: 98.05%.
[ Wed Jun 28 15:20:51 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 15:20:52 2023 ] Training epoch: 129
[ Wed Jun 28 16:05:11 2023 ] using warm up, epoch: 5
[ Wed Jun 28 16:05:12 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 16:05:12 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 16:05:12 2023 ] Start training Predictor
[ Wed Jun 28 16:05:12 2023 ] Training epoch: 1
[ Wed Jun 28 16:05:18 2023 ] 	Training loss: 107.7543.  Training acc: 34.28%.
[ Wed Jun 28 16:05:18 2023 ] 	Time consumption: [Data]05%, [Network]94%
[ Wed Jun 28 16:05:18 2023 ] Eval epoch: 1
[ Wed Jun 28 16:05:19 2023 ] 	Mean test loss of 625 batches: 4318.025146.
[ Wed Jun 28 16:05:19 2023 ] 	Top1: 38.60%
[ Wed Jun 28 16:05:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:05:19 2023 ] Training epoch: 2
[ Wed Jun 28 16:05:22 2023 ] 	Training loss: 12.1560.  Training acc: 42.74%.
[ Wed Jun 28 16:05:22 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:05:22 2023 ] Eval epoch: 2
[ Wed Jun 28 16:05:22 2023 ] 	Mean test loss of 625 batches: 123.550403.
[ Wed Jun 28 16:05:22 2023 ] 	Top1: 38.60%
[ Wed Jun 28 16:05:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:05:22 2023 ] Training epoch: 3
[ Wed Jun 28 16:05:25 2023 ] 	Training loss: 5.8260.  Training acc: 54.41%.
[ Wed Jun 28 16:05:25 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:05:25 2023 ] Eval epoch: 3
[ Wed Jun 28 16:05:26 2023 ] 	Mean test loss of 625 batches: 14.465816.
[ Wed Jun 28 16:05:26 2023 ] 	Top1: 54.39%
[ Wed Jun 28 16:05:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:05:26 2023 ] Training epoch: 4
[ Wed Jun 28 16:05:29 2023 ] 	Training loss: 5.1703.  Training acc: 64.52%.
[ Wed Jun 28 16:05:29 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:05:29 2023 ] Eval epoch: 4
[ Wed Jun 28 16:05:29 2023 ] 	Mean test loss of 625 batches: 4.567295.
[ Wed Jun 28 16:05:29 2023 ] 	Top1: 68.42%
[ Wed Jun 28 16:05:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:05:29 2023 ] Training epoch: 5
[ Wed Jun 28 16:05:32 2023 ] 	Training loss: 3.6556.  Training acc: 64.06%.
[ Wed Jun 28 16:05:32 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Wed Jun 28 16:05:32 2023 ] Eval epoch: 5
[ Wed Jun 28 16:05:33 2023 ] 	Mean test loss of 625 batches: 4.615249.
[ Wed Jun 28 16:05:33 2023 ] 	Top1: 56.14%
[ Wed Jun 28 16:05:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:05:33 2023 ] Training epoch: 6
[ Wed Jun 28 16:05:36 2023 ] 	Training loss: 2.5831.  Training acc: 61.67%.
[ Wed Jun 28 16:05:36 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:05:36 2023 ] Eval epoch: 6
[ Wed Jun 28 16:05:37 2023 ] 	Mean test loss of 625 batches: 1.280378.
[ Wed Jun 28 16:05:37 2023 ] 	Top1: 80.70%
[ Wed Jun 28 16:05:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:05:37 2023 ] Training epoch: 7
[ Wed Jun 28 16:05:40 2023 ] 	Training loss: 1.8351.  Training acc: 66.64%.
[ Wed Jun 28 16:05:40 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:05:40 2023 ] Eval epoch: 7
[ Wed Jun 28 16:05:40 2023 ] 	Mean test loss of 625 batches: 0.821249.
[ Wed Jun 28 16:05:40 2023 ] 	Top1: 75.44%
[ Wed Jun 28 16:05:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:05:40 2023 ] Training epoch: 8
[ Wed Jun 28 16:05:43 2023 ] 	Training loss: 1.5761.  Training acc: 70.13%.
[ Wed Jun 28 16:05:43 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:05:43 2023 ] Eval epoch: 8
[ Wed Jun 28 16:05:44 2023 ] 	Mean test loss of 625 batches: 1.458145.
[ Wed Jun 28 16:05:44 2023 ] 	Top1: 73.68%
[ Wed Jun 28 16:05:44 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:05:44 2023 ] Training epoch: 9
[ Wed Jun 28 16:05:47 2023 ] 	Training loss: 1.4017.  Training acc: 73.71%.
[ Wed Jun 28 16:05:47 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:05:47 2023 ] Eval epoch: 9
[ Wed Jun 28 16:05:47 2023 ] 	Mean test loss of 625 batches: 4.224678.
[ Wed Jun 28 16:05:47 2023 ] 	Top1: 52.63%
[ Wed Jun 28 16:05:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:05:47 2023 ] Training epoch: 10
[ Wed Jun 28 16:05:50 2023 ] 	Training loss: 2.3540.  Training acc: 67.56%.
[ Wed Jun 28 16:05:50 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:05:50 2023 ] Eval epoch: 10
[ Wed Jun 28 16:05:51 2023 ] 	Mean test loss of 625 batches: 1.970086.
[ Wed Jun 28 16:05:51 2023 ] 	Top1: 70.18%
[ Wed Jun 28 16:05:51 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:05:51 2023 ] Training epoch: 11
[ Wed Jun 28 16:05:54 2023 ] 	Training loss: 1.4800.  Training acc: 74.63%.
[ Wed Jun 28 16:05:54 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:05:54 2023 ] Eval epoch: 11
[ Wed Jun 28 16:05:55 2023 ] 	Mean test loss of 625 batches: 0.712308.
[ Wed Jun 28 16:05:55 2023 ] 	Top1: 94.74%
[ Wed Jun 28 16:05:55 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:05:55 2023 ] Training epoch: 12
[ Wed Jun 28 16:05:58 2023 ] 	Training loss: 1.0047.  Training acc: 80.79%.
[ Wed Jun 28 16:05:58 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 16:05:58 2023 ] Eval epoch: 12
[ Wed Jun 28 16:05:58 2023 ] 	Mean test loss of 625 batches: 0.557616.
[ Wed Jun 28 16:05:58 2023 ] 	Top1: 98.25%
[ Wed Jun 28 16:05:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:05:58 2023 ] Training epoch: 13
[ Wed Jun 28 16:06:01 2023 ] 	Training loss: 0.8043.  Training acc: 86.76%.
[ Wed Jun 28 16:06:01 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:06:01 2023 ] Eval epoch: 13
[ Wed Jun 28 16:06:02 2023 ] 	Mean test loss of 625 batches: 0.633938.
[ Wed Jun 28 16:06:02 2023 ] 	Top1: 85.96%
[ Wed Jun 28 16:06:02 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:06:02 2023 ] Training epoch: 14
[ Wed Jun 28 16:06:05 2023 ] 	Training loss: 0.6718.  Training acc: 91.54%.
[ Wed Jun 28 16:06:05 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:06:05 2023 ] Eval epoch: 14
[ Wed Jun 28 16:06:06 2023 ] 	Mean test loss of 625 batches: 0.554200.
[ Wed Jun 28 16:06:06 2023 ] 	Top1: 92.98%
[ Wed Jun 28 16:06:06 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:06:06 2023 ] Training epoch: 15
[ Wed Jun 28 16:06:09 2023 ] 	Training loss: 0.6535.  Training acc: 92.00%.
[ Wed Jun 28 16:06:09 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:06:09 2023 ] Eval epoch: 15
[ Wed Jun 28 16:06:09 2023 ] 	Mean test loss of 625 batches: 0.454408.
[ Wed Jun 28 16:06:09 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:06:09 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:06:09 2023 ] Training epoch: 16
[ Wed Jun 28 16:06:12 2023 ] 	Training loss: 0.5984.  Training acc: 93.47%.
[ Wed Jun 28 16:06:12 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:06:12 2023 ] Eval epoch: 16
[ Wed Jun 28 16:06:13 2023 ] 	Mean test loss of 625 batches: 0.427954.
[ Wed Jun 28 16:06:13 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:06:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:06:13 2023 ] Training epoch: 17
[ Wed Jun 28 16:06:16 2023 ] 	Training loss: 0.5852.  Training acc: 94.03%.
[ Wed Jun 28 16:06:16 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:06:16 2023 ] Eval epoch: 17
[ Wed Jun 28 16:06:16 2023 ] 	Mean test loss of 625 batches: 0.461674.
[ Wed Jun 28 16:06:16 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:06:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:06:16 2023 ] Training epoch: 18
[ Wed Jun 28 16:06:19 2023 ] 	Training loss: 0.5305.  Training acc: 95.40%.
[ Wed Jun 28 16:06:19 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:06:19 2023 ] Eval epoch: 18
[ Wed Jun 28 16:06:20 2023 ] 	Mean test loss of 625 batches: 0.416462.
[ Wed Jun 28 16:06:20 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:06:20 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:06:20 2023 ] Training epoch: 19
[ Wed Jun 28 16:06:23 2023 ] 	Training loss: 0.5293.  Training acc: 94.58%.
[ Wed Jun 28 16:06:23 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:06:23 2023 ] Eval epoch: 19
[ Wed Jun 28 16:06:24 2023 ] 	Mean test loss of 625 batches: 0.406682.
[ Wed Jun 28 16:06:24 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:06:24 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:06:24 2023 ] Training epoch: 20
[ Wed Jun 28 16:06:26 2023 ] 	Training loss: 0.5023.  Training acc: 96.60%.
[ Wed Jun 28 16:06:26 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 16:06:26 2023 ] Eval epoch: 20
[ Wed Jun 28 16:06:27 2023 ] 	Mean test loss of 625 batches: 0.435255.
[ Wed Jun 28 16:06:27 2023 ] 	Top1: 98.25%
[ Wed Jun 28 16:06:27 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:06:27 2023 ] Training epoch: 21
[ Wed Jun 28 16:06:30 2023 ] 	Training loss: 0.4649.  Training acc: 96.69%.
[ Wed Jun 28 16:06:30 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:06:30 2023 ] Eval epoch: 21
[ Wed Jun 28 16:06:31 2023 ] 	Mean test loss of 625 batches: 0.402768.
[ Wed Jun 28 16:06:31 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:06:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:06:31 2023 ] Training epoch: 22
[ Wed Jun 28 16:06:34 2023 ] 	Training loss: 0.4649.  Training acc: 96.88%.
[ Wed Jun 28 16:06:34 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:06:34 2023 ] Eval epoch: 22
[ Wed Jun 28 16:06:34 2023 ] 	Mean test loss of 625 batches: 0.395780.
[ Wed Jun 28 16:06:34 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:06:34 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:06:34 2023 ] Training epoch: 23
[ Wed Jun 28 16:06:37 2023 ] 	Training loss: 0.4655.  Training acc: 96.69%.
[ Wed Jun 28 16:06:37 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:06:37 2023 ] Eval epoch: 23
[ Wed Jun 28 16:06:38 2023 ] 	Mean test loss of 625 batches: 0.389048.
[ Wed Jun 28 16:06:38 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:06:38 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:06:38 2023 ] Training epoch: 24
[ Wed Jun 28 16:06:41 2023 ] 	Training loss: 0.4383.  Training acc: 97.43%.
[ Wed Jun 28 16:06:41 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:06:41 2023 ] Eval epoch: 24
[ Wed Jun 28 16:06:42 2023 ] 	Mean test loss of 625 batches: 0.383499.
[ Wed Jun 28 16:06:42 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:06:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:06:42 2023 ] Training epoch: 25
[ Wed Jun 28 16:06:44 2023 ] 	Training loss: 0.4420.  Training acc: 97.15%.
[ Wed Jun 28 16:06:44 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 16:06:44 2023 ] Eval epoch: 25
[ Wed Jun 28 16:06:45 2023 ] 	Mean test loss of 625 batches: 0.386424.
[ Wed Jun 28 16:06:45 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:06:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:06:45 2023 ] Training epoch: 26
[ Wed Jun 28 16:06:48 2023 ] 	Training loss: 0.4443.  Training acc: 97.24%.
[ Wed Jun 28 16:06:48 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:06:48 2023 ] Eval epoch: 26
[ Wed Jun 28 16:06:49 2023 ] 	Mean test loss of 625 batches: 0.374494.
[ Wed Jun 28 16:06:49 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:06:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:06:49 2023 ] Training epoch: 27
[ Wed Jun 28 16:06:52 2023 ] 	Training loss: 0.4252.  Training acc: 97.43%.
[ Wed Jun 28 16:06:52 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:06:52 2023 ] Eval epoch: 27
[ Wed Jun 28 16:06:52 2023 ] 	Mean test loss of 625 batches: 0.373190.
[ Wed Jun 28 16:06:52 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:06:52 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:06:52 2023 ] Training epoch: 28
[ Wed Jun 28 16:06:55 2023 ] 	Training loss: 0.4124.  Training acc: 98.25%.
[ Wed Jun 28 16:06:55 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:06:55 2023 ] Eval epoch: 28
[ Wed Jun 28 16:06:56 2023 ] 	Mean test loss of 625 batches: 0.375775.
[ Wed Jun 28 16:06:56 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:06:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:06:56 2023 ] Training epoch: 29
[ Wed Jun 28 16:06:59 2023 ] 	Training loss: 0.4177.  Training acc: 97.70%.
[ Wed Jun 28 16:06:59 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:06:59 2023 ] Eval epoch: 29
[ Wed Jun 28 16:06:59 2023 ] 	Mean test loss of 625 batches: 0.372197.
[ Wed Jun 28 16:06:59 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:06:59 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:06:59 2023 ] Training epoch: 30
[ Wed Jun 28 16:07:02 2023 ] 	Training loss: 0.4134.  Training acc: 97.79%.
[ Wed Jun 28 16:07:02 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:07:02 2023 ] Eval epoch: 30
[ Wed Jun 28 16:07:03 2023 ] 	Mean test loss of 625 batches: 0.370932.
[ Wed Jun 28 16:07:03 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:07:03 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:07:04 2023 ] Best accuracy: 1.0
[ Wed Jun 28 16:07:04 2023 ] Epoch number: 15
[ Wed Jun 28 16:07:04 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 16:07:04 2023 ] Weight decay: 0.0005
[ Wed Jun 28 16:07:04 2023 ] Base LR: 0.1
[ Wed Jun 28 16:07:04 2023 ] Batch Size: 64
[ Wed Jun 28 16:07:04 2023 ] Test Batch Size: 64
[ Wed Jun 28 16:07:04 2023 ] seed: 1
[ Wed Jun 28 16:07:04 2023 ] Start training Corrector
[ Wed Jun 28 16:07:05 2023 ] Training epoch: 1
[ Wed Jun 28 16:07:13 2023 ] 	Training loss: 17.3457.  Training acc: 37.63%.
[ Wed Jun 28 16:07:13 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:07:14 2023 ] Training epoch: 2
[ Wed Jun 28 16:07:21 2023 ] 	Training loss: 11.9547.  Training acc: 59.11%.
[ Wed Jun 28 16:07:21 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:07:21 2023 ] Training epoch: 3
[ Wed Jun 28 16:07:28 2023 ] 	Training loss: 9.0392.  Training acc: 44.66%.
[ Wed Jun 28 16:07:28 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:07:28 2023 ] Training epoch: 4
[ Wed Jun 28 16:07:35 2023 ] 	Training loss: 8.0660.  Training acc: 56.64%.
[ Wed Jun 28 16:07:35 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:07:35 2023 ] Training epoch: 5
[ Wed Jun 28 16:07:42 2023 ] 	Training loss: 7.9865.  Training acc: 47.92%.
[ Wed Jun 28 16:07:42 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:07:43 2023 ] Training epoch: 6
[ Wed Jun 28 16:07:49 2023 ] 	Training loss: 7.6046.  Training acc: 61.59%.
[ Wed Jun 28 16:07:49 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:07:50 2023 ] Training epoch: 7
[ Wed Jun 28 16:07:56 2023 ] 	Training loss: 7.2236.  Training acc: 61.85%.
[ Wed Jun 28 16:07:56 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:07:57 2023 ] Training epoch: 8
[ Wed Jun 28 16:08:04 2023 ] 	Training loss: 7.8181.  Training acc: 29.04%.
[ Wed Jun 28 16:08:04 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:08:04 2023 ] Training epoch: 9
[ Wed Jun 28 16:08:11 2023 ] 	Training loss: 12.7687.  Training acc: 31.90%.
[ Wed Jun 28 16:08:11 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:08:11 2023 ] Training epoch: 10
[ Wed Jun 28 16:08:18 2023 ] 	Training loss: 17.5533.  Training acc: 30.21%.
[ Wed Jun 28 16:08:18 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:08:19 2023 ] Training epoch: 11
[ Wed Jun 28 16:08:25 2023 ] 	Training loss: 14.4105.  Training acc: 27.99%.
[ Wed Jun 28 16:08:25 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:08:26 2023 ] Training epoch: 12
[ Wed Jun 28 16:08:32 2023 ] 	Training loss: 12.1210.  Training acc: 27.73%.
[ Wed Jun 28 16:08:32 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:08:33 2023 ] Training epoch: 13
[ Wed Jun 28 16:08:40 2023 ] 	Training loss: 10.2047.  Training acc: 29.69%.
[ Wed Jun 28 16:08:40 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:08:40 2023 ] Training epoch: 14
[ Wed Jun 28 16:08:47 2023 ] 	Training loss: 8.9423.  Training acc: 40.89%.
[ Wed Jun 28 16:08:47 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:08:47 2023 ] Training epoch: 15
[ Wed Jun 28 16:08:54 2023 ] 	Training loss: 8.5692.  Training acc: 41.28%.
[ Wed Jun 28 16:08:54 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:08:55 2023 ] Training epoch: 16
[ Wed Jun 28 16:09:01 2023 ] 	Training loss: 8.4238.  Training acc: 46.35%.
[ Wed Jun 28 16:09:01 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:09:02 2023 ] Training epoch: 17
[ Wed Jun 28 16:09:08 2023 ] 	Training loss: 8.1919.  Training acc: 48.18%.
[ Wed Jun 28 16:09:08 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:09:09 2023 ] Training epoch: 18
[ Wed Jun 28 16:09:16 2023 ] 	Training loss: 8.0008.  Training acc: 49.48%.
[ Wed Jun 28 16:09:16 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:09:16 2023 ] Training epoch: 19
[ Wed Jun 28 16:09:23 2023 ] 	Training loss: 7.9413.  Training acc: 47.92%.
[ Wed Jun 28 16:09:23 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:09:24 2023 ] Training epoch: 20
[ Wed Jun 28 16:09:30 2023 ] 	Training loss: 7.7057.  Training acc: 46.09%.
[ Wed Jun 28 16:09:30 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:09:31 2023 ] Training epoch: 21
[ Wed Jun 28 16:09:37 2023 ] 	Training loss: 7.6782.  Training acc: 49.74%.
[ Wed Jun 28 16:09:37 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:09:38 2023 ] Training epoch: 22
[ Wed Jun 28 16:09:45 2023 ] 	Training loss: 7.6115.  Training acc: 52.34%.
[ Wed Jun 28 16:09:45 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:09:45 2023 ] Training epoch: 23
[ Wed Jun 28 16:09:52 2023 ] 	Training loss: 7.5472.  Training acc: 55.60%.
[ Wed Jun 28 16:09:52 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:09:52 2023 ] Training epoch: 24
[ Wed Jun 28 16:09:59 2023 ] 	Training loss: 7.6063.  Training acc: 56.90%.
[ Wed Jun 28 16:09:59 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:10:00 2023 ] Training epoch: 25
[ Wed Jun 28 16:10:06 2023 ] 	Training loss: 7.6434.  Training acc: 57.94%.
[ Wed Jun 28 16:10:06 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:10:07 2023 ] Training epoch: 26
[ Wed Jun 28 16:10:13 2023 ] 	Training loss: 7.4833.  Training acc: 56.90%.
[ Wed Jun 28 16:10:13 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:10:14 2023 ] Training epoch: 27
[ Wed Jun 28 16:10:20 2023 ] 	Training loss: 7.4636.  Training acc: 56.90%.
[ Wed Jun 28 16:10:20 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:10:21 2023 ] Training epoch: 28
[ Wed Jun 28 16:10:28 2023 ] 	Training loss: 7.5793.  Training acc: 53.65%.
[ Wed Jun 28 16:10:28 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:10:28 2023 ] Training epoch: 29
[ Wed Jun 28 16:10:35 2023 ] 	Training loss: 7.4644.  Training acc: 55.34%.
[ Wed Jun 28 16:10:35 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:10:35 2023 ] Training epoch: 30
[ Wed Jun 28 16:10:42 2023 ] 	Training loss: 7.5829.  Training acc: 55.99%.
[ Wed Jun 28 16:10:42 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:10:43 2023 ] Training epoch: 31
[ Wed Jun 28 16:10:49 2023 ] 	Training loss: 7.5433.  Training acc: 60.81%.
[ Wed Jun 28 16:10:49 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:10:50 2023 ] Training epoch: 32
[ Wed Jun 28 16:10:56 2023 ] 	Training loss: 7.3404.  Training acc: 63.67%.
[ Wed Jun 28 16:10:56 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:10:57 2023 ] Training epoch: 33
[ Wed Jun 28 16:11:04 2023 ] 	Training loss: 7.4696.  Training acc: 63.41%.
[ Wed Jun 28 16:11:04 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:11:04 2023 ] Training epoch: 34
[ Wed Jun 28 16:11:11 2023 ] 	Training loss: 7.3855.  Training acc: 64.45%.
[ Wed Jun 28 16:11:11 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:11:11 2023 ] Training epoch: 35
[ Wed Jun 28 16:11:18 2023 ] 	Training loss: 7.4776.  Training acc: 63.41%.
[ Wed Jun 28 16:11:18 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:11:18 2023 ] Training epoch: 36
[ Wed Jun 28 16:11:25 2023 ] 	Training loss: 7.4399.  Training acc: 63.41%.
[ Wed Jun 28 16:11:25 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:11:25 2023 ] Training epoch: 37
[ Wed Jun 28 16:11:32 2023 ] 	Training loss: 7.5276.  Training acc: 65.49%.
[ Wed Jun 28 16:11:32 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:11:33 2023 ] Training epoch: 38
[ Wed Jun 28 16:11:39 2023 ] 	Training loss: 7.4348.  Training acc: 62.89%.
[ Wed Jun 28 16:11:39 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:11:40 2023 ] Training epoch: 39
[ Wed Jun 28 16:11:46 2023 ] 	Training loss: 7.3297.  Training acc: 60.03%.
[ Wed Jun 28 16:11:46 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:11:47 2023 ] Training epoch: 40
[ Wed Jun 28 16:11:53 2023 ] 	Training loss: 7.4475.  Training acc: 58.46%.
[ Wed Jun 28 16:11:53 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:11:54 2023 ] Training epoch: 41
[ Wed Jun 28 16:12:01 2023 ] 	Training loss: 7.3098.  Training acc: 59.64%.
[ Wed Jun 28 16:12:01 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:12:01 2023 ] Training epoch: 42
[ Wed Jun 28 16:12:08 2023 ] 	Training loss: 7.3127.  Training acc: 62.89%.
[ Wed Jun 28 16:12:08 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:12:08 2023 ] Training epoch: 43
[ Wed Jun 28 16:12:15 2023 ] 	Training loss: 7.4440.  Training acc: 66.54%.
[ Wed Jun 28 16:12:15 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:12:16 2023 ] Training epoch: 44
[ Wed Jun 28 16:12:22 2023 ] 	Training loss: 7.1767.  Training acc: 66.93%.
[ Wed Jun 28 16:12:22 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:12:23 2023 ] Training epoch: 45
[ Wed Jun 28 16:12:29 2023 ] 	Training loss: 7.3088.  Training acc: 63.28%.
[ Wed Jun 28 16:12:29 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:12:30 2023 ] Training epoch: 46
[ Wed Jun 28 16:12:36 2023 ] 	Training loss: 7.2189.  Training acc: 59.24%.
[ Wed Jun 28 16:12:36 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:12:37 2023 ] Training epoch: 47
[ Wed Jun 28 16:12:43 2023 ] 	Training loss: 7.4465.  Training acc: 58.07%.
[ Wed Jun 28 16:12:43 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:12:44 2023 ] Training epoch: 48
[ Wed Jun 28 16:12:51 2023 ] 	Training loss: 7.4398.  Training acc: 59.90%.
[ Wed Jun 28 16:12:51 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:12:51 2023 ] Training epoch: 49
[ Wed Jun 28 16:12:58 2023 ] 	Training loss: 7.4931.  Training acc: 64.97%.
[ Wed Jun 28 16:12:58 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:12:58 2023 ] Training epoch: 50
[ Wed Jun 28 16:13:05 2023 ] 	Training loss: 7.2233.  Training acc: 62.76%.
[ Wed Jun 28 16:13:05 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:13:06 2023 ] Training epoch: 51
[ Wed Jun 28 16:13:12 2023 ] 	Training loss: 7.2862.  Training acc: 57.68%.
[ Wed Jun 28 16:13:12 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:13:13 2023 ] Training epoch: 52
[ Wed Jun 28 16:13:19 2023 ] 	Training loss: 7.2070.  Training acc: 58.07%.
[ Wed Jun 28 16:13:19 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:13:20 2023 ] Training epoch: 53
[ Wed Jun 28 16:13:27 2023 ] 	Training loss: 7.1247.  Training acc: 58.72%.
[ Wed Jun 28 16:13:27 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:13:27 2023 ] Training epoch: 54
[ Wed Jun 28 16:13:34 2023 ] 	Training loss: 7.1886.  Training acc: 63.28%.
[ Wed Jun 28 16:13:34 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:13:34 2023 ] Training epoch: 55
[ Wed Jun 28 16:13:41 2023 ] 	Training loss: 7.2908.  Training acc: 62.76%.
[ Wed Jun 28 16:13:41 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:13:41 2023 ] Training epoch: 56
[ Wed Jun 28 16:13:48 2023 ] 	Training loss: 7.2779.  Training acc: 61.98%.
[ Wed Jun 28 16:13:48 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:13:49 2023 ] Training epoch: 57
[ Wed Jun 28 16:13:55 2023 ] 	Training loss: 7.2053.  Training acc: 62.24%.
[ Wed Jun 28 16:13:55 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:13:56 2023 ] Training epoch: 58
[ Wed Jun 28 16:14:02 2023 ] 	Training loss: 7.3306.  Training acc: 64.71%.
[ Wed Jun 28 16:14:02 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 16:14:03 2023 ] Training epoch: 59
[ Wed Jun 28 16:14:09 2023 ] 	Training loss: 7.1657.  Training acc: 70.44%.
[ Wed Jun 28 16:14:09 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:14:10 2023 ] Training epoch: 60
[ Wed Jun 28 16:14:17 2023 ] 	Training loss: 7.2483.  Training acc: 67.06%.
[ Wed Jun 28 16:14:17 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:14:17 2023 ] Training epoch: 61
[ Wed Jun 28 16:14:24 2023 ] 	Training loss: 7.1553.  Training acc: 64.32%.
[ Wed Jun 28 16:14:24 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:14:25 2023 ] Training epoch: 62
[ Wed Jun 28 16:14:31 2023 ] 	Training loss: 7.0103.  Training acc: 62.76%.
[ Wed Jun 28 16:14:31 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:14:32 2023 ] Training epoch: 63
[ Wed Jun 28 16:14:38 2023 ] 	Training loss: 7.2859.  Training acc: 66.80%.
[ Wed Jun 28 16:14:38 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:14:39 2023 ] Training epoch: 64
[ Wed Jun 28 16:14:46 2023 ] 	Training loss: 7.1795.  Training acc: 60.94%.
[ Wed Jun 28 16:14:46 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:14:46 2023 ] Training epoch: 65
[ Wed Jun 28 16:14:53 2023 ] 	Training loss: 7.1054.  Training acc: 62.76%.
[ Wed Jun 28 16:14:53 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:14:53 2023 ] Training epoch: 66
[ Wed Jun 28 16:15:00 2023 ] 	Training loss: 7.0778.  Training acc: 66.41%.
[ Wed Jun 28 16:15:00 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:15:01 2023 ] Training epoch: 67
[ Wed Jun 28 16:15:07 2023 ] 	Training loss: 7.2964.  Training acc: 74.61%.
[ Wed Jun 28 16:15:07 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:15:08 2023 ] Training epoch: 68
[ Wed Jun 28 16:15:14 2023 ] 	Training loss: 7.1043.  Training acc: 74.22%.
[ Wed Jun 28 16:15:14 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:15:15 2023 ] Training epoch: 69
[ Wed Jun 28 16:15:22 2023 ] 	Training loss: 7.2657.  Training acc: 75.78%.
[ Wed Jun 28 16:15:22 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:15:22 2023 ] Training epoch: 70
[ Wed Jun 28 16:15:29 2023 ] 	Training loss: 7.1222.  Training acc: 77.21%.
[ Wed Jun 28 16:15:29 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:15:29 2023 ] Training epoch: 71
[ Wed Jun 28 16:15:35 2023 ] 	Training loss: 7.1014.  Training acc: 73.05%.
[ Wed Jun 28 16:15:35 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 16:15:36 2023 ] Training epoch: 72
[ Wed Jun 28 16:15:41 2023 ] 	Training loss: 7.1082.  Training acc: 76.43%.
[ Wed Jun 28 16:15:41 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 16:15:41 2023 ] Training epoch: 73
[ Wed Jun 28 16:15:46 2023 ] 	Training loss: 7.1262.  Training acc: 75.26%.
[ Wed Jun 28 16:15:46 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 16:15:47 2023 ] Training epoch: 74
[ Wed Jun 28 16:15:52 2023 ] 	Training loss: 7.1853.  Training acc: 79.69%.
[ Wed Jun 28 16:15:52 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 16:15:52 2023 ] Training epoch: 75
[ Wed Jun 28 16:15:57 2023 ] 	Training loss: 7.2142.  Training acc: 75.52%.
[ Wed Jun 28 16:15:57 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 16:15:58 2023 ] Training epoch: 76
[ Wed Jun 28 16:16:03 2023 ] 	Training loss: 7.0182.  Training acc: 78.39%.
[ Wed Jun 28 16:16:03 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 16:16:03 2023 ] Training epoch: 77
[ Wed Jun 28 16:16:10 2023 ] 	Training loss: 7.0556.  Training acc: 77.08%.
[ Wed Jun 28 16:16:10 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:16:11 2023 ] Training epoch: 78
[ Wed Jun 28 16:16:17 2023 ] 	Training loss: 7.1050.  Training acc: 80.47%.
[ Wed Jun 28 16:16:17 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:16:18 2023 ] Training epoch: 79
[ Wed Jun 28 16:16:24 2023 ] 	Training loss: 6.9592.  Training acc: 83.07%.
[ Wed Jun 28 16:16:24 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:16:25 2023 ] Training epoch: 80
[ Wed Jun 28 16:16:31 2023 ] 	Training loss: 7.0879.  Training acc: 80.86%.
[ Wed Jun 28 16:16:31 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:16:32 2023 ] Training epoch: 81
[ Wed Jun 28 16:16:38 2023 ] 	Training loss: 6.9979.  Training acc: 78.65%.
[ Wed Jun 28 16:16:38 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:16:39 2023 ] Training epoch: 82
[ Wed Jun 28 16:16:46 2023 ] 	Training loss: 7.1542.  Training acc: 79.69%.
[ Wed Jun 28 16:16:46 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:16:46 2023 ] Training epoch: 83
[ Wed Jun 28 16:16:53 2023 ] 	Training loss: 6.9824.  Training acc: 82.94%.
[ Wed Jun 28 16:16:53 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:16:53 2023 ] Training epoch: 84
[ Wed Jun 28 16:17:00 2023 ] 	Training loss: 7.0885.  Training acc: 82.68%.
[ Wed Jun 28 16:17:00 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:17:00 2023 ] Training epoch: 85
[ Wed Jun 28 16:17:07 2023 ] 	Training loss: 7.0390.  Training acc: 78.91%.
[ Wed Jun 28 16:17:07 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:17:08 2023 ] Training epoch: 86
[ Wed Jun 28 16:17:14 2023 ] 	Training loss: 6.9073.  Training acc: 85.03%.
[ Wed Jun 28 16:17:14 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:17:15 2023 ] Training epoch: 87
[ Wed Jun 28 16:17:21 2023 ] 	Training loss: 7.0685.  Training acc: 87.89%.
[ Wed Jun 28 16:17:21 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:17:22 2023 ] Training epoch: 88
[ Wed Jun 28 16:17:28 2023 ] 	Training loss: 7.1815.  Training acc: 87.50%.
[ Wed Jun 28 16:17:28 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:17:29 2023 ] Training epoch: 89
[ Wed Jun 28 16:17:36 2023 ] 	Training loss: 7.0771.  Training acc: 88.80%.
[ Wed Jun 28 16:17:36 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:17:36 2023 ] Training epoch: 90
[ Wed Jun 28 16:17:43 2023 ] 	Training loss: 7.0903.  Training acc: 89.97%.
[ Wed Jun 28 16:17:43 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:17:43 2023 ] Training epoch: 91
[ Wed Jun 28 16:17:50 2023 ] 	Training loss: 7.0165.  Training acc: 87.37%.
[ Wed Jun 28 16:17:50 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:17:50 2023 ] Training epoch: 92
[ Wed Jun 28 16:17:57 2023 ] 	Training loss: 7.0196.  Training acc: 86.33%.
[ Wed Jun 28 16:17:57 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:17:58 2023 ] Training epoch: 93
[ Wed Jun 28 16:18:04 2023 ] 	Training loss: 6.9278.  Training acc: 83.72%.
[ Wed Jun 28 16:18:04 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:18:05 2023 ] Training epoch: 94
[ Wed Jun 28 16:18:11 2023 ] 	Training loss: 6.7789.  Training acc: 79.43%.
[ Wed Jun 28 16:18:11 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:18:12 2023 ] Training epoch: 95
[ Wed Jun 28 16:18:18 2023 ] 	Training loss: 6.9551.  Training acc: 86.46%.
[ Wed Jun 28 16:18:18 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:18:19 2023 ] Training epoch: 96
[ Wed Jun 28 16:18:25 2023 ] 	Training loss: 6.9949.  Training acc: 83.33%.
[ Wed Jun 28 16:18:25 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:18:26 2023 ] Training epoch: 97
[ Wed Jun 28 16:18:33 2023 ] 	Training loss: 6.9936.  Training acc: 86.46%.
[ Wed Jun 28 16:18:33 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 16:18:33 2023 ] Training epoch: 98
[ Wed Jun 28 16:18:40 2023 ] 	Training loss: 6.8638.  Training acc: 82.16%.
[ Wed Jun 28 16:18:40 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:18:40 2023 ] Training epoch: 99
[ Wed Jun 28 16:18:47 2023 ] 	Training loss: 6.9413.  Training acc: 88.41%.
[ Wed Jun 28 16:18:47 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:18:48 2023 ] Training epoch: 100
[ Wed Jun 28 16:18:54 2023 ] 	Training loss: 6.9854.  Training acc: 86.98%.
[ Wed Jun 28 16:18:54 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:18:55 2023 ] Training epoch: 101
[ Wed Jun 28 16:19:01 2023 ] 	Training loss: 6.9479.  Training acc: 88.15%.
[ Wed Jun 28 16:19:01 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:19:02 2023 ] Training epoch: 102
[ Wed Jun 28 16:19:09 2023 ] 	Training loss: 6.9137.  Training acc: 89.45%.
[ Wed Jun 28 16:19:09 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:19:09 2023 ] Training epoch: 103
[ Wed Jun 28 16:19:16 2023 ] 	Training loss: 6.9728.  Training acc: 82.68%.
[ Wed Jun 28 16:19:16 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:19:17 2023 ] Training epoch: 104
[ Wed Jun 28 16:19:23 2023 ] 	Training loss: 7.0600.  Training acc: 66.41%.
[ Wed Jun 28 16:19:23 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:19:24 2023 ] Training epoch: 105
[ Wed Jun 28 16:19:30 2023 ] 	Training loss: 6.9288.  Training acc: 79.30%.
[ Wed Jun 28 16:19:30 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:19:31 2023 ] Training epoch: 106
[ Wed Jun 28 16:19:38 2023 ] 	Training loss: 6.9087.  Training acc: 84.90%.
[ Wed Jun 28 16:19:38 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:19:38 2023 ] Training epoch: 107
[ Wed Jun 28 16:19:45 2023 ] 	Training loss: 6.9075.  Training acc: 86.59%.
[ Wed Jun 28 16:19:45 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:19:45 2023 ] Training epoch: 108
[ Wed Jun 28 16:19:52 2023 ] 	Training loss: 6.9483.  Training acc: 84.11%.
[ Wed Jun 28 16:19:52 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:19:53 2023 ] Training epoch: 109
[ Wed Jun 28 16:19:59 2023 ] 	Training loss: 7.0409.  Training acc: 82.16%.
[ Wed Jun 28 16:19:59 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:20:00 2023 ] Training epoch: 110
[ Wed Jun 28 16:20:06 2023 ] 	Training loss: 7.0118.  Training acc: 86.07%.
[ Wed Jun 28 16:20:06 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:20:07 2023 ] Training epoch: 111
[ Wed Jun 28 16:20:13 2023 ] 	Training loss: 6.7012.  Training acc: 88.93%.
[ Wed Jun 28 16:20:13 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:20:14 2023 ] Training epoch: 112
[ Wed Jun 28 16:20:21 2023 ] 	Training loss: 6.8866.  Training acc: 86.85%.
[ Wed Jun 28 16:20:21 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:20:21 2023 ] Training epoch: 113
[ Wed Jun 28 16:20:28 2023 ] 	Training loss: 6.8733.  Training acc: 89.45%.
[ Wed Jun 28 16:20:28 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:20:29 2023 ] Training epoch: 114
[ Wed Jun 28 16:20:35 2023 ] 	Training loss: 6.7160.  Training acc: 86.59%.
[ Wed Jun 28 16:20:35 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:20:36 2023 ] Training epoch: 115
[ Wed Jun 28 16:20:42 2023 ] 	Training loss: 6.8551.  Training acc: 88.28%.
[ Wed Jun 28 16:20:42 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:20:43 2023 ] Training epoch: 116
[ Wed Jun 28 16:20:50 2023 ] 	Training loss: 6.8533.  Training acc: 90.76%.
[ Wed Jun 28 16:20:50 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:20:50 2023 ] Training epoch: 117
[ Wed Jun 28 16:20:57 2023 ] 	Training loss: 6.8259.  Training acc: 87.89%.
[ Wed Jun 28 16:20:57 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:20:57 2023 ] Training epoch: 118
[ Wed Jun 28 16:21:04 2023 ] 	Training loss: 6.7233.  Training acc: 81.51%.
[ Wed Jun 28 16:21:04 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:21:04 2023 ] Training epoch: 119
[ Wed Jun 28 16:21:11 2023 ] 	Training loss: 6.8375.  Training acc: 77.99%.
[ Wed Jun 28 16:21:11 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:21:12 2023 ] Training epoch: 120
[ Wed Jun 28 16:21:18 2023 ] 	Training loss: 6.6629.  Training acc: 88.15%.
[ Wed Jun 28 16:21:18 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:21:19 2023 ] Training epoch: 121
[ Wed Jun 28 16:21:25 2023 ] 	Training loss: 6.7789.  Training acc: 91.93%.
[ Wed Jun 28 16:21:25 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:21:26 2023 ] Training epoch: 122
[ Wed Jun 28 16:21:33 2023 ] 	Training loss: 6.8059.  Training acc: 85.29%.
[ Wed Jun 28 16:21:33 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:21:33 2023 ] Training epoch: 123
[ Wed Jun 28 16:21:40 2023 ] 	Training loss: 6.8413.  Training acc: 78.52%.
[ Wed Jun 28 16:21:40 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:21:40 2023 ] Training epoch: 124
[ Wed Jun 28 16:21:47 2023 ] 	Training loss: 6.7973.  Training acc: 75.91%.
[ Wed Jun 28 16:21:47 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:21:48 2023 ] Training epoch: 125
[ Wed Jun 28 16:21:54 2023 ] 	Training loss: 6.7304.  Training acc: 77.86%.
[ Wed Jun 28 16:21:54 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 16:21:55 2023 ] Training epoch: 126
[ Wed Jun 28 16:22:01 2023 ] 	Training loss: 6.8766.  Training acc: 82.81%.
[ Wed Jun 28 16:22:01 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:22:02 2023 ] Training epoch: 127
[ Wed Jun 28 16:22:09 2023 ] 	Training loss: 6.6885.  Training acc: 87.37%.
[ Wed Jun 28 16:22:09 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:22:09 2023 ] Training epoch: 128
[ Wed Jun 28 16:22:16 2023 ] 	Training loss: 6.6392.  Training acc: 85.42%.
[ Wed Jun 28 16:22:16 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:22:17 2023 ] Training epoch: 129
[ Wed Jun 28 16:22:23 2023 ] 	Training loss: 6.6809.  Training acc: 84.38%.
[ Wed Jun 28 16:22:23 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:22:24 2023 ] Training epoch: 130
[ Wed Jun 28 16:22:30 2023 ] 	Training loss: 6.8608.  Training acc: 85.03%.
[ Wed Jun 28 16:22:30 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:22:31 2023 ] Training epoch: 131
[ Wed Jun 28 16:22:37 2023 ] 	Training loss: 6.8238.  Training acc: 84.24%.
[ Wed Jun 28 16:22:37 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:22:38 2023 ] Training epoch: 132
[ Wed Jun 28 16:22:45 2023 ] 	Training loss: 6.7107.  Training acc: 85.55%.
[ Wed Jun 28 16:22:45 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:22:45 2023 ] Training epoch: 133
[ Wed Jun 28 16:22:52 2023 ] 	Training loss: 6.7497.  Training acc: 85.42%.
[ Wed Jun 28 16:22:52 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:22:53 2023 ] Training epoch: 134
[ Wed Jun 28 16:23:00 2023 ] 	Training loss: 6.8191.  Training acc: 89.32%.
[ Wed Jun 28 16:23:00 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:23:00 2023 ] Training epoch: 135
[ Wed Jun 28 16:23:07 2023 ] 	Training loss: 6.8397.  Training acc: 90.89%.
[ Wed Jun 28 16:23:07 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:23:08 2023 ] Training epoch: 136
[ Wed Jun 28 16:23:14 2023 ] 	Training loss: 6.8240.  Training acc: 91.15%.
[ Wed Jun 28 16:23:14 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:23:15 2023 ] Training epoch: 137
[ Wed Jun 28 16:23:21 2023 ] 	Training loss: 6.7588.  Training acc: 93.36%.
[ Wed Jun 28 16:23:21 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:23:22 2023 ] Training epoch: 138
[ Wed Jun 28 16:23:28 2023 ] 	Training loss: 6.7821.  Training acc: 92.19%.
[ Wed Jun 28 16:23:28 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:23:29 2023 ] Training epoch: 139
[ Wed Jun 28 16:23:35 2023 ] 	Training loss: 6.6843.  Training acc: 90.89%.
[ Wed Jun 28 16:23:35 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:23:36 2023 ] Training epoch: 140
[ Wed Jun 28 16:23:43 2023 ] 	Training loss: 6.8029.  Training acc: 92.19%.
[ Wed Jun 28 16:23:43 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:23:43 2023 ] Training epoch: 141
[ Wed Jun 28 16:23:50 2023 ] 	Training loss: 6.5495.  Training acc: 90.89%.
[ Wed Jun 28 16:23:50 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:23:50 2023 ] Training epoch: 142
[ Wed Jun 28 16:23:57 2023 ] 	Training loss: 6.6392.  Training acc: 92.58%.
[ Wed Jun 28 16:23:57 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:23:58 2023 ] Training epoch: 143
[ Wed Jun 28 16:24:04 2023 ] 	Training loss: 6.6199.  Training acc: 90.76%.
[ Wed Jun 28 16:24:04 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:24:05 2023 ] Training epoch: 144
[ Wed Jun 28 16:24:11 2023 ] 	Training loss: 6.7535.  Training acc: 89.97%.
[ Wed Jun 28 16:24:11 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:24:12 2023 ] Training epoch: 145
[ Wed Jun 28 16:24:19 2023 ] 	Training loss: 6.7018.  Training acc: 92.06%.
[ Wed Jun 28 16:24:19 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:24:19 2023 ] Training epoch: 146
[ Wed Jun 28 16:24:26 2023 ] 	Training loss: 6.7849.  Training acc: 87.89%.
[ Wed Jun 28 16:24:26 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:24:26 2023 ] Training epoch: 147
[ Wed Jun 28 16:24:33 2023 ] 	Training loss: 6.5973.  Training acc: 89.71%.
[ Wed Jun 28 16:24:33 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:24:34 2023 ] Training epoch: 148
[ Wed Jun 28 16:24:40 2023 ] 	Training loss: 6.7205.  Training acc: 85.16%.
[ Wed Jun 28 16:24:40 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:24:41 2023 ] Training epoch: 149
[ Wed Jun 28 16:24:47 2023 ] 	Training loss: 6.6120.  Training acc: 90.36%.
[ Wed Jun 28 16:24:47 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:24:48 2023 ] Training epoch: 150
[ Wed Jun 28 16:24:54 2023 ] 	Training loss: 6.7637.  Training acc: 90.10%.
[ Wed Jun 28 16:24:54 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:37:26 2023 ] using warm up, epoch: 5
[ Wed Jun 28 16:37:26 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 16:37:26 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 16:37:26 2023 ] Start training Predictor
[ Wed Jun 28 16:37:26 2023 ] Training epoch: 1
[ Wed Jun 28 16:37:31 2023 ] 	Training loss: 105.4156.  Training acc: 33.64%.
[ Wed Jun 28 16:37:31 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 16:37:31 2023 ] Eval epoch: 1
[ Wed Jun 28 16:37:32 2023 ] 	Mean test loss of 625 batches: 7774.596777.
[ Wed Jun 28 16:37:32 2023 ] 	Top1: 29.82%
[ Wed Jun 28 16:37:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:37:33 2023 ] Training epoch: 2
[ Wed Jun 28 16:37:35 2023 ] 	Training loss: 10.0824.  Training acc: 34.65%.
[ Wed Jun 28 16:37:35 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 16:37:35 2023 ] Eval epoch: 2
[ Wed Jun 28 16:37:36 2023 ] 	Mean test loss of 625 batches: 3.046652.
[ Wed Jun 28 16:37:36 2023 ] 	Top1: 31.58%
[ Wed Jun 28 16:37:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:37:36 2023 ] Training epoch: 3
[ Wed Jun 28 16:37:39 2023 ] 	Training loss: 7.2869.  Training acc: 36.03%.
[ Wed Jun 28 16:37:39 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:37:39 2023 ] Eval epoch: 3
[ Wed Jun 28 16:37:40 2023 ] 	Mean test loss of 625 batches: 1.571326.
[ Wed Jun 28 16:37:40 2023 ] 	Top1: 31.58%
[ Wed Jun 28 16:37:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:37:40 2023 ] Training epoch: 4
[ Wed Jun 28 16:37:42 2023 ] 	Training loss: 5.3409.  Training acc: 42.83%.
[ Wed Jun 28 16:37:42 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:37:42 2023 ] Eval epoch: 4
[ Wed Jun 28 16:37:43 2023 ] 	Mean test loss of 625 batches: 4.572283.
[ Wed Jun 28 16:37:43 2023 ] 	Top1: 40.35%
[ Wed Jun 28 16:37:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:37:43 2023 ] Training epoch: 5
[ Wed Jun 28 16:37:46 2023 ] 	Training loss: 3.3363.  Training acc: 60.11%.
[ Wed Jun 28 16:37:46 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:37:46 2023 ] Eval epoch: 5
[ Wed Jun 28 16:37:47 2023 ] 	Mean test loss of 625 batches: 2.185562.
[ Wed Jun 28 16:37:47 2023 ] 	Top1: 75.44%
[ Wed Jun 28 16:37:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:37:47 2023 ] Training epoch: 6
[ Wed Jun 28 16:37:50 2023 ] 	Training loss: 1.7249.  Training acc: 71.88%.
[ Wed Jun 28 16:37:50 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:37:50 2023 ] Eval epoch: 6
[ Wed Jun 28 16:37:50 2023 ] 	Mean test loss of 625 batches: 1.101761.
[ Wed Jun 28 16:37:50 2023 ] 	Top1: 91.23%
[ Wed Jun 28 16:37:50 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:37:50 2023 ] Training epoch: 7
[ Wed Jun 28 16:37:53 2023 ] 	Training loss: 1.0555.  Training acc: 83.18%.
[ Wed Jun 28 16:37:53 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:37:53 2023 ] Eval epoch: 7
[ Wed Jun 28 16:37:54 2023 ] 	Mean test loss of 625 batches: 0.444554.
[ Wed Jun 28 16:37:54 2023 ] 	Top1: 96.49%
[ Wed Jun 28 16:37:54 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:37:54 2023 ] Training epoch: 8
[ Wed Jun 28 16:37:57 2023 ] 	Training loss: 0.9030.  Training acc: 85.48%.
[ Wed Jun 28 16:37:57 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:37:57 2023 ] Eval epoch: 8
[ Wed Jun 28 16:37:57 2023 ] 	Mean test loss of 625 batches: 1.357772.
[ Wed Jun 28 16:37:57 2023 ] 	Top1: 71.93%
[ Wed Jun 28 16:37:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:37:57 2023 ] Training epoch: 9
[ Wed Jun 28 16:38:00 2023 ] 	Training loss: 2.4255.  Training acc: 80.70%.
[ Wed Jun 28 16:38:00 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:38:00 2023 ] Eval epoch: 9
[ Wed Jun 28 16:38:01 2023 ] 	Mean test loss of 625 batches: 1.418810.
[ Wed Jun 28 16:38:01 2023 ] 	Top1: 80.70%
[ Wed Jun 28 16:38:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:38:01 2023 ] Training epoch: 10
[ Wed Jun 28 16:38:04 2023 ] 	Training loss: 1.4753.  Training acc: 73.99%.
[ Wed Jun 28 16:38:04 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:38:04 2023 ] Eval epoch: 10
[ Wed Jun 28 16:38:04 2023 ] 	Mean test loss of 625 batches: 0.688071.
[ Wed Jun 28 16:38:04 2023 ] 	Top1: 91.23%
[ Wed Jun 28 16:38:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:38:04 2023 ] Training epoch: 11
[ Wed Jun 28 16:38:07 2023 ] 	Training loss: 0.8527.  Training acc: 85.39%.
[ Wed Jun 28 16:38:07 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:38:07 2023 ] Eval epoch: 11
[ Wed Jun 28 16:38:08 2023 ] 	Mean test loss of 625 batches: 0.526132.
[ Wed Jun 28 16:38:08 2023 ] 	Top1: 98.25%
[ Wed Jun 28 16:38:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:38:08 2023 ] Training epoch: 12
[ Wed Jun 28 16:38:11 2023 ] 	Training loss: 0.7220.  Training acc: 86.49%.
[ Wed Jun 28 16:38:11 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:38:11 2023 ] Eval epoch: 12
[ Wed Jun 28 16:38:12 2023 ] 	Mean test loss of 625 batches: 0.494396.
[ Wed Jun 28 16:38:12 2023 ] 	Top1: 98.25%
[ Wed Jun 28 16:38:12 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:38:12 2023 ] Training epoch: 13
[ Wed Jun 28 16:38:14 2023 ] 	Training loss: 0.6605.  Training acc: 88.33%.
[ Wed Jun 28 16:38:14 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 16:38:14 2023 ] Eval epoch: 13
[ Wed Jun 28 16:38:15 2023 ] 	Mean test loss of 625 batches: 0.510345.
[ Wed Jun 28 16:38:15 2023 ] 	Top1: 98.25%
[ Wed Jun 28 16:38:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:38:15 2023 ] Training epoch: 14
[ Wed Jun 28 16:38:18 2023 ] 	Training loss: 0.5921.  Training acc: 92.74%.
[ Wed Jun 28 16:38:18 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 16:38:18 2023 ] Eval epoch: 14
[ Wed Jun 28 16:38:19 2023 ] 	Mean test loss of 625 batches: 0.516590.
[ Wed Jun 28 16:38:19 2023 ] 	Top1: 98.25%
[ Wed Jun 28 16:38:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:38:19 2023 ] Training epoch: 15
[ Wed Jun 28 16:38:22 2023 ] 	Training loss: 0.5592.  Training acc: 92.92%.
[ Wed Jun 28 16:38:22 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:38:22 2023 ] Eval epoch: 15
[ Wed Jun 28 16:38:22 2023 ] 	Mean test loss of 625 batches: 0.469390.
[ Wed Jun 28 16:38:22 2023 ] 	Top1: 98.25%
[ Wed Jun 28 16:38:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:38:22 2023 ] Training epoch: 16
[ Wed Jun 28 16:38:25 2023 ] 	Training loss: 0.5278.  Training acc: 93.38%.
[ Wed Jun 28 16:38:25 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:38:25 2023 ] Eval epoch: 16
[ Wed Jun 28 16:38:26 2023 ] 	Mean test loss of 625 batches: 0.452799.
[ Wed Jun 28 16:38:26 2023 ] 	Top1: 98.25%
[ Wed Jun 28 16:38:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:38:26 2023 ] Training epoch: 17
[ Wed Jun 28 16:38:29 2023 ] 	Training loss: 0.5172.  Training acc: 93.38%.
[ Wed Jun 28 16:38:29 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:38:29 2023 ] Eval epoch: 17
[ Wed Jun 28 16:38:29 2023 ] 	Mean test loss of 625 batches: 0.452400.
[ Wed Jun 28 16:38:29 2023 ] 	Top1: 98.25%
[ Wed Jun 28 16:38:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:38:29 2023 ] Training epoch: 18
[ Wed Jun 28 16:38:32 2023 ] 	Training loss: 0.5090.  Training acc: 94.12%.
[ Wed Jun 28 16:38:32 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:38:32 2023 ] Eval epoch: 18
[ Wed Jun 28 16:38:33 2023 ] 	Mean test loss of 625 batches: 0.349456.
[ Wed Jun 28 16:38:33 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:38:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:38:33 2023 ] Training epoch: 19
[ Wed Jun 28 16:38:36 2023 ] 	Training loss: 0.4719.  Training acc: 95.59%.
[ Wed Jun 28 16:38:36 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:38:36 2023 ] Eval epoch: 19
[ Wed Jun 28 16:38:36 2023 ] 	Mean test loss of 625 batches: 0.341767.
[ Wed Jun 28 16:38:36 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:38:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:38:36 2023 ] Training epoch: 20
[ Wed Jun 28 16:38:39 2023 ] 	Training loss: 0.4326.  Training acc: 96.78%.
[ Wed Jun 28 16:38:39 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:38:39 2023 ] Eval epoch: 20
[ Wed Jun 28 16:38:40 2023 ] 	Mean test loss of 625 batches: 0.352222.
[ Wed Jun 28 16:38:40 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:38:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:38:40 2023 ] Training epoch: 21
[ Wed Jun 28 16:38:43 2023 ] 	Training loss: 0.4312.  Training acc: 97.70%.
[ Wed Jun 28 16:38:43 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:38:43 2023 ] Eval epoch: 21
[ Wed Jun 28 16:38:43 2023 ] 	Mean test loss of 625 batches: 0.352756.
[ Wed Jun 28 16:38:43 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:38:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:38:43 2023 ] Training epoch: 22
[ Wed Jun 28 16:38:46 2023 ] 	Training loss: 0.4260.  Training acc: 96.32%.
[ Wed Jun 28 16:38:46 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:38:46 2023 ] Eval epoch: 22
[ Wed Jun 28 16:38:47 2023 ] 	Mean test loss of 625 batches: 0.352296.
[ Wed Jun 28 16:38:47 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:38:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:38:47 2023 ] Training epoch: 23
[ Wed Jun 28 16:38:50 2023 ] 	Training loss: 0.4363.  Training acc: 96.23%.
[ Wed Jun 28 16:38:50 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 16:38:50 2023 ] Eval epoch: 23
[ Wed Jun 28 16:38:51 2023 ] 	Mean test loss of 625 batches: 0.356383.
[ Wed Jun 28 16:38:51 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:38:51 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:38:51 2023 ] Training epoch: 24
[ Wed Jun 28 16:38:53 2023 ] 	Training loss: 0.4092.  Training acc: 97.79%.
[ Wed Jun 28 16:38:53 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:38:53 2023 ] Eval epoch: 24
[ Wed Jun 28 16:38:54 2023 ] 	Mean test loss of 625 batches: 0.349286.
[ Wed Jun 28 16:38:54 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:38:54 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:38:54 2023 ] Training epoch: 25
[ Wed Jun 28 16:38:57 2023 ] 	Training loss: 0.4179.  Training acc: 96.42%.
[ Wed Jun 28 16:38:57 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:38:57 2023 ] Eval epoch: 25
[ Wed Jun 28 16:38:58 2023 ] 	Mean test loss of 625 batches: 0.357904.
[ Wed Jun 28 16:38:58 2023 ] 	Top1: 98.25%
[ Wed Jun 28 16:38:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:38:58 2023 ] Training epoch: 26
[ Wed Jun 28 16:39:01 2023 ] 	Training loss: 0.4263.  Training acc: 96.69%.
[ Wed Jun 28 16:39:01 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 16:39:01 2023 ] Eval epoch: 26
[ Wed Jun 28 16:39:01 2023 ] 	Mean test loss of 625 batches: 0.341716.
[ Wed Jun 28 16:39:01 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:39:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:39:01 2023 ] Training epoch: 27
[ Wed Jun 28 16:39:04 2023 ] 	Training loss: 0.4156.  Training acc: 96.51%.
[ Wed Jun 28 16:39:04 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:39:04 2023 ] Eval epoch: 27
[ Wed Jun 28 16:39:05 2023 ] 	Mean test loss of 625 batches: 0.350601.
[ Wed Jun 28 16:39:05 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:39:05 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:39:05 2023 ] Training epoch: 28
[ Wed Jun 28 16:39:08 2023 ] 	Training loss: 0.4085.  Training acc: 97.98%.
[ Wed Jun 28 16:39:08 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:39:08 2023 ] Eval epoch: 28
[ Wed Jun 28 16:39:08 2023 ] 	Mean test loss of 625 batches: 0.351381.
[ Wed Jun 28 16:39:08 2023 ] 	Top1: 98.25%
[ Wed Jun 28 16:39:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:39:08 2023 ] Training epoch: 29
[ Wed Jun 28 16:39:11 2023 ] 	Training loss: 0.4190.  Training acc: 96.42%.
[ Wed Jun 28 16:39:11 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 16:39:11 2023 ] Eval epoch: 29
[ Wed Jun 28 16:39:12 2023 ] 	Mean test loss of 625 batches: 0.337183.
[ Wed Jun 28 16:39:12 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:39:12 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:39:12 2023 ] Training epoch: 30
[ Wed Jun 28 16:39:15 2023 ] 	Training loss: 0.4216.  Training acc: 96.69%.
[ Wed Jun 28 16:39:15 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 16:39:15 2023 ] Eval epoch: 30
[ Wed Jun 28 16:39:15 2023 ] 	Mean test loss of 625 batches: 0.344062.
[ Wed Jun 28 16:39:15 2023 ] 	Top1: 100.00%
[ Wed Jun 28 16:39:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 16:39:16 2023 ] Best accuracy: 1.0
[ Wed Jun 28 16:39:16 2023 ] Epoch number: 18
[ Wed Jun 28 16:39:16 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 16:39:16 2023 ] Weight decay: 0.0005
[ Wed Jun 28 16:39:16 2023 ] Base LR: 0.1
[ Wed Jun 28 16:39:16 2023 ] Batch Size: 64
[ Wed Jun 28 16:39:16 2023 ] Test Batch Size: 64
[ Wed Jun 28 16:39:16 2023 ] seed: 1
[ Wed Jun 28 16:39:16 2023 ] Start training Corrector
[ Wed Jun 28 16:39:17 2023 ] Training epoch: 1
[ Wed Jun 28 16:39:25 2023 ] 	Training loss: 17.7599.  Training acc: 47.40%.
[ Wed Jun 28 16:39:25 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 16:39:26 2023 ] Training epoch: 2
[ Wed Jun 28 16:39:33 2023 ] 	Training loss: 11.8834.  Training acc: 60.16%.
[ Wed Jun 28 16:39:33 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:39:33 2023 ] Training epoch: 3
[ Wed Jun 28 16:39:40 2023 ] 	Training loss: 11.1086.  Training acc: 76.69%.
[ Wed Jun 28 16:39:40 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:39:40 2023 ] Training epoch: 4
[ Wed Jun 28 16:39:47 2023 ] 	Training loss: 10.7870.  Training acc: 48.31%.
[ Wed Jun 28 16:39:47 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:39:47 2023 ] Training epoch: 5
[ Wed Jun 28 16:39:54 2023 ] 	Training loss: 11.0781.  Training acc: 33.07%.
[ Wed Jun 28 16:39:54 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:39:54 2023 ] Training epoch: 6
[ Wed Jun 28 16:40:01 2023 ] 	Training loss: 11.1250.  Training acc: 33.98%.
[ Wed Jun 28 16:40:01 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:40:01 2023 ] Training epoch: 7
[ Wed Jun 28 16:40:08 2023 ] 	Training loss: 13.4778.  Training acc: 33.20%.
[ Wed Jun 28 16:40:08 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:40:09 2023 ] Training epoch: 8
[ Wed Jun 28 16:40:15 2023 ] 	Training loss: 10.6683.  Training acc: 33.07%.
[ Wed Jun 28 16:40:15 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:40:16 2023 ] Training epoch: 9
[ Wed Jun 28 16:40:22 2023 ] 	Training loss: 9.1087.  Training acc: 33.98%.
[ Wed Jun 28 16:40:22 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:40:23 2023 ] Training epoch: 10
[ Wed Jun 28 16:40:29 2023 ] 	Training loss: 11.0272.  Training acc: 29.69%.
[ Wed Jun 28 16:40:29 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:40:30 2023 ] Training epoch: 11
[ Wed Jun 28 16:40:36 2023 ] 	Training loss: 10.0732.  Training acc: 34.77%.
[ Wed Jun 28 16:40:36 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:40:37 2023 ] Training epoch: 12
[ Wed Jun 28 16:40:43 2023 ] 	Training loss: 9.0573.  Training acc: 34.90%.
[ Wed Jun 28 16:40:43 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:40:44 2023 ] Training epoch: 13
[ Wed Jun 28 16:40:50 2023 ] 	Training loss: 8.4093.  Training acc: 40.49%.
[ Wed Jun 28 16:40:50 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:40:51 2023 ] Training epoch: 14
[ Wed Jun 28 16:40:57 2023 ] 	Training loss: 8.1758.  Training acc: 32.81%.
[ Wed Jun 28 16:40:57 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:40:58 2023 ] Training epoch: 15
[ Wed Jun 28 16:41:05 2023 ] 	Training loss: 8.2743.  Training acc: 33.46%.
[ Wed Jun 28 16:41:05 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:41:05 2023 ] Training epoch: 16
[ Wed Jun 28 16:41:12 2023 ] 	Training loss: 8.1670.  Training acc: 33.20%.
[ Wed Jun 28 16:41:12 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:41:12 2023 ] Training epoch: 17
[ Wed Jun 28 16:41:19 2023 ] 	Training loss: 7.9980.  Training acc: 40.89%.
[ Wed Jun 28 16:41:19 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:41:19 2023 ] Training epoch: 18
[ Wed Jun 28 16:41:26 2023 ] 	Training loss: 7.5812.  Training acc: 32.03%.
[ Wed Jun 28 16:41:26 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:41:26 2023 ] Training epoch: 19
[ Wed Jun 28 16:41:33 2023 ] 	Training loss: 7.5330.  Training acc: 33.33%.
[ Wed Jun 28 16:41:33 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:41:33 2023 ] Training epoch: 20
[ Wed Jun 28 16:41:40 2023 ] 	Training loss: 7.4006.  Training acc: 33.59%.
[ Wed Jun 28 16:41:40 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:41:41 2023 ] Training epoch: 21
[ Wed Jun 28 16:41:47 2023 ] 	Training loss: 7.4141.  Training acc: 34.24%.
[ Wed Jun 28 16:41:47 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:41:48 2023 ] Training epoch: 22
[ Wed Jun 28 16:41:54 2023 ] 	Training loss: 7.3623.  Training acc: 33.46%.
[ Wed Jun 28 16:41:54 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:41:55 2023 ] Training epoch: 23
[ Wed Jun 28 16:42:01 2023 ] 	Training loss: 7.2911.  Training acc: 33.20%.
[ Wed Jun 28 16:42:01 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:42:02 2023 ] Training epoch: 24
[ Wed Jun 28 16:42:08 2023 ] 	Training loss: 7.3509.  Training acc: 33.20%.
[ Wed Jun 28 16:42:08 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:42:09 2023 ] Training epoch: 25
[ Wed Jun 28 16:42:15 2023 ] 	Training loss: 7.4262.  Training acc: 33.07%.
[ Wed Jun 28 16:42:15 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:42:16 2023 ] Training epoch: 26
[ Wed Jun 28 16:42:23 2023 ] 	Training loss: 7.2555.  Training acc: 33.33%.
[ Wed Jun 28 16:42:23 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:42:23 2023 ] Training epoch: 27
[ Wed Jun 28 16:42:30 2023 ] 	Training loss: 7.2173.  Training acc: 33.07%.
[ Wed Jun 28 16:42:30 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:42:30 2023 ] Training epoch: 28
[ Wed Jun 28 16:42:37 2023 ] 	Training loss: 7.3429.  Training acc: 33.33%.
[ Wed Jun 28 16:42:37 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:42:37 2023 ] Training epoch: 29
[ Wed Jun 28 16:42:44 2023 ] 	Training loss: 7.2276.  Training acc: 35.29%.
[ Wed Jun 28 16:42:44 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:42:44 2023 ] Training epoch: 30
[ Wed Jun 28 16:42:51 2023 ] 	Training loss: 7.3382.  Training acc: 40.36%.
[ Wed Jun 28 16:42:51 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:42:51 2023 ] Training epoch: 31
[ Wed Jun 28 16:42:58 2023 ] 	Training loss: 7.3195.  Training acc: 43.62%.
[ Wed Jun 28 16:42:58 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:42:58 2023 ] Training epoch: 32
[ Wed Jun 28 16:43:05 2023 ] 	Training loss: 7.1142.  Training acc: 45.96%.
[ Wed Jun 28 16:43:05 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:43:06 2023 ] Training epoch: 33
[ Wed Jun 28 16:43:12 2023 ] 	Training loss: 7.2354.  Training acc: 45.18%.
[ Wed Jun 28 16:43:12 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:43:13 2023 ] Training epoch: 34
[ Wed Jun 28 16:43:19 2023 ] 	Training loss: 7.1340.  Training acc: 48.96%.
[ Wed Jun 28 16:43:19 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:43:20 2023 ] Training epoch: 35
[ Wed Jun 28 16:43:26 2023 ] 	Training loss: 7.2734.  Training acc: 44.92%.
[ Wed Jun 28 16:43:26 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:43:27 2023 ] Training epoch: 36
[ Wed Jun 28 16:43:33 2023 ] 	Training loss: 7.2468.  Training acc: 47.14%.
[ Wed Jun 28 16:43:33 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:43:34 2023 ] Training epoch: 37
[ Wed Jun 28 16:43:41 2023 ] 	Training loss: 7.3040.  Training acc: 48.96%.
[ Wed Jun 28 16:43:41 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:43:41 2023 ] Training epoch: 38
[ Wed Jun 28 16:43:48 2023 ] 	Training loss: 7.2119.  Training acc: 52.08%.
[ Wed Jun 28 16:43:48 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:43:48 2023 ] Training epoch: 39
[ Wed Jun 28 16:43:55 2023 ] 	Training loss: 7.0987.  Training acc: 48.70%.
[ Wed Jun 28 16:43:55 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:43:55 2023 ] Training epoch: 40
[ Wed Jun 28 16:44:02 2023 ] 	Training loss: 7.2087.  Training acc: 51.04%.
[ Wed Jun 28 16:44:02 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:44:03 2023 ] Training epoch: 41
[ Wed Jun 28 16:44:09 2023 ] 	Training loss: 7.0588.  Training acc: 51.43%.
[ Wed Jun 28 16:44:09 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:44:10 2023 ] Training epoch: 42
[ Wed Jun 28 16:44:16 2023 ] 	Training loss: 7.0953.  Training acc: 52.60%.
[ Wed Jun 28 16:44:16 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:44:17 2023 ] Training epoch: 43
[ Wed Jun 28 16:44:23 2023 ] 	Training loss: 7.2135.  Training acc: 54.04%.
[ Wed Jun 28 16:44:23 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:44:24 2023 ] Training epoch: 44
[ Wed Jun 28 16:44:31 2023 ] 	Training loss: 6.9503.  Training acc: 53.12%.
[ Wed Jun 28 16:44:31 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:44:31 2023 ] Training epoch: 45
[ Wed Jun 28 16:44:38 2023 ] 	Training loss: 7.0554.  Training acc: 52.08%.
[ Wed Jun 28 16:44:38 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:44:38 2023 ] Training epoch: 46
[ Wed Jun 28 16:44:45 2023 ] 	Training loss: 6.9256.  Training acc: 55.08%.
[ Wed Jun 28 16:44:45 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:44:46 2023 ] Training epoch: 47
[ Wed Jun 28 16:44:52 2023 ] 	Training loss: 7.1873.  Training acc: 52.73%.
[ Wed Jun 28 16:44:52 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:44:53 2023 ] Training epoch: 48
[ Wed Jun 28 16:44:59 2023 ] 	Training loss: 7.1843.  Training acc: 55.47%.
[ Wed Jun 28 16:44:59 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:45:00 2023 ] Training epoch: 49
[ Wed Jun 28 16:45:06 2023 ] 	Training loss: 7.2227.  Training acc: 54.95%.
[ Wed Jun 28 16:45:06 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:45:07 2023 ] Training epoch: 50
[ Wed Jun 28 16:45:14 2023 ] 	Training loss: 7.0090.  Training acc: 57.42%.
[ Wed Jun 28 16:45:14 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:45:14 2023 ] Training epoch: 51
[ Wed Jun 28 16:45:21 2023 ] 	Training loss: 7.0768.  Training acc: 56.12%.
[ Wed Jun 28 16:45:21 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:45:21 2023 ] Training epoch: 52
[ Wed Jun 28 16:45:28 2023 ] 	Training loss: 6.9806.  Training acc: 55.34%.
[ Wed Jun 28 16:45:28 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:45:28 2023 ] Training epoch: 53
[ Wed Jun 28 16:45:35 2023 ] 	Training loss: 6.8812.  Training acc: 61.98%.
[ Wed Jun 28 16:45:35 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:45:36 2023 ] Training epoch: 54
[ Wed Jun 28 16:45:42 2023 ] 	Training loss: 6.9714.  Training acc: 58.46%.
[ Wed Jun 28 16:45:42 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:45:43 2023 ] Training epoch: 55
[ Wed Jun 28 16:45:49 2023 ] 	Training loss: 7.0466.  Training acc: 63.02%.
[ Wed Jun 28 16:45:49 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:45:50 2023 ] Training epoch: 56
[ Wed Jun 28 16:45:56 2023 ] 	Training loss: 7.0850.  Training acc: 71.09%.
[ Wed Jun 28 16:45:56 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:45:57 2023 ] Training epoch: 57
[ Wed Jun 28 16:46:04 2023 ] 	Training loss: 6.9994.  Training acc: 65.36%.
[ Wed Jun 28 16:46:04 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:46:04 2023 ] Training epoch: 58
[ Wed Jun 28 16:46:11 2023 ] 	Training loss: 7.1031.  Training acc: 75.39%.
[ Wed Jun 28 16:46:11 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:46:11 2023 ] Training epoch: 59
[ Wed Jun 28 16:46:18 2023 ] 	Training loss: 6.9426.  Training acc: 76.82%.
[ Wed Jun 28 16:46:18 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:46:19 2023 ] Training epoch: 60
[ Wed Jun 28 16:46:25 2023 ] 	Training loss: 7.0489.  Training acc: 80.73%.
[ Wed Jun 28 16:46:25 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:46:26 2023 ] Training epoch: 61
[ Wed Jun 28 16:46:32 2023 ] 	Training loss: 6.9563.  Training acc: 80.47%.
[ Wed Jun 28 16:46:32 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:46:33 2023 ] Training epoch: 62
[ Wed Jun 28 16:46:39 2023 ] 	Training loss: 6.8399.  Training acc: 81.12%.
[ Wed Jun 28 16:46:39 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:46:40 2023 ] Training epoch: 63
[ Wed Jun 28 16:46:47 2023 ] 	Training loss: 7.1143.  Training acc: 90.23%.
[ Wed Jun 28 16:46:47 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:46:47 2023 ] Training epoch: 64
[ Wed Jun 28 16:46:54 2023 ] 	Training loss: 7.0092.  Training acc: 87.50%.
[ Wed Jun 28 16:46:54 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:46:54 2023 ] Training epoch: 65
[ Wed Jun 28 16:47:01 2023 ] 	Training loss: 6.9028.  Training acc: 89.58%.
[ Wed Jun 28 16:47:01 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:47:02 2023 ] Training epoch: 66
[ Wed Jun 28 16:47:08 2023 ] 	Training loss: 6.9234.  Training acc: 91.93%.
[ Wed Jun 28 16:47:08 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:47:09 2023 ] Training epoch: 67
[ Wed Jun 28 16:47:15 2023 ] 	Training loss: 7.0986.  Training acc: 93.23%.
[ Wed Jun 28 16:47:15 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:47:16 2023 ] Training epoch: 68
[ Wed Jun 28 16:47:22 2023 ] 	Training loss: 6.9432.  Training acc: 94.79%.
[ Wed Jun 28 16:47:22 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:47:23 2023 ] Training epoch: 69
[ Wed Jun 28 16:47:29 2023 ] 	Training loss: 7.1188.  Training acc: 93.36%.
[ Wed Jun 28 16:47:29 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:47:30 2023 ] Training epoch: 70
[ Wed Jun 28 16:47:37 2023 ] 	Training loss: 6.9755.  Training acc: 92.71%.
[ Wed Jun 28 16:47:37 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:47:37 2023 ] Training epoch: 71
[ Wed Jun 28 16:47:44 2023 ] 	Training loss: 6.9853.  Training acc: 92.58%.
[ Wed Jun 28 16:47:44 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:47:44 2023 ] Training epoch: 72
[ Wed Jun 28 16:47:51 2023 ] 	Training loss: 6.9751.  Training acc: 91.67%.
[ Wed Jun 28 16:47:51 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:47:51 2023 ] Training epoch: 73
[ Wed Jun 28 16:47:58 2023 ] 	Training loss: 6.9579.  Training acc: 92.06%.
[ Wed Jun 28 16:47:58 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:47:59 2023 ] Training epoch: 74
[ Wed Jun 28 16:48:05 2023 ] 	Training loss: 7.0624.  Training acc: 94.27%.
[ Wed Jun 28 16:48:05 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:48:06 2023 ] Training epoch: 75
[ Wed Jun 28 16:48:12 2023 ] 	Training loss: 7.0498.  Training acc: 92.45%.
[ Wed Jun 28 16:48:12 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:48:13 2023 ] Training epoch: 76
[ Wed Jun 28 16:48:19 2023 ] 	Training loss: 6.8653.  Training acc: 94.14%.
[ Wed Jun 28 16:48:19 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:48:20 2023 ] Training epoch: 77
[ Wed Jun 28 16:48:27 2023 ] 	Training loss: 6.8919.  Training acc: 94.40%.
[ Wed Jun 28 16:48:27 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:48:27 2023 ] Training epoch: 78
[ Wed Jun 28 16:48:34 2023 ] 	Training loss: 6.9743.  Training acc: 92.32%.
[ Wed Jun 28 16:48:34 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:48:35 2023 ] Training epoch: 79
[ Wed Jun 28 16:48:41 2023 ] 	Training loss: 6.8461.  Training acc: 94.01%.
[ Wed Jun 28 16:48:41 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:48:42 2023 ] Training epoch: 80
[ Wed Jun 28 16:48:48 2023 ] 	Training loss: 6.9632.  Training acc: 91.67%.
[ Wed Jun 28 16:48:48 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:48:49 2023 ] Training epoch: 81
[ Wed Jun 28 16:48:56 2023 ] 	Training loss: 6.8465.  Training acc: 93.62%.
[ Wed Jun 28 16:48:56 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:48:56 2023 ] Training epoch: 82
[ Wed Jun 28 16:49:03 2023 ] 	Training loss: 7.0290.  Training acc: 92.06%.
[ Wed Jun 28 16:49:03 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:49:03 2023 ] Training epoch: 83
[ Wed Jun 28 16:49:10 2023 ] 	Training loss: 6.8966.  Training acc: 92.97%.
[ Wed Jun 28 16:49:10 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:49:11 2023 ] Training epoch: 84
[ Wed Jun 28 16:49:17 2023 ] 	Training loss: 6.9775.  Training acc: 94.01%.
[ Wed Jun 28 16:49:17 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:49:18 2023 ] Training epoch: 85
[ Wed Jun 28 16:49:24 2023 ] 	Training loss: 6.9235.  Training acc: 93.88%.
[ Wed Jun 28 16:49:24 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:49:25 2023 ] Training epoch: 86
[ Wed Jun 28 16:49:31 2023 ] 	Training loss: 6.7834.  Training acc: 95.96%.
[ Wed Jun 28 16:49:31 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:49:32 2023 ] Training epoch: 87
[ Wed Jun 28 16:49:39 2023 ] 	Training loss: 6.8978.  Training acc: 93.10%.
[ Wed Jun 28 16:49:39 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:49:39 2023 ] Training epoch: 88
[ Wed Jun 28 16:49:46 2023 ] 	Training loss: 7.0585.  Training acc: 94.66%.
[ Wed Jun 28 16:49:46 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:49:46 2023 ] Training epoch: 89
[ Wed Jun 28 16:49:53 2023 ] 	Training loss: 6.9763.  Training acc: 92.84%.
[ Wed Jun 28 16:49:53 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:49:54 2023 ] Training epoch: 90
[ Wed Jun 28 16:50:00 2023 ] 	Training loss: 6.9851.  Training acc: 94.14%.
[ Wed Jun 28 16:50:00 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:50:01 2023 ] Training epoch: 91
[ Wed Jun 28 16:50:07 2023 ] 	Training loss: 6.9715.  Training acc: 93.49%.
[ Wed Jun 28 16:50:07 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:50:08 2023 ] Training epoch: 92
[ Wed Jun 28 16:50:15 2023 ] 	Training loss: 6.9229.  Training acc: 96.48%.
[ Wed Jun 28 16:50:15 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:50:15 2023 ] Training epoch: 93
[ Wed Jun 28 16:50:22 2023 ] 	Training loss: 6.8589.  Training acc: 90.89%.
[ Wed Jun 28 16:50:22 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:50:22 2023 ] Training epoch: 94
[ Wed Jun 28 16:50:29 2023 ] 	Training loss: 6.7267.  Training acc: 93.49%.
[ Wed Jun 28 16:50:29 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:50:29 2023 ] Training epoch: 95
[ Wed Jun 28 16:50:36 2023 ] 	Training loss: 6.8765.  Training acc: 96.48%.
[ Wed Jun 28 16:50:36 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:50:37 2023 ] Training epoch: 96
[ Wed Jun 28 16:50:43 2023 ] 	Training loss: 6.9233.  Training acc: 94.01%.
[ Wed Jun 28 16:50:43 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:50:44 2023 ] Training epoch: 97
[ Wed Jun 28 16:50:50 2023 ] 	Training loss: 6.9320.  Training acc: 92.71%.
[ Wed Jun 28 16:50:50 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:50:51 2023 ] Training epoch: 98
[ Wed Jun 28 16:50:57 2023 ] 	Training loss: 6.7806.  Training acc: 93.62%.
[ Wed Jun 28 16:50:57 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:50:58 2023 ] Training epoch: 99
[ Wed Jun 28 16:51:05 2023 ] 	Training loss: 6.8631.  Training acc: 95.44%.
[ Wed Jun 28 16:51:05 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:51:05 2023 ] Training epoch: 100
[ Wed Jun 28 16:51:12 2023 ] 	Training loss: 6.9704.  Training acc: 92.84%.
[ Wed Jun 28 16:51:12 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:51:12 2023 ] Training epoch: 101
[ Wed Jun 28 16:51:19 2023 ] 	Training loss: 6.9116.  Training acc: 94.79%.
[ Wed Jun 28 16:51:19 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:51:20 2023 ] Training epoch: 102
[ Wed Jun 28 16:51:26 2023 ] 	Training loss: 6.8497.  Training acc: 95.44%.
[ Wed Jun 28 16:51:26 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:51:27 2023 ] Training epoch: 103
[ Wed Jun 28 16:51:33 2023 ] 	Training loss: 6.9173.  Training acc: 96.09%.
[ Wed Jun 28 16:51:33 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:51:34 2023 ] Training epoch: 104
[ Wed Jun 28 16:51:40 2023 ] 	Training loss: 6.9942.  Training acc: 94.53%.
[ Wed Jun 28 16:51:40 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:51:41 2023 ] Training epoch: 105
[ Wed Jun 28 16:51:48 2023 ] 	Training loss: 6.8759.  Training acc: 93.88%.
[ Wed Jun 28 16:51:48 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:51:48 2023 ] Training epoch: 106
[ Wed Jun 28 16:51:55 2023 ] 	Training loss: 6.9033.  Training acc: 95.57%.
[ Wed Jun 28 16:51:55 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:51:55 2023 ] Training epoch: 107
[ Wed Jun 28 16:52:02 2023 ] 	Training loss: 6.8679.  Training acc: 94.01%.
[ Wed Jun 28 16:52:02 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:52:03 2023 ] Training epoch: 108
[ Wed Jun 28 16:52:09 2023 ] 	Training loss: 6.9171.  Training acc: 93.36%.
[ Wed Jun 28 16:52:09 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:52:10 2023 ] Training epoch: 109
[ Wed Jun 28 16:52:16 2023 ] 	Training loss: 6.9891.  Training acc: 93.23%.
[ Wed Jun 28 16:52:16 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:52:17 2023 ] Training epoch: 110
[ Wed Jun 28 16:52:24 2023 ] 	Training loss: 7.0179.  Training acc: 93.23%.
[ Wed Jun 28 16:52:24 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:52:24 2023 ] Training epoch: 111
[ Wed Jun 28 16:52:31 2023 ] 	Training loss: 6.7251.  Training acc: 95.18%.
[ Wed Jun 28 16:52:31 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:52:31 2023 ] Training epoch: 112
[ Wed Jun 28 16:52:38 2023 ] 	Training loss: 6.8948.  Training acc: 94.01%.
[ Wed Jun 28 16:52:38 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:52:39 2023 ] Training epoch: 113
[ Wed Jun 28 16:52:45 2023 ] 	Training loss: 6.8958.  Training acc: 95.83%.
[ Wed Jun 28 16:52:45 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:52:46 2023 ] Training epoch: 114
[ Wed Jun 28 16:52:52 2023 ] 	Training loss: 6.7210.  Training acc: 95.83%.
[ Wed Jun 28 16:52:52 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:52:53 2023 ] Training epoch: 115
[ Wed Jun 28 16:52:59 2023 ] 	Training loss: 6.8873.  Training acc: 94.66%.
[ Wed Jun 28 16:52:59 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:53:00 2023 ] Training epoch: 116
[ Wed Jun 28 16:53:07 2023 ] 	Training loss: 6.8764.  Training acc: 94.14%.
[ Wed Jun 28 16:53:07 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:53:07 2023 ] Training epoch: 117
[ Wed Jun 28 16:53:14 2023 ] 	Training loss: 6.8571.  Training acc: 95.18%.
[ Wed Jun 28 16:53:14 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:53:14 2023 ] Training epoch: 118
[ Wed Jun 28 16:53:21 2023 ] 	Training loss: 6.7490.  Training acc: 95.44%.
[ Wed Jun 28 16:53:21 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:53:21 2023 ] Training epoch: 119
[ Wed Jun 28 16:53:26 2023 ] 	Training loss: 6.9106.  Training acc: 75.26%.
[ Wed Jun 28 16:53:26 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 16:53:27 2023 ] Training epoch: 120
[ Wed Jun 28 16:53:32 2023 ] 	Training loss: 6.9731.  Training acc: 38.80%.
[ Wed Jun 28 16:53:32 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 16:53:32 2023 ] Training epoch: 121
[ Wed Jun 28 16:53:37 2023 ] 	Training loss: 6.9660.  Training acc: 47.27%.
[ Wed Jun 28 16:53:37 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 16:53:38 2023 ] Training epoch: 122
[ Wed Jun 28 16:53:43 2023 ] 	Training loss: 6.9193.  Training acc: 83.33%.
[ Wed Jun 28 16:53:43 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 16:53:44 2023 ] Training epoch: 123
[ Wed Jun 28 16:53:49 2023 ] 	Training loss: 6.8762.  Training acc: 93.23%.
[ Wed Jun 28 16:53:49 2023 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Jun 28 16:53:49 2023 ] Training epoch: 124
[ Wed Jun 28 16:53:55 2023 ] 	Training loss: 6.8237.  Training acc: 93.23%.
[ Wed Jun 28 16:53:55 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 16:53:56 2023 ] Training epoch: 125
[ Wed Jun 28 16:54:02 2023 ] 	Training loss: 6.7433.  Training acc: 95.44%.
[ Wed Jun 28 16:54:02 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:54:03 2023 ] Training epoch: 126
[ Wed Jun 28 16:54:09 2023 ] 	Training loss: 6.9534.  Training acc: 94.92%.
[ Wed Jun 28 16:54:09 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:54:10 2023 ] Training epoch: 127
[ Wed Jun 28 16:54:16 2023 ] 	Training loss: 6.7454.  Training acc: 93.49%.
[ Wed Jun 28 16:54:16 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:54:17 2023 ] Training epoch: 128
[ Wed Jun 28 16:54:24 2023 ] 	Training loss: 6.6837.  Training acc: 96.22%.
[ Wed Jun 28 16:54:24 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:54:24 2023 ] Training epoch: 129
[ Wed Jun 28 16:54:31 2023 ] 	Training loss: 6.7551.  Training acc: 94.79%.
[ Wed Jun 28 16:54:31 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:54:32 2023 ] Training epoch: 130
[ Wed Jun 28 16:54:38 2023 ] 	Training loss: 6.9016.  Training acc: 94.79%.
[ Wed Jun 28 16:54:38 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:54:39 2023 ] Training epoch: 131
[ Wed Jun 28 16:54:45 2023 ] 	Training loss: 6.8406.  Training acc: 96.74%.
[ Wed Jun 28 16:54:45 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:54:46 2023 ] Training epoch: 132
[ Wed Jun 28 16:54:53 2023 ] 	Training loss: 6.7572.  Training acc: 95.70%.
[ Wed Jun 28 16:54:53 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:54:53 2023 ] Training epoch: 133
[ Wed Jun 28 16:55:00 2023 ] 	Training loss: 6.7946.  Training acc: 96.22%.
[ Wed Jun 28 16:55:00 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:55:00 2023 ] Training epoch: 134
[ Wed Jun 28 16:55:07 2023 ] 	Training loss: 6.8873.  Training acc: 94.27%.
[ Wed Jun 28 16:55:07 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:55:07 2023 ] Training epoch: 135
[ Wed Jun 28 16:55:14 2023 ] 	Training loss: 6.8928.  Training acc: 93.49%.
[ Wed Jun 28 16:55:14 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:55:15 2023 ] Training epoch: 136
[ Wed Jun 28 16:55:21 2023 ] 	Training loss: 6.8817.  Training acc: 94.79%.
[ Wed Jun 28 16:55:21 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:55:22 2023 ] Training epoch: 137
[ Wed Jun 28 16:55:28 2023 ] 	Training loss: 6.8859.  Training acc: 95.44%.
[ Wed Jun 28 16:55:28 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:55:29 2023 ] Training epoch: 138
[ Wed Jun 28 16:55:36 2023 ] 	Training loss: 6.8408.  Training acc: 95.70%.
[ Wed Jun 28 16:55:36 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:55:36 2023 ] Training epoch: 139
[ Wed Jun 28 16:55:43 2023 ] 	Training loss: 6.8028.  Training acc: 94.79%.
[ Wed Jun 28 16:55:43 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:55:44 2023 ] Training epoch: 140
[ Wed Jun 28 16:55:50 2023 ] 	Training loss: 6.9072.  Training acc: 95.70%.
[ Wed Jun 28 16:55:50 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:55:51 2023 ] Training epoch: 141
[ Wed Jun 28 16:55:57 2023 ] 	Training loss: 6.6607.  Training acc: 95.96%.
[ Wed Jun 28 16:55:57 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 16:55:58 2023 ] Training epoch: 142
[ Wed Jun 28 16:56:04 2023 ] 	Training loss: 6.7467.  Training acc: 97.01%.
[ Wed Jun 28 16:56:04 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:56:05 2023 ] Training epoch: 143
[ Wed Jun 28 16:56:12 2023 ] 	Training loss: 6.7503.  Training acc: 94.79%.
[ Wed Jun 28 16:56:12 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:56:12 2023 ] Training epoch: 144
[ Wed Jun 28 16:56:19 2023 ] 	Training loss: 6.8714.  Training acc: 93.75%.
[ Wed Jun 28 16:56:19 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:56:19 2023 ] Training epoch: 145
[ Wed Jun 28 16:56:26 2023 ] 	Training loss: 6.8301.  Training acc: 97.01%.
[ Wed Jun 28 16:56:26 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:56:26 2023 ] Training epoch: 146
[ Wed Jun 28 16:56:33 2023 ] 	Training loss: 6.8918.  Training acc: 96.74%.
[ Wed Jun 28 16:56:33 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:56:33 2023 ] Training epoch: 147
[ Wed Jun 28 16:56:40 2023 ] 	Training loss: 6.7355.  Training acc: 96.88%.
[ Wed Jun 28 16:56:40 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:56:41 2023 ] Training epoch: 148
[ Wed Jun 28 16:56:47 2023 ] 	Training loss: 6.8083.  Training acc: 95.96%.
[ Wed Jun 28 16:56:47 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 16:56:48 2023 ] Training epoch: 149
[ Wed Jun 28 16:56:54 2023 ] 	Training loss: 6.7461.  Training acc: 92.32%.
[ Wed Jun 28 16:56:54 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 16:56:55 2023 ] Training epoch: 150
[ Wed Jun 28 16:57:01 2023 ] 	Training loss: 6.9375.  Training acc: 93.62%.
[ Wed Jun 28 16:57:01 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 17:56:04 2023 ] using warm up, epoch: 5
[ Wed Jun 28 17:56:04 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 17:56:04 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 17:56:04 2023 ] Start training Predictor
[ Wed Jun 28 17:56:04 2023 ] Training epoch: 1
[ Wed Jun 28 17:56:10 2023 ] 	Training loss: 102.2312.  Training acc: 33.27%.
[ Wed Jun 28 17:56:10 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 17:56:10 2023 ] Eval epoch: 1
[ Wed Jun 28 17:56:11 2023 ] 	Mean test loss of 625 batches: 2293.856689.
[ Wed Jun 28 17:56:11 2023 ] 	Top1: 29.82%
[ Wed Jun 28 17:56:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:56:11 2023 ] Training epoch: 2
[ Wed Jun 28 17:56:14 2023 ] 	Training loss: 8.7529.  Training acc: 34.65%.
[ Wed Jun 28 17:56:14 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 17:56:14 2023 ] Eval epoch: 2
[ Wed Jun 28 17:56:14 2023 ] 	Mean test loss of 625 batches: 1.263990.
[ Wed Jun 28 17:56:14 2023 ] 	Top1: 68.42%
[ Wed Jun 28 17:56:14 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:56:14 2023 ] Training epoch: 3
[ Wed Jun 28 17:56:17 2023 ] 	Training loss: 5.7762.  Training acc: 44.49%.
[ Wed Jun 28 17:56:17 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 17:56:17 2023 ] Eval epoch: 3
[ Wed Jun 28 17:56:18 2023 ] 	Mean test loss of 625 batches: 1.593627.
[ Wed Jun 28 17:56:18 2023 ] 	Top1: 64.91%
[ Wed Jun 28 17:56:18 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:56:18 2023 ] Training epoch: 4
[ Wed Jun 28 17:56:21 2023 ] 	Training loss: 3.4690.  Training acc: 64.71%.
[ Wed Jun 28 17:56:21 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 17:56:21 2023 ] Eval epoch: 4
[ Wed Jun 28 17:56:22 2023 ] 	Mean test loss of 625 batches: 5.781542.
[ Wed Jun 28 17:56:22 2023 ] 	Top1: 57.89%
[ Wed Jun 28 17:56:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:56:22 2023 ] Training epoch: 5
[ Wed Jun 28 17:56:25 2023 ] 	Training loss: 2.3929.  Training acc: 68.47%.
[ Wed Jun 28 17:56:25 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 17:56:25 2023 ] Eval epoch: 5
[ Wed Jun 28 17:56:25 2023 ] 	Mean test loss of 625 batches: 1.021457.
[ Wed Jun 28 17:56:25 2023 ] 	Top1: 92.98%
[ Wed Jun 28 17:56:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:56:25 2023 ] Training epoch: 6
[ Wed Jun 28 17:56:28 2023 ] 	Training loss: 2.5236.  Training acc: 62.68%.
[ Wed Jun 28 17:56:28 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 17:56:28 2023 ] Eval epoch: 6
[ Wed Jun 28 17:56:29 2023 ] 	Mean test loss of 625 batches: 1.311149.
[ Wed Jun 28 17:56:29 2023 ] 	Top1: 71.93%
[ Wed Jun 28 17:56:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:56:29 2023 ] Training epoch: 7
[ Wed Jun 28 17:56:32 2023 ] 	Training loss: 1.7005.  Training acc: 67.56%.
[ Wed Jun 28 17:56:32 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 17:56:32 2023 ] Eval epoch: 7
[ Wed Jun 28 17:56:33 2023 ] 	Mean test loss of 625 batches: 3.371978.
[ Wed Jun 28 17:56:33 2023 ] 	Top1: 59.65%
[ Wed Jun 28 17:56:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:56:33 2023 ] Training epoch: 8
[ Wed Jun 28 17:56:36 2023 ] 	Training loss: 1.6602.  Training acc: 72.24%.
[ Wed Jun 28 17:56:36 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 17:56:36 2023 ] Eval epoch: 8
[ Wed Jun 28 17:56:37 2023 ] 	Mean test loss of 625 batches: 1.209906.
[ Wed Jun 28 17:56:37 2023 ] 	Top1: 89.47%
[ Wed Jun 28 17:56:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:56:37 2023 ] Training epoch: 9
[ Wed Jun 28 17:56:40 2023 ] 	Training loss: 1.0156.  Training acc: 82.44%.
[ Wed Jun 28 17:56:40 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 17:56:40 2023 ] Eval epoch: 9
[ Wed Jun 28 17:56:41 2023 ] 	Mean test loss of 625 batches: 0.584992.
[ Wed Jun 28 17:56:41 2023 ] 	Top1: 91.23%
[ Wed Jun 28 17:56:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:56:41 2023 ] Training epoch: 10
[ Wed Jun 28 17:56:44 2023 ] 	Training loss: 0.7067.  Training acc: 86.76%.
[ Wed Jun 28 17:56:44 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 17:56:44 2023 ] Eval epoch: 10
[ Wed Jun 28 17:56:44 2023 ] 	Mean test loss of 625 batches: 0.444659.
[ Wed Jun 28 17:56:44 2023 ] 	Top1: 96.49%
[ Wed Jun 28 17:56:44 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:56:44 2023 ] Training epoch: 11
[ Wed Jun 28 17:56:47 2023 ] 	Training loss: 0.5128.  Training acc: 93.20%.
[ Wed Jun 28 17:56:47 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 17:56:47 2023 ] Eval epoch: 11
[ Wed Jun 28 17:56:48 2023 ] 	Mean test loss of 625 batches: 0.381619.
[ Wed Jun 28 17:56:48 2023 ] 	Top1: 100.00%
[ Wed Jun 28 17:56:48 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:56:48 2023 ] Training epoch: 12
[ Wed Jun 28 17:56:51 2023 ] 	Training loss: 0.4753.  Training acc: 94.12%.
[ Wed Jun 28 17:56:51 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 17:56:51 2023 ] Eval epoch: 12
[ Wed Jun 28 17:56:52 2023 ] 	Mean test loss of 625 batches: 0.364374.
[ Wed Jun 28 17:56:52 2023 ] 	Top1: 100.00%
[ Wed Jun 28 17:56:52 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:56:52 2023 ] Training epoch: 13
[ Wed Jun 28 17:56:55 2023 ] 	Training loss: 0.4311.  Training acc: 95.68%.
[ Wed Jun 28 17:56:55 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 17:56:55 2023 ] Eval epoch: 13
[ Wed Jun 28 17:56:56 2023 ] 	Mean test loss of 625 batches: 0.360475.
[ Wed Jun 28 17:56:56 2023 ] 	Top1: 100.00%
[ Wed Jun 28 17:56:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:56:56 2023 ] Training epoch: 14
[ Wed Jun 28 17:56:59 2023 ] 	Training loss: 0.3967.  Training acc: 97.79%.
[ Wed Jun 28 17:56:59 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 17:56:59 2023 ] Eval epoch: 14
[ Wed Jun 28 17:57:00 2023 ] 	Mean test loss of 625 batches: 0.331370.
[ Wed Jun 28 17:57:00 2023 ] 	Top1: 100.00%
[ Wed Jun 28 17:57:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:57:00 2023 ] Training epoch: 15
[ Wed Jun 28 17:57:03 2023 ] 	Training loss: 0.4010.  Training acc: 97.33%.
[ Wed Jun 28 17:57:03 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 17:57:03 2023 ] Eval epoch: 15
[ Wed Jun 28 17:57:03 2023 ] 	Mean test loss of 625 batches: 0.373572.
[ Wed Jun 28 17:57:03 2023 ] 	Top1: 100.00%
[ Wed Jun 28 17:57:03 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:57:03 2023 ] Training epoch: 16
[ Wed Jun 28 17:57:06 2023 ] 	Training loss: 0.4020.  Training acc: 97.24%.
[ Wed Jun 28 17:57:06 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 17:57:06 2023 ] Eval epoch: 16
[ Wed Jun 28 17:57:07 2023 ] 	Mean test loss of 625 batches: 0.336770.
[ Wed Jun 28 17:57:07 2023 ] 	Top1: 100.00%
[ Wed Jun 28 17:57:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:57:07 2023 ] Training epoch: 17
[ Wed Jun 28 17:57:10 2023 ] 	Training loss: 0.3780.  Training acc: 98.35%.
[ Wed Jun 28 17:57:10 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 17:57:10 2023 ] Eval epoch: 17
[ Wed Jun 28 17:57:11 2023 ] 	Mean test loss of 625 batches: 0.327878.
[ Wed Jun 28 17:57:11 2023 ] 	Top1: 100.00%
[ Wed Jun 28 17:57:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:57:11 2023 ] Training epoch: 18
[ Wed Jun 28 17:57:14 2023 ] 	Training loss: 0.3736.  Training acc: 98.44%.
[ Wed Jun 28 17:57:14 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Wed Jun 28 17:57:14 2023 ] Eval epoch: 18
[ Wed Jun 28 17:57:15 2023 ] 	Mean test loss of 625 batches: 0.336709.
[ Wed Jun 28 17:57:15 2023 ] 	Top1: 100.00%
[ Wed Jun 28 17:57:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:57:15 2023 ] Training epoch: 19
[ Wed Jun 28 17:57:18 2023 ] 	Training loss: 0.3913.  Training acc: 97.70%.
[ Wed Jun 28 17:57:18 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 17:57:18 2023 ] Eval epoch: 19
[ Wed Jun 28 17:57:18 2023 ] 	Mean test loss of 625 batches: 0.331892.
[ Wed Jun 28 17:57:18 2023 ] 	Top1: 100.00%
[ Wed Jun 28 17:57:18 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:57:18 2023 ] Training epoch: 20
[ Wed Jun 28 17:57:21 2023 ] 	Training loss: 0.3663.  Training acc: 99.08%.
[ Wed Jun 28 17:57:21 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 17:57:21 2023 ] Eval epoch: 20
[ Wed Jun 28 17:57:22 2023 ] 	Mean test loss of 625 batches: 0.336961.
[ Wed Jun 28 17:57:22 2023 ] 	Top1: 100.00%
[ Wed Jun 28 17:57:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:57:22 2023 ] Training epoch: 21
[ Wed Jun 28 17:57:25 2023 ] 	Training loss: 0.3526.  Training acc: 99.17%.
[ Wed Jun 28 17:57:25 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 17:57:25 2023 ] Eval epoch: 21
[ Wed Jun 28 17:57:26 2023 ] 	Mean test loss of 625 batches: 0.321246.
[ Wed Jun 28 17:57:26 2023 ] 	Top1: 100.00%
[ Wed Jun 28 17:57:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:57:26 2023 ] Training epoch: 22
[ Wed Jun 28 17:57:29 2023 ] 	Training loss: 0.3600.  Training acc: 98.71%.
[ Wed Jun 28 17:57:29 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 17:57:29 2023 ] Eval epoch: 22
[ Wed Jun 28 17:57:30 2023 ] 	Mean test loss of 625 batches: 0.327505.
[ Wed Jun 28 17:57:30 2023 ] 	Top1: 100.00%
[ Wed Jun 28 17:57:30 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:57:30 2023 ] Training epoch: 23
[ Wed Jun 28 17:57:33 2023 ] 	Training loss: 0.3530.  Training acc: 98.90%.
[ Wed Jun 28 17:57:33 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 17:57:33 2023 ] Eval epoch: 23
[ Wed Jun 28 17:57:34 2023 ] 	Mean test loss of 625 batches: 0.327903.
[ Wed Jun 28 17:57:34 2023 ] 	Top1: 100.00%
[ Wed Jun 28 17:57:34 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:57:34 2023 ] Training epoch: 24
[ Wed Jun 28 17:57:37 2023 ] 	Training loss: 0.3465.  Training acc: 99.26%.
[ Wed Jun 28 17:57:37 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 17:57:37 2023 ] Eval epoch: 24
[ Wed Jun 28 17:57:37 2023 ] 	Mean test loss of 625 batches: 0.326118.
[ Wed Jun 28 17:57:37 2023 ] 	Top1: 100.00%
[ Wed Jun 28 17:57:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:57:37 2023 ] Training epoch: 25
[ Wed Jun 28 17:57:40 2023 ] 	Training loss: 0.3550.  Training acc: 98.99%.
[ Wed Jun 28 17:57:40 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 17:57:40 2023 ] Eval epoch: 25
[ Wed Jun 28 17:57:41 2023 ] 	Mean test loss of 625 batches: 0.329041.
[ Wed Jun 28 17:57:41 2023 ] 	Top1: 100.00%
[ Wed Jun 28 17:57:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:57:41 2023 ] Training epoch: 26
[ Wed Jun 28 17:57:44 2023 ] 	Training loss: 0.3534.  Training acc: 98.90%.
[ Wed Jun 28 17:57:44 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 17:57:44 2023 ] Eval epoch: 26
[ Wed Jun 28 17:57:45 2023 ] 	Mean test loss of 625 batches: 0.326436.
[ Wed Jun 28 17:57:45 2023 ] 	Top1: 100.00%
[ Wed Jun 28 17:57:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:57:45 2023 ] Training epoch: 27
[ Wed Jun 28 17:57:48 2023 ] 	Training loss: 0.3463.  Training acc: 99.54%.
[ Wed Jun 28 17:57:48 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 17:57:48 2023 ] Eval epoch: 27
[ Wed Jun 28 17:57:49 2023 ] 	Mean test loss of 625 batches: 0.326251.
[ Wed Jun 28 17:57:49 2023 ] 	Top1: 100.00%
[ Wed Jun 28 17:57:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:57:49 2023 ] Training epoch: 28
[ Wed Jun 28 17:57:52 2023 ] 	Training loss: 0.3458.  Training acc: 99.08%.
[ Wed Jun 28 17:57:52 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 17:57:52 2023 ] Eval epoch: 28
[ Wed Jun 28 17:57:52 2023 ] 	Mean test loss of 625 batches: 0.322224.
[ Wed Jun 28 17:57:52 2023 ] 	Top1: 100.00%
[ Wed Jun 28 17:57:52 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:57:52 2023 ] Training epoch: 29
[ Wed Jun 28 17:57:55 2023 ] 	Training loss: 0.3567.  Training acc: 98.53%.
[ Wed Jun 28 17:57:55 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 17:57:55 2023 ] Eval epoch: 29
[ Wed Jun 28 17:57:56 2023 ] 	Mean test loss of 625 batches: 0.320353.
[ Wed Jun 28 17:57:56 2023 ] 	Top1: 100.00%
[ Wed Jun 28 17:57:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:57:56 2023 ] Training epoch: 30
[ Wed Jun 28 17:57:59 2023 ] 	Training loss: 0.3503.  Training acc: 98.90%.
[ Wed Jun 28 17:57:59 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Wed Jun 28 17:57:59 2023 ] Eval epoch: 30
[ Wed Jun 28 17:58:00 2023 ] 	Mean test loss of 625 batches: 0.322449.
[ Wed Jun 28 17:58:00 2023 ] 	Top1: 100.00%
[ Wed Jun 28 17:58:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:58:01 2023 ] Best accuracy: 1.0
[ Wed Jun 28 17:58:01 2023 ] Epoch number: 11
[ Wed Jun 28 17:58:01 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 17:58:01 2023 ] Weight decay: 0.0005
[ Wed Jun 28 17:58:01 2023 ] Base LR: 0.1
[ Wed Jun 28 17:58:01 2023 ] Batch Size: 64
[ Wed Jun 28 17:58:01 2023 ] Test Batch Size: 64
[ Wed Jun 28 17:58:01 2023 ] seed: 1
[ Wed Jun 28 17:58:01 2023 ] Start training Corrector
[ Wed Jun 28 17:58:01 2023 ] # Parameters Corrector: 2407569
[ Wed Jun 28 17:58:02 2023 ] Training epoch: 1
[ Wed Jun 28 17:58:11 2023 ] 	Training loss: 20.3884.  Training acc: 42.58%.
[ Wed Jun 28 17:58:11 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 17:59:02 2023 ] using warm up, epoch: 5
[ Wed Jun 28 17:59:02 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 17:59:02 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 17:59:02 2023 ] Start training Predictor
[ Wed Jun 28 17:59:02 2023 ] Training epoch: 1
[ Wed Jun 28 17:59:08 2023 ] 	Training loss: 103.8907.  Training acc: 34.93%.
[ Wed Jun 28 17:59:08 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 17:59:08 2023 ] Eval epoch: 1
[ Wed Jun 28 17:59:09 2023 ] 	Mean test loss of 625 batches: 1224.507397.
[ Wed Jun 28 17:59:09 2023 ] 	Top1: 29.82%
[ Wed Jun 28 17:59:09 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:59:09 2023 ] Training epoch: 2
[ Wed Jun 28 17:59:12 2023 ] 	Training loss: 8.7429.  Training acc: 38.42%.
[ Wed Jun 28 17:59:12 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 17:59:12 2023 ] Eval epoch: 2
[ Wed Jun 28 17:59:12 2023 ] 	Mean test loss of 625 batches: 4.230597.
[ Wed Jun 28 17:59:12 2023 ] 	Top1: 36.84%
[ Wed Jun 28 17:59:12 2023 ] 	Top5: 100.00%
[ Wed Jun 28 17:59:13 2023 ] Training epoch: 3
[ Wed Jun 28 17:59:54 2023 ] using warm up, epoch: 5
[ Wed Jun 28 17:59:55 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 17:59:55 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 17:59:55 2023 ] Start training Predictor
[ Wed Jun 28 17:59:55 2023 ] Training epoch: 1
[ Wed Jun 28 18:00:00 2023 ] 	Training loss: 114.7217.  Training acc: 33.82%.
[ Wed Jun 28 18:00:00 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 18:00:00 2023 ] Eval epoch: 1
[ Wed Jun 28 18:00:01 2023 ] 	Mean test loss of 625 batches: 176.188356.
[ Wed Jun 28 18:00:01 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:00:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:00:01 2023 ] Training epoch: 2
[ Wed Jun 28 18:00:04 2023 ] 	Training loss: 11.4369.  Training acc: 34.38%.
[ Wed Jun 28 18:00:04 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:00:04 2023 ] Eval epoch: 2
[ Wed Jun 28 18:00:05 2023 ] 	Mean test loss of 625 batches: 22.197737.
[ Wed Jun 28 18:00:05 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:00:05 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:00:05 2023 ] Training epoch: 3
[ Wed Jun 28 18:00:07 2023 ] 	Training loss: 7.4054.  Training acc: 33.73%.
[ Wed Jun 28 18:00:07 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:00:07 2023 ] Eval epoch: 3
[ Wed Jun 28 18:00:08 2023 ] 	Mean test loss of 625 batches: 2.306142.
[ Wed Jun 28 18:00:08 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:00:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:00:08 2023 ] Training epoch: 4
[ Wed Jun 28 18:00:11 2023 ] 	Training loss: 6.4433.  Training acc: 32.90%.
[ Wed Jun 28 18:00:11 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:00:11 2023 ] Eval epoch: 4
[ Wed Jun 28 18:00:12 2023 ] 	Mean test loss of 625 batches: 2.654770.
[ Wed Jun 28 18:00:12 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:00:12 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:00:12 2023 ] Training epoch: 5
[ Wed Jun 28 18:00:14 2023 ] 	Training loss: 6.7997.  Training acc: 36.03%.
[ Wed Jun 28 18:00:14 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:00:14 2023 ] Eval epoch: 5
[ Wed Jun 28 18:00:15 2023 ] 	Mean test loss of 625 batches: 1.685292.
[ Wed Jun 28 18:00:15 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:00:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:00:15 2023 ] Training epoch: 6
[ Wed Jun 28 18:00:18 2023 ] 	Training loss: 3.7840.  Training acc: 35.29%.
[ Wed Jun 28 18:00:18 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:00:18 2023 ] Eval epoch: 6
[ Wed Jun 28 18:00:19 2023 ] 	Mean test loss of 625 batches: 1.754221.
[ Wed Jun 28 18:00:19 2023 ] 	Top1: 29.82%
[ Wed Jun 28 18:00:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:00:19 2023 ] Training epoch: 7
[ Wed Jun 28 18:00:21 2023 ] 	Training loss: 2.9968.  Training acc: 37.59%.
[ Wed Jun 28 18:00:21 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:00:21 2023 ] Eval epoch: 7
[ Wed Jun 28 18:00:22 2023 ] 	Mean test loss of 625 batches: 0.970381.
[ Wed Jun 28 18:00:22 2023 ] 	Top1: 56.14%
[ Wed Jun 28 18:00:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:00:22 2023 ] Training epoch: 8
[ Wed Jun 28 18:00:25 2023 ] 	Training loss: 2.4772.  Training acc: 39.43%.
[ Wed Jun 28 18:00:25 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:00:25 2023 ] Eval epoch: 8
[ Wed Jun 28 18:00:26 2023 ] 	Mean test loss of 625 batches: 1.109704.
[ Wed Jun 28 18:00:26 2023 ] 	Top1: 40.35%
[ Wed Jun 28 18:00:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:00:26 2023 ] Training epoch: 9
[ Wed Jun 28 18:00:28 2023 ] 	Training loss: 1.8190.  Training acc: 49.91%.
[ Wed Jun 28 18:00:28 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:00:28 2023 ] Eval epoch: 9
[ Wed Jun 28 18:00:29 2023 ] 	Mean test loss of 625 batches: 0.990580.
[ Wed Jun 28 18:00:29 2023 ] 	Top1: 57.89%
[ Wed Jun 28 18:00:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:00:29 2023 ] Training epoch: 10
[ Wed Jun 28 18:00:32 2023 ] 	Training loss: 1.6451.  Training acc: 48.25%.
[ Wed Jun 28 18:00:32 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:00:32 2023 ] Eval epoch: 10
[ Wed Jun 28 18:00:33 2023 ] 	Mean test loss of 625 batches: 4.166982.
[ Wed Jun 28 18:00:33 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:00:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:00:33 2023 ] Training epoch: 11
[ Wed Jun 28 18:00:35 2023 ] 	Training loss: 1.2292.  Training acc: 62.50%.
[ Wed Jun 28 18:00:35 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:00:35 2023 ] Eval epoch: 11
[ Wed Jun 28 18:00:36 2023 ] 	Mean test loss of 625 batches: 0.747334.
[ Wed Jun 28 18:00:36 2023 ] 	Top1: 73.68%
[ Wed Jun 28 18:00:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:00:36 2023 ] Training epoch: 12
[ Wed Jun 28 18:00:39 2023 ] 	Training loss: 1.1565.  Training acc: 61.76%.
[ Wed Jun 28 18:00:39 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:00:39 2023 ] Eval epoch: 12
[ Wed Jun 28 18:00:40 2023 ] 	Mean test loss of 625 batches: 0.715125.
[ Wed Jun 28 18:00:40 2023 ] 	Top1: 75.44%
[ Wed Jun 28 18:00:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:00:40 2023 ] Training epoch: 13
[ Wed Jun 28 18:00:43 2023 ] 	Training loss: 1.0702.  Training acc: 63.69%.
[ Wed Jun 28 18:00:43 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:00:43 2023 ] Eval epoch: 13
[ Wed Jun 28 18:00:43 2023 ] 	Mean test loss of 625 batches: 0.688513.
[ Wed Jun 28 18:00:43 2023 ] 	Top1: 77.19%
[ Wed Jun 28 18:00:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:00:43 2023 ] Training epoch: 14
[ Wed Jun 28 18:00:46 2023 ] 	Training loss: 1.0344.  Training acc: 67.00%.
[ Wed Jun 28 18:00:46 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:00:46 2023 ] Eval epoch: 14
[ Wed Jun 28 18:00:47 2023 ] 	Mean test loss of 625 batches: 0.654052.
[ Wed Jun 28 18:00:47 2023 ] 	Top1: 78.95%
[ Wed Jun 28 18:00:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:00:47 2023 ] Training epoch: 15
[ Wed Jun 28 18:00:50 2023 ] 	Training loss: 1.0397.  Training acc: 65.17%.
[ Wed Jun 28 18:00:50 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:00:50 2023 ] Eval epoch: 15
[ Wed Jun 28 18:00:51 2023 ] 	Mean test loss of 625 batches: 0.669618.
[ Wed Jun 28 18:00:51 2023 ] 	Top1: 78.95%
[ Wed Jun 28 18:00:51 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:00:51 2023 ] Training epoch: 16
[ Wed Jun 28 18:00:53 2023 ] 	Training loss: 0.9877.  Training acc: 67.00%.
[ Wed Jun 28 18:00:53 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:00:53 2023 ] Eval epoch: 16
[ Wed Jun 28 18:00:54 2023 ] 	Mean test loss of 625 batches: 0.633535.
[ Wed Jun 28 18:00:54 2023 ] 	Top1: 87.72%
[ Wed Jun 28 18:00:54 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:00:54 2023 ] Training epoch: 17
[ Wed Jun 28 18:00:57 2023 ] 	Training loss: 0.9240.  Training acc: 70.77%.
[ Wed Jun 28 18:00:57 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:00:57 2023 ] Eval epoch: 17
[ Wed Jun 28 18:00:57 2023 ] 	Mean test loss of 625 batches: 0.696035.
[ Wed Jun 28 18:00:57 2023 ] 	Top1: 85.96%
[ Wed Jun 28 18:00:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:00:57 2023 ] Training epoch: 18
[ Wed Jun 28 18:01:00 2023 ] 	Training loss: 0.8977.  Training acc: 71.60%.
[ Wed Jun 28 18:01:00 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:01:00 2023 ] Eval epoch: 18
[ Wed Jun 28 18:01:01 2023 ] 	Mean test loss of 625 batches: 0.615002.
[ Wed Jun 28 18:01:01 2023 ] 	Top1: 85.96%
[ Wed Jun 28 18:01:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:01:01 2023 ] Training epoch: 19
[ Wed Jun 28 18:01:04 2023 ] 	Training loss: 0.9149.  Training acc: 71.97%.
[ Wed Jun 28 18:01:04 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:01:04 2023 ] Eval epoch: 19
[ Wed Jun 28 18:01:04 2023 ] 	Mean test loss of 625 batches: 0.618304.
[ Wed Jun 28 18:01:04 2023 ] 	Top1: 91.23%
[ Wed Jun 28 18:01:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:01:04 2023 ] Training epoch: 20
[ Wed Jun 28 18:01:07 2023 ] 	Training loss: 0.8201.  Training acc: 76.29%.
[ Wed Jun 28 18:01:07 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:01:07 2023 ] Eval epoch: 20
[ Wed Jun 28 18:01:08 2023 ] 	Mean test loss of 625 batches: 0.552294.
[ Wed Jun 28 18:01:08 2023 ] 	Top1: 91.23%
[ Wed Jun 28 18:01:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:01:08 2023 ] Training epoch: 21
[ Wed Jun 28 18:01:11 2023 ] 	Training loss: 0.8077.  Training acc: 76.84%.
[ Wed Jun 28 18:01:11 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:01:11 2023 ] Eval epoch: 21
[ Wed Jun 28 18:01:11 2023 ] 	Mean test loss of 625 batches: 0.564156.
[ Wed Jun 28 18:01:11 2023 ] 	Top1: 94.74%
[ Wed Jun 28 18:01:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:01:11 2023 ] Training epoch: 22
[ Wed Jun 28 18:01:14 2023 ] 	Training loss: 0.7679.  Training acc: 79.32%.
[ Wed Jun 28 18:01:14 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:01:14 2023 ] Eval epoch: 22
[ Wed Jun 28 18:01:15 2023 ] 	Mean test loss of 625 batches: 0.545786.
[ Wed Jun 28 18:01:15 2023 ] 	Top1: 94.74%
[ Wed Jun 28 18:01:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:01:15 2023 ] Training epoch: 23
[ Wed Jun 28 18:01:18 2023 ] 	Training loss: 0.7829.  Training acc: 78.40%.
[ Wed Jun 28 18:01:18 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:01:18 2023 ] Eval epoch: 23
[ Wed Jun 28 18:01:18 2023 ] 	Mean test loss of 625 batches: 0.562555.
[ Wed Jun 28 18:01:18 2023 ] 	Top1: 91.23%
[ Wed Jun 28 18:01:18 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:01:18 2023 ] Training epoch: 24
[ Wed Jun 28 18:01:21 2023 ] 	Training loss: 0.7652.  Training acc: 79.04%.
[ Wed Jun 28 18:01:21 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:01:21 2023 ] Eval epoch: 24
[ Wed Jun 28 18:01:22 2023 ] 	Mean test loss of 625 batches: 0.539894.
[ Wed Jun 28 18:01:22 2023 ] 	Top1: 92.98%
[ Wed Jun 28 18:01:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:01:22 2023 ] Training epoch: 25
[ Wed Jun 28 18:01:25 2023 ] 	Training loss: 0.7705.  Training acc: 78.03%.
[ Wed Jun 28 18:01:25 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:01:25 2023 ] Eval epoch: 25
[ Wed Jun 28 18:01:25 2023 ] 	Mean test loss of 625 batches: 0.538070.
[ Wed Jun 28 18:01:25 2023 ] 	Top1: 92.98%
[ Wed Jun 28 18:01:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:01:25 2023 ] Training epoch: 26
[ Wed Jun 28 18:01:28 2023 ] 	Training loss: 0.7615.  Training acc: 79.41%.
[ Wed Jun 28 18:01:28 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:01:28 2023 ] Eval epoch: 26
[ Wed Jun 28 18:01:29 2023 ] 	Mean test loss of 625 batches: 0.540663.
[ Wed Jun 28 18:01:29 2023 ] 	Top1: 94.74%
[ Wed Jun 28 18:01:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:01:29 2023 ] Training epoch: 27
[ Wed Jun 28 18:01:32 2023 ] 	Training loss: 0.7848.  Training acc: 76.65%.
[ Wed Jun 28 18:01:32 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:01:32 2023 ] Eval epoch: 27
[ Wed Jun 28 18:01:32 2023 ] 	Mean test loss of 625 batches: 0.557100.
[ Wed Jun 28 18:01:32 2023 ] 	Top1: 96.49%
[ Wed Jun 28 18:01:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:01:33 2023 ] Training epoch: 28
[ Wed Jun 28 18:01:35 2023 ] 	Training loss: 0.7506.  Training acc: 80.51%.
[ Wed Jun 28 18:01:35 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:01:35 2023 ] Eval epoch: 28
[ Wed Jun 28 18:01:36 2023 ] 	Mean test loss of 625 batches: 0.535941.
[ Wed Jun 28 18:01:36 2023 ] 	Top1: 91.23%
[ Wed Jun 28 18:01:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:01:36 2023 ] Training epoch: 29
[ Wed Jun 28 18:01:39 2023 ] 	Training loss: 0.7508.  Training acc: 80.51%.
[ Wed Jun 28 18:01:39 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:01:39 2023 ] Eval epoch: 29
[ Wed Jun 28 18:01:39 2023 ] 	Mean test loss of 625 batches: 0.527502.
[ Wed Jun 28 18:01:39 2023 ] 	Top1: 94.74%
[ Wed Jun 28 18:01:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:01:39 2023 ] Training epoch: 30
[ Wed Jun 28 18:01:42 2023 ] 	Training loss: 0.7091.  Training acc: 82.17%.
[ Wed Jun 28 18:01:42 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:01:42 2023 ] Eval epoch: 30
[ Wed Jun 28 18:01:43 2023 ] 	Mean test loss of 625 batches: 0.528583.
[ Wed Jun 28 18:01:43 2023 ] 	Top1: 92.98%
[ Wed Jun 28 18:01:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:01:44 2023 ] Best accuracy: 0.9649122807017544
[ Wed Jun 28 18:01:44 2023 ] Epoch number: 27
[ Wed Jun 28 18:01:44 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 18:01:44 2023 ] Weight decay: 0.0005
[ Wed Jun 28 18:01:44 2023 ] Base LR: 0.1
[ Wed Jun 28 18:01:44 2023 ] Batch Size: 64
[ Wed Jun 28 18:01:44 2023 ] Test Batch Size: 64
[ Wed Jun 28 18:01:44 2023 ] seed: 1
[ Wed Jun 28 18:01:44 2023 ] Start training Corrector
[ Wed Jun 28 18:01:44 2023 ] # Parameters Corrector: 2407569
[ Wed Jun 28 18:01:45 2023 ] Training epoch: 1
[ Wed Jun 28 18:01:53 2023 ] 	Training loss: 19.0964.  Training acc: 28.91%.
[ Wed Jun 28 18:01:53 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 18:01:53 2023 ] Eval epoch: 1
[ Wed Jun 28 18:03:54 2023 ] using warm up, epoch: 5
[ Wed Jun 28 18:03:55 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 18:03:55 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 18:03:55 2023 ] Start training Predictor
[ Wed Jun 28 18:03:55 2023 ] Training epoch: 1
[ Wed Jun 28 18:04:00 2023 ] 	Training loss: 118.1543.  Training acc: 35.75%.
[ Wed Jun 28 18:04:00 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 18:04:00 2023 ] Eval epoch: 1
[ Wed Jun 28 18:04:01 2023 ] 	Mean test loss of 625 batches: 613.509619.
[ Wed Jun 28 18:04:01 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:04:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:04:01 2023 ] Training epoch: 2
[ Wed Jun 28 18:04:04 2023 ] 	Training loss: 8.1202.  Training acc: 40.72%.
[ Wed Jun 28 18:04:04 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:04:04 2023 ] Eval epoch: 2
[ Wed Jun 28 18:04:05 2023 ] 	Mean test loss of 625 batches: 70.294620.
[ Wed Jun 28 18:04:05 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:04:05 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:04:05 2023 ] Training epoch: 3
[ Wed Jun 28 18:04:08 2023 ] 	Training loss: 5.7288.  Training acc: 51.65%.
[ Wed Jun 28 18:04:08 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:04:08 2023 ] Eval epoch: 3
[ Wed Jun 28 18:04:08 2023 ] 	Mean test loss of 625 batches: 2.420918.
[ Wed Jun 28 18:04:08 2023 ] 	Top1: 73.68%
[ Wed Jun 28 18:04:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:04:08 2023 ] Training epoch: 4
[ Wed Jun 28 18:04:11 2023 ] 	Training loss: 3.6882.  Training acc: 62.59%.
[ Wed Jun 28 18:04:11 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:04:11 2023 ] Eval epoch: 4
[ Wed Jun 28 18:04:12 2023 ] 	Mean test loss of 625 batches: 15.124944.
[ Wed Jun 28 18:04:12 2023 ] 	Top1: 29.82%
[ Wed Jun 28 18:04:12 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:04:12 2023 ] Training epoch: 5
[ Wed Jun 28 18:04:15 2023 ] 	Training loss: 5.3287.  Training acc: 68.66%.
[ Wed Jun 28 18:04:15 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:04:15 2023 ] Eval epoch: 5
[ Wed Jun 28 18:04:16 2023 ] 	Mean test loss of 625 batches: 1.627130.
[ Wed Jun 28 18:04:16 2023 ] 	Top1: 87.72%
[ Wed Jun 28 18:04:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:04:16 2023 ] Training epoch: 6
[ Wed Jun 28 18:04:18 2023 ] 	Training loss: 2.5896.  Training acc: 74.45%.
[ Wed Jun 28 18:04:18 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:04:18 2023 ] Eval epoch: 6
[ Wed Jun 28 18:04:19 2023 ] 	Mean test loss of 625 batches: 1.406151.
[ Wed Jun 28 18:04:19 2023 ] 	Top1: 96.49%
[ Wed Jun 28 18:04:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:04:19 2023 ] Training epoch: 7
[ Wed Jun 28 18:04:22 2023 ] 	Training loss: 1.3278.  Training acc: 83.36%.
[ Wed Jun 28 18:04:22 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:04:22 2023 ] Eval epoch: 7
[ Wed Jun 28 18:04:23 2023 ] 	Mean test loss of 625 batches: 0.666180.
[ Wed Jun 28 18:04:23 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:04:23 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:04:23 2023 ] Training epoch: 8
[ Wed Jun 28 18:04:25 2023 ] 	Training loss: 2.0518.  Training acc: 83.18%.
[ Wed Jun 28 18:04:25 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:04:25 2023 ] Eval epoch: 8
[ Wed Jun 28 18:04:26 2023 ] 	Mean test loss of 625 batches: 1.257867.
[ Wed Jun 28 18:04:26 2023 ] 	Top1: 87.72%
[ Wed Jun 28 18:04:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:04:26 2023 ] Training epoch: 9
[ Wed Jun 28 18:04:29 2023 ] 	Training loss: 1.4412.  Training acc: 87.68%.
[ Wed Jun 28 18:04:29 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:04:29 2023 ] Eval epoch: 9
[ Wed Jun 28 18:04:30 2023 ] 	Mean test loss of 625 batches: 0.592618.
[ Wed Jun 28 18:04:30 2023 ] 	Top1: 85.96%
[ Wed Jun 28 18:04:30 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:04:30 2023 ] Training epoch: 10
[ Wed Jun 28 18:04:32 2023 ] 	Training loss: 0.7809.  Training acc: 86.86%.
[ Wed Jun 28 18:04:32 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:04:32 2023 ] Eval epoch: 10
[ Wed Jun 28 18:04:33 2023 ] 	Mean test loss of 625 batches: 0.778737.
[ Wed Jun 28 18:04:33 2023 ] 	Top1: 66.67%
[ Wed Jun 28 18:04:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:04:33 2023 ] Training epoch: 11
[ Wed Jun 28 18:04:36 2023 ] 	Training loss: 0.6405.  Training acc: 90.90%.
[ Wed Jun 28 18:04:36 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:04:36 2023 ] Eval epoch: 11
[ Wed Jun 28 18:04:37 2023 ] 	Mean test loss of 625 batches: 0.457053.
[ Wed Jun 28 18:04:37 2023 ] 	Top1: 96.49%
[ Wed Jun 28 18:04:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:04:37 2023 ] Training epoch: 12
[ Wed Jun 28 18:04:39 2023 ] 	Training loss: 0.5514.  Training acc: 95.22%.
[ Wed Jun 28 18:04:39 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:04:39 2023 ] Eval epoch: 12
[ Wed Jun 28 18:04:40 2023 ] 	Mean test loss of 625 batches: 0.440133.
[ Wed Jun 28 18:04:40 2023 ] 	Top1: 96.49%
[ Wed Jun 28 18:04:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:04:40 2023 ] Training epoch: 13
[ Wed Jun 28 18:04:43 2023 ] 	Training loss: 0.5506.  Training acc: 94.12%.
[ Wed Jun 28 18:04:43 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:04:43 2023 ] Eval epoch: 13
[ Wed Jun 28 18:04:44 2023 ] 	Mean test loss of 625 batches: 0.486417.
[ Wed Jun 28 18:04:44 2023 ] 	Top1: 91.23%
[ Wed Jun 28 18:04:44 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:04:44 2023 ] Training epoch: 14
[ Wed Jun 28 18:04:47 2023 ] 	Training loss: 0.5055.  Training acc: 94.67%.
[ Wed Jun 28 18:04:47 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:04:47 2023 ] Eval epoch: 14
[ Wed Jun 28 18:04:47 2023 ] 	Mean test loss of 625 batches: 0.417426.
[ Wed Jun 28 18:04:47 2023 ] 	Top1: 96.49%
[ Wed Jun 28 18:04:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:04:47 2023 ] Training epoch: 15
[ Wed Jun 28 18:04:50 2023 ] 	Training loss: 0.4883.  Training acc: 95.40%.
[ Wed Jun 28 18:04:50 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:04:50 2023 ] Eval epoch: 15
[ Wed Jun 28 18:04:51 2023 ] 	Mean test loss of 625 batches: 0.383268.
[ Wed Jun 28 18:04:51 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:04:51 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:04:51 2023 ] Training epoch: 16
[ Wed Jun 28 18:04:54 2023 ] 	Training loss: 0.4755.  Training acc: 95.50%.
[ Wed Jun 28 18:04:54 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:04:54 2023 ] Eval epoch: 16
[ Wed Jun 28 18:04:54 2023 ] 	Mean test loss of 625 batches: 0.391872.
[ Wed Jun 28 18:04:54 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:04:54 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:04:54 2023 ] Training epoch: 17
[ Wed Jun 28 18:04:57 2023 ] 	Training loss: 0.4709.  Training acc: 96.42%.
[ Wed Jun 28 18:04:57 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:04:57 2023 ] Eval epoch: 17
[ Wed Jun 28 18:04:58 2023 ] 	Mean test loss of 625 batches: 0.364408.
[ Wed Jun 28 18:04:58 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:04:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:04:58 2023 ] Training epoch: 18
[ Wed Jun 28 18:05:00 2023 ] 	Training loss: 0.4574.  Training acc: 95.50%.
[ Wed Jun 28 18:05:00 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:05:00 2023 ] Eval epoch: 18
[ Wed Jun 28 18:05:01 2023 ] 	Mean test loss of 625 batches: 0.361625.
[ Wed Jun 28 18:05:01 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:05:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:05:01 2023 ] Training epoch: 19
[ Wed Jun 28 18:05:04 2023 ] 	Training loss: 0.4517.  Training acc: 95.50%.
[ Wed Jun 28 18:05:04 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:05:04 2023 ] Eval epoch: 19
[ Wed Jun 28 18:05:05 2023 ] 	Mean test loss of 625 batches: 0.371333.
[ Wed Jun 28 18:05:05 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:05:05 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:05:05 2023 ] Training epoch: 20
[ Wed Jun 28 18:05:08 2023 ] 	Training loss: 0.4252.  Training acc: 96.88%.
[ Wed Jun 28 18:05:08 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:05:08 2023 ] Eval epoch: 20
[ Wed Jun 28 18:05:08 2023 ] 	Mean test loss of 625 batches: 0.401890.
[ Wed Jun 28 18:05:08 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:05:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:05:08 2023 ] Training epoch: 21
[ Wed Jun 28 18:05:11 2023 ] 	Training loss: 0.4317.  Training acc: 95.96%.
[ Wed Jun 28 18:05:11 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:05:11 2023 ] Eval epoch: 21
[ Wed Jun 28 18:05:12 2023 ] 	Mean test loss of 625 batches: 0.341201.
[ Wed Jun 28 18:05:12 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:05:12 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:05:12 2023 ] Training epoch: 22
[ Wed Jun 28 18:05:14 2023 ] 	Training loss: 0.4173.  Training acc: 96.78%.
[ Wed Jun 28 18:05:14 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:05:14 2023 ] Eval epoch: 22
[ Wed Jun 28 18:05:15 2023 ] 	Mean test loss of 625 batches: 0.348528.
[ Wed Jun 28 18:05:15 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:05:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:05:15 2023 ] Training epoch: 23
[ Wed Jun 28 18:05:18 2023 ] 	Training loss: 0.4218.  Training acc: 96.97%.
[ Wed Jun 28 18:05:18 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:05:18 2023 ] Eval epoch: 23
[ Wed Jun 28 18:05:19 2023 ] 	Mean test loss of 625 batches: 0.353962.
[ Wed Jun 28 18:05:19 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:05:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:05:19 2023 ] Training epoch: 24
[ Wed Jun 28 18:05:22 2023 ] 	Training loss: 0.4171.  Training acc: 97.33%.
[ Wed Jun 28 18:05:22 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:05:22 2023 ] Eval epoch: 24
[ Wed Jun 28 18:05:22 2023 ] 	Mean test loss of 625 batches: 0.344162.
[ Wed Jun 28 18:05:22 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:05:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:05:22 2023 ] Training epoch: 25
[ Wed Jun 28 18:05:25 2023 ] 	Training loss: 0.4112.  Training acc: 97.89%.
[ Wed Jun 28 18:05:25 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:05:25 2023 ] Eval epoch: 25
[ Wed Jun 28 18:05:26 2023 ] 	Mean test loss of 625 batches: 0.351773.
[ Wed Jun 28 18:05:26 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:05:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:05:26 2023 ] Training epoch: 26
[ Wed Jun 28 18:05:28 2023 ] 	Training loss: 0.4256.  Training acc: 96.78%.
[ Wed Jun 28 18:05:28 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:05:28 2023 ] Eval epoch: 26
[ Wed Jun 28 18:05:29 2023 ] 	Mean test loss of 625 batches: 0.344689.
[ Wed Jun 28 18:05:29 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:05:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:05:29 2023 ] Training epoch: 27
[ Wed Jun 28 18:05:32 2023 ] 	Training loss: 0.4078.  Training acc: 97.24%.
[ Wed Jun 28 18:05:32 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:05:32 2023 ] Eval epoch: 27
[ Wed Jun 28 18:05:33 2023 ] 	Mean test loss of 625 batches: 0.344991.
[ Wed Jun 28 18:05:33 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:05:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:05:33 2023 ] Training epoch: 28
[ Wed Jun 28 18:05:35 2023 ] 	Training loss: 0.4065.  Training acc: 97.70%.
[ Wed Jun 28 18:05:35 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:05:35 2023 ] Eval epoch: 28
[ Wed Jun 28 18:05:36 2023 ] 	Mean test loss of 625 batches: 0.345535.
[ Wed Jun 28 18:05:36 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:05:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:05:36 2023 ] Training epoch: 29
[ Wed Jun 28 18:05:39 2023 ] 	Training loss: 0.4125.  Training acc: 97.61%.
[ Wed Jun 28 18:05:39 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:05:39 2023 ] Eval epoch: 29
[ Wed Jun 28 18:05:40 2023 ] 	Mean test loss of 625 batches: 0.341156.
[ Wed Jun 28 18:05:40 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:05:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:05:40 2023 ] Training epoch: 30
[ Wed Jun 28 18:05:42 2023 ] 	Training loss: 0.4087.  Training acc: 97.52%.
[ Wed Jun 28 18:05:42 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:05:42 2023 ] Eval epoch: 30
[ Wed Jun 28 18:05:43 2023 ] 	Mean test loss of 625 batches: 0.341372.
[ Wed Jun 28 18:05:43 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:05:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:05:44 2023 ] Best accuracy: 1.0
[ Wed Jun 28 18:05:44 2023 ] Epoch number: 7
[ Wed Jun 28 18:05:44 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 18:05:44 2023 ] Weight decay: 0.0005
[ Wed Jun 28 18:05:44 2023 ] Base LR: 0.1
[ Wed Jun 28 18:05:44 2023 ] Batch Size: 64
[ Wed Jun 28 18:05:44 2023 ] Test Batch Size: 64
[ Wed Jun 28 18:05:44 2023 ] seed: 1
[ Wed Jun 28 18:05:44 2023 ] Start training Corrector
[ Wed Jun 28 18:05:44 2023 ] # Parameters Corrector: 2407569
[ Wed Jun 28 18:05:45 2023 ] Training epoch: 1
[ Wed Jun 28 18:05:53 2023 ] 	Training loss: 16.5223.  Training acc: 33.59%.
[ Wed Jun 28 18:05:53 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 18:05:53 2023 ] Eval epoch: 1
[ Wed Jun 28 18:08:30 2023 ] using warm up, epoch: 5
[ Wed Jun 28 18:08:30 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 18:08:30 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 18:08:30 2023 ] Start training Predictor
[ Wed Jun 28 18:08:30 2023 ] Training epoch: 1
[ Wed Jun 28 18:08:36 2023 ] 	Training loss: 108.8627.  Training acc: 34.74%.
[ Wed Jun 28 18:08:36 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 18:08:36 2023 ] Eval epoch: 1
[ Wed Jun 28 18:08:37 2023 ] 	Mean test loss of 625 batches: 1051.969568.
[ Wed Jun 28 18:08:37 2023 ] 	Top1: 29.82%
[ Wed Jun 28 18:08:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:08:37 2023 ] Training epoch: 2
[ Wed Jun 28 18:08:39 2023 ] 	Training loss: 12.3056.  Training acc: 39.80%.
[ Wed Jun 28 18:08:39 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:08:39 2023 ] Eval epoch: 2
[ Wed Jun 28 18:08:40 2023 ] 	Mean test loss of 625 batches: 12.897737.
[ Wed Jun 28 18:08:40 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:08:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:08:40 2023 ] Training epoch: 3
[ Wed Jun 28 18:08:43 2023 ] 	Training loss: 6.0123.  Training acc: 51.93%.
[ Wed Jun 28 18:08:43 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:08:43 2023 ] Eval epoch: 3
[ Wed Jun 28 18:08:44 2023 ] 	Mean test loss of 625 batches: 18.489127.
[ Wed Jun 28 18:08:44 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:08:44 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:08:44 2023 ] Training epoch: 4
[ Wed Jun 28 18:08:46 2023 ] 	Training loss: 3.8059.  Training acc: 69.39%.
[ Wed Jun 28 18:08:46 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:08:46 2023 ] Eval epoch: 4
[ Wed Jun 28 18:08:47 2023 ] 	Mean test loss of 625 batches: 3.592294.
[ Wed Jun 28 18:08:47 2023 ] 	Top1: 59.65%
[ Wed Jun 28 18:08:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:08:47 2023 ] Training epoch: 5
[ Wed Jun 28 18:08:50 2023 ] 	Training loss: 5.0219.  Training acc: 69.85%.
[ Wed Jun 28 18:08:50 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:08:50 2023 ] Eval epoch: 5
[ Wed Jun 28 18:08:51 2023 ] 	Mean test loss of 625 batches: 27.670557.
[ Wed Jun 28 18:08:51 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:08:51 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:08:51 2023 ] Training epoch: 6
[ Wed Jun 28 18:08:53 2023 ] 	Training loss: 3.3084.  Training acc: 64.52%.
[ Wed Jun 28 18:08:53 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:08:53 2023 ] Eval epoch: 6
[ Wed Jun 28 18:08:54 2023 ] 	Mean test loss of 625 batches: 6.384893.
[ Wed Jun 28 18:08:54 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:08:54 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:08:54 2023 ] Training epoch: 7
[ Wed Jun 28 18:08:57 2023 ] 	Training loss: 1.5047.  Training acc: 77.94%.
[ Wed Jun 28 18:08:57 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:08:57 2023 ] Eval epoch: 7
[ Wed Jun 28 18:08:58 2023 ] 	Mean test loss of 625 batches: 9.431325.
[ Wed Jun 28 18:08:58 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:08:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:08:58 2023 ] Training epoch: 8
[ Wed Jun 28 18:09:00 2023 ] 	Training loss: 1.1272.  Training acc: 81.71%.
[ Wed Jun 28 18:09:00 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:09:00 2023 ] Eval epoch: 8
[ Wed Jun 28 18:09:01 2023 ] 	Mean test loss of 625 batches: 0.803900.
[ Wed Jun 28 18:09:01 2023 ] 	Top1: 85.96%
[ Wed Jun 28 18:09:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:09:01 2023 ] Training epoch: 9
[ Wed Jun 28 18:09:04 2023 ] 	Training loss: 0.8976.  Training acc: 85.85%.
[ Wed Jun 28 18:09:04 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:09:04 2023 ] Eval epoch: 9
[ Wed Jun 28 18:09:05 2023 ] 	Mean test loss of 625 batches: 0.607370.
[ Wed Jun 28 18:09:05 2023 ] 	Top1: 96.49%
[ Wed Jun 28 18:09:05 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:09:05 2023 ] Training epoch: 10
[ Wed Jun 28 18:09:08 2023 ] 	Training loss: 0.9855.  Training acc: 85.29%.
[ Wed Jun 28 18:09:08 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:09:08 2023 ] Eval epoch: 10
[ Wed Jun 28 18:09:08 2023 ] 	Mean test loss of 625 batches: 0.532451.
[ Wed Jun 28 18:09:08 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:09:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:09:08 2023 ] Training epoch: 11
[ Wed Jun 28 18:09:11 2023 ] 	Training loss: 0.8518.  Training acc: 89.80%.
[ Wed Jun 28 18:09:11 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:09:11 2023 ] Eval epoch: 11
[ Wed Jun 28 18:09:12 2023 ] 	Mean test loss of 625 batches: 0.418561.
[ Wed Jun 28 18:09:12 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:09:12 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:09:12 2023 ] Training epoch: 12
[ Wed Jun 28 18:09:15 2023 ] 	Training loss: 0.6311.  Training acc: 92.00%.
[ Wed Jun 28 18:09:15 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:09:15 2023 ] Eval epoch: 12
[ Wed Jun 28 18:09:15 2023 ] 	Mean test loss of 625 batches: 0.409207.
[ Wed Jun 28 18:09:15 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:09:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:09:15 2023 ] Training epoch: 13
[ Wed Jun 28 18:09:18 2023 ] 	Training loss: 0.5557.  Training acc: 93.66%.
[ Wed Jun 28 18:09:18 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:09:18 2023 ] Eval epoch: 13
[ Wed Jun 28 18:09:19 2023 ] 	Mean test loss of 625 batches: 0.395172.
[ Wed Jun 28 18:09:19 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:09:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:09:19 2023 ] Training epoch: 14
[ Wed Jun 28 18:09:22 2023 ] 	Training loss: 0.5568.  Training acc: 93.93%.
[ Wed Jun 28 18:09:22 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:09:22 2023 ] Eval epoch: 14
[ Wed Jun 28 18:09:23 2023 ] 	Mean test loss of 625 batches: 0.381180.
[ Wed Jun 28 18:09:23 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:09:23 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:09:23 2023 ] Training epoch: 15
[ Wed Jun 28 18:09:25 2023 ] 	Training loss: 0.5271.  Training acc: 93.38%.
[ Wed Jun 28 18:09:25 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:09:25 2023 ] Eval epoch: 15
[ Wed Jun 28 18:09:26 2023 ] 	Mean test loss of 625 batches: 0.363288.
[ Wed Jun 28 18:09:26 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:09:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:09:26 2023 ] Training epoch: 16
[ Wed Jun 28 18:09:29 2023 ] 	Training loss: 0.5135.  Training acc: 94.67%.
[ Wed Jun 28 18:09:29 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:09:29 2023 ] Eval epoch: 16
[ Wed Jun 28 18:09:30 2023 ] 	Mean test loss of 625 batches: 0.353142.
[ Wed Jun 28 18:09:30 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:09:30 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:09:30 2023 ] Training epoch: 17
[ Wed Jun 28 18:09:33 2023 ] 	Training loss: 0.5047.  Training acc: 94.85%.
[ Wed Jun 28 18:09:33 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:09:33 2023 ] Eval epoch: 17
[ Wed Jun 28 18:09:33 2023 ] 	Mean test loss of 625 batches: 0.366983.
[ Wed Jun 28 18:09:33 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:09:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:09:33 2023 ] Training epoch: 18
[ Wed Jun 28 18:09:36 2023 ] 	Training loss: 0.5034.  Training acc: 93.66%.
[ Wed Jun 28 18:09:36 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:09:36 2023 ] Eval epoch: 18
[ Wed Jun 28 18:09:37 2023 ] 	Mean test loss of 625 batches: 0.377093.
[ Wed Jun 28 18:09:37 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:09:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:09:37 2023 ] Training epoch: 19
[ Wed Jun 28 18:09:40 2023 ] 	Training loss: 0.4862.  Training acc: 95.31%.
[ Wed Jun 28 18:09:40 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:09:40 2023 ] Eval epoch: 19
[ Wed Jun 28 18:09:40 2023 ] 	Mean test loss of 625 batches: 0.362498.
[ Wed Jun 28 18:09:40 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:09:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:09:40 2023 ] Training epoch: 20
[ Wed Jun 28 18:09:43 2023 ] 	Training loss: 0.4435.  Training acc: 96.78%.
[ Wed Jun 28 18:09:43 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:09:43 2023 ] Eval epoch: 20
[ Wed Jun 28 18:09:44 2023 ] 	Mean test loss of 625 batches: 0.346445.
[ Wed Jun 28 18:09:44 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:09:44 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:09:44 2023 ] Training epoch: 21
[ Wed Jun 28 18:09:47 2023 ] 	Training loss: 0.4422.  Training acc: 96.97%.
[ Wed Jun 28 18:09:47 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:09:47 2023 ] Eval epoch: 21
[ Wed Jun 28 18:09:47 2023 ] 	Mean test loss of 625 batches: 0.358789.
[ Wed Jun 28 18:09:47 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:09:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:09:47 2023 ] Training epoch: 22
[ Wed Jun 28 18:09:50 2023 ] 	Training loss: 0.4292.  Training acc: 97.24%.
[ Wed Jun 28 18:09:50 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:09:50 2023 ] Eval epoch: 22
[ Wed Jun 28 18:09:51 2023 ] 	Mean test loss of 625 batches: 0.349957.
[ Wed Jun 28 18:09:51 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:09:51 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:09:51 2023 ] Training epoch: 23
[ Wed Jun 28 18:09:54 2023 ] 	Training loss: 0.4336.  Training acc: 97.24%.
[ Wed Jun 28 18:09:54 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:09:54 2023 ] Eval epoch: 23
[ Wed Jun 28 18:09:54 2023 ] 	Mean test loss of 625 batches: 0.361507.
[ Wed Jun 28 18:09:54 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:09:54 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:09:54 2023 ] Training epoch: 24
[ Wed Jun 28 18:09:57 2023 ] 	Training loss: 0.4096.  Training acc: 97.70%.
[ Wed Jun 28 18:09:57 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:09:57 2023 ] Eval epoch: 24
[ Wed Jun 28 18:09:58 2023 ] 	Mean test loss of 625 batches: 0.356599.
[ Wed Jun 28 18:09:58 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:09:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:09:58 2023 ] Training epoch: 25
[ Wed Jun 28 18:10:01 2023 ] 	Training loss: 0.4572.  Training acc: 94.39%.
[ Wed Jun 28 18:10:01 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:10:01 2023 ] Eval epoch: 25
[ Wed Jun 28 18:10:01 2023 ] 	Mean test loss of 625 batches: 0.358375.
[ Wed Jun 28 18:10:01 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:10:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:10:01 2023 ] Training epoch: 26
[ Wed Jun 28 18:10:04 2023 ] 	Training loss: 0.4271.  Training acc: 97.15%.
[ Wed Jun 28 18:10:04 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:10:04 2023 ] Eval epoch: 26
[ Wed Jun 28 18:10:05 2023 ] 	Mean test loss of 625 batches: 0.348772.
[ Wed Jun 28 18:10:05 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:10:05 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:10:05 2023 ] Training epoch: 27
[ Wed Jun 28 18:10:08 2023 ] 	Training loss: 0.4343.  Training acc: 96.78%.
[ Wed Jun 28 18:10:08 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:10:08 2023 ] Eval epoch: 27
[ Wed Jun 28 18:10:08 2023 ] 	Mean test loss of 625 batches: 0.352515.
[ Wed Jun 28 18:10:08 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:10:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:10:08 2023 ] Training epoch: 28
[ Wed Jun 28 18:10:11 2023 ] 	Training loss: 0.4442.  Training acc: 96.69%.
[ Wed Jun 28 18:10:11 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:10:11 2023 ] Eval epoch: 28
[ Wed Jun 28 18:10:12 2023 ] 	Mean test loss of 625 batches: 0.353599.
[ Wed Jun 28 18:10:12 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:10:12 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:10:12 2023 ] Training epoch: 29
[ Wed Jun 28 18:10:15 2023 ] 	Training loss: 0.4539.  Training acc: 96.05%.
[ Wed Jun 28 18:10:15 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:10:15 2023 ] Eval epoch: 29
[ Wed Jun 28 18:10:15 2023 ] 	Mean test loss of 625 batches: 0.344684.
[ Wed Jun 28 18:10:15 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:10:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:10:15 2023 ] Training epoch: 30
[ Wed Jun 28 18:10:18 2023 ] 	Training loss: 0.4272.  Training acc: 97.15%.
[ Wed Jun 28 18:10:18 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:10:18 2023 ] Eval epoch: 30
[ Wed Jun 28 18:10:19 2023 ] 	Mean test loss of 625 batches: 0.342207.
[ Wed Jun 28 18:10:19 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:10:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:10:20 2023 ] Best accuracy: 1.0
[ Wed Jun 28 18:10:20 2023 ] Epoch number: 13
[ Wed Jun 28 18:10:20 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 18:10:20 2023 ] Weight decay: 0.0005
[ Wed Jun 28 18:10:20 2023 ] Base LR: 0.1
[ Wed Jun 28 18:10:20 2023 ] Batch Size: 64
[ Wed Jun 28 18:10:20 2023 ] Test Batch Size: 64
[ Wed Jun 28 18:10:20 2023 ] seed: 1
[ Wed Jun 28 18:10:20 2023 ] Start training Corrector
[ Wed Jun 28 18:10:20 2023 ] # Parameters Corrector: 2407569
[ Wed Jun 28 18:10:21 2023 ] Training epoch: 1
[ Wed Jun 28 18:10:29 2023 ] 	Training loss: 16.5253.  Training acc: 47.66%.
[ Wed Jun 28 18:10:29 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 18:10:29 2023 ] Eval epoch: 1
[ Wed Jun 28 18:16:48 2023 ] using warm up, epoch: 5
[ Wed Jun 28 18:16:48 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 18:16:48 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 18:16:48 2023 ] Start training Predictor
[ Wed Jun 28 18:16:48 2023 ] Training epoch: 1
[ Wed Jun 28 18:16:54 2023 ] 	Training loss: 107.9483.  Training acc: 36.03%.
[ Wed Jun 28 18:16:54 2023 ] 	Time consumption: [Data]05%, [Network]94%
[ Wed Jun 28 18:16:54 2023 ] Eval epoch: 1
[ Wed Jun 28 18:16:55 2023 ] 	Mean test loss of 625 batches: 26998.896484.
[ Wed Jun 28 18:16:55 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:16:55 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:16:55 2023 ] Training epoch: 2
[ Wed Jun 28 18:16:58 2023 ] 	Training loss: 9.6511.  Training acc: 42.46%.
[ Wed Jun 28 18:16:58 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 18:16:58 2023 ] Eval epoch: 2
[ Wed Jun 28 18:16:58 2023 ] 	Mean test loss of 625 batches: 32.213341.
[ Wed Jun 28 18:16:58 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:16:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:16:58 2023 ] Training epoch: 3
[ Wed Jun 28 18:17:01 2023 ] 	Training loss: 4.7612.  Training acc: 58.09%.
[ Wed Jun 28 18:17:01 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:17:01 2023 ] Eval epoch: 3
[ Wed Jun 28 18:17:02 2023 ] 	Mean test loss of 625 batches: 6.185833.
[ Wed Jun 28 18:17:02 2023 ] 	Top1: 42.11%
[ Wed Jun 28 18:17:02 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:17:02 2023 ] Training epoch: 4
[ Wed Jun 28 18:17:05 2023 ] 	Training loss: 3.2921.  Training acc: 67.10%.
[ Wed Jun 28 18:17:05 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 18:17:05 2023 ] Eval epoch: 4
[ Wed Jun 28 18:17:06 2023 ] 	Mean test loss of 625 batches: 6.848259.
[ Wed Jun 28 18:17:06 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:17:06 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:17:06 2023 ] Training epoch: 5
[ Wed Jun 28 18:17:08 2023 ] 	Training loss: 6.1498.  Training acc: 62.32%.
[ Wed Jun 28 18:17:08 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:17:08 2023 ] Eval epoch: 5
[ Wed Jun 28 18:17:09 2023 ] 	Mean test loss of 625 batches: 5.325082.
[ Wed Jun 28 18:17:09 2023 ] 	Top1: 29.82%
[ Wed Jun 28 18:17:09 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:17:09 2023 ] Training epoch: 6
[ Wed Jun 28 18:17:12 2023 ] 	Training loss: 4.6279.  Training acc: 39.15%.
[ Wed Jun 28 18:17:12 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 18:17:12 2023 ] Eval epoch: 6
[ Wed Jun 28 18:17:13 2023 ] 	Mean test loss of 625 batches: 12.657973.
[ Wed Jun 28 18:17:13 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:17:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:17:13 2023 ] Training epoch: 7
[ Wed Jun 28 18:17:15 2023 ] 	Training loss: 2.7523.  Training acc: 35.29%.
[ Wed Jun 28 18:17:15 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:17:15 2023 ] Eval epoch: 7
[ Wed Jun 28 18:17:16 2023 ] 	Mean test loss of 625 batches: 9.790589.
[ Wed Jun 28 18:17:16 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:17:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:17:16 2023 ] Training epoch: 8
[ Wed Jun 28 18:17:19 2023 ] 	Training loss: 2.1312.  Training acc: 39.98%.
[ Wed Jun 28 18:17:19 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 18:17:19 2023 ] Eval epoch: 8
[ Wed Jun 28 18:17:20 2023 ] 	Mean test loss of 625 batches: 1.638585.
[ Wed Jun 28 18:17:20 2023 ] 	Top1: 33.33%
[ Wed Jun 28 18:17:20 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:17:20 2023 ] Training epoch: 9
[ Wed Jun 28 18:17:22 2023 ] 	Training loss: 2.4095.  Training acc: 42.56%.
[ Wed Jun 28 18:17:22 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:17:22 2023 ] Eval epoch: 9
[ Wed Jun 28 18:17:23 2023 ] 	Mean test loss of 625 batches: 1.897448.
[ Wed Jun 28 18:17:23 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:17:23 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:17:23 2023 ] Training epoch: 10
[ Wed Jun 28 18:17:26 2023 ] 	Training loss: 1.8143.  Training acc: 46.69%.
[ Wed Jun 28 18:17:26 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:17:26 2023 ] Eval epoch: 10
[ Wed Jun 28 18:17:27 2023 ] 	Mean test loss of 625 batches: 2.455416.
[ Wed Jun 28 18:17:27 2023 ] 	Top1: 49.12%
[ Wed Jun 28 18:17:27 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:17:27 2023 ] Training epoch: 11
[ Wed Jun 28 18:17:30 2023 ] 	Training loss: 1.3086.  Training acc: 57.63%.
[ Wed Jun 28 18:17:30 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:17:30 2023 ] Eval epoch: 11
[ Wed Jun 28 18:17:30 2023 ] 	Mean test loss of 625 batches: 0.785123.
[ Wed Jun 28 18:17:30 2023 ] 	Top1: 50.88%
[ Wed Jun 28 18:17:30 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:17:30 2023 ] Training epoch: 12
[ Wed Jun 28 18:17:33 2023 ] 	Training loss: 1.0693.  Training acc: 59.38%.
[ Wed Jun 28 18:17:33 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:17:33 2023 ] Eval epoch: 12
[ Wed Jun 28 18:17:34 2023 ] 	Mean test loss of 625 batches: 0.685104.
[ Wed Jun 28 18:17:34 2023 ] 	Top1: 66.67%
[ Wed Jun 28 18:17:34 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:17:34 2023 ] Training epoch: 13
[ Wed Jun 28 18:17:37 2023 ] 	Training loss: 0.8902.  Training acc: 63.69%.
[ Wed Jun 28 18:17:37 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:17:37 2023 ] Eval epoch: 13
[ Wed Jun 28 18:17:38 2023 ] 	Mean test loss of 625 batches: 0.692409.
[ Wed Jun 28 18:17:38 2023 ] 	Top1: 71.93%
[ Wed Jun 28 18:17:38 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:17:38 2023 ] Training epoch: 14
[ Wed Jun 28 18:17:41 2023 ] 	Training loss: 0.8599.  Training acc: 63.33%.
[ Wed Jun 28 18:17:41 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:17:41 2023 ] Eval epoch: 14
[ Wed Jun 28 18:17:41 2023 ] 	Mean test loss of 625 batches: 0.663463.
[ Wed Jun 28 18:17:41 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:17:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:17:41 2023 ] Training epoch: 15
[ Wed Jun 28 18:17:44 2023 ] 	Training loss: 0.8232.  Training acc: 64.71%.
[ Wed Jun 28 18:17:44 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:17:44 2023 ] Eval epoch: 15
[ Wed Jun 28 18:17:45 2023 ] 	Mean test loss of 625 batches: 0.660579.
[ Wed Jun 28 18:17:45 2023 ] 	Top1: 77.19%
[ Wed Jun 28 18:17:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:17:45 2023 ] Training epoch: 16
[ Wed Jun 28 18:17:48 2023 ] 	Training loss: 0.8006.  Training acc: 67.83%.
[ Wed Jun 28 18:17:48 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:17:48 2023 ] Eval epoch: 16
[ Wed Jun 28 18:17:49 2023 ] 	Mean test loss of 625 batches: 0.643468.
[ Wed Jun 28 18:17:49 2023 ] 	Top1: 75.44%
[ Wed Jun 28 18:17:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:17:49 2023 ] Training epoch: 17
[ Wed Jun 28 18:17:52 2023 ] 	Training loss: 0.7678.  Training acc: 70.96%.
[ Wed Jun 28 18:17:52 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:17:52 2023 ] Eval epoch: 17
[ Wed Jun 28 18:17:53 2023 ] 	Mean test loss of 625 batches: 0.646703.
[ Wed Jun 28 18:17:53 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:17:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:17:53 2023 ] Training epoch: 18
[ Wed Jun 28 18:17:56 2023 ] 	Training loss: 0.7343.  Training acc: 73.71%.
[ Wed Jun 28 18:17:56 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 18:17:56 2023 ] Eval epoch: 18
[ Wed Jun 28 18:17:56 2023 ] 	Mean test loss of 625 batches: 0.725437.
[ Wed Jun 28 18:17:56 2023 ] 	Top1: 73.68%
[ Wed Jun 28 18:17:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:17:56 2023 ] Training epoch: 19
[ Wed Jun 28 18:17:59 2023 ] 	Training loss: 0.7439.  Training acc: 72.79%.
[ Wed Jun 28 18:17:59 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 18:17:59 2023 ] Eval epoch: 19
[ Wed Jun 28 18:18:00 2023 ] 	Mean test loss of 625 batches: 0.649113.
[ Wed Jun 28 18:18:00 2023 ] 	Top1: 80.70%
[ Wed Jun 28 18:18:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:18:00 2023 ] Training epoch: 20
[ Wed Jun 28 18:18:03 2023 ] 	Training loss: 0.6882.  Training acc: 77.94%.
[ Wed Jun 28 18:18:03 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 18:18:03 2023 ] Eval epoch: 20
[ Wed Jun 28 18:18:04 2023 ] 	Mean test loss of 625 batches: 0.700335.
[ Wed Jun 28 18:18:04 2023 ] 	Top1: 80.70%
[ Wed Jun 28 18:18:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:18:04 2023 ] Training epoch: 21
[ Wed Jun 28 18:18:07 2023 ] 	Training loss: 0.6944.  Training acc: 78.68%.
[ Wed Jun 28 18:18:07 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Wed Jun 28 18:18:07 2023 ] Eval epoch: 21
[ Wed Jun 28 18:18:07 2023 ] 	Mean test loss of 625 batches: 0.624472.
[ Wed Jun 28 18:18:07 2023 ] 	Top1: 82.46%
[ Wed Jun 28 18:18:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:18:07 2023 ] Training epoch: 22
[ Wed Jun 28 18:18:10 2023 ] 	Training loss: 0.6743.  Training acc: 78.12%.
[ Wed Jun 28 18:18:10 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 18:18:10 2023 ] Eval epoch: 22
[ Wed Jun 28 18:18:11 2023 ] 	Mean test loss of 625 batches: 0.643255.
[ Wed Jun 28 18:18:11 2023 ] 	Top1: 82.46%
[ Wed Jun 28 18:18:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:18:11 2023 ] Training epoch: 23
[ Wed Jun 28 18:18:14 2023 ] 	Training loss: 0.6609.  Training acc: 78.77%.
[ Wed Jun 28 18:18:14 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 18:18:14 2023 ] Eval epoch: 23
[ Wed Jun 28 18:18:15 2023 ] 	Mean test loss of 625 batches: 0.643545.
[ Wed Jun 28 18:18:15 2023 ] 	Top1: 80.70%
[ Wed Jun 28 18:18:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:18:15 2023 ] Training epoch: 24
[ Wed Jun 28 18:18:18 2023 ] 	Training loss: 0.6532.  Training acc: 81.16%.
[ Wed Jun 28 18:18:18 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 18:18:18 2023 ] Eval epoch: 24
[ Wed Jun 28 18:18:18 2023 ] 	Mean test loss of 625 batches: 0.629635.
[ Wed Jun 28 18:18:18 2023 ] 	Top1: 82.46%
[ Wed Jun 28 18:18:18 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:18:18 2023 ] Training epoch: 25
[ Wed Jun 28 18:18:21 2023 ] 	Training loss: 0.6622.  Training acc: 80.79%.
[ Wed Jun 28 18:18:21 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 18:18:21 2023 ] Eval epoch: 25
[ Wed Jun 28 18:18:22 2023 ] 	Mean test loss of 625 batches: 0.633171.
[ Wed Jun 28 18:18:22 2023 ] 	Top1: 84.21%
[ Wed Jun 28 18:18:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:18:22 2023 ] Training epoch: 26
[ Wed Jun 28 18:18:25 2023 ] 	Training loss: 0.6480.  Training acc: 81.07%.
[ Wed Jun 28 18:18:25 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 18:18:25 2023 ] Eval epoch: 26
[ Wed Jun 28 18:18:26 2023 ] 	Mean test loss of 625 batches: 0.637941.
[ Wed Jun 28 18:18:26 2023 ] 	Top1: 80.70%
[ Wed Jun 28 18:18:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:18:26 2023 ] Training epoch: 27
[ Wed Jun 28 18:18:29 2023 ] 	Training loss: 0.6707.  Training acc: 81.07%.
[ Wed Jun 28 18:18:29 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 18:18:29 2023 ] Eval epoch: 27
[ Wed Jun 28 18:18:30 2023 ] 	Mean test loss of 625 batches: 0.645855.
[ Wed Jun 28 18:18:30 2023 ] 	Top1: 82.46%
[ Wed Jun 28 18:18:30 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:18:30 2023 ] Training epoch: 28
[ Wed Jun 28 18:18:33 2023 ] 	Training loss: 0.6284.  Training acc: 84.65%.
[ Wed Jun 28 18:18:33 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:18:33 2023 ] Eval epoch: 28
[ Wed Jun 28 18:18:33 2023 ] 	Mean test loss of 625 batches: 0.618974.
[ Wed Jun 28 18:18:33 2023 ] 	Top1: 82.46%
[ Wed Jun 28 18:18:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:18:33 2023 ] Training epoch: 29
[ Wed Jun 28 18:18:36 2023 ] 	Training loss: 0.6355.  Training acc: 83.36%.
[ Wed Jun 28 18:18:36 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 18:18:36 2023 ] Eval epoch: 29
[ Wed Jun 28 18:18:37 2023 ] 	Mean test loss of 625 batches: 0.621508.
[ Wed Jun 28 18:18:37 2023 ] 	Top1: 80.70%
[ Wed Jun 28 18:18:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:18:37 2023 ] Training epoch: 30
[ Wed Jun 28 18:18:40 2023 ] 	Training loss: 0.6074.  Training acc: 86.03%.
[ Wed Jun 28 18:18:40 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 18:18:40 2023 ] Eval epoch: 30
[ Wed Jun 28 18:18:41 2023 ] 	Mean test loss of 625 batches: 0.625453.
[ Wed Jun 28 18:18:41 2023 ] 	Top1: 82.46%
[ Wed Jun 28 18:18:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:18:41 2023 ] Best accuracy: 0.8421052631578947
[ Wed Jun 28 18:18:41 2023 ] Epoch number: 25
[ Wed Jun 28 18:18:41 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 18:18:41 2023 ] Weight decay: 0.0005
[ Wed Jun 28 18:18:41 2023 ] Base LR: 0.1
[ Wed Jun 28 18:18:41 2023 ] Batch Size: 64
[ Wed Jun 28 18:18:41 2023 ] Test Batch Size: 64
[ Wed Jun 28 18:18:41 2023 ] seed: 1
[ Wed Jun 28 18:18:41 2023 ] Start training Corrector
[ Wed Jun 28 18:18:41 2023 ] # Parameters Corrector: 2407569
[ Wed Jun 28 18:18:43 2023 ] Training epoch: 1
[ Wed Jun 28 18:18:51 2023 ] 	Training loss: 22.4531.  Training acc: 48.70%.
[ Wed Jun 28 18:18:51 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:18:51 2023 ] Eval epoch: 1
[ Wed Jun 28 18:20:54 2023 ] using warm up, epoch: 5
[ Wed Jun 28 18:20:54 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 18:20:54 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 18:20:54 2023 ] Start training Predictor
[ Wed Jun 28 18:20:54 2023 ] Training epoch: 1
[ Wed Jun 28 18:20:59 2023 ] 	Training loss: 117.9010.  Training acc: 35.29%.
[ Wed Jun 28 18:20:59 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 18:20:59 2023 ] Eval epoch: 1
[ Wed Jun 28 18:21:01 2023 ] 	Mean test loss of 625 batches: 855.861804.
[ Wed Jun 28 18:21:01 2023 ] 	Top1: 29.82%
[ Wed Jun 28 18:21:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:21:01 2023 ] Training epoch: 2
[ Wed Jun 28 18:21:03 2023 ] 	Training loss: 10.8031.  Training acc: 35.85%.
[ Wed Jun 28 18:21:03 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:21:03 2023 ] Eval epoch: 2
[ Wed Jun 28 18:21:04 2023 ] 	Mean test loss of 625 batches: 2.493700.
[ Wed Jun 28 18:21:04 2023 ] 	Top1: 40.35%
[ Wed Jun 28 18:21:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:21:04 2023 ] Training epoch: 3
[ Wed Jun 28 18:21:07 2023 ] 	Training loss: 6.7318.  Training acc: 39.43%.
[ Wed Jun 28 18:21:07 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:21:07 2023 ] Eval epoch: 3
[ Wed Jun 28 18:21:08 2023 ] 	Mean test loss of 625 batches: 4.229662.
[ Wed Jun 28 18:21:08 2023 ] 	Top1: 33.33%
[ Wed Jun 28 18:21:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:21:08 2023 ] Training epoch: 4
[ Wed Jun 28 18:21:10 2023 ] 	Training loss: 5.0452.  Training acc: 45.22%.
[ Wed Jun 28 18:21:10 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:21:10 2023 ] Eval epoch: 4
[ Wed Jun 28 18:21:11 2023 ] 	Mean test loss of 625 batches: 2.793255.
[ Wed Jun 28 18:21:11 2023 ] 	Top1: 50.88%
[ Wed Jun 28 18:21:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:21:11 2023 ] Training epoch: 5
[ Wed Jun 28 18:21:14 2023 ] 	Training loss: 5.8597.  Training acc: 55.06%.
[ Wed Jun 28 18:21:14 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:21:14 2023 ] Eval epoch: 5
[ Wed Jun 28 18:21:15 2023 ] 	Mean test loss of 625 batches: 2.376221.
[ Wed Jun 28 18:21:15 2023 ] 	Top1: 61.40%
[ Wed Jun 28 18:21:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:21:15 2023 ] Training epoch: 6
[ Wed Jun 28 18:21:18 2023 ] 	Training loss: 2.1909.  Training acc: 70.04%.
[ Wed Jun 28 18:21:18 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:21:18 2023 ] Eval epoch: 6
[ Wed Jun 28 18:21:18 2023 ] 	Mean test loss of 625 batches: 2.664473.
[ Wed Jun 28 18:21:18 2023 ] 	Top1: 80.70%
[ Wed Jun 28 18:21:18 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:21:18 2023 ] Training epoch: 7
[ Wed Jun 28 18:21:21 2023 ] 	Training loss: 1.7214.  Training acc: 69.67%.
[ Wed Jun 28 18:21:21 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:21:21 2023 ] Eval epoch: 7
[ Wed Jun 28 18:21:22 2023 ] 	Mean test loss of 625 batches: 0.929677.
[ Wed Jun 28 18:21:22 2023 ] 	Top1: 91.23%
[ Wed Jun 28 18:21:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:21:22 2023 ] Training epoch: 8
[ Wed Jun 28 18:21:25 2023 ] 	Training loss: 1.4555.  Training acc: 70.31%.
[ Wed Jun 28 18:21:25 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:21:25 2023 ] Eval epoch: 8
[ Wed Jun 28 18:21:25 2023 ] 	Mean test loss of 625 batches: 0.901801.
[ Wed Jun 28 18:21:25 2023 ] 	Top1: 84.21%
[ Wed Jun 28 18:21:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:21:25 2023 ] Training epoch: 9
[ Wed Jun 28 18:21:28 2023 ] 	Training loss: 1.3326.  Training acc: 77.02%.
[ Wed Jun 28 18:21:28 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:21:28 2023 ] Eval epoch: 9
[ Wed Jun 28 18:21:29 2023 ] 	Mean test loss of 625 batches: 1.027081.
[ Wed Jun 28 18:21:29 2023 ] 	Top1: 73.68%
[ Wed Jun 28 18:21:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:21:29 2023 ] Training epoch: 10
[ Wed Jun 28 18:21:32 2023 ] 	Training loss: 1.1899.  Training acc: 77.21%.
[ Wed Jun 28 18:21:32 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:21:32 2023 ] Eval epoch: 10
[ Wed Jun 28 18:21:32 2023 ] 	Mean test loss of 625 batches: 1.008517.
[ Wed Jun 28 18:21:32 2023 ] 	Top1: 82.46%
[ Wed Jun 28 18:21:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:21:32 2023 ] Training epoch: 11
[ Wed Jun 28 18:21:35 2023 ] 	Training loss: 0.9460.  Training acc: 83.92%.
[ Wed Jun 28 18:21:35 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:21:35 2023 ] Eval epoch: 11
[ Wed Jun 28 18:21:36 2023 ] 	Mean test loss of 625 batches: 0.719429.
[ Wed Jun 28 18:21:36 2023 ] 	Top1: 87.72%
[ Wed Jun 28 18:21:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:21:36 2023 ] Training epoch: 12
[ Wed Jun 28 18:21:39 2023 ] 	Training loss: 0.8982.  Training acc: 84.28%.
[ Wed Jun 28 18:21:39 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:21:39 2023 ] Eval epoch: 12
[ Wed Jun 28 18:21:39 2023 ] 	Mean test loss of 625 batches: 0.692958.
[ Wed Jun 28 18:21:39 2023 ] 	Top1: 85.96%
[ Wed Jun 28 18:21:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:21:39 2023 ] Training epoch: 13
[ Wed Jun 28 18:21:42 2023 ] 	Training loss: 0.8456.  Training acc: 85.02%.
[ Wed Jun 28 18:21:42 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:21:42 2023 ] Eval epoch: 13
[ Wed Jun 28 18:21:43 2023 ] 	Mean test loss of 625 batches: 0.644784.
[ Wed Jun 28 18:21:43 2023 ] 	Top1: 89.47%
[ Wed Jun 28 18:21:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:21:43 2023 ] Training epoch: 14
[ Wed Jun 28 18:21:46 2023 ] 	Training loss: 0.8556.  Training acc: 84.74%.
[ Wed Jun 28 18:21:46 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:21:46 2023 ] Eval epoch: 14
[ Wed Jun 28 18:21:47 2023 ] 	Mean test loss of 625 batches: 0.649052.
[ Wed Jun 28 18:21:47 2023 ] 	Top1: 94.74%
[ Wed Jun 28 18:21:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:21:47 2023 ] Training epoch: 15
[ Wed Jun 28 18:21:49 2023 ] 	Training loss: 0.8457.  Training acc: 86.12%.
[ Wed Jun 28 18:21:49 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:21:49 2023 ] Eval epoch: 15
[ Wed Jun 28 18:21:50 2023 ] 	Mean test loss of 625 batches: 0.623498.
[ Wed Jun 28 18:21:50 2023 ] 	Top1: 96.49%
[ Wed Jun 28 18:21:50 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:21:50 2023 ] Training epoch: 16
[ Wed Jun 28 18:21:53 2023 ] 	Training loss: 0.8596.  Training acc: 84.74%.
[ Wed Jun 28 18:21:53 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:21:53 2023 ] Eval epoch: 16
[ Wed Jun 28 18:21:54 2023 ] 	Mean test loss of 625 batches: 0.580832.
[ Wed Jun 28 18:21:54 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:21:54 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:21:54 2023 ] Training epoch: 17
[ Wed Jun 28 18:21:56 2023 ] 	Training loss: 0.8050.  Training acc: 87.59%.
[ Wed Jun 28 18:21:56 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:21:56 2023 ] Eval epoch: 17
[ Wed Jun 28 18:21:57 2023 ] 	Mean test loss of 625 batches: 0.599468.
[ Wed Jun 28 18:21:57 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:21:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:21:57 2023 ] Training epoch: 18
[ Wed Jun 28 18:22:00 2023 ] 	Training loss: 0.7807.  Training acc: 87.04%.
[ Wed Jun 28 18:22:00 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:22:00 2023 ] Eval epoch: 18
[ Wed Jun 28 18:22:01 2023 ] 	Mean test loss of 625 batches: 0.576374.
[ Wed Jun 28 18:22:01 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:22:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:22:01 2023 ] Training epoch: 19
[ Wed Jun 28 18:22:04 2023 ] 	Training loss: 0.8125.  Training acc: 87.04%.
[ Wed Jun 28 18:22:04 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:22:04 2023 ] Eval epoch: 19
[ Wed Jun 28 18:22:04 2023 ] 	Mean test loss of 625 batches: 0.541221.
[ Wed Jun 28 18:22:04 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:22:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:22:04 2023 ] Training epoch: 20
[ Wed Jun 28 18:22:07 2023 ] 	Training loss: 0.7790.  Training acc: 86.58%.
[ Wed Jun 28 18:22:07 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:22:07 2023 ] Eval epoch: 20
[ Wed Jun 28 18:22:08 2023 ] 	Mean test loss of 625 batches: 0.554574.
[ Wed Jun 28 18:22:08 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:22:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:22:08 2023 ] Training epoch: 21
[ Wed Jun 28 18:22:11 2023 ] 	Training loss: 0.7338.  Training acc: 89.34%.
[ Wed Jun 28 18:22:11 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:22:11 2023 ] Eval epoch: 21
[ Wed Jun 28 18:22:11 2023 ] 	Mean test loss of 625 batches: 0.575313.
[ Wed Jun 28 18:22:11 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:22:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:22:11 2023 ] Training epoch: 22
[ Wed Jun 28 18:22:14 2023 ] 	Training loss: 0.7464.  Training acc: 89.61%.
[ Wed Jun 28 18:22:14 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:22:14 2023 ] Eval epoch: 22
[ Wed Jun 28 18:22:15 2023 ] 	Mean test loss of 625 batches: 0.565583.
[ Wed Jun 28 18:22:15 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:22:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:22:15 2023 ] Training epoch: 23
[ Wed Jun 28 18:22:17 2023 ] 	Training loss: 0.7475.  Training acc: 87.68%.
[ Wed Jun 28 18:22:17 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:22:17 2023 ] Eval epoch: 23
[ Wed Jun 28 18:22:18 2023 ] 	Mean test loss of 625 batches: 0.558172.
[ Wed Jun 28 18:22:18 2023 ] 	Top1: 94.74%
[ Wed Jun 28 18:22:18 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:22:18 2023 ] Training epoch: 24
[ Wed Jun 28 18:22:21 2023 ] 	Training loss: 0.7097.  Training acc: 89.61%.
[ Wed Jun 28 18:22:21 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:22:21 2023 ] Eval epoch: 24
[ Wed Jun 28 18:22:22 2023 ] 	Mean test loss of 625 batches: 0.551095.
[ Wed Jun 28 18:22:22 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:22:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:22:22 2023 ] Training epoch: 25
[ Wed Jun 28 18:22:25 2023 ] 	Training loss: 0.7468.  Training acc: 88.42%.
[ Wed Jun 28 18:22:25 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:22:25 2023 ] Eval epoch: 25
[ Wed Jun 28 18:22:25 2023 ] 	Mean test loss of 625 batches: 0.548586.
[ Wed Jun 28 18:22:25 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:22:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:22:25 2023 ] Training epoch: 26
[ Wed Jun 28 18:22:28 2023 ] 	Training loss: 0.7559.  Training acc: 89.06%.
[ Wed Jun 28 18:22:28 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:22:28 2023 ] Eval epoch: 26
[ Wed Jun 28 18:22:29 2023 ] 	Mean test loss of 625 batches: 0.540772.
[ Wed Jun 28 18:22:29 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:22:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:22:29 2023 ] Training epoch: 27
[ Wed Jun 28 18:22:32 2023 ] 	Training loss: 0.7653.  Training acc: 89.71%.
[ Wed Jun 28 18:22:32 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 18:22:32 2023 ] Eval epoch: 27
[ Wed Jun 28 18:22:32 2023 ] 	Mean test loss of 625 batches: 0.543478.
[ Wed Jun 28 18:22:32 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:22:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:22:32 2023 ] Training epoch: 28
[ Wed Jun 28 18:22:35 2023 ] 	Training loss: 0.7267.  Training acc: 89.15%.
[ Wed Jun 28 18:22:35 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:22:35 2023 ] Eval epoch: 28
[ Wed Jun 28 18:22:36 2023 ] 	Mean test loss of 625 batches: 0.545013.
[ Wed Jun 28 18:22:36 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:22:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:22:36 2023 ] Training epoch: 29
[ Wed Jun 28 18:22:39 2023 ] 	Training loss: 0.7262.  Training acc: 90.17%.
[ Wed Jun 28 18:22:39 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:22:39 2023 ] Eval epoch: 29
[ Wed Jun 28 18:22:39 2023 ] 	Mean test loss of 625 batches: 0.532748.
[ Wed Jun 28 18:22:39 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:22:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:22:39 2023 ] Training epoch: 30
[ Wed Jun 28 18:22:42 2023 ] 	Training loss: 0.7029.  Training acc: 90.62%.
[ Wed Jun 28 18:22:42 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:22:42 2023 ] Eval epoch: 30
[ Wed Jun 28 18:22:43 2023 ] 	Mean test loss of 625 batches: 0.534658.
[ Wed Jun 28 18:22:43 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:22:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:22:44 2023 ] Best accuracy: 1.0
[ Wed Jun 28 18:22:44 2023 ] Epoch number: 18
[ Wed Jun 28 18:22:44 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 18:22:44 2023 ] Weight decay: 0.0005
[ Wed Jun 28 18:22:44 2023 ] Base LR: 0.1
[ Wed Jun 28 18:22:44 2023 ] Batch Size: 64
[ Wed Jun 28 18:22:44 2023 ] Test Batch Size: 64
[ Wed Jun 28 18:22:44 2023 ] seed: 1
[ Wed Jun 28 18:22:44 2023 ] Start training Corrector
[ Wed Jun 28 18:22:44 2023 ] # Parameters Corrector: 2407569
[ Wed Jun 28 18:22:45 2023 ] Training epoch: 1
[ Wed Jun 28 18:22:53 2023 ] 	Training loss: 19.9489.  Training acc: 49.48%.
[ Wed Jun 28 18:22:53 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 18:22:53 2023 ] Eval epoch: 1
[ Wed Jun 28 18:28:51 2023 ] using warm up, epoch: 5
[ Wed Jun 28 18:28:52 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 18:28:52 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 18:28:52 2023 ] Start training Predictor
[ Wed Jun 28 18:28:52 2023 ] Training epoch: 1
[ Wed Jun 28 18:28:57 2023 ] 	Training loss: 103.6114.  Training acc: 34.10%.
[ Wed Jun 28 18:28:57 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 18:28:57 2023 ] Eval epoch: 1
[ Wed Jun 28 18:28:58 2023 ] 	Mean test loss of 625 batches: 771.038281.
[ Wed Jun 28 18:28:58 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:28:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:28:58 2023 ] Training epoch: 2
[ Wed Jun 28 18:29:01 2023 ] 	Training loss: 8.1105.  Training acc: 41.91%.
[ Wed Jun 28 18:29:01 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:29:01 2023 ] Eval epoch: 2
[ Wed Jun 28 18:29:02 2023 ] 	Mean test loss of 625 batches: 7.245280.
[ Wed Jun 28 18:29:02 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:29:02 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:29:02 2023 ] Training epoch: 3
[ Wed Jun 28 18:29:05 2023 ] 	Training loss: 4.5822.  Training acc: 58.82%.
[ Wed Jun 28 18:29:05 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:29:05 2023 ] Eval epoch: 3
[ Wed Jun 28 18:29:05 2023 ] 	Mean test loss of 625 batches: 1.702024.
[ Wed Jun 28 18:29:05 2023 ] 	Top1: 61.40%
[ Wed Jun 28 18:29:05 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:29:05 2023 ] Training epoch: 4
[ Wed Jun 28 18:29:08 2023 ] 	Training loss: 3.4249.  Training acc: 61.12%.
[ Wed Jun 28 18:29:08 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:29:08 2023 ] Eval epoch: 4
[ Wed Jun 28 18:29:09 2023 ] 	Mean test loss of 625 batches: 3.957944.
[ Wed Jun 28 18:29:09 2023 ] 	Top1: 64.91%
[ Wed Jun 28 18:29:09 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:29:09 2023 ] Training epoch: 5
[ Wed Jun 28 18:29:12 2023 ] 	Training loss: 3.0345.  Training acc: 65.44%.
[ Wed Jun 28 18:29:12 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:29:12 2023 ] Eval epoch: 5
[ Wed Jun 28 18:29:12 2023 ] 	Mean test loss of 625 batches: 2.260151.
[ Wed Jun 28 18:29:12 2023 ] 	Top1: 75.44%
[ Wed Jun 28 18:29:12 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:29:12 2023 ] Training epoch: 6
[ Wed Jun 28 18:29:15 2023 ] 	Training loss: 3.0375.  Training acc: 71.14%.
[ Wed Jun 28 18:29:15 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:29:15 2023 ] Eval epoch: 6
[ Wed Jun 28 18:29:16 2023 ] 	Mean test loss of 625 batches: 2.796725.
[ Wed Jun 28 18:29:16 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:29:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:29:16 2023 ] Training epoch: 7
[ Wed Jun 28 18:29:19 2023 ] 	Training loss: 1.6159.  Training acc: 63.60%.
[ Wed Jun 28 18:29:19 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:29:19 2023 ] Eval epoch: 7
[ Wed Jun 28 18:29:20 2023 ] 	Mean test loss of 625 batches: 2.318402.
[ Wed Jun 28 18:29:20 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:29:20 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:29:20 2023 ] Training epoch: 8
[ Wed Jun 28 18:29:22 2023 ] 	Training loss: 2.1160.  Training acc: 53.12%.
[ Wed Jun 28 18:29:22 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:29:22 2023 ] Eval epoch: 8
[ Wed Jun 28 18:29:23 2023 ] 	Mean test loss of 625 batches: 1.184130.
[ Wed Jun 28 18:29:23 2023 ] 	Top1: 71.93%
[ Wed Jun 28 18:29:23 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:29:23 2023 ] Training epoch: 9
[ Wed Jun 28 18:29:26 2023 ] 	Training loss: 1.2950.  Training acc: 62.78%.
[ Wed Jun 28 18:29:26 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:29:26 2023 ] Eval epoch: 9
[ Wed Jun 28 18:29:27 2023 ] 	Mean test loss of 625 batches: 0.992577.
[ Wed Jun 28 18:29:27 2023 ] 	Top1: 66.67%
[ Wed Jun 28 18:29:27 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:29:27 2023 ] Training epoch: 10
[ Wed Jun 28 18:29:29 2023 ] 	Training loss: 1.7602.  Training acc: 64.06%.
[ Wed Jun 28 18:29:29 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:29:29 2023 ] Eval epoch: 10
[ Wed Jun 28 18:29:30 2023 ] 	Mean test loss of 625 batches: 0.816253.
[ Wed Jun 28 18:29:30 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:29:30 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:29:30 2023 ] Training epoch: 11
[ Wed Jun 28 18:29:33 2023 ] 	Training loss: 0.8895.  Training acc: 70.04%.
[ Wed Jun 28 18:29:33 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:29:33 2023 ] Eval epoch: 11
[ Wed Jun 28 18:29:34 2023 ] 	Mean test loss of 625 batches: 0.684978.
[ Wed Jun 28 18:29:34 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:29:34 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:29:34 2023 ] Training epoch: 12
[ Wed Jun 28 18:29:37 2023 ] 	Training loss: 0.8180.  Training acc: 73.44%.
[ Wed Jun 28 18:29:37 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:29:37 2023 ] Eval epoch: 12
[ Wed Jun 28 18:29:37 2023 ] 	Mean test loss of 625 batches: 0.639639.
[ Wed Jun 28 18:29:37 2023 ] 	Top1: 75.44%
[ Wed Jun 28 18:29:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:29:37 2023 ] Training epoch: 13
[ Wed Jun 28 18:29:40 2023 ] 	Training loss: 0.7679.  Training acc: 76.75%.
[ Wed Jun 28 18:29:40 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:29:40 2023 ] Eval epoch: 13
[ Wed Jun 28 18:29:41 2023 ] 	Mean test loss of 625 batches: 0.623544.
[ Wed Jun 28 18:29:41 2023 ] 	Top1: 92.98%
[ Wed Jun 28 18:29:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:29:41 2023 ] Training epoch: 14
[ Wed Jun 28 18:29:44 2023 ] 	Training loss: 0.7175.  Training acc: 81.16%.
[ Wed Jun 28 18:29:44 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:29:44 2023 ] Eval epoch: 14
[ Wed Jun 28 18:29:44 2023 ] 	Mean test loss of 625 batches: 0.589306.
[ Wed Jun 28 18:29:44 2023 ] 	Top1: 77.19%
[ Wed Jun 28 18:29:44 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:29:44 2023 ] Training epoch: 15
[ Wed Jun 28 18:29:47 2023 ] 	Training loss: 0.7589.  Training acc: 78.86%.
[ Wed Jun 28 18:29:47 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:29:47 2023 ] Eval epoch: 15
[ Wed Jun 28 18:29:48 2023 ] 	Mean test loss of 625 batches: 0.596924.
[ Wed Jun 28 18:29:48 2023 ] 	Top1: 92.98%
[ Wed Jun 28 18:29:48 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:29:48 2023 ] Training epoch: 16
[ Wed Jun 28 18:29:51 2023 ] 	Training loss: 0.7217.  Training acc: 81.89%.
[ Wed Jun 28 18:29:51 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:29:51 2023 ] Eval epoch: 16
[ Wed Jun 28 18:29:51 2023 ] 	Mean test loss of 625 batches: 0.538455.
[ Wed Jun 28 18:29:51 2023 ] 	Top1: 96.49%
[ Wed Jun 28 18:29:51 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:29:51 2023 ] Training epoch: 17
[ Wed Jun 28 18:29:54 2023 ] 	Training loss: 0.6871.  Training acc: 84.93%.
[ Wed Jun 28 18:29:54 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:29:54 2023 ] Eval epoch: 17
[ Wed Jun 28 18:29:55 2023 ] 	Mean test loss of 625 batches: 0.511233.
[ Wed Jun 28 18:29:55 2023 ] 	Top1: 94.74%
[ Wed Jun 28 18:29:55 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:29:55 2023 ] Training epoch: 18
[ Wed Jun 28 18:29:58 2023 ] 	Training loss: 0.6913.  Training acc: 82.72%.
[ Wed Jun 28 18:29:58 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:29:58 2023 ] Eval epoch: 18
[ Wed Jun 28 18:29:59 2023 ] 	Mean test loss of 625 batches: 0.548077.
[ Wed Jun 28 18:29:59 2023 ] 	Top1: 85.96%
[ Wed Jun 28 18:29:59 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:29:59 2023 ] Training epoch: 19
[ Wed Jun 28 18:30:01 2023 ] 	Training loss: 0.7011.  Training acc: 83.46%.
[ Wed Jun 28 18:30:01 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:30:01 2023 ] Eval epoch: 19
[ Wed Jun 28 18:30:02 2023 ] 	Mean test loss of 625 batches: 0.503449.
[ Wed Jun 28 18:30:02 2023 ] 	Top1: 96.49%
[ Wed Jun 28 18:30:02 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:30:02 2023 ] Training epoch: 20
[ Wed Jun 28 18:30:05 2023 ] 	Training loss: 0.6567.  Training acc: 85.75%.
[ Wed Jun 28 18:30:05 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:30:05 2023 ] Eval epoch: 20
[ Wed Jun 28 18:30:06 2023 ] 	Mean test loss of 625 batches: 0.578459.
[ Wed Jun 28 18:30:06 2023 ] 	Top1: 84.21%
[ Wed Jun 28 18:30:06 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:30:06 2023 ] Training epoch: 21
[ Wed Jun 28 18:30:08 2023 ] 	Training loss: 0.6513.  Training acc: 88.33%.
[ Wed Jun 28 18:30:08 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:30:08 2023 ] Eval epoch: 21
[ Wed Jun 28 18:30:09 2023 ] 	Mean test loss of 625 batches: 0.563209.
[ Wed Jun 28 18:30:09 2023 ] 	Top1: 91.23%
[ Wed Jun 28 18:30:09 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:30:09 2023 ] Training epoch: 22
[ Wed Jun 28 18:30:12 2023 ] 	Training loss: 0.6318.  Training acc: 89.98%.
[ Wed Jun 28 18:30:12 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:30:12 2023 ] Eval epoch: 22
[ Wed Jun 28 18:30:13 2023 ] 	Mean test loss of 625 batches: 0.555178.
[ Wed Jun 28 18:30:13 2023 ] 	Top1: 87.72%
[ Wed Jun 28 18:30:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:30:13 2023 ] Training epoch: 23
[ Wed Jun 28 18:30:15 2023 ] 	Training loss: 0.6351.  Training acc: 90.81%.
[ Wed Jun 28 18:30:15 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:30:15 2023 ] Eval epoch: 23
[ Wed Jun 28 18:30:16 2023 ] 	Mean test loss of 625 batches: 0.563231.
[ Wed Jun 28 18:30:16 2023 ] 	Top1: 89.47%
[ Wed Jun 28 18:30:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:30:16 2023 ] Training epoch: 24
[ Wed Jun 28 18:30:19 2023 ] 	Training loss: 0.6236.  Training acc: 91.54%.
[ Wed Jun 28 18:30:19 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:30:19 2023 ] Eval epoch: 24
[ Wed Jun 28 18:30:20 2023 ] 	Mean test loss of 625 batches: 0.538832.
[ Wed Jun 28 18:30:20 2023 ] 	Top1: 92.98%
[ Wed Jun 28 18:30:20 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:30:20 2023 ] Training epoch: 25
[ Wed Jun 28 18:30:23 2023 ] 	Training loss: 0.6362.  Training acc: 89.71%.
[ Wed Jun 28 18:30:23 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:30:23 2023 ] Eval epoch: 25
[ Wed Jun 28 18:30:23 2023 ] 	Mean test loss of 625 batches: 0.558885.
[ Wed Jun 28 18:30:23 2023 ] 	Top1: 87.72%
[ Wed Jun 28 18:30:23 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:30:23 2023 ] Training epoch: 26
[ Wed Jun 28 18:30:26 2023 ] 	Training loss: 0.6406.  Training acc: 91.36%.
[ Wed Jun 28 18:30:26 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:30:26 2023 ] Eval epoch: 26
[ Wed Jun 28 18:30:27 2023 ] 	Mean test loss of 625 batches: 0.532100.
[ Wed Jun 28 18:30:27 2023 ] 	Top1: 92.98%
[ Wed Jun 28 18:30:27 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:30:27 2023 ] Training epoch: 27
[ Wed Jun 28 18:30:30 2023 ] 	Training loss: 0.6222.  Training acc: 90.99%.
[ Wed Jun 28 18:30:30 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:30:30 2023 ] Eval epoch: 27
[ Wed Jun 28 18:30:30 2023 ] 	Mean test loss of 625 batches: 0.566843.
[ Wed Jun 28 18:30:30 2023 ] 	Top1: 87.72%
[ Wed Jun 28 18:30:30 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:30:30 2023 ] Training epoch: 28
[ Wed Jun 28 18:30:33 2023 ] 	Training loss: 0.6072.  Training acc: 93.01%.
[ Wed Jun 28 18:30:33 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:30:33 2023 ] Eval epoch: 28
[ Wed Jun 28 18:30:34 2023 ] 	Mean test loss of 625 batches: 0.552015.
[ Wed Jun 28 18:30:34 2023 ] 	Top1: 89.47%
[ Wed Jun 28 18:30:34 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:30:34 2023 ] Training epoch: 29
[ Wed Jun 28 18:30:37 2023 ] 	Training loss: 0.6360.  Training acc: 91.36%.
[ Wed Jun 28 18:30:37 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:30:37 2023 ] Eval epoch: 29
[ Wed Jun 28 18:30:37 2023 ] 	Mean test loss of 625 batches: 0.539585.
[ Wed Jun 28 18:30:37 2023 ] 	Top1: 91.23%
[ Wed Jun 28 18:30:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:30:37 2023 ] Training epoch: 30
[ Wed Jun 28 18:30:40 2023 ] 	Training loss: 0.6247.  Training acc: 90.35%.
[ Wed Jun 28 18:30:40 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:30:40 2023 ] Eval epoch: 30
[ Wed Jun 28 18:30:41 2023 ] 	Mean test loss of 625 batches: 0.543872.
[ Wed Jun 28 18:30:41 2023 ] 	Top1: 89.47%
[ Wed Jun 28 18:30:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:30:42 2023 ] Best accuracy: 0.9649122807017544
[ Wed Jun 28 18:30:42 2023 ] Epoch number: 16
[ Wed Jun 28 18:30:42 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 18:30:42 2023 ] Weight decay: 0.0005
[ Wed Jun 28 18:30:42 2023 ] Base LR: 0.1
[ Wed Jun 28 18:30:42 2023 ] Batch Size: 64
[ Wed Jun 28 18:30:42 2023 ] Test Batch Size: 64
[ Wed Jun 28 18:30:42 2023 ] seed: 1
[ Wed Jun 28 18:30:42 2023 ] Start training Corrector
[ Wed Jun 28 18:30:42 2023 ] # Parameters Corrector: 2407569
[ Wed Jun 28 18:30:43 2023 ] Training epoch: 1
[ Wed Jun 28 18:30:51 2023 ] 	Training loss: 19.6511.  Training acc: 35.16%.
[ Wed Jun 28 18:30:51 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 18:30:51 2023 ] Eval epoch: 1
[ Wed Jun 28 18:31:43 2023 ] using warm up, epoch: 5
[ Wed Jun 28 18:31:43 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 18:31:43 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 18:31:43 2023 ] Start training Predictor
[ Wed Jun 28 18:31:43 2023 ] Training epoch: 1
[ Wed Jun 28 18:31:48 2023 ] 	Training loss: 113.6478.  Training acc: 34.65%.
[ Wed Jun 28 18:31:48 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 18:31:48 2023 ] Eval epoch: 1
[ Wed Jun 28 18:31:49 2023 ] 	Mean test loss of 625 batches: 450.622458.
[ Wed Jun 28 18:31:49 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:31:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:31:50 2023 ] Training epoch: 2
[ Wed Jun 28 18:31:52 2023 ] 	Training loss: 10.1304.  Training acc: 34.10%.
[ Wed Jun 28 18:31:52 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:31:52 2023 ] Eval epoch: 2
[ Wed Jun 28 18:31:53 2023 ] 	Mean test loss of 625 batches: 3.386532.
[ Wed Jun 28 18:31:53 2023 ] 	Top1: 29.82%
[ Wed Jun 28 18:31:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:31:53 2023 ] Training epoch: 3
[ Wed Jun 28 18:31:56 2023 ] 	Training loss: 7.2496.  Training acc: 34.19%.
[ Wed Jun 28 18:31:56 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:31:56 2023 ] Eval epoch: 3
[ Wed Jun 28 18:31:57 2023 ] 	Mean test loss of 625 batches: 2.281745.
[ Wed Jun 28 18:31:57 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:31:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:31:57 2023 ] Training epoch: 4
[ Wed Jun 28 18:31:59 2023 ] 	Training loss: 6.1693.  Training acc: 33.46%.
[ Wed Jun 28 18:31:59 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:31:59 2023 ] Eval epoch: 4
[ Wed Jun 28 18:32:00 2023 ] 	Mean test loss of 625 batches: 1.675948.
[ Wed Jun 28 18:32:00 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:32:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:32:00 2023 ] Training epoch: 5
[ Wed Jun 28 18:32:03 2023 ] 	Training loss: 7.1118.  Training acc: 36.31%.
[ Wed Jun 28 18:32:03 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:32:03 2023 ] Eval epoch: 5
[ Wed Jun 28 18:32:04 2023 ] 	Mean test loss of 625 batches: 3.945284.
[ Wed Jun 28 18:32:04 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:32:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:32:04 2023 ] Training epoch: 6
[ Wed Jun 28 18:32:06 2023 ] 	Training loss: 4.1500.  Training acc: 36.31%.
[ Wed Jun 28 18:32:06 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:32:06 2023 ] Eval epoch: 6
[ Wed Jun 28 18:32:07 2023 ] 	Mean test loss of 625 batches: 1.629301.
[ Wed Jun 28 18:32:07 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:32:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:32:07 2023 ] Training epoch: 7
[ Wed Jun 28 18:32:10 2023 ] 	Training loss: 3.2345.  Training acc: 34.47%.
[ Wed Jun 28 18:32:10 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:32:10 2023 ] Eval epoch: 7
[ Wed Jun 28 18:32:11 2023 ] 	Mean test loss of 625 batches: 1.200140.
[ Wed Jun 28 18:32:11 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:32:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:32:11 2023 ] Training epoch: 8
[ Wed Jun 28 18:32:14 2023 ] 	Training loss: 2.7323.  Training acc: 33.18%.
[ Wed Jun 28 18:32:14 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:32:14 2023 ] Eval epoch: 8
[ Wed Jun 28 18:32:14 2023 ] 	Mean test loss of 625 batches: 1.097585.
[ Wed Jun 28 18:32:14 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:32:14 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:32:14 2023 ] Training epoch: 9
[ Wed Jun 28 18:32:17 2023 ] 	Training loss: 2.1351.  Training acc: 34.38%.
[ Wed Jun 28 18:32:17 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:32:17 2023 ] Eval epoch: 9
[ Wed Jun 28 18:32:18 2023 ] 	Mean test loss of 625 batches: 1.102553.
[ Wed Jun 28 18:32:18 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:32:18 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:32:18 2023 ] Training epoch: 10
[ Wed Jun 28 18:32:21 2023 ] 	Training loss: 1.9476.  Training acc: 33.46%.
[ Wed Jun 28 18:32:21 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:32:21 2023 ] Eval epoch: 10
[ Wed Jun 28 18:32:21 2023 ] 	Mean test loss of 625 batches: 1.137293.
[ Wed Jun 28 18:32:21 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:32:21 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:32:21 2023 ] Training epoch: 11
[ Wed Jun 28 18:32:24 2023 ] 	Training loss: 1.7206.  Training acc: 33.00%.
[ Wed Jun 28 18:32:24 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:32:24 2023 ] Eval epoch: 11
[ Wed Jun 28 18:32:25 2023 ] 	Mean test loss of 625 batches: 1.115531.
[ Wed Jun 28 18:32:25 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:32:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:32:25 2023 ] Training epoch: 12
[ Wed Jun 28 18:32:28 2023 ] 	Training loss: 1.7099.  Training acc: 33.36%.
[ Wed Jun 28 18:32:28 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:32:28 2023 ] Eval epoch: 12
[ Wed Jun 28 18:32:28 2023 ] 	Mean test loss of 625 batches: 1.111331.
[ Wed Jun 28 18:32:28 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:32:28 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:32:28 2023 ] Training epoch: 13
[ Wed Jun 28 18:32:31 2023 ] 	Training loss: 1.5848.  Training acc: 36.49%.
[ Wed Jun 28 18:32:31 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:32:31 2023 ] Eval epoch: 13
[ Wed Jun 28 18:32:32 2023 ] 	Mean test loss of 625 batches: 1.113744.
[ Wed Jun 28 18:32:32 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:32:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:32:32 2023 ] Training epoch: 14
[ Wed Jun 28 18:32:35 2023 ] 	Training loss: 1.6575.  Training acc: 31.80%.
[ Wed Jun 28 18:32:35 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:32:35 2023 ] Eval epoch: 14
[ Wed Jun 28 18:32:36 2023 ] 	Mean test loss of 625 batches: 1.111858.
[ Wed Jun 28 18:32:36 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:32:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:32:36 2023 ] Training epoch: 15
[ Wed Jun 28 18:32:38 2023 ] 	Training loss: 1.6280.  Training acc: 34.38%.
[ Wed Jun 28 18:32:38 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:32:38 2023 ] Eval epoch: 15
[ Wed Jun 28 18:32:39 2023 ] 	Mean test loss of 625 batches: 1.114434.
[ Wed Jun 28 18:32:39 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:32:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:32:39 2023 ] Training epoch: 16
[ Wed Jun 28 18:32:42 2023 ] 	Training loss: 1.5765.  Training acc: 34.93%.
[ Wed Jun 28 18:32:42 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Jun 28 18:32:42 2023 ] Eval epoch: 16
[ Wed Jun 28 18:32:43 2023 ] 	Mean test loss of 625 batches: 1.114258.
[ Wed Jun 28 18:32:43 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:32:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:32:43 2023 ] Training epoch: 17
[ Wed Jun 28 18:32:46 2023 ] 	Training loss: 1.5580.  Training acc: 36.03%.
[ Wed Jun 28 18:32:46 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:32:46 2023 ] Eval epoch: 17
[ Wed Jun 28 18:32:47 2023 ] 	Mean test loss of 625 batches: 1.107266.
[ Wed Jun 28 18:32:47 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:32:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:32:47 2023 ] Training epoch: 18
[ Wed Jun 28 18:32:49 2023 ] 	Training loss: 1.5257.  Training acc: 35.48%.
[ Wed Jun 28 18:32:49 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:32:49 2023 ] Eval epoch: 18
[ Wed Jun 28 18:32:50 2023 ] 	Mean test loss of 625 batches: 1.101047.
[ Wed Jun 28 18:32:50 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:32:50 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:32:50 2023 ] Training epoch: 19
[ Wed Jun 28 18:32:53 2023 ] 	Training loss: 1.5234.  Training acc: 35.29%.
[ Wed Jun 28 18:32:53 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:32:53 2023 ] Eval epoch: 19
[ Wed Jun 28 18:32:54 2023 ] 	Mean test loss of 625 batches: 1.122705.
[ Wed Jun 28 18:32:54 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:32:54 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:32:54 2023 ] Training epoch: 20
[ Wed Jun 28 18:32:57 2023 ] 	Training loss: 1.4477.  Training acc: 35.94%.
[ Wed Jun 28 18:32:57 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:32:57 2023 ] Eval epoch: 20
[ Wed Jun 28 18:32:57 2023 ] 	Mean test loss of 625 batches: 1.109988.
[ Wed Jun 28 18:32:57 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:32:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:32:57 2023 ] Training epoch: 21
[ Wed Jun 28 18:33:00 2023 ] 	Training loss: 1.4514.  Training acc: 34.28%.
[ Wed Jun 28 18:33:00 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:33:00 2023 ] Eval epoch: 21
[ Wed Jun 28 18:33:01 2023 ] 	Mean test loss of 625 batches: 1.108960.
[ Wed Jun 28 18:33:01 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:33:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:33:01 2023 ] Training epoch: 22
[ Wed Jun 28 18:33:04 2023 ] 	Training loss: 1.4317.  Training acc: 35.75%.
[ Wed Jun 28 18:33:04 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:33:04 2023 ] Eval epoch: 22
[ Wed Jun 28 18:33:04 2023 ] 	Mean test loss of 625 batches: 1.108039.
[ Wed Jun 28 18:33:04 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:33:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:33:04 2023 ] Training epoch: 23
[ Wed Jun 28 18:33:07 2023 ] 	Training loss: 1.4068.  Training acc: 36.76%.
[ Wed Jun 28 18:33:07 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:33:07 2023 ] Eval epoch: 23
[ Wed Jun 28 18:33:08 2023 ] 	Mean test loss of 625 batches: 1.106489.
[ Wed Jun 28 18:33:08 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:33:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:33:08 2023 ] Training epoch: 24
[ Wed Jun 28 18:33:11 2023 ] 	Training loss: 1.4384.  Training acc: 33.27%.
[ Wed Jun 28 18:33:11 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:33:11 2023 ] Eval epoch: 24
[ Wed Jun 28 18:33:11 2023 ] 	Mean test loss of 625 batches: 1.107413.
[ Wed Jun 28 18:33:11 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:33:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:33:11 2023 ] Training epoch: 25
[ Wed Jun 28 18:33:14 2023 ] 	Training loss: 1.4770.  Training acc: 32.90%.
[ Wed Jun 28 18:33:14 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:33:14 2023 ] Eval epoch: 25
[ Wed Jun 28 18:33:15 2023 ] 	Mean test loss of 625 batches: 1.109903.
[ Wed Jun 28 18:33:15 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:33:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:33:15 2023 ] Training epoch: 26
[ Wed Jun 28 18:33:18 2023 ] 	Training loss: 1.4209.  Training acc: 36.49%.
[ Wed Jun 28 18:33:18 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:33:18 2023 ] Eval epoch: 26
[ Wed Jun 28 18:33:19 2023 ] 	Mean test loss of 625 batches: 1.108996.
[ Wed Jun 28 18:33:19 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:33:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:33:19 2023 ] Training epoch: 27
[ Wed Jun 28 18:33:22 2023 ] 	Training loss: 1.5019.  Training acc: 32.90%.
[ Wed Jun 28 18:33:22 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:33:22 2023 ] Eval epoch: 27
[ Wed Jun 28 18:33:22 2023 ] 	Mean test loss of 625 batches: 1.108248.
[ Wed Jun 28 18:33:22 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:33:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:33:22 2023 ] Training epoch: 28
[ Wed Jun 28 18:33:25 2023 ] 	Training loss: 1.4005.  Training acc: 35.85%.
[ Wed Jun 28 18:33:25 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:33:25 2023 ] Eval epoch: 28
[ Wed Jun 28 18:33:26 2023 ] 	Mean test loss of 625 batches: 1.109679.
[ Wed Jun 28 18:33:26 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:33:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:33:26 2023 ] Training epoch: 29
[ Wed Jun 28 18:33:29 2023 ] 	Training loss: 1.4408.  Training acc: 36.03%.
[ Wed Jun 28 18:33:29 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:33:29 2023 ] Eval epoch: 29
[ Wed Jun 28 18:33:29 2023 ] 	Mean test loss of 625 batches: 1.109250.
[ Wed Jun 28 18:33:29 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:33:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:33:29 2023 ] Training epoch: 30
[ Wed Jun 28 18:33:32 2023 ] 	Training loss: 1.3975.  Training acc: 34.56%.
[ Wed Jun 28 18:33:32 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:33:32 2023 ] Eval epoch: 30
[ Wed Jun 28 18:33:33 2023 ] 	Mean test loss of 625 batches: 1.111403.
[ Wed Jun 28 18:33:33 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:33:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:33:34 2023 ] Best accuracy: 0.38596491228070173
[ Wed Jun 28 18:33:34 2023 ] Epoch number: 5
[ Wed Jun 28 18:33:34 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 18:33:34 2023 ] Weight decay: 0.0005
[ Wed Jun 28 18:33:34 2023 ] Base LR: 0.1
[ Wed Jun 28 18:33:34 2023 ] Batch Size: 64
[ Wed Jun 28 18:33:34 2023 ] Test Batch Size: 64
[ Wed Jun 28 18:33:34 2023 ] seed: 1
[ Wed Jun 28 18:33:34 2023 ] Start training Corrector
[ Wed Jun 28 18:33:34 2023 ] # Parameters Corrector: 2407569
[ Wed Jun 28 18:33:35 2023 ] Training epoch: 1
[ Wed Jun 28 18:33:43 2023 ] 	Training loss: 15.6573.  Training acc: 32.94%.
[ Wed Jun 28 18:33:43 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 18:33:43 2023 ] Eval epoch: 1
[ Wed Jun 28 18:35:28 2023 ] using warm up, epoch: 5
[ Wed Jun 28 18:35:28 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 18:35:28 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 18:35:28 2023 ] Start training Predictor
[ Wed Jun 28 18:35:28 2023 ] Training epoch: 1
[ Wed Jun 28 18:35:34 2023 ] 	Training loss: 110.5475.  Training acc: 36.03%.
[ Wed Jun 28 18:35:34 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:35:34 2023 ] Eval epoch: 1
[ Wed Jun 28 18:35:35 2023 ] 	Mean test loss of 625 batches: 481.901282.
[ Wed Jun 28 18:35:35 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:35:35 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:35:35 2023 ] Training epoch: 2
[ Wed Jun 28 18:35:38 2023 ] 	Training loss: 8.1398.  Training acc: 44.12%.
[ Wed Jun 28 18:35:38 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:35:38 2023 ] Eval epoch: 2
[ Wed Jun 28 18:35:39 2023 ] 	Mean test loss of 625 batches: 9.207829.
[ Wed Jun 28 18:35:39 2023 ] 	Top1: 52.63%
[ Wed Jun 28 18:35:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:35:39 2023 ] Training epoch: 3
[ Wed Jun 28 18:35:41 2023 ] 	Training loss: 4.5154.  Training acc: 55.15%.
[ Wed Jun 28 18:35:41 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:35:41 2023 ] Eval epoch: 3
[ Wed Jun 28 18:35:42 2023 ] 	Mean test loss of 625 batches: 7.232120.
[ Wed Jun 28 18:35:42 2023 ] 	Top1: 47.37%
[ Wed Jun 28 18:35:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:35:42 2023 ] Training epoch: 4
[ Wed Jun 28 18:35:45 2023 ] 	Training loss: 3.3380.  Training acc: 66.45%.
[ Wed Jun 28 18:35:45 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:35:45 2023 ] Eval epoch: 4
[ Wed Jun 28 18:35:46 2023 ] 	Mean test loss of 625 batches: 3.234558.
[ Wed Jun 28 18:35:46 2023 ] 	Top1: 68.42%
[ Wed Jun 28 18:35:46 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:35:46 2023 ] Training epoch: 5
[ Wed Jun 28 18:35:48 2023 ] 	Training loss: 2.3398.  Training acc: 67.19%.
[ Wed Jun 28 18:35:48 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:35:48 2023 ] Eval epoch: 5
[ Wed Jun 28 18:35:49 2023 ] 	Mean test loss of 625 batches: 2.297142.
[ Wed Jun 28 18:35:49 2023 ] 	Top1: 66.67%
[ Wed Jun 28 18:35:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:35:49 2023 ] Training epoch: 6
[ Wed Jun 28 18:35:52 2023 ] 	Training loss: 4.7004.  Training acc: 60.48%.
[ Wed Jun 28 18:35:52 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:35:52 2023 ] Eval epoch: 6
[ Wed Jun 28 18:35:53 2023 ] 	Mean test loss of 625 batches: 6.465249.
[ Wed Jun 28 18:35:53 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:35:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:35:53 2023 ] Training epoch: 7
[ Wed Jun 28 18:35:55 2023 ] 	Training loss: 4.7066.  Training acc: 38.97%.
[ Wed Jun 28 18:35:55 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 18:35:55 2023 ] Eval epoch: 7
[ Wed Jun 28 18:35:56 2023 ] 	Mean test loss of 625 batches: 3.126037.
[ Wed Jun 28 18:35:56 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:35:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:35:56 2023 ] Training epoch: 8
[ Wed Jun 28 18:35:59 2023 ] 	Training loss: 4.8141.  Training acc: 32.26%.
[ Wed Jun 28 18:35:59 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:35:59 2023 ] Eval epoch: 8
[ Wed Jun 28 18:36:00 2023 ] 	Mean test loss of 625 batches: 2.795733.
[ Wed Jun 28 18:36:00 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:36:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:36:00 2023 ] Training epoch: 9
[ Wed Jun 28 18:36:02 2023 ] 	Training loss: 3.0833.  Training acc: 34.10%.
[ Wed Jun 28 18:36:02 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:36:02 2023 ] Eval epoch: 9
[ Wed Jun 28 18:36:03 2023 ] 	Mean test loss of 625 batches: 1.421460.
[ Wed Jun 28 18:36:03 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:36:03 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:36:03 2023 ] Training epoch: 10
[ Wed Jun 28 18:36:06 2023 ] 	Training loss: 2.4509.  Training acc: 34.01%.
[ Wed Jun 28 18:36:06 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 18:36:06 2023 ] Eval epoch: 10
[ Wed Jun 28 18:36:07 2023 ] 	Mean test loss of 625 batches: 1.138364.
[ Wed Jun 28 18:36:07 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:36:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:36:07 2023 ] Training epoch: 11
[ Wed Jun 28 18:36:09 2023 ] 	Training loss: 2.0347.  Training acc: 35.02%.
[ Wed Jun 28 18:36:09 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:36:09 2023 ] Eval epoch: 11
[ Wed Jun 28 18:36:10 2023 ] 	Mean test loss of 625 batches: 1.131867.
[ Wed Jun 28 18:36:10 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:36:10 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:36:10 2023 ] Training epoch: 12
[ Wed Jun 28 18:36:13 2023 ] 	Training loss: 2.0748.  Training acc: 34.56%.
[ Wed Jun 28 18:36:13 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 18:36:13 2023 ] Eval epoch: 12
[ Wed Jun 28 18:36:14 2023 ] 	Mean test loss of 625 batches: 1.120370.
[ Wed Jun 28 18:36:14 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:36:14 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:36:14 2023 ] Training epoch: 13
[ Wed Jun 28 18:36:16 2023 ] 	Training loss: 1.8903.  Training acc: 36.31%.
[ Wed Jun 28 18:36:16 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:36:16 2023 ] Eval epoch: 13
[ Wed Jun 28 18:36:17 2023 ] 	Mean test loss of 625 batches: 1.115850.
[ Wed Jun 28 18:36:17 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:36:17 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:36:17 2023 ] Training epoch: 14
[ Wed Jun 28 18:36:20 2023 ] 	Training loss: 1.9554.  Training acc: 33.00%.
[ Wed Jun 28 18:36:20 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:36:20 2023 ] Eval epoch: 14
[ Wed Jun 28 18:36:21 2023 ] 	Mean test loss of 625 batches: 1.129570.
[ Wed Jun 28 18:36:21 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:36:21 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:36:21 2023 ] Training epoch: 15
[ Wed Jun 28 18:36:24 2023 ] 	Training loss: 1.9182.  Training acc: 34.47%.
[ Wed Jun 28 18:36:24 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 18:36:24 2023 ] Eval epoch: 15
[ Wed Jun 28 18:36:24 2023 ] 	Mean test loss of 625 batches: 1.123613.
[ Wed Jun 28 18:36:24 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:36:24 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:36:24 2023 ] Training epoch: 16
[ Wed Jun 28 18:36:27 2023 ] 	Training loss: 1.8584.  Training acc: 33.73%.
[ Wed Jun 28 18:36:27 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 18:36:27 2023 ] Eval epoch: 16
[ Wed Jun 28 18:36:28 2023 ] 	Mean test loss of 625 batches: 1.121687.
[ Wed Jun 28 18:36:28 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:36:28 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:36:28 2023 ] Training epoch: 17
[ Wed Jun 28 18:36:31 2023 ] 	Training loss: 1.8021.  Training acc: 35.57%.
[ Wed Jun 28 18:36:31 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:36:31 2023 ] Eval epoch: 17
[ Wed Jun 28 18:36:31 2023 ] 	Mean test loss of 625 batches: 1.113101.
[ Wed Jun 28 18:36:31 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:36:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:36:31 2023 ] Training epoch: 18
[ Wed Jun 28 18:36:34 2023 ] 	Training loss: 1.7862.  Training acc: 33.82%.
[ Wed Jun 28 18:36:34 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:36:34 2023 ] Eval epoch: 18
[ Wed Jun 28 18:36:35 2023 ] 	Mean test loss of 625 batches: 1.107649.
[ Wed Jun 28 18:36:35 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:36:35 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:36:35 2023 ] Training epoch: 19
[ Wed Jun 28 18:36:38 2023 ] 	Training loss: 1.7419.  Training acc: 34.10%.
[ Wed Jun 28 18:36:38 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 18:36:38 2023 ] Eval epoch: 19
[ Wed Jun 28 18:36:39 2023 ] 	Mean test loss of 625 batches: 1.134049.
[ Wed Jun 28 18:36:39 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:36:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:36:39 2023 ] Training epoch: 20
[ Wed Jun 28 18:36:42 2023 ] 	Training loss: 1.6223.  Training acc: 35.94%.
[ Wed Jun 28 18:36:42 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:36:42 2023 ] Eval epoch: 20
[ Wed Jun 28 18:36:43 2023 ] 	Mean test loss of 625 batches: 1.120786.
[ Wed Jun 28 18:36:43 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:36:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:36:43 2023 ] Training epoch: 21
[ Wed Jun 28 18:36:45 2023 ] 	Training loss: 1.6538.  Training acc: 34.65%.
[ Wed Jun 28 18:36:45 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:36:45 2023 ] Eval epoch: 21
[ Wed Jun 28 18:36:46 2023 ] 	Mean test loss of 625 batches: 1.117456.
[ Wed Jun 28 18:36:46 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:36:46 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:36:46 2023 ] Training epoch: 22
[ Wed Jun 28 18:36:49 2023 ] 	Training loss: 1.6162.  Training acc: 35.39%.
[ Wed Jun 28 18:36:49 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:36:49 2023 ] Eval epoch: 22
[ Wed Jun 28 18:36:49 2023 ] 	Mean test loss of 625 batches: 1.114532.
[ Wed Jun 28 18:36:49 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:36:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:36:49 2023 ] Training epoch: 23
[ Wed Jun 28 18:36:52 2023 ] 	Training loss: 1.5960.  Training acc: 36.49%.
[ Wed Jun 28 18:36:52 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:36:52 2023 ] Eval epoch: 23
[ Wed Jun 28 18:36:53 2023 ] 	Mean test loss of 625 batches: 1.112733.
[ Wed Jun 28 18:36:53 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:36:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:36:53 2023 ] Training epoch: 24
[ Wed Jun 28 18:36:56 2023 ] 	Training loss: 1.6178.  Training acc: 33.73%.
[ Wed Jun 28 18:36:56 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:36:56 2023 ] Eval epoch: 24
[ Wed Jun 28 18:36:56 2023 ] 	Mean test loss of 625 batches: 1.114221.
[ Wed Jun 28 18:36:56 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:36:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:36:56 2023 ] Training epoch: 25
[ Wed Jun 28 18:36:59 2023 ] 	Training loss: 1.6772.  Training acc: 31.62%.
[ Wed Jun 28 18:36:59 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:36:59 2023 ] Eval epoch: 25
[ Wed Jun 28 18:37:00 2023 ] 	Mean test loss of 625 batches: 1.117815.
[ Wed Jun 28 18:37:00 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:37:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:37:00 2023 ] Training epoch: 26
[ Wed Jun 28 18:37:03 2023 ] 	Training loss: 1.5982.  Training acc: 37.22%.
[ Wed Jun 28 18:37:03 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:37:03 2023 ] Eval epoch: 26
[ Wed Jun 28 18:37:03 2023 ] 	Mean test loss of 625 batches: 1.117102.
[ Wed Jun 28 18:37:03 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:37:03 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:37:03 2023 ] Training epoch: 27
[ Wed Jun 28 18:37:06 2023 ] 	Training loss: 1.6774.  Training acc: 33.64%.
[ Wed Jun 28 18:37:06 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:37:06 2023 ] Eval epoch: 27
[ Wed Jun 28 18:37:07 2023 ] 	Mean test loss of 625 batches: 1.116731.
[ Wed Jun 28 18:37:07 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:37:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:37:07 2023 ] Training epoch: 28
[ Wed Jun 28 18:37:10 2023 ] 	Training loss: 1.5850.  Training acc: 34.28%.
[ Wed Jun 28 18:37:10 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:37:10 2023 ] Eval epoch: 28
[ Wed Jun 28 18:37:10 2023 ] 	Mean test loss of 625 batches: 1.119496.
[ Wed Jun 28 18:37:10 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:37:10 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:37:10 2023 ] Training epoch: 29
[ Wed Jun 28 18:37:13 2023 ] 	Training loss: 1.6128.  Training acc: 34.93%.
[ Wed Jun 28 18:37:13 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:37:13 2023 ] Eval epoch: 29
[ Wed Jun 28 18:37:14 2023 ] 	Mean test loss of 625 batches: 1.119132.
[ Wed Jun 28 18:37:14 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:37:14 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:37:14 2023 ] Training epoch: 30
[ Wed Jun 28 18:37:17 2023 ] 	Training loss: 1.5434.  Training acc: 34.10%.
[ Wed Jun 28 18:37:17 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:37:17 2023 ] Eval epoch: 30
[ Wed Jun 28 18:37:17 2023 ] 	Mean test loss of 625 batches: 1.121453.
[ Wed Jun 28 18:37:17 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:37:17 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:37:18 2023 ] Best accuracy: 0.6842105263157895
[ Wed Jun 28 18:37:18 2023 ] Epoch number: 4
[ Wed Jun 28 18:37:18 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 18:37:18 2023 ] Weight decay: 0.0005
[ Wed Jun 28 18:37:18 2023 ] Base LR: 0.1
[ Wed Jun 28 18:37:18 2023 ] Batch Size: 64
[ Wed Jun 28 18:37:18 2023 ] Test Batch Size: 64
[ Wed Jun 28 18:37:18 2023 ] seed: 1
[ Wed Jun 28 18:37:18 2023 ] Start training Corrector
[ Wed Jun 28 18:37:18 2023 ] # Parameters Corrector: 2407569
[ Wed Jun 28 18:37:20 2023 ] Training epoch: 1
[ Wed Jun 28 18:37:28 2023 ] 	Training loss: 21.0482.  Training acc: 38.54%.
[ Wed Jun 28 18:37:28 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 18:37:28 2023 ] Eval epoch: 1
[ Wed Jun 28 18:38:04 2023 ] using warm up, epoch: 5
[ Wed Jun 28 18:38:04 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 18:38:04 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 18:38:04 2023 ] Start training Predictor
[ Wed Jun 28 18:38:04 2023 ] Training epoch: 1
[ Wed Jun 28 18:38:10 2023 ] 	Training loss: 106.1235.  Training acc: 35.66%.
[ Wed Jun 28 18:38:10 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 18:38:10 2023 ] Eval epoch: 1
[ Wed Jun 28 18:38:10 2023 ] 	Mean test loss of 625 batches: 628.384564.
[ Wed Jun 28 18:38:10 2023 ] 	Top1: 29.82%
[ Wed Jun 28 18:38:10 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:38:11 2023 ] Training epoch: 2
[ Wed Jun 28 18:38:13 2023 ] 	Training loss: 15.2688.  Training acc: 35.85%.
[ Wed Jun 28 18:38:13 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:38:13 2023 ] Eval epoch: 2
[ Wed Jun 28 18:38:14 2023 ] 	Mean test loss of 625 batches: 24.030524.
[ Wed Jun 28 18:38:14 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:38:14 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:38:14 2023 ] Training epoch: 3
[ Wed Jun 28 18:38:17 2023 ] 	Training loss: 5.9653.  Training acc: 36.86%.
[ Wed Jun 28 18:38:17 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:38:17 2023 ] Eval epoch: 3
[ Wed Jun 28 18:38:18 2023 ] 	Mean test loss of 625 batches: 2.855499.
[ Wed Jun 28 18:38:18 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:38:18 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:38:18 2023 ] Training epoch: 4
[ Wed Jun 28 18:38:21 2023 ] 	Training loss: 3.4235.  Training acc: 56.80%.
[ Wed Jun 28 18:38:21 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:38:21 2023 ] Eval epoch: 4
[ Wed Jun 28 18:38:21 2023 ] 	Mean test loss of 625 batches: 12.938151.
[ Wed Jun 28 18:38:21 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:38:21 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:38:21 2023 ] Training epoch: 5
[ Wed Jun 28 18:38:24 2023 ] 	Training loss: 4.7476.  Training acc: 56.71%.
[ Wed Jun 28 18:38:24 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:38:24 2023 ] Eval epoch: 5
[ Wed Jun 28 18:38:25 2023 ] 	Mean test loss of 625 batches: 6.539653.
[ Wed Jun 28 18:38:25 2023 ] 	Top1: 54.39%
[ Wed Jun 28 18:38:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:38:25 2023 ] Training epoch: 6
[ Wed Jun 28 18:38:28 2023 ] 	Training loss: 3.2291.  Training acc: 60.20%.
[ Wed Jun 28 18:38:28 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:38:28 2023 ] Eval epoch: 6
[ Wed Jun 28 18:38:28 2023 ] 	Mean test loss of 625 batches: 3.102795.
[ Wed Jun 28 18:38:28 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:38:28 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:38:28 2023 ] Training epoch: 7
[ Wed Jun 28 18:38:31 2023 ] 	Training loss: 1.9682.  Training acc: 63.79%.
[ Wed Jun 28 18:38:31 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:38:31 2023 ] Eval epoch: 7
[ Wed Jun 28 18:38:32 2023 ] 	Mean test loss of 625 batches: 0.759489.
[ Wed Jun 28 18:38:32 2023 ] 	Top1: 64.91%
[ Wed Jun 28 18:38:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:38:32 2023 ] Training epoch: 8
[ Wed Jun 28 18:38:35 2023 ] 	Training loss: 1.0220.  Training acc: 66.27%.
[ Wed Jun 28 18:38:35 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:38:35 2023 ] Eval epoch: 8
[ Wed Jun 28 18:38:35 2023 ] 	Mean test loss of 625 batches: 1.205133.
[ Wed Jun 28 18:38:35 2023 ] 	Top1: 52.63%
[ Wed Jun 28 18:38:35 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:38:35 2023 ] Training epoch: 9
[ Wed Jun 28 18:38:38 2023 ] 	Training loss: 0.7350.  Training acc: 79.41%.
[ Wed Jun 28 18:38:38 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:38:38 2023 ] Eval epoch: 9
[ Wed Jun 28 18:38:39 2023 ] 	Mean test loss of 625 batches: 1.039041.
[ Wed Jun 28 18:38:39 2023 ] 	Top1: 50.88%
[ Wed Jun 28 18:38:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:38:39 2023 ] Training epoch: 10
[ Wed Jun 28 18:38:41 2023 ] 	Training loss: 0.7431.  Training acc: 80.97%.
[ Wed Jun 28 18:38:41 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:38:42 2023 ] Eval epoch: 10
[ Wed Jun 28 18:38:42 2023 ] 	Mean test loss of 625 batches: 0.612230.
[ Wed Jun 28 18:38:42 2023 ] 	Top1: 75.44%
[ Wed Jun 28 18:38:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:38:42 2023 ] Training epoch: 11
[ Wed Jun 28 18:38:45 2023 ] 	Training loss: 0.5945.  Training acc: 90.72%.
[ Wed Jun 28 18:38:45 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:38:45 2023 ] Eval epoch: 11
[ Wed Jun 28 18:38:46 2023 ] 	Mean test loss of 625 batches: 0.401497.
[ Wed Jun 28 18:38:46 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:38:46 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:38:46 2023 ] Training epoch: 12
[ Wed Jun 28 18:38:48 2023 ] 	Training loss: 0.4625.  Training acc: 96.23%.
[ Wed Jun 28 18:38:48 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:38:48 2023 ] Eval epoch: 12
[ Wed Jun 28 18:38:49 2023 ] 	Mean test loss of 625 batches: 0.407139.
[ Wed Jun 28 18:38:49 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:38:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:38:49 2023 ] Training epoch: 13
[ Wed Jun 28 18:38:52 2023 ] 	Training loss: 0.4539.  Training acc: 96.23%.
[ Wed Jun 28 18:38:52 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:38:52 2023 ] Eval epoch: 13
[ Wed Jun 28 18:38:53 2023 ] 	Mean test loss of 625 batches: 0.382794.
[ Wed Jun 28 18:38:53 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:38:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:38:53 2023 ] Training epoch: 14
[ Wed Jun 28 18:38:55 2023 ] 	Training loss: 0.4251.  Training acc: 96.88%.
[ Wed Jun 28 18:38:55 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:38:55 2023 ] Eval epoch: 14
[ Wed Jun 28 18:38:56 2023 ] 	Mean test loss of 625 batches: 0.347723.
[ Wed Jun 28 18:38:56 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:38:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:38:56 2023 ] Training epoch: 15
[ Wed Jun 28 18:38:59 2023 ] 	Training loss: 0.4255.  Training acc: 96.78%.
[ Wed Jun 28 18:38:59 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:38:59 2023 ] Eval epoch: 15
[ Wed Jun 28 18:39:00 2023 ] 	Mean test loss of 625 batches: 0.354677.
[ Wed Jun 28 18:39:00 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:39:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:39:00 2023 ] Training epoch: 16
[ Wed Jun 28 18:39:02 2023 ] 	Training loss: 0.4115.  Training acc: 97.79%.
[ Wed Jun 28 18:39:02 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:39:02 2023 ] Eval epoch: 16
[ Wed Jun 28 18:39:03 2023 ] 	Mean test loss of 625 batches: 0.349089.
[ Wed Jun 28 18:39:03 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:39:03 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:39:03 2023 ] Training epoch: 17
[ Wed Jun 28 18:39:06 2023 ] 	Training loss: 0.3954.  Training acc: 98.07%.
[ Wed Jun 28 18:39:06 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:39:06 2023 ] Eval epoch: 17
[ Wed Jun 28 18:39:07 2023 ] 	Mean test loss of 625 batches: 0.331113.
[ Wed Jun 28 18:39:07 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:39:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:39:07 2023 ] Training epoch: 18
[ Wed Jun 28 18:39:10 2023 ] 	Training loss: 0.3904.  Training acc: 98.07%.
[ Wed Jun 28 18:39:10 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 18:39:10 2023 ] Eval epoch: 18
[ Wed Jun 28 18:39:11 2023 ] 	Mean test loss of 625 batches: 0.327713.
[ Wed Jun 28 18:39:11 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:39:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:39:11 2023 ] Training epoch: 19
[ Wed Jun 28 18:39:14 2023 ] 	Training loss: 0.3928.  Training acc: 97.33%.
[ Wed Jun 28 18:39:14 2023 ] 	Time consumption: [Data]19%, [Network]80%
[ Wed Jun 28 18:39:14 2023 ] Eval epoch: 19
[ Wed Jun 28 18:39:14 2023 ] 	Mean test loss of 625 batches: 0.329847.
[ Wed Jun 28 18:39:14 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:39:14 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:39:14 2023 ] Training epoch: 20
[ Wed Jun 28 18:39:17 2023 ] 	Training loss: 0.3708.  Training acc: 98.99%.
[ Wed Jun 28 18:39:17 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:39:17 2023 ] Eval epoch: 20
[ Wed Jun 28 18:39:18 2023 ] 	Mean test loss of 625 batches: 0.330284.
[ Wed Jun 28 18:39:18 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:39:18 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:39:18 2023 ] Training epoch: 21
[ Wed Jun 28 18:39:21 2023 ] 	Training loss: 0.3740.  Training acc: 98.90%.
[ Wed Jun 28 18:39:21 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:39:21 2023 ] Eval epoch: 21
[ Wed Jun 28 18:39:21 2023 ] 	Mean test loss of 625 batches: 0.324606.
[ Wed Jun 28 18:39:21 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:39:21 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:39:21 2023 ] Training epoch: 22
[ Wed Jun 28 18:39:24 2023 ] 	Training loss: 0.3683.  Training acc: 98.81%.
[ Wed Jun 28 18:39:24 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:39:24 2023 ] Eval epoch: 22
[ Wed Jun 28 18:39:25 2023 ] 	Mean test loss of 625 batches: 0.322840.
[ Wed Jun 28 18:39:25 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:39:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:39:25 2023 ] Training epoch: 23
[ Wed Jun 28 18:39:27 2023 ] 	Training loss: 0.3646.  Training acc: 98.90%.
[ Wed Jun 28 18:39:27 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:39:27 2023 ] Eval epoch: 23
[ Wed Jun 28 18:39:28 2023 ] 	Mean test loss of 625 batches: 0.336276.
[ Wed Jun 28 18:39:28 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:39:28 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:39:28 2023 ] Training epoch: 24
[ Wed Jun 28 18:39:31 2023 ] 	Training loss: 0.3591.  Training acc: 99.08%.
[ Wed Jun 28 18:39:31 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:39:31 2023 ] Eval epoch: 24
[ Wed Jun 28 18:39:32 2023 ] 	Mean test loss of 625 batches: 0.323742.
[ Wed Jun 28 18:39:32 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:39:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:39:32 2023 ] Training epoch: 25
[ Wed Jun 28 18:39:34 2023 ] 	Training loss: 0.3699.  Training acc: 98.71%.
[ Wed Jun 28 18:39:34 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:39:34 2023 ] Eval epoch: 25
[ Wed Jun 28 18:39:35 2023 ] 	Mean test loss of 625 batches: 0.326929.
[ Wed Jun 28 18:39:35 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:39:35 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:39:35 2023 ] Training epoch: 26
[ Wed Jun 28 18:39:38 2023 ] 	Training loss: 0.3603.  Training acc: 99.08%.
[ Wed Jun 28 18:39:38 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:39:38 2023 ] Eval epoch: 26
[ Wed Jun 28 18:39:39 2023 ] 	Mean test loss of 625 batches: 0.323477.
[ Wed Jun 28 18:39:39 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:39:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:39:39 2023 ] Training epoch: 27
[ Wed Jun 28 18:39:41 2023 ] 	Training loss: 0.3560.  Training acc: 99.26%.
[ Wed Jun 28 18:39:41 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:39:41 2023 ] Eval epoch: 27
[ Wed Jun 28 18:39:42 2023 ] 	Mean test loss of 625 batches: 0.324443.
[ Wed Jun 28 18:39:42 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:39:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:39:42 2023 ] Training epoch: 28
[ Wed Jun 28 18:39:45 2023 ] 	Training loss: 0.3538.  Training acc: 99.63%.
[ Wed Jun 28 18:39:45 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:39:45 2023 ] Eval epoch: 28
[ Wed Jun 28 18:39:45 2023 ] 	Mean test loss of 625 batches: 0.319487.
[ Wed Jun 28 18:39:45 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:39:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:39:46 2023 ] Training epoch: 29
[ Wed Jun 28 18:39:48 2023 ] 	Training loss: 0.3591.  Training acc: 98.90%.
[ Wed Jun 28 18:39:48 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:39:48 2023 ] Eval epoch: 29
[ Wed Jun 28 18:39:49 2023 ] 	Mean test loss of 625 batches: 0.322100.
[ Wed Jun 28 18:39:49 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:39:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:39:49 2023 ] Training epoch: 30
[ Wed Jun 28 18:39:52 2023 ] 	Training loss: 0.3577.  Training acc: 99.36%.
[ Wed Jun 28 18:39:52 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:39:52 2023 ] Eval epoch: 30
[ Wed Jun 28 18:39:53 2023 ] 	Mean test loss of 625 batches: 0.315654.
[ Wed Jun 28 18:39:53 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:39:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:39:53 2023 ] Best accuracy: 1.0
[ Wed Jun 28 18:39:53 2023 ] Epoch number: 11
[ Wed Jun 28 18:39:53 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 18:39:53 2023 ] Weight decay: 0.0005
[ Wed Jun 28 18:39:53 2023 ] Base LR: 0.1
[ Wed Jun 28 18:39:53 2023 ] Batch Size: 64
[ Wed Jun 28 18:39:53 2023 ] Test Batch Size: 64
[ Wed Jun 28 18:39:53 2023 ] seed: 1
[ Wed Jun 28 18:39:53 2023 ] Start training Corrector
[ Wed Jun 28 18:39:53 2023 ] # Parameters Corrector: 2407569
[ Wed Jun 28 18:39:55 2023 ] Training epoch: 1
[ Wed Jun 28 18:40:03 2023 ] 	Training loss: 16.1364.  Training acc: 42.97%.
[ Wed Jun 28 18:40:03 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 18:40:03 2023 ] Eval epoch: 1
[ Wed Jun 28 18:40:04 2023 ] 	Mean test loss of 625 batches: 2.992472.
[ Wed Jun 28 18:40:04 2023 ] 	Top1: 26.32%
[ Wed Jun 28 18:40:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:40:24 2023 ] using warm up, epoch: 5
[ Wed Jun 28 18:40:24 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 18:40:24 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 18:40:24 2023 ] Start training Predictor
[ Wed Jun 28 18:40:24 2023 ] Training epoch: 1
[ Wed Jun 28 18:40:30 2023 ] 	Training loss: 116.1789.  Training acc: 34.28%.
[ Wed Jun 28 18:40:30 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 18:40:30 2023 ] Eval epoch: 1
[ Wed Jun 28 18:40:31 2023 ] 	Mean test loss of 625 batches: 1620.462646.
[ Wed Jun 28 18:40:31 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:40:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:40:31 2023 ] Training epoch: 2
[ Wed Jun 28 18:40:34 2023 ] 	Training loss: 25.8361.  Training acc: 34.93%.
[ Wed Jun 28 18:40:34 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:40:34 2023 ] Eval epoch: 2
[ Wed Jun 28 18:40:34 2023 ] 	Mean test loss of 625 batches: 120.872078.
[ Wed Jun 28 18:40:34 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:40:34 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:40:34 2023 ] Training epoch: 3
[ Wed Jun 28 18:40:37 2023 ] 	Training loss: 7.2730.  Training acc: 35.29%.
[ Wed Jun 28 18:40:37 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:40:37 2023 ] Eval epoch: 3
[ Wed Jun 28 18:40:38 2023 ] 	Mean test loss of 625 batches: 2.798387.
[ Wed Jun 28 18:40:38 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:40:38 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:40:38 2023 ] Training epoch: 4
[ Wed Jun 28 18:40:41 2023 ] 	Training loss: 6.2677.  Training acc: 32.17%.
[ Wed Jun 28 18:40:41 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:40:41 2023 ] Eval epoch: 4
[ Wed Jun 28 18:40:42 2023 ] 	Mean test loss of 625 batches: 1.997383.
[ Wed Jun 28 18:40:42 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:40:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:40:42 2023 ] Training epoch: 5
[ Wed Jun 28 18:40:44 2023 ] 	Training loss: 5.0101.  Training acc: 35.11%.
[ Wed Jun 28 18:40:44 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:40:44 2023 ] Eval epoch: 5
[ Wed Jun 28 18:40:45 2023 ] 	Mean test loss of 625 batches: 1.649836.
[ Wed Jun 28 18:40:45 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:40:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:40:45 2023 ] Training epoch: 6
[ Wed Jun 28 18:40:48 2023 ] 	Training loss: 3.9106.  Training acc: 37.59%.
[ Wed Jun 28 18:40:48 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 18:40:48 2023 ] Eval epoch: 6
[ Wed Jun 28 18:40:49 2023 ] 	Mean test loss of 625 batches: 1.278827.
[ Wed Jun 28 18:40:49 2023 ] 	Top1: 29.82%
[ Wed Jun 28 18:40:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:40:49 2023 ] Training epoch: 7
[ Wed Jun 28 18:40:52 2023 ] 	Training loss: 5.0699.  Training acc: 33.92%.
[ Wed Jun 28 18:40:52 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 18:40:52 2023 ] Eval epoch: 7
[ Wed Jun 28 18:40:53 2023 ] 	Mean test loss of 625 batches: 1.241043.
[ Wed Jun 28 18:40:53 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:40:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:40:53 2023 ] Training epoch: 8
[ Wed Jun 28 18:40:56 2023 ] 	Training loss: 3.0444.  Training acc: 33.18%.
[ Wed Jun 28 18:40:56 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 18:40:56 2023 ] Eval epoch: 8
[ Wed Jun 28 18:40:56 2023 ] 	Mean test loss of 625 batches: 1.210501.
[ Wed Jun 28 18:40:56 2023 ] 	Top1: 29.82%
[ Wed Jun 28 18:40:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:40:56 2023 ] Training epoch: 9
[ Wed Jun 28 18:40:59 2023 ] 	Training loss: 2.3487.  Training acc: 34.56%.
[ Wed Jun 28 18:40:59 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:40:59 2023 ] Eval epoch: 9
[ Wed Jun 28 18:41:00 2023 ] 	Mean test loss of 625 batches: 1.183929.
[ Wed Jun 28 18:41:00 2023 ] 	Top1: 29.82%
[ Wed Jun 28 18:41:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:41:00 2023 ] Training epoch: 10
[ Wed Jun 28 18:41:03 2023 ] 	Training loss: 2.1055.  Training acc: 33.00%.
[ Wed Jun 28 18:41:03 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:41:03 2023 ] Eval epoch: 10
[ Wed Jun 28 18:41:03 2023 ] 	Mean test loss of 625 batches: 1.187485.
[ Wed Jun 28 18:41:03 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:41:03 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:41:03 2023 ] Training epoch: 11
[ Wed Jun 28 18:41:06 2023 ] 	Training loss: 1.7424.  Training acc: 38.14%.
[ Wed Jun 28 18:41:06 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:41:06 2023 ] Eval epoch: 11
[ Wed Jun 28 18:41:07 2023 ] 	Mean test loss of 625 batches: 1.013893.
[ Wed Jun 28 18:41:07 2023 ] 	Top1: 66.67%
[ Wed Jun 28 18:41:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:41:07 2023 ] Training epoch: 12
[ Wed Jun 28 18:41:10 2023 ] 	Training loss: 1.5727.  Training acc: 41.54%.
[ Wed Jun 28 18:41:10 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:41:10 2023 ] Eval epoch: 12
[ Wed Jun 28 18:41:11 2023 ] 	Mean test loss of 625 batches: 0.913774.
[ Wed Jun 28 18:41:11 2023 ] 	Top1: 66.67%
[ Wed Jun 28 18:41:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:41:11 2023 ] Training epoch: 13
[ Wed Jun 28 18:41:14 2023 ] 	Training loss: 1.3615.  Training acc: 50.64%.
[ Wed Jun 28 18:41:14 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:41:14 2023 ] Eval epoch: 13
[ Wed Jun 28 18:41:14 2023 ] 	Mean test loss of 625 batches: 0.721215.
[ Wed Jun 28 18:41:14 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:41:14 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:41:14 2023 ] Training epoch: 14
[ Wed Jun 28 18:41:17 2023 ] 	Training loss: 1.1727.  Training acc: 57.81%.
[ Wed Jun 28 18:41:17 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:41:17 2023 ] Eval epoch: 14
[ Wed Jun 28 18:41:18 2023 ] 	Mean test loss of 625 batches: 0.672262.
[ Wed Jun 28 18:41:18 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:41:18 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:41:18 2023 ] Training epoch: 15
[ Wed Jun 28 18:41:21 2023 ] 	Training loss: 1.1283.  Training acc: 61.12%.
[ Wed Jun 28 18:41:21 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:41:21 2023 ] Eval epoch: 15
[ Wed Jun 28 18:41:22 2023 ] 	Mean test loss of 625 batches: 0.664250.
[ Wed Jun 28 18:41:22 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:41:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:41:22 2023 ] Training epoch: 16
[ Wed Jun 28 18:41:25 2023 ] 	Training loss: 1.0865.  Training acc: 62.96%.
[ Wed Jun 28 18:41:25 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:41:25 2023 ] Eval epoch: 16
[ Wed Jun 28 18:41:25 2023 ] 	Mean test loss of 625 batches: 0.692025.
[ Wed Jun 28 18:41:25 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:41:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:41:25 2023 ] Training epoch: 17
[ Wed Jun 28 18:41:28 2023 ] 	Training loss: 1.0169.  Training acc: 65.44%.
[ Wed Jun 28 18:41:28 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:41:28 2023 ] Eval epoch: 17
[ Wed Jun 28 18:41:29 2023 ] 	Mean test loss of 625 batches: 0.652712.
[ Wed Jun 28 18:41:29 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:41:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:41:29 2023 ] Training epoch: 18
[ Wed Jun 28 18:41:32 2023 ] 	Training loss: 0.9850.  Training acc: 64.71%.
[ Wed Jun 28 18:41:32 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:41:32 2023 ] Eval epoch: 18
[ Wed Jun 28 18:41:33 2023 ] 	Mean test loss of 625 batches: 0.653496.
[ Wed Jun 28 18:41:33 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:41:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:41:33 2023 ] Training epoch: 19
[ Wed Jun 28 18:41:36 2023 ] 	Training loss: 1.0078.  Training acc: 64.61%.
[ Wed Jun 28 18:41:36 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 18:41:36 2023 ] Eval epoch: 19
[ Wed Jun 28 18:41:36 2023 ] 	Mean test loss of 625 batches: 0.673988.
[ Wed Jun 28 18:41:36 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:41:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:41:36 2023 ] Training epoch: 20
[ Wed Jun 28 18:41:39 2023 ] 	Training loss: 0.9249.  Training acc: 67.56%.
[ Wed Jun 28 18:41:39 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:41:39 2023 ] Eval epoch: 20
[ Wed Jun 28 18:41:40 2023 ] 	Mean test loss of 625 batches: 0.645828.
[ Wed Jun 28 18:41:40 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:41:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:41:40 2023 ] Training epoch: 21
[ Wed Jun 28 18:41:43 2023 ] 	Training loss: 0.9602.  Training acc: 67.00%.
[ Wed Jun 28 18:41:43 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:41:43 2023 ] Eval epoch: 21
[ Wed Jun 28 18:41:43 2023 ] 	Mean test loss of 625 batches: 0.647022.
[ Wed Jun 28 18:41:43 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:41:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:41:43 2023 ] Training epoch: 22
[ Wed Jun 28 18:41:46 2023 ] 	Training loss: 0.9077.  Training acc: 67.56%.
[ Wed Jun 28 18:41:46 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:41:46 2023 ] Eval epoch: 22
[ Wed Jun 28 18:41:47 2023 ] 	Mean test loss of 625 batches: 0.630294.
[ Wed Jun 28 18:41:47 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:41:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:41:47 2023 ] Training epoch: 23
[ Wed Jun 28 18:41:50 2023 ] 	Training loss: 0.9183.  Training acc: 66.54%.
[ Wed Jun 28 18:41:50 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:41:50 2023 ] Eval epoch: 23
[ Wed Jun 28 18:41:51 2023 ] 	Mean test loss of 625 batches: 0.644997.
[ Wed Jun 28 18:41:51 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:41:51 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:41:51 2023 ] Training epoch: 24
[ Wed Jun 28 18:41:54 2023 ] 	Training loss: 0.9386.  Training acc: 65.81%.
[ Wed Jun 28 18:41:54 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:41:54 2023 ] Eval epoch: 24
[ Wed Jun 28 18:41:54 2023 ] 	Mean test loss of 625 batches: 0.634269.
[ Wed Jun 28 18:41:54 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:41:54 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:41:54 2023 ] Training epoch: 25
[ Wed Jun 28 18:41:57 2023 ] 	Training loss: 0.9193.  Training acc: 67.19%.
[ Wed Jun 28 18:41:57 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:41:57 2023 ] Eval epoch: 25
[ Wed Jun 28 18:41:58 2023 ] 	Mean test loss of 625 batches: 0.633380.
[ Wed Jun 28 18:41:58 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:41:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:41:58 2023 ] Training epoch: 26
[ Wed Jun 28 18:42:01 2023 ] 	Training loss: 0.8994.  Training acc: 69.03%.
[ Wed Jun 28 18:42:01 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:42:01 2023 ] Eval epoch: 26
[ Wed Jun 28 18:42:02 2023 ] 	Mean test loss of 625 batches: 0.626506.
[ Wed Jun 28 18:42:02 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:42:02 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:42:02 2023 ] Training epoch: 27
[ Wed Jun 28 18:42:05 2023 ] 	Training loss: 0.9410.  Training acc: 66.27%.
[ Wed Jun 28 18:42:05 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:42:05 2023 ] Eval epoch: 27
[ Wed Jun 28 18:42:05 2023 ] 	Mean test loss of 625 batches: 0.622737.
[ Wed Jun 28 18:42:05 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:42:05 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:42:05 2023 ] Training epoch: 28
[ Wed Jun 28 18:42:08 2023 ] 	Training loss: 0.8757.  Training acc: 68.29%.
[ Wed Jun 28 18:42:08 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:42:08 2023 ] Eval epoch: 28
[ Wed Jun 28 18:42:09 2023 ] 	Mean test loss of 625 batches: 0.617345.
[ Wed Jun 28 18:42:09 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:42:09 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:42:09 2023 ] Training epoch: 29
[ Wed Jun 28 18:42:12 2023 ] 	Training loss: 0.8969.  Training acc: 68.47%.
[ Wed Jun 28 18:42:12 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:42:12 2023 ] Eval epoch: 29
[ Wed Jun 28 18:42:13 2023 ] 	Mean test loss of 625 batches: 0.603414.
[ Wed Jun 28 18:42:13 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:42:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:42:13 2023 ] Training epoch: 30
[ Wed Jun 28 18:42:16 2023 ] 	Training loss: 0.8421.  Training acc: 70.96%.
[ Wed Jun 28 18:42:16 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:42:16 2023 ] Eval epoch: 30
[ Wed Jun 28 18:42:16 2023 ] 	Mean test loss of 625 batches: 0.603903.
[ Wed Jun 28 18:42:16 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:42:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:42:17 2023 ] Best accuracy: 0.7017543859649122
[ Wed Jun 28 18:42:17 2023 ] Epoch number: 13
[ Wed Jun 28 18:42:17 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 18:42:17 2023 ] Weight decay: 0.0005
[ Wed Jun 28 18:42:17 2023 ] Base LR: 0.1
[ Wed Jun 28 18:42:17 2023 ] Batch Size: 64
[ Wed Jun 28 18:42:17 2023 ] Test Batch Size: 64
[ Wed Jun 28 18:42:17 2023 ] seed: 1
[ Wed Jun 28 18:42:17 2023 ] Start training Corrector
[ Wed Jun 28 18:42:17 2023 ] # Parameters Corrector: 2407569
[ Wed Jun 28 18:42:18 2023 ] Training epoch: 1
[ Wed Jun 28 18:42:27 2023 ] 	Training loss: 16.2311.  Training acc: 38.54%.
[ Wed Jun 28 18:42:27 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 18:42:27 2023 ] Eval epoch: 1
[ Wed Jun 28 18:42:28 2023 ] 	Mean test loss of 625 batches: 1.452159.
[ Wed Jun 28 18:42:28 2023 ] 	Top1: 50.00%
[ Wed Jun 28 18:42:28 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:42:29 2023 ] Training epoch: 2
[ Wed Jun 28 18:42:36 2023 ] 	Training loss: 11.1131.  Training acc: 40.76%.
[ Wed Jun 28 18:42:36 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:42:36 2023 ] Eval epoch: 2
[ Wed Jun 28 18:42:37 2023 ] 	Mean test loss of 625 batches: 1.813305.
[ Wed Jun 28 18:42:37 2023 ] 	Top1: 21.05%
[ Wed Jun 28 18:42:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:42:38 2023 ] Training epoch: 3
[ Wed Jun 28 18:46:55 2023 ] using warm up, epoch: 5
[ Wed Jun 28 18:46:55 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 18:46:55 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 18:46:55 2023 ] Start training Predictor
[ Wed Jun 28 18:46:55 2023 ] Training epoch: 1
[ Wed Jun 28 18:47:01 2023 ] 	Training loss: 114.1221.  Training acc: 34.10%.
[ Wed Jun 28 18:47:01 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 18:47:01 2023 ] Eval epoch: 1
[ Wed Jun 28 18:47:02 2023 ] 	Mean test loss of 625 batches: 942.840479.
[ Wed Jun 28 18:47:02 2023 ] 	Top1: 29.82%
[ Wed Jun 28 18:47:02 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:47:02 2023 ] Training epoch: 2
[ Wed Jun 28 18:47:05 2023 ] 	Training loss: 9.7042.  Training acc: 35.94%.
[ Wed Jun 28 18:47:05 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:47:05 2023 ] Eval epoch: 2
[ Wed Jun 28 18:47:06 2023 ] 	Mean test loss of 625 batches: 13.229625.
[ Wed Jun 28 18:47:06 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:47:06 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:47:06 2023 ] Training epoch: 3
[ Wed Jun 28 18:47:09 2023 ] 	Training loss: 6.1934.  Training acc: 42.92%.
[ Wed Jun 28 18:47:09 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:47:09 2023 ] Eval epoch: 3
[ Wed Jun 28 18:47:09 2023 ] 	Mean test loss of 625 batches: 17.427469.
[ Wed Jun 28 18:47:09 2023 ] 	Top1: 29.82%
[ Wed Jun 28 18:47:09 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:47:09 2023 ] Training epoch: 4
[ Wed Jun 28 18:47:12 2023 ] 	Training loss: 4.8547.  Training acc: 57.81%.
[ Wed Jun 28 18:47:12 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:47:12 2023 ] Eval epoch: 4
[ Wed Jun 28 18:47:13 2023 ] 	Mean test loss of 625 batches: 10.391352.
[ Wed Jun 28 18:47:13 2023 ] 	Top1: 42.11%
[ Wed Jun 28 18:47:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:47:13 2023 ] Training epoch: 5
[ Wed Jun 28 18:47:16 2023 ] 	Training loss: 4.8046.  Training acc: 60.29%.
[ Wed Jun 28 18:47:16 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:47:16 2023 ] Eval epoch: 5
[ Wed Jun 28 18:47:16 2023 ] 	Mean test loss of 625 batches: 6.801404.
[ Wed Jun 28 18:47:16 2023 ] 	Top1: 75.44%
[ Wed Jun 28 18:47:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:47:16 2023 ] Training epoch: 6
[ Wed Jun 28 18:47:19 2023 ] 	Training loss: 4.3477.  Training acc: 56.53%.
[ Wed Jun 28 18:47:19 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:47:19 2023 ] Eval epoch: 6
[ Wed Jun 28 18:47:20 2023 ] 	Mean test loss of 625 batches: 4.212498.
[ Wed Jun 28 18:47:20 2023 ] 	Top1: 52.63%
[ Wed Jun 28 18:47:20 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:47:20 2023 ] Training epoch: 7
[ Wed Jun 28 18:47:23 2023 ] 	Training loss: 2.5509.  Training acc: 54.23%.
[ Wed Jun 28 18:47:23 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:47:23 2023 ] Eval epoch: 7
[ Wed Jun 28 18:47:24 2023 ] 	Mean test loss of 625 batches: 1.824970.
[ Wed Jun 28 18:47:24 2023 ] 	Top1: 63.16%
[ Wed Jun 28 18:47:24 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:47:24 2023 ] Training epoch: 8
[ Wed Jun 28 18:47:27 2023 ] 	Training loss: 2.1410.  Training acc: 54.60%.
[ Wed Jun 28 18:47:27 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:47:27 2023 ] Eval epoch: 8
[ Wed Jun 28 18:47:27 2023 ] 	Mean test loss of 625 batches: 4.579126.
[ Wed Jun 28 18:47:27 2023 ] 	Top1: 40.35%
[ Wed Jun 28 18:47:27 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:47:27 2023 ] Training epoch: 9
[ Wed Jun 28 18:47:30 2023 ] 	Training loss: 1.7901.  Training acc: 54.87%.
[ Wed Jun 28 18:47:30 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 18:47:30 2023 ] Eval epoch: 9
[ Wed Jun 28 18:47:31 2023 ] 	Mean test loss of 625 batches: 1.423219.
[ Wed Jun 28 18:47:31 2023 ] 	Top1: 63.16%
[ Wed Jun 28 18:47:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:47:31 2023 ] Training epoch: 10
[ Wed Jun 28 18:47:34 2023 ] 	Training loss: 1.8057.  Training acc: 51.29%.
[ Wed Jun 28 18:47:34 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:47:34 2023 ] Eval epoch: 10
[ Wed Jun 28 18:47:35 2023 ] 	Mean test loss of 625 batches: 1.789758.
[ Wed Jun 28 18:47:35 2023 ] 	Top1: 54.39%
[ Wed Jun 28 18:47:35 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:47:35 2023 ] Training epoch: 11
[ Wed Jun 28 18:47:38 2023 ] 	Training loss: 1.4484.  Training acc: 55.61%.
[ Wed Jun 28 18:47:38 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:47:38 2023 ] Eval epoch: 11
[ Wed Jun 28 18:47:38 2023 ] 	Mean test loss of 625 batches: 0.980198.
[ Wed Jun 28 18:47:38 2023 ] 	Top1: 64.91%
[ Wed Jun 28 18:47:38 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:47:38 2023 ] Training epoch: 12
[ Wed Jun 28 18:47:41 2023 ] 	Training loss: 1.2738.  Training acc: 56.80%.
[ Wed Jun 28 18:47:41 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:47:41 2023 ] Eval epoch: 12
[ Wed Jun 28 18:47:42 2023 ] 	Mean test loss of 625 batches: 0.581864.
[ Wed Jun 28 18:47:42 2023 ] 	Top1: 92.98%
[ Wed Jun 28 18:47:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:47:42 2023 ] Training epoch: 13
[ Wed Jun 28 18:47:45 2023 ] 	Training loss: 1.2123.  Training acc: 59.65%.
[ Wed Jun 28 18:47:45 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:47:45 2023 ] Eval epoch: 13
[ Wed Jun 28 18:47:45 2023 ] 	Mean test loss of 625 batches: 0.670807.
[ Wed Jun 28 18:47:45 2023 ] 	Top1: 80.70%
[ Wed Jun 28 18:47:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:47:45 2023 ] Training epoch: 14
[ Wed Jun 28 18:47:48 2023 ] 	Training loss: 1.1333.  Training acc: 58.73%.
[ Wed Jun 28 18:47:48 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:47:48 2023 ] Eval epoch: 14
[ Wed Jun 28 18:47:49 2023 ] 	Mean test loss of 625 batches: 0.578081.
[ Wed Jun 28 18:47:49 2023 ] 	Top1: 85.96%
[ Wed Jun 28 18:47:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:47:49 2023 ] Training epoch: 15
[ Wed Jun 28 18:47:52 2023 ] 	Training loss: 1.0432.  Training acc: 61.76%.
[ Wed Jun 28 18:47:52 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:47:52 2023 ] Eval epoch: 15
[ Wed Jun 28 18:47:53 2023 ] 	Mean test loss of 625 batches: 0.572421.
[ Wed Jun 28 18:47:53 2023 ] 	Top1: 91.23%
[ Wed Jun 28 18:47:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:47:53 2023 ] Training epoch: 16
[ Wed Jun 28 18:47:55 2023 ] 	Training loss: 1.0273.  Training acc: 63.79%.
[ Wed Jun 28 18:47:55 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:47:55 2023 ] Eval epoch: 16
[ Wed Jun 28 18:47:56 2023 ] 	Mean test loss of 625 batches: 0.617704.
[ Wed Jun 28 18:47:56 2023 ] 	Top1: 85.96%
[ Wed Jun 28 18:47:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:47:56 2023 ] Training epoch: 17
[ Wed Jun 28 18:47:59 2023 ] 	Training loss: 0.9452.  Training acc: 64.80%.
[ Wed Jun 28 18:47:59 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:47:59 2023 ] Eval epoch: 17
[ Wed Jun 28 18:48:00 2023 ] 	Mean test loss of 625 batches: 0.589336.
[ Wed Jun 28 18:48:00 2023 ] 	Top1: 94.74%
[ Wed Jun 28 18:48:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:48:00 2023 ] Training epoch: 18
[ Wed Jun 28 18:48:03 2023 ] 	Training loss: 0.9562.  Training acc: 65.44%.
[ Wed Jun 28 18:48:03 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:48:03 2023 ] Eval epoch: 18
[ Wed Jun 28 18:48:03 2023 ] 	Mean test loss of 625 batches: 0.624669.
[ Wed Jun 28 18:48:03 2023 ] 	Top1: 87.72%
[ Wed Jun 28 18:48:03 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:48:03 2023 ] Training epoch: 19
[ Wed Jun 28 18:48:06 2023 ] 	Training loss: 0.9747.  Training acc: 63.88%.
[ Wed Jun 28 18:48:06 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:48:06 2023 ] Eval epoch: 19
[ Wed Jun 28 18:48:07 2023 ] 	Mean test loss of 625 batches: 0.680866.
[ Wed Jun 28 18:48:07 2023 ] 	Top1: 78.95%
[ Wed Jun 28 18:48:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:48:07 2023 ] Training epoch: 20
[ Wed Jun 28 18:48:10 2023 ] 	Training loss: 0.8702.  Training acc: 68.11%.
[ Wed Jun 28 18:48:10 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:48:10 2023 ] Eval epoch: 20
[ Wed Jun 28 18:48:11 2023 ] 	Mean test loss of 625 batches: 0.691634.
[ Wed Jun 28 18:48:11 2023 ] 	Top1: 84.21%
[ Wed Jun 28 18:48:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:48:11 2023 ] Training epoch: 21
[ Wed Jun 28 18:48:14 2023 ] 	Training loss: 0.8632.  Training acc: 69.12%.
[ Wed Jun 28 18:48:14 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:48:14 2023 ] Eval epoch: 21
[ Wed Jun 28 18:48:14 2023 ] 	Mean test loss of 625 batches: 0.616364.
[ Wed Jun 28 18:48:14 2023 ] 	Top1: 89.47%
[ Wed Jun 28 18:48:14 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:48:14 2023 ] Training epoch: 22
[ Wed Jun 28 18:48:17 2023 ] 	Training loss: 0.8317.  Training acc: 69.39%.
[ Wed Jun 28 18:48:17 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:48:17 2023 ] Eval epoch: 22
[ Wed Jun 28 18:48:18 2023 ] 	Mean test loss of 625 batches: 0.594887.
[ Wed Jun 28 18:48:18 2023 ] 	Top1: 91.23%
[ Wed Jun 28 18:48:18 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:48:18 2023 ] Training epoch: 23
[ Wed Jun 28 18:48:21 2023 ] 	Training loss: 0.8388.  Training acc: 69.49%.
[ Wed Jun 28 18:48:21 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 18:48:21 2023 ] Eval epoch: 23
[ Wed Jun 28 18:48:21 2023 ] 	Mean test loss of 625 batches: 0.583399.
[ Wed Jun 28 18:48:21 2023 ] 	Top1: 91.23%
[ Wed Jun 28 18:48:21 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:48:21 2023 ] Training epoch: 24
[ Wed Jun 28 18:48:24 2023 ] 	Training loss: 0.8436.  Training acc: 69.39%.
[ Wed Jun 28 18:48:24 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:48:24 2023 ] Eval epoch: 24
[ Wed Jun 28 18:48:25 2023 ] 	Mean test loss of 625 batches: 0.594552.
[ Wed Jun 28 18:48:25 2023 ] 	Top1: 91.23%
[ Wed Jun 28 18:48:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:48:25 2023 ] Training epoch: 25
[ Wed Jun 28 18:48:28 2023 ] 	Training loss: 0.8511.  Training acc: 68.66%.
[ Wed Jun 28 18:48:28 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:48:28 2023 ] Eval epoch: 25
[ Wed Jun 28 18:48:29 2023 ] 	Mean test loss of 625 batches: 0.594857.
[ Wed Jun 28 18:48:29 2023 ] 	Top1: 91.23%
[ Wed Jun 28 18:48:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:48:29 2023 ] Training epoch: 26
[ Wed Jun 28 18:48:32 2023 ] 	Training loss: 0.8401.  Training acc: 70.68%.
[ Wed Jun 28 18:48:32 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:48:32 2023 ] Eval epoch: 26
[ Wed Jun 28 18:48:32 2023 ] 	Mean test loss of 625 batches: 0.588081.
[ Wed Jun 28 18:48:32 2023 ] 	Top1: 91.23%
[ Wed Jun 28 18:48:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:48:32 2023 ] Training epoch: 27
[ Wed Jun 28 18:48:35 2023 ] 	Training loss: 0.8613.  Training acc: 68.29%.
[ Wed Jun 28 18:48:35 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:48:35 2023 ] Eval epoch: 27
[ Wed Jun 28 18:48:36 2023 ] 	Mean test loss of 625 batches: 0.582386.
[ Wed Jun 28 18:48:36 2023 ] 	Top1: 92.98%
[ Wed Jun 28 18:48:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:48:36 2023 ] Training epoch: 28
[ Wed Jun 28 18:48:39 2023 ] 	Training loss: 0.8237.  Training acc: 70.59%.
[ Wed Jun 28 18:48:39 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:48:39 2023 ] Eval epoch: 28
[ Wed Jun 28 18:48:40 2023 ] 	Mean test loss of 625 batches: 0.584779.
[ Wed Jun 28 18:48:40 2023 ] 	Top1: 91.23%
[ Wed Jun 28 18:48:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:48:40 2023 ] Training epoch: 29
[ Wed Jun 28 18:48:43 2023 ] 	Training loss: 0.8278.  Training acc: 71.05%.
[ Wed Jun 28 18:48:43 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:48:43 2023 ] Eval epoch: 29
[ Wed Jun 28 18:48:44 2023 ] 	Mean test loss of 625 batches: 0.594046.
[ Wed Jun 28 18:48:44 2023 ] 	Top1: 89.47%
[ Wed Jun 28 18:48:44 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:48:44 2023 ] Training epoch: 30
[ Wed Jun 28 18:48:46 2023 ] 	Training loss: 0.7977.  Training acc: 72.61%.
[ Wed Jun 28 18:48:46 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:48:46 2023 ] Eval epoch: 30
[ Wed Jun 28 18:48:47 2023 ] 	Mean test loss of 625 batches: 0.571144.
[ Wed Jun 28 18:48:47 2023 ] 	Top1: 91.23%
[ Wed Jun 28 18:48:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:48:48 2023 ] Best accuracy: 0.9473684210526315
[ Wed Jun 28 18:48:48 2023 ] Epoch number: 17
[ Wed Jun 28 18:48:48 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 18:48:48 2023 ] Weight decay: 0.0005
[ Wed Jun 28 18:48:48 2023 ] Base LR: 0.1
[ Wed Jun 28 18:48:48 2023 ] Batch Size: 64
[ Wed Jun 28 18:48:48 2023 ] Test Batch Size: 64
[ Wed Jun 28 18:48:48 2023 ] seed: 1
[ Wed Jun 28 18:48:48 2023 ] Start training Corrector
[ Wed Jun 28 18:48:48 2023 ] # Parameters Corrector: 2407569
[ Wed Jun 28 18:48:49 2023 ] Training epoch: 1
[ Wed Jun 28 18:48:57 2023 ] 	Training loss: 24.3712.  Training acc: 38.28%.
[ Wed Jun 28 18:48:57 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 18:48:57 2023 ] Eval epoch: 1
[ Wed Jun 28 18:49:00 2023 ] 	Mean test loss of 625 batches: 3.701675.
[ Wed Jun 28 18:49:00 2023 ] 	Mean test label-loss of 625 batches: 65.530837.
[ Wed Jun 28 18:49:00 2023 ] 	Top1: 23.68%
[ Wed Jun 28 18:49:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:49:00 2023 ] Training epoch: 2
[ Wed Jun 28 18:49:07 2023 ] 	Training loss: 23.4167.  Training acc: 32.42%.
[ Wed Jun 28 18:49:07 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 18:49:07 2023 ] Eval epoch: 2
[ Wed Jun 28 18:49:09 2023 ] 	Mean test loss of 625 batches: 5.379274.
[ Wed Jun 28 18:49:09 2023 ] 	Mean test label-loss of 625 batches: 57.294291.
[ Wed Jun 28 18:49:09 2023 ] 	Top1: 23.68%
[ Wed Jun 28 18:49:09 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:49:09 2023 ] Training epoch: 3
[ Wed Jun 28 18:49:16 2023 ] 	Training loss: 22.7699.  Training acc: 23.44%.
[ Wed Jun 28 18:49:16 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:49:16 2023 ] Eval epoch: 3
[ Wed Jun 28 18:49:18 2023 ] 	Mean test loss of 625 batches: 1.250335.
[ Wed Jun 28 18:49:18 2023 ] 	Mean test label-loss of 625 batches: 61.618906.
[ Wed Jun 28 18:49:18 2023 ] 	Top1: 34.21%
[ Wed Jun 28 18:49:18 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:49:19 2023 ] Training epoch: 4
[ Wed Jun 28 18:49:25 2023 ] 	Training loss: 37.7846.  Training acc: 17.97%.
[ Wed Jun 28 18:49:25 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Wed Jun 28 18:49:25 2023 ] Eval epoch: 4
[ Wed Jun 28 18:49:27 2023 ] 	Mean test loss of 625 batches: 14.216155.
[ Wed Jun 28 18:49:27 2023 ] 	Mean test label-loss of 625 batches: 55.171371.
[ Wed Jun 28 18:49:27 2023 ] 	Top1: 2.63%
[ Wed Jun 28 18:49:27 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:49:28 2023 ] Training epoch: 5
[ Wed Jun 28 18:49:34 2023 ] 	Training loss: 35.3772.  Training acc: 27.86%.
[ Wed Jun 28 18:49:34 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:49:34 2023 ] Eval epoch: 5
[ Wed Jun 28 18:49:36 2023 ] 	Mean test loss of 625 batches: 1.470983.
[ Wed Jun 28 18:49:36 2023 ] 	Mean test label-loss of 625 batches: 53.571898.
[ Wed Jun 28 18:49:36 2023 ] 	Top1: 47.37%
[ Wed Jun 28 18:49:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:49:37 2023 ] Training epoch: 6
[ Wed Jun 28 18:49:43 2023 ] 	Training loss: 29.1672.  Training acc: 29.30%.
[ Wed Jun 28 18:49:43 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:49:43 2023 ] Eval epoch: 6
[ Wed Jun 28 18:49:45 2023 ] 	Mean test loss of 625 batches: 3.075204.
[ Wed Jun 28 18:49:45 2023 ] 	Mean test label-loss of 625 batches: 44.180439.
[ Wed Jun 28 18:49:45 2023 ] 	Top1: 26.32%
[ Wed Jun 28 18:49:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:49:46 2023 ] Training epoch: 7
[ Wed Jun 28 18:49:53 2023 ] 	Training loss: 29.5314.  Training acc: 34.11%.
[ Wed Jun 28 18:49:53 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:49:53 2023 ] Eval epoch: 7
[ Wed Jun 28 18:49:54 2023 ] 	Mean test loss of 625 batches: 3.790433.
[ Wed Jun 28 18:49:54 2023 ] 	Mean test label-loss of 625 batches: 39.733365.
[ Wed Jun 28 18:49:54 2023 ] 	Top1: 28.95%
[ Wed Jun 28 18:49:54 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:49:55 2023 ] Training epoch: 8
[ Wed Jun 28 18:50:02 2023 ] 	Training loss: 27.7255.  Training acc: 39.97%.
[ Wed Jun 28 18:50:02 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:50:02 2023 ] Eval epoch: 8
[ Wed Jun 28 18:50:04 2023 ] 	Mean test loss of 625 batches: 1.608850.
[ Wed Jun 28 18:50:04 2023 ] 	Mean test label-loss of 625 batches: 36.678892.
[ Wed Jun 28 18:50:04 2023 ] 	Top1: 52.63%
[ Wed Jun 28 18:50:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:50:04 2023 ] Training epoch: 9
[ Wed Jun 28 18:50:11 2023 ] 	Training loss: 29.4279.  Training acc: 48.57%.
[ Wed Jun 28 18:50:11 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 18:50:11 2023 ] Eval epoch: 9
[ Wed Jun 28 18:50:13 2023 ] 	Mean test loss of 625 batches: 10.048443.
[ Wed Jun 28 18:50:13 2023 ] 	Mean test label-loss of 625 batches: 43.081985.
[ Wed Jun 28 18:50:13 2023 ] 	Top1: 39.47%
[ Wed Jun 28 18:50:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:50:13 2023 ] Training epoch: 10
[ Wed Jun 28 18:50:20 2023 ] 	Training loss: 43.4911.  Training acc: 32.55%.
[ Wed Jun 28 18:50:20 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:50:20 2023 ] Eval epoch: 10
[ Wed Jun 28 18:50:22 2023 ] 	Mean test loss of 625 batches: 33.486767.
[ Wed Jun 28 18:50:22 2023 ] 	Mean test label-loss of 625 batches: 48.918994.
[ Wed Jun 28 18:50:22 2023 ] 	Top1: 7.89%
[ Wed Jun 28 18:50:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:50:22 2023 ] Training epoch: 11
[ Wed Jun 28 18:50:29 2023 ] 	Training loss: 55.4697.  Training acc: 27.73%.
[ Wed Jun 28 18:50:29 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:50:29 2023 ] Eval epoch: 11
[ Wed Jun 28 18:50:31 2023 ] 	Mean test loss of 625 batches: 30.653879.
[ Wed Jun 28 18:50:31 2023 ] 	Mean test label-loss of 625 batches: 56.485330.
[ Wed Jun 28 18:50:31 2023 ] 	Top1: 23.68%
[ Wed Jun 28 18:50:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:50:32 2023 ] Training epoch: 12
[ Wed Jun 28 18:50:38 2023 ] 	Training loss: 54.0978.  Training acc: 27.60%.
[ Wed Jun 28 18:50:38 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 18:50:38 2023 ] Eval epoch: 12
[ Wed Jun 28 18:50:40 2023 ] 	Mean test loss of 625 batches: 30.192422.
[ Wed Jun 28 18:50:40 2023 ] 	Mean test label-loss of 625 batches: 55.259071.
[ Wed Jun 28 18:50:40 2023 ] 	Top1: 21.05%
[ Wed Jun 28 18:50:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:50:41 2023 ] Training epoch: 13
[ Wed Jun 28 18:50:47 2023 ] 	Training loss: 54.2929.  Training acc: 27.60%.
[ Wed Jun 28 18:50:47 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 18:50:47 2023 ] Eval epoch: 13
[ Wed Jun 28 18:50:49 2023 ] 	Mean test loss of 625 batches: 30.155387.
[ Wed Jun 28 18:50:49 2023 ] 	Mean test label-loss of 625 batches: 55.959869.
[ Wed Jun 28 18:50:49 2023 ] 	Top1: 18.42%
[ Wed Jun 28 18:50:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:50:50 2023 ] Training epoch: 14
[ Wed Jun 28 18:50:56 2023 ] 	Training loss: 53.9473.  Training acc: 27.34%.
[ Wed Jun 28 18:50:56 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 18:50:56 2023 ] Eval epoch: 14
[ Wed Jun 28 18:50:58 2023 ] 	Mean test loss of 625 batches: 25.014304.
[ Wed Jun 28 18:50:58 2023 ] 	Mean test label-loss of 625 batches: 54.821456.
[ Wed Jun 28 18:50:58 2023 ] 	Top1: 18.42%
[ Wed Jun 28 18:50:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:50:59 2023 ] Training epoch: 15
[ Wed Jun 28 18:51:05 2023 ] 	Training loss: 52.5301.  Training acc: 27.08%.
[ Wed Jun 28 18:51:05 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:51:05 2023 ] Eval epoch: 15
[ Wed Jun 28 18:51:07 2023 ] 	Mean test loss of 625 batches: 22.313175.
[ Wed Jun 28 18:51:07 2023 ] 	Mean test label-loss of 625 batches: 54.123996.
[ Wed Jun 28 18:51:07 2023 ] 	Top1: 26.32%
[ Wed Jun 28 18:51:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:51:08 2023 ] Training epoch: 16
[ Wed Jun 28 18:51:14 2023 ] 	Training loss: 51.1084.  Training acc: 27.34%.
[ Wed Jun 28 18:51:14 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:51:14 2023 ] Eval epoch: 16
[ Wed Jun 28 18:51:16 2023 ] 	Mean test loss of 625 batches: 20.091707.
[ Wed Jun 28 18:51:16 2023 ] 	Mean test label-loss of 625 batches: 52.545875.
[ Wed Jun 28 18:51:16 2023 ] 	Top1: 23.68%
[ Wed Jun 28 18:51:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:51:17 2023 ] Training epoch: 17
[ Wed Jun 28 18:51:23 2023 ] 	Training loss: 50.6776.  Training acc: 28.26%.
[ Wed Jun 28 18:51:23 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:51:23 2023 ] Eval epoch: 17
[ Wed Jun 28 18:51:25 2023 ] 	Mean test loss of 625 batches: 22.505575.
[ Wed Jun 28 18:51:25 2023 ] 	Mean test label-loss of 625 batches: 51.257226.
[ Wed Jun 28 18:51:25 2023 ] 	Top1: 23.68%
[ Wed Jun 28 18:51:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:51:26 2023 ] Training epoch: 18
[ Wed Jun 28 18:51:32 2023 ] 	Training loss: 50.7174.  Training acc: 27.60%.
[ Wed Jun 28 18:51:32 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 18:51:32 2023 ] Eval epoch: 18
[ Wed Jun 28 18:51:34 2023 ] 	Mean test loss of 625 batches: 23.400286.
[ Wed Jun 28 18:51:34 2023 ] 	Mean test label-loss of 625 batches: 51.472798.
[ Wed Jun 28 18:51:34 2023 ] 	Top1: 21.05%
[ Wed Jun 28 18:51:34 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:51:35 2023 ] Training epoch: 19
[ Wed Jun 28 18:51:43 2023 ] using warm up, epoch: 5
[ Wed Jun 28 18:51:43 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 18:51:43 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 18:51:43 2023 ] Start training Predictor
[ Wed Jun 28 18:51:43 2023 ] Training epoch: 1
[ Wed Jun 28 18:51:49 2023 ] 	Training loss: 102.4461.  Training acc: 34.83%.
[ Wed Jun 28 18:51:49 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 18:51:49 2023 ] Eval epoch: 1
[ Wed Jun 28 18:51:50 2023 ] 	Mean test loss of 625 batches: 93.824554.
[ Wed Jun 28 18:51:50 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:51:50 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:51:50 2023 ] Training epoch: 2
[ Wed Jun 28 18:51:53 2023 ] 	Training loss: 11.3135.  Training acc: 36.49%.
[ Wed Jun 28 18:51:53 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:51:53 2023 ] Eval epoch: 2
[ Wed Jun 28 18:51:53 2023 ] 	Mean test loss of 625 batches: 2.827058.
[ Wed Jun 28 18:51:53 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:51:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:51:53 2023 ] Training epoch: 3
[ Wed Jun 28 18:51:56 2023 ] 	Training loss: 6.1323.  Training acc: 43.20%.
[ Wed Jun 28 18:51:56 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:51:56 2023 ] Eval epoch: 3
[ Wed Jun 28 18:51:57 2023 ] 	Mean test loss of 625 batches: 9.792489.
[ Wed Jun 28 18:51:57 2023 ] 	Top1: 29.82%
[ Wed Jun 28 18:51:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:51:57 2023 ] Training epoch: 4
[ Wed Jun 28 18:52:00 2023 ] 	Training loss: 5.2492.  Training acc: 53.58%.
[ Wed Jun 28 18:52:00 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:52:00 2023 ] Eval epoch: 4
[ Wed Jun 28 18:52:01 2023 ] 	Mean test loss of 625 batches: 3.240825.
[ Wed Jun 28 18:52:01 2023 ] 	Top1: 49.12%
[ Wed Jun 28 18:52:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:52:01 2023 ] Training epoch: 5
[ Wed Jun 28 18:52:04 2023 ] 	Training loss: 3.7958.  Training acc: 58.36%.
[ Wed Jun 28 18:52:04 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:52:04 2023 ] Eval epoch: 5
[ Wed Jun 28 18:52:04 2023 ] 	Mean test loss of 625 batches: 1.013977.
[ Wed Jun 28 18:52:04 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:52:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:52:04 2023 ] Training epoch: 6
[ Wed Jun 28 18:52:07 2023 ] 	Training loss: 2.5526.  Training acc: 56.89%.
[ Wed Jun 28 18:52:07 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:52:07 2023 ] Eval epoch: 6
[ Wed Jun 28 18:52:08 2023 ] 	Mean test loss of 625 batches: 0.860447.
[ Wed Jun 28 18:52:08 2023 ] 	Top1: 82.46%
[ Wed Jun 28 18:52:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:52:08 2023 ] Training epoch: 7
[ Wed Jun 28 18:52:11 2023 ] 	Training loss: 2.2723.  Training acc: 62.32%.
[ Wed Jun 28 18:52:11 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:52:11 2023 ] Eval epoch: 7
[ Wed Jun 28 18:52:12 2023 ] 	Mean test loss of 625 batches: 4.656391.
[ Wed Jun 28 18:52:12 2023 ] 	Top1: 29.82%
[ Wed Jun 28 18:52:12 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:52:12 2023 ] Training epoch: 8
[ Wed Jun 28 18:52:14 2023 ] 	Training loss: 1.5190.  Training acc: 63.42%.
[ Wed Jun 28 18:52:14 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:52:14 2023 ] Eval epoch: 8
[ Wed Jun 28 18:52:15 2023 ] 	Mean test loss of 625 batches: 1.043471.
[ Wed Jun 28 18:52:15 2023 ] 	Top1: 68.42%
[ Wed Jun 28 18:52:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:52:15 2023 ] Training epoch: 9
[ Wed Jun 28 18:52:18 2023 ] 	Training loss: 1.1992.  Training acc: 71.51%.
[ Wed Jun 28 18:52:18 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:52:18 2023 ] Eval epoch: 9
[ Wed Jun 28 18:52:19 2023 ] 	Mean test loss of 625 batches: 1.102160.
[ Wed Jun 28 18:52:19 2023 ] 	Top1: 33.33%
[ Wed Jun 28 18:52:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:52:19 2023 ] Training epoch: 10
[ Wed Jun 28 18:52:22 2023 ] 	Training loss: 1.5913.  Training acc: 62.87%.
[ Wed Jun 28 18:52:22 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:52:22 2023 ] Eval epoch: 10
[ Wed Jun 28 18:52:22 2023 ] 	Mean test loss of 625 batches: 5.481666.
[ Wed Jun 28 18:52:22 2023 ] 	Top1: 40.35%
[ Wed Jun 28 18:52:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:52:22 2023 ] Training epoch: 11
[ Wed Jun 28 18:52:25 2023 ] 	Training loss: 1.5051.  Training acc: 64.98%.
[ Wed Jun 28 18:52:25 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:52:25 2023 ] Eval epoch: 11
[ Wed Jun 28 18:52:26 2023 ] 	Mean test loss of 625 batches: 0.673651.
[ Wed Jun 28 18:52:26 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:52:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:52:26 2023 ] Training epoch: 12
[ Wed Jun 28 18:52:29 2023 ] 	Training loss: 1.0322.  Training acc: 69.49%.
[ Wed Jun 28 18:52:29 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:52:29 2023 ] Eval epoch: 12
[ Wed Jun 28 18:52:29 2023 ] 	Mean test loss of 625 batches: 0.627451.
[ Wed Jun 28 18:52:29 2023 ] 	Top1: 96.49%
[ Wed Jun 28 18:52:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:52:29 2023 ] Training epoch: 13
[ Wed Jun 28 18:52:32 2023 ] 	Training loss: 0.8485.  Training acc: 74.36%.
[ Wed Jun 28 18:52:32 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:52:32 2023 ] Eval epoch: 13
[ Wed Jun 28 18:52:33 2023 ] 	Mean test loss of 625 batches: 0.568208.
[ Wed Jun 28 18:52:33 2023 ] 	Top1: 92.98%
[ Wed Jun 28 18:52:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:52:33 2023 ] Training epoch: 14
[ Wed Jun 28 18:52:36 2023 ] 	Training loss: 0.7968.  Training acc: 75.37%.
[ Wed Jun 28 18:52:36 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:52:36 2023 ] Eval epoch: 14
[ Wed Jun 28 18:52:37 2023 ] 	Mean test loss of 625 batches: 0.550922.
[ Wed Jun 28 18:52:37 2023 ] 	Top1: 96.49%
[ Wed Jun 28 18:52:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:52:37 2023 ] Training epoch: 15
[ Wed Jun 28 18:52:40 2023 ] 	Training loss: 0.7683.  Training acc: 77.76%.
[ Wed Jun 28 18:52:40 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:52:40 2023 ] Eval epoch: 15
[ Wed Jun 28 18:52:40 2023 ] 	Mean test loss of 625 batches: 0.566039.
[ Wed Jun 28 18:52:40 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:52:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:52:40 2023 ] Training epoch: 16
[ Wed Jun 28 18:52:43 2023 ] 	Training loss: 0.7647.  Training acc: 79.78%.
[ Wed Jun 28 18:52:43 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:52:43 2023 ] Eval epoch: 16
[ Wed Jun 28 18:52:44 2023 ] 	Mean test loss of 625 batches: 0.538445.
[ Wed Jun 28 18:52:44 2023 ] 	Top1: 94.74%
[ Wed Jun 28 18:52:44 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:52:44 2023 ] Training epoch: 17
[ Wed Jun 28 18:52:47 2023 ] 	Training loss: 0.7129.  Training acc: 81.99%.
[ Wed Jun 28 18:52:47 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:52:47 2023 ] Eval epoch: 17
[ Wed Jun 28 18:52:47 2023 ] 	Mean test loss of 625 batches: 0.530630.
[ Wed Jun 28 18:52:47 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:52:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:52:47 2023 ] Training epoch: 18
[ Wed Jun 28 18:52:50 2023 ] 	Training loss: 0.7127.  Training acc: 80.88%.
[ Wed Jun 28 18:52:50 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:52:50 2023 ] Eval epoch: 18
[ Wed Jun 28 18:52:51 2023 ] 	Mean test loss of 625 batches: 0.528264.
[ Wed Jun 28 18:52:51 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:52:51 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:52:51 2023 ] Training epoch: 19
[ Wed Jun 28 18:52:54 2023 ] 	Training loss: 0.6707.  Training acc: 86.03%.
[ Wed Jun 28 18:52:54 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:52:54 2023 ] Eval epoch: 19
[ Wed Jun 28 18:52:54 2023 ] 	Mean test loss of 625 batches: 0.475189.
[ Wed Jun 28 18:52:54 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:52:54 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:52:54 2023 ] Training epoch: 20
[ Wed Jun 28 18:52:57 2023 ] 	Training loss: 0.6433.  Training acc: 87.32%.
[ Wed Jun 28 18:52:57 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:52:57 2023 ] Eval epoch: 20
[ Wed Jun 28 18:52:58 2023 ] 	Mean test loss of 625 batches: 0.486405.
[ Wed Jun 28 18:52:58 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:52:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:52:58 2023 ] Training epoch: 21
[ Wed Jun 28 18:53:01 2023 ] 	Training loss: 0.6193.  Training acc: 88.60%.
[ Wed Jun 28 18:53:01 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:53:01 2023 ] Eval epoch: 21
[ Wed Jun 28 18:53:02 2023 ] 	Mean test loss of 625 batches: 0.469910.
[ Wed Jun 28 18:53:02 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:53:02 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:53:02 2023 ] Training epoch: 22
[ Wed Jun 28 18:53:04 2023 ] 	Training loss: 0.6087.  Training acc: 89.06%.
[ Wed Jun 28 18:53:04 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:53:04 2023 ] Eval epoch: 22
[ Wed Jun 28 18:53:05 2023 ] 	Mean test loss of 625 batches: 0.474919.
[ Wed Jun 28 18:53:05 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:53:05 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:53:05 2023 ] Training epoch: 23
[ Wed Jun 28 18:53:08 2023 ] 	Training loss: 0.5966.  Training acc: 89.25%.
[ Wed Jun 28 18:53:08 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:53:08 2023 ] Eval epoch: 23
[ Wed Jun 28 18:53:09 2023 ] 	Mean test loss of 625 batches: 0.467786.
[ Wed Jun 28 18:53:09 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:53:09 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:53:09 2023 ] Training epoch: 24
[ Wed Jun 28 18:53:12 2023 ] 	Training loss: 0.6004.  Training acc: 89.06%.
[ Wed Jun 28 18:53:12 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:53:12 2023 ] Eval epoch: 24
[ Wed Jun 28 18:53:12 2023 ] 	Mean test loss of 625 batches: 0.466485.
[ Wed Jun 28 18:53:12 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:53:12 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:53:12 2023 ] Training epoch: 25
[ Wed Jun 28 18:53:15 2023 ] 	Training loss: 0.5949.  Training acc: 89.71%.
[ Wed Jun 28 18:53:15 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:53:15 2023 ] Eval epoch: 25
[ Wed Jun 28 18:53:16 2023 ] 	Mean test loss of 625 batches: 0.467611.
[ Wed Jun 28 18:53:16 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:53:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:53:16 2023 ] Training epoch: 26
[ Wed Jun 28 18:53:19 2023 ] 	Training loss: 0.5828.  Training acc: 91.08%.
[ Wed Jun 28 18:53:19 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:53:19 2023 ] Eval epoch: 26
[ Wed Jun 28 18:53:19 2023 ] 	Mean test loss of 625 batches: 0.469594.
[ Wed Jun 28 18:53:19 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:53:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:53:19 2023 ] Training epoch: 27
[ Wed Jun 28 18:53:22 2023 ] 	Training loss: 0.5919.  Training acc: 89.25%.
[ Wed Jun 28 18:53:22 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:53:22 2023 ] Eval epoch: 27
[ Wed Jun 28 18:53:23 2023 ] 	Mean test loss of 625 batches: 0.470740.
[ Wed Jun 28 18:53:23 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:53:23 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:53:23 2023 ] Training epoch: 28
[ Wed Jun 28 18:53:26 2023 ] 	Training loss: 0.5714.  Training acc: 92.10%.
[ Wed Jun 28 18:53:26 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:53:26 2023 ] Eval epoch: 28
[ Wed Jun 28 18:53:26 2023 ] 	Mean test loss of 625 batches: 0.467027.
[ Wed Jun 28 18:53:26 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:53:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:53:26 2023 ] Training epoch: 29
[ Wed Jun 28 18:53:29 2023 ] 	Training loss: 0.5695.  Training acc: 91.73%.
[ Wed Jun 28 18:53:29 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:53:29 2023 ] Eval epoch: 29
[ Wed Jun 28 18:53:30 2023 ] 	Mean test loss of 625 batches: 0.468386.
[ Wed Jun 28 18:53:30 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:53:30 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:53:30 2023 ] Training epoch: 30
[ Wed Jun 28 18:53:33 2023 ] 	Training loss: 0.5656.  Training acc: 91.82%.
[ Wed Jun 28 18:53:33 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:53:33 2023 ] Eval epoch: 30
[ Wed Jun 28 18:53:34 2023 ] 	Mean test loss of 625 batches: 0.465498.
[ Wed Jun 28 18:53:34 2023 ] 	Top1: 100.00%
[ Wed Jun 28 18:53:34 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:53:34 2023 ] Best accuracy: 1.0
[ Wed Jun 28 18:53:34 2023 ] Epoch number: 15
[ Wed Jun 28 18:53:34 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 18:53:34 2023 ] Weight decay: 0.0005
[ Wed Jun 28 18:53:34 2023 ] Base LR: 0.1
[ Wed Jun 28 18:53:34 2023 ] Batch Size: 64
[ Wed Jun 28 18:53:34 2023 ] Test Batch Size: 64
[ Wed Jun 28 18:53:34 2023 ] seed: 1
[ Wed Jun 28 18:53:34 2023 ] Start training Corrector
[ Wed Jun 28 18:53:34 2023 ] # Parameters Corrector: 2407569
[ Wed Jun 28 18:53:36 2023 ] Training epoch: 1
[ Wed Jun 28 18:53:44 2023 ] 	Training loss: 19.6986.  Training acc: 52.99%.
[ Wed Jun 28 18:53:44 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 18:53:44 2023 ] Eval epoch: 1
[ Wed Jun 28 18:53:46 2023 ] 	Mean test loss of 625 batches: 5.802542.
[ Wed Jun 28 18:53:46 2023 ] 	Mean test label-loss of 625 batches: 50.605434.
[ Wed Jun 28 18:53:46 2023 ] 	Top1: 28.95%
[ Wed Jun 28 18:53:46 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:53:47 2023 ] Training epoch: 2
[ Wed Jun 28 18:53:53 2023 ] 	Training loss: 13.0815.  Training acc: 43.23%.
[ Wed Jun 28 18:53:53 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 18:53:53 2023 ] Eval epoch: 2
[ Wed Jun 28 18:53:55 2023 ] 	Mean test loss of 625 batches: 6.205714.
[ Wed Jun 28 18:53:55 2023 ] 	Mean test label-loss of 625 batches: 36.230859.
[ Wed Jun 28 18:53:55 2023 ] 	Top1: 21.05%
[ Wed Jun 28 18:53:55 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:53:56 2023 ] Training epoch: 3
[ Wed Jun 28 18:54:02 2023 ] 	Training loss: 20.2959.  Training acc: 34.38%.
[ Wed Jun 28 18:54:02 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:54:02 2023 ] Eval epoch: 3
[ Wed Jun 28 18:54:04 2023 ] 	Mean test loss of 625 batches: 38.418762.
[ Wed Jun 28 18:54:04 2023 ] 	Mean test label-loss of 625 batches: 52.128423.
[ Wed Jun 28 18:54:04 2023 ] 	Top1: 26.32%
[ Wed Jun 28 18:54:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:54:05 2023 ] Training epoch: 4
[ Wed Jun 28 18:54:11 2023 ] 	Training loss: 30.6231.  Training acc: 28.78%.
[ Wed Jun 28 18:54:11 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:54:11 2023 ] Eval epoch: 4
[ Wed Jun 28 18:54:13 2023 ] 	Mean test loss of 625 batches: 13.984791.
[ Wed Jun 28 18:54:13 2023 ] 	Mean test label-loss of 625 batches: 56.558841.
[ Wed Jun 28 18:54:13 2023 ] 	Top1: 15.79%
[ Wed Jun 28 18:54:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:54:14 2023 ] Training epoch: 5
[ Wed Jun 28 18:54:20 2023 ] 	Training loss: 38.3078.  Training acc: 37.89%.
[ Wed Jun 28 18:54:20 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:54:20 2023 ] Eval epoch: 5
[ Wed Jun 28 18:54:22 2023 ] 	Mean test loss of 625 batches: 5.455048.
[ Wed Jun 28 18:54:22 2023 ] 	Mean test label-loss of 625 batches: 71.832354.
[ Wed Jun 28 18:54:22 2023 ] 	Top1: 10.53%
[ Wed Jun 28 18:54:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:54:23 2023 ] Training epoch: 6
[ Wed Jun 28 18:54:29 2023 ] 	Training loss: 46.0251.  Training acc: 31.25%.
[ Wed Jun 28 18:54:29 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:54:29 2023 ] Eval epoch: 6
[ Wed Jun 28 18:54:31 2023 ] 	Mean test loss of 625 batches: 4.628560.
[ Wed Jun 28 18:54:31 2023 ] 	Mean test label-loss of 625 batches: 70.627522.
[ Wed Jun 28 18:54:31 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:54:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:54:32 2023 ] Training epoch: 7
[ Wed Jun 28 18:54:38 2023 ] 	Training loss: 45.9616.  Training acc: 35.29%.
[ Wed Jun 28 18:54:38 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 18:54:38 2023 ] Eval epoch: 7
[ Wed Jun 28 18:54:40 2023 ] 	Mean test loss of 625 batches: 3.386541.
[ Wed Jun 28 18:54:40 2023 ] 	Mean test label-loss of 625 batches: 65.880308.
[ Wed Jun 28 18:54:40 2023 ] 	Top1: 50.00%
[ Wed Jun 28 18:54:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:54:41 2023 ] Training epoch: 8
[ Wed Jun 28 18:54:47 2023 ] 	Training loss: 45.0949.  Training acc: 39.71%.
[ Wed Jun 28 18:54:47 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 18:54:47 2023 ] Eval epoch: 8
[ Wed Jun 28 18:54:49 2023 ] 	Mean test loss of 625 batches: 9.876449.
[ Wed Jun 28 18:54:49 2023 ] 	Mean test label-loss of 625 batches: 73.496990.
[ Wed Jun 28 18:54:49 2023 ] 	Top1: 28.95%
[ Wed Jun 28 18:54:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:54:50 2023 ] Training epoch: 9
[ Wed Jun 28 18:54:56 2023 ] 	Training loss: 52.3622.  Training acc: 31.38%.
[ Wed Jun 28 18:54:56 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:54:56 2023 ] Eval epoch: 9
[ Wed Jun 28 18:54:58 2023 ] 	Mean test loss of 625 batches: 10.216392.
[ Wed Jun 28 18:54:58 2023 ] 	Mean test label-loss of 625 batches: 76.665149.
[ Wed Jun 28 18:54:58 2023 ] 	Top1: 28.95%
[ Wed Jun 28 18:54:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:54:59 2023 ] Training epoch: 10
[ Wed Jun 28 18:55:05 2023 ] 	Training loss: 50.8419.  Training acc: 29.56%.
[ Wed Jun 28 18:55:05 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 18:55:05 2023 ] Eval epoch: 10
[ Wed Jun 28 18:55:07 2023 ] 	Mean test loss of 625 batches: 10.248761.
[ Wed Jun 28 18:55:07 2023 ] 	Mean test label-loss of 625 batches: 68.991217.
[ Wed Jun 28 18:55:07 2023 ] 	Top1: 21.05%
[ Wed Jun 28 18:55:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:55:08 2023 ] Training epoch: 11
[ Wed Jun 28 18:55:15 2023 ] 	Training loss: 49.7102.  Training acc: 27.99%.
[ Wed Jun 28 18:55:15 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:55:15 2023 ] Eval epoch: 11
[ Wed Jun 28 18:55:16 2023 ] 	Mean test loss of 625 batches: 13.846310.
[ Wed Jun 28 18:55:16 2023 ] 	Mean test label-loss of 625 batches: 67.121243.
[ Wed Jun 28 18:55:16 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:55:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:55:17 2023 ] Training epoch: 12
[ Wed Jun 28 18:55:23 2023 ] 	Training loss: 49.8667.  Training acc: 24.74%.
[ Wed Jun 28 18:55:23 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:55:23 2023 ] Eval epoch: 12
[ Wed Jun 28 18:55:25 2023 ] 	Mean test loss of 625 batches: 14.605916.
[ Wed Jun 28 18:55:25 2023 ] 	Mean test label-loss of 625 batches: 65.880205.
[ Wed Jun 28 18:55:25 2023 ] 	Top1: 39.47%
[ Wed Jun 28 18:55:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:55:26 2023 ] Training epoch: 13
[ Wed Jun 28 18:55:33 2023 ] 	Training loss: 48.7501.  Training acc: 29.43%.
[ Wed Jun 28 18:55:33 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 18:55:33 2023 ] Eval epoch: 13
[ Wed Jun 28 18:55:35 2023 ] 	Mean test loss of 625 batches: 12.368166.
[ Wed Jun 28 18:55:35 2023 ] 	Mean test label-loss of 625 batches: 65.136137.
[ Wed Jun 28 18:55:35 2023 ] 	Top1: 26.32%
[ Wed Jun 28 18:55:35 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:55:35 2023 ] Training epoch: 14
[ Wed Jun 28 18:55:42 2023 ] 	Training loss: 47.9139.  Training acc: 28.52%.
[ Wed Jun 28 18:55:42 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:55:42 2023 ] Eval epoch: 14
[ Wed Jun 28 18:55:44 2023 ] 	Mean test loss of 625 batches: 13.220926.
[ Wed Jun 28 18:55:44 2023 ] 	Mean test label-loss of 625 batches: 64.640344.
[ Wed Jun 28 18:55:44 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:55:44 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:55:45 2023 ] Training epoch: 15
[ Wed Jun 28 18:55:51 2023 ] 	Training loss: 48.1181.  Training acc: 25.78%.
[ Wed Jun 28 18:55:51 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:55:51 2023 ] Eval epoch: 15
[ Wed Jun 28 18:55:53 2023 ] 	Mean test loss of 625 batches: 10.844042.
[ Wed Jun 28 18:55:53 2023 ] 	Mean test label-loss of 625 batches: 65.304765.
[ Wed Jun 28 18:55:53 2023 ] 	Top1: 21.05%
[ Wed Jun 28 18:55:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:55:54 2023 ] Training epoch: 16
[ Wed Jun 28 18:56:00 2023 ] 	Training loss: 48.8013.  Training acc: 25.00%.
[ Wed Jun 28 18:56:00 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:56:00 2023 ] Eval epoch: 16
[ Wed Jun 28 18:56:02 2023 ] 	Mean test loss of 625 batches: 11.953750.
[ Wed Jun 28 18:56:02 2023 ] 	Mean test label-loss of 625 batches: 66.764463.
[ Wed Jun 28 18:56:02 2023 ] 	Top1: 26.32%
[ Wed Jun 28 18:56:02 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:56:03 2023 ] Training epoch: 17
[ Wed Jun 28 18:56:10 2023 ] 	Training loss: 49.0891.  Training acc: 21.74%.
[ Wed Jun 28 18:56:10 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:56:10 2023 ] Eval epoch: 17
[ Wed Jun 28 18:56:12 2023 ] 	Mean test loss of 625 batches: 15.886239.
[ Wed Jun 28 18:56:12 2023 ] 	Mean test label-loss of 625 batches: 66.413458.
[ Wed Jun 28 18:56:12 2023 ] 	Top1: 7.89%
[ Wed Jun 28 18:56:12 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:56:13 2023 ] Training epoch: 18
[ Wed Jun 28 18:56:19 2023 ] 	Training loss: 49.1448.  Training acc: 20.18%.
[ Wed Jun 28 18:56:19 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:56:19 2023 ] Eval epoch: 18
[ Wed Jun 28 18:56:21 2023 ] 	Mean test loss of 625 batches: 7.788379.
[ Wed Jun 28 18:56:21 2023 ] 	Mean test label-loss of 625 batches: 66.494911.
[ Wed Jun 28 18:56:21 2023 ] 	Top1: 15.79%
[ Wed Jun 28 18:56:21 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:56:22 2023 ] Training epoch: 19
[ Wed Jun 28 18:56:28 2023 ] 	Training loss: 49.1811.  Training acc: 24.61%.
[ Wed Jun 28 18:56:28 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 18:56:28 2023 ] Eval epoch: 19
[ Wed Jun 28 18:56:30 2023 ] 	Mean test loss of 625 batches: 8.237545.
[ Wed Jun 28 18:56:30 2023 ] 	Mean test label-loss of 625 batches: 66.316672.
[ Wed Jun 28 18:56:30 2023 ] 	Top1: 18.42%
[ Wed Jun 28 18:56:30 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:56:31 2023 ] Training epoch: 20
[ Wed Jun 28 18:56:37 2023 ] 	Training loss: 48.3759.  Training acc: 27.21%.
[ Wed Jun 28 18:56:37 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 18:56:37 2023 ] Eval epoch: 20
[ Wed Jun 28 18:56:39 2023 ] 	Mean test loss of 625 batches: 8.580350.
[ Wed Jun 28 18:56:39 2023 ] 	Mean test label-loss of 625 batches: 65.745228.
[ Wed Jun 28 18:56:39 2023 ] 	Top1: 23.68%
[ Wed Jun 28 18:56:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:56:40 2023 ] Training epoch: 21
[ Wed Jun 28 18:56:46 2023 ] 	Training loss: 47.6188.  Training acc: 27.86%.
[ Wed Jun 28 18:56:46 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 18:56:46 2023 ] Eval epoch: 21
[ Wed Jun 28 18:56:48 2023 ] 	Mean test loss of 625 batches: 7.626336.
[ Wed Jun 28 18:56:48 2023 ] 	Mean test label-loss of 625 batches: 65.848117.
[ Wed Jun 28 18:56:48 2023 ] 	Top1: 34.21%
[ Wed Jun 28 18:56:48 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:56:49 2023 ] Training epoch: 22
[ Wed Jun 28 18:56:55 2023 ] 	Training loss: 47.9985.  Training acc: 25.39%.
[ Wed Jun 28 18:56:55 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 18:56:55 2023 ] Eval epoch: 22
[ Wed Jun 28 18:56:57 2023 ] 	Mean test loss of 625 batches: 7.206549.
[ Wed Jun 28 18:56:57 2023 ] 	Mean test label-loss of 625 batches: 65.634059.
[ Wed Jun 28 18:56:57 2023 ] 	Top1: 34.21%
[ Wed Jun 28 18:56:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:56:58 2023 ] Training epoch: 23
[ Wed Jun 28 18:57:04 2023 ] 	Training loss: 48.3169.  Training acc: 26.56%.
[ Wed Jun 28 18:57:04 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 18:57:04 2023 ] Eval epoch: 23
[ Wed Jun 28 18:57:06 2023 ] 	Mean test loss of 625 batches: 8.494214.
[ Wed Jun 28 18:57:06 2023 ] 	Mean test label-loss of 625 batches: 65.885132.
[ Wed Jun 28 18:57:06 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:57:06 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:57:07 2023 ] Training epoch: 24
[ Wed Jun 28 18:57:13 2023 ] 	Training loss: 48.4182.  Training acc: 27.21%.
[ Wed Jun 28 18:57:13 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 18:57:13 2023 ] Eval epoch: 24
[ Wed Jun 28 18:57:15 2023 ] 	Mean test loss of 625 batches: 7.190955.
[ Wed Jun 28 18:57:15 2023 ] 	Mean test label-loss of 625 batches: 65.813146.
[ Wed Jun 28 18:57:15 2023 ] 	Top1: 18.42%
[ Wed Jun 28 18:57:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:57:16 2023 ] Training epoch: 25
[ Wed Jun 28 18:57:22 2023 ] 	Training loss: 48.1244.  Training acc: 25.26%.
[ Wed Jun 28 18:57:22 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 18:57:22 2023 ] Eval epoch: 25
[ Wed Jun 28 18:57:24 2023 ] 	Mean test loss of 625 batches: 6.749844.
[ Wed Jun 28 18:57:24 2023 ] 	Mean test label-loss of 625 batches: 65.724225.
[ Wed Jun 28 18:57:24 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:57:24 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:57:25 2023 ] Training epoch: 26
[ Wed Jun 28 18:57:50 2023 ] using warm up, epoch: 5
[ Wed Jun 28 18:57:50 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 18:57:50 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 18:57:50 2023 ] Start training Predictor
[ Wed Jun 28 18:57:50 2023 ] Training epoch: 1
[ Wed Jun 28 18:57:56 2023 ] 	Training loss: 106.9709.  Training acc: 34.74%.
[ Wed Jun 28 18:57:56 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 18:57:56 2023 ] Eval epoch: 1
[ Wed Jun 28 18:57:57 2023 ] 	Mean test loss of 625 batches: 3790.508081.
[ Wed Jun 28 18:57:57 2023 ] 	Top1: 31.58%
[ Wed Jun 28 18:57:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:57:57 2023 ] Training epoch: 2
[ Wed Jun 28 18:58:00 2023 ] 	Training loss: 11.0398.  Training acc: 35.11%.
[ Wed Jun 28 18:58:00 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:58:00 2023 ] Eval epoch: 2
[ Wed Jun 28 18:58:00 2023 ] 	Mean test loss of 625 batches: 24.196402.
[ Wed Jun 28 18:58:00 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:58:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:58:00 2023 ] Training epoch: 3
[ Wed Jun 28 18:58:03 2023 ] 	Training loss: 6.9690.  Training acc: 38.05%.
[ Wed Jun 28 18:58:03 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:58:03 2023 ] Eval epoch: 3
[ Wed Jun 28 18:58:04 2023 ] 	Mean test loss of 625 batches: 1.892472.
[ Wed Jun 28 18:58:04 2023 ] 	Top1: 21.05%
[ Wed Jun 28 18:58:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:58:04 2023 ] Training epoch: 4
[ Wed Jun 28 18:58:07 2023 ] 	Training loss: 5.2191.  Training acc: 42.56%.
[ Wed Jun 28 18:58:07 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:58:07 2023 ] Eval epoch: 4
[ Wed Jun 28 18:58:08 2023 ] 	Mean test loss of 625 batches: 3.266454.
[ Wed Jun 28 18:58:08 2023 ] 	Top1: 35.09%
[ Wed Jun 28 18:58:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:58:08 2023 ] Training epoch: 5
[ Wed Jun 28 18:58:10 2023 ] 	Training loss: 2.9761.  Training acc: 58.55%.
[ Wed Jun 28 18:58:10 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:58:10 2023 ] Eval epoch: 5
[ Wed Jun 28 18:58:11 2023 ] 	Mean test loss of 625 batches: 4.913180.
[ Wed Jun 28 18:58:11 2023 ] 	Top1: 70.18%
[ Wed Jun 28 18:58:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:58:11 2023 ] Training epoch: 6
[ Wed Jun 28 18:58:14 2023 ] 	Training loss: 1.9136.  Training acc: 69.85%.
[ Wed Jun 28 18:58:14 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Wed Jun 28 18:58:14 2023 ] Eval epoch: 6
[ Wed Jun 28 18:58:15 2023 ] 	Mean test loss of 625 batches: 13.165310.
[ Wed Jun 28 18:58:15 2023 ] 	Top1: 43.86%
[ Wed Jun 28 18:58:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:58:15 2023 ] Training epoch: 7
[ Wed Jun 28 18:58:18 2023 ] 	Training loss: 2.1155.  Training acc: 56.89%.
[ Wed Jun 28 18:58:18 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:58:18 2023 ] Eval epoch: 7
[ Wed Jun 28 18:58:19 2023 ] 	Mean test loss of 625 batches: 4.131740.
[ Wed Jun 28 18:58:19 2023 ] 	Top1: 36.84%
[ Wed Jun 28 18:58:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:58:19 2023 ] Training epoch: 8
[ Wed Jun 28 18:58:21 2023 ] 	Training loss: 2.0014.  Training acc: 49.08%.
[ Wed Jun 28 18:58:21 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:58:21 2023 ] Eval epoch: 8
[ Wed Jun 28 18:58:22 2023 ] 	Mean test loss of 625 batches: 1.125312.
[ Wed Jun 28 18:58:22 2023 ] 	Top1: 29.82%
[ Wed Jun 28 18:58:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:58:22 2023 ] Training epoch: 9
[ Wed Jun 28 18:58:25 2023 ] 	Training loss: 1.3315.  Training acc: 51.93%.
[ Wed Jun 28 18:58:25 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:58:25 2023 ] Eval epoch: 9
[ Wed Jun 28 18:58:26 2023 ] 	Mean test loss of 625 batches: 141.716612.
[ Wed Jun 28 18:58:26 2023 ] 	Top1: 38.60%
[ Wed Jun 28 18:58:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:58:26 2023 ] Training epoch: 10
[ Wed Jun 28 18:58:29 2023 ] 	Training loss: 2.6562.  Training acc: 43.57%.
[ Wed Jun 28 18:58:29 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:58:29 2023 ] Eval epoch: 10
[ Wed Jun 28 18:58:30 2023 ] 	Mean test loss of 625 batches: 1.339026.
[ Wed Jun 28 18:58:30 2023 ] 	Top1: 54.39%
[ Wed Jun 28 18:58:30 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:58:30 2023 ] Training epoch: 11
[ Wed Jun 28 18:58:33 2023 ] 	Training loss: 1.2876.  Training acc: 51.10%.
[ Wed Jun 28 18:58:33 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:58:33 2023 ] Eval epoch: 11
[ Wed Jun 28 18:58:33 2023 ] 	Mean test loss of 625 batches: 0.749668.
[ Wed Jun 28 18:58:33 2023 ] 	Top1: 71.93%
[ Wed Jun 28 18:58:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:58:33 2023 ] Training epoch: 12
[ Wed Jun 28 18:58:36 2023 ] 	Training loss: 0.9258.  Training acc: 60.75%.
[ Wed Jun 28 18:58:36 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:58:36 2023 ] Eval epoch: 12
[ Wed Jun 28 18:58:37 2023 ] 	Mean test loss of 625 batches: 0.671210.
[ Wed Jun 28 18:58:37 2023 ] 	Top1: 77.19%
[ Wed Jun 28 18:58:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:58:37 2023 ] Training epoch: 13
[ Wed Jun 28 18:58:40 2023 ] 	Training loss: 0.7827.  Training acc: 71.14%.
[ Wed Jun 28 18:58:40 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:58:40 2023 ] Eval epoch: 13
[ Wed Jun 28 18:58:41 2023 ] 	Mean test loss of 625 batches: 0.601526.
[ Wed Jun 28 18:58:41 2023 ] 	Top1: 84.21%
[ Wed Jun 28 18:58:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:58:41 2023 ] Training epoch: 14
[ Wed Jun 28 18:58:44 2023 ] 	Training loss: 0.6611.  Training acc: 78.68%.
[ Wed Jun 28 18:58:44 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:58:44 2023 ] Eval epoch: 14
[ Wed Jun 28 18:58:45 2023 ] 	Mean test loss of 625 batches: 0.577432.
[ Wed Jun 28 18:58:45 2023 ] 	Top1: 80.70%
[ Wed Jun 28 18:58:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:58:45 2023 ] Training epoch: 15
[ Wed Jun 28 18:58:48 2023 ] 	Training loss: 0.6246.  Training acc: 80.97%.
[ Wed Jun 28 18:58:48 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:58:48 2023 ] Eval epoch: 15
[ Wed Jun 28 18:58:48 2023 ] 	Mean test loss of 625 batches: 0.486999.
[ Wed Jun 28 18:58:48 2023 ] 	Top1: 89.47%
[ Wed Jun 28 18:58:48 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:58:48 2023 ] Training epoch: 16
[ Wed Jun 28 18:58:51 2023 ] 	Training loss: 0.5516.  Training acc: 85.39%.
[ Wed Jun 28 18:58:51 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 18:58:51 2023 ] Eval epoch: 16
[ Wed Jun 28 18:58:52 2023 ] 	Mean test loss of 625 batches: 0.483538.
[ Wed Jun 28 18:58:52 2023 ] 	Top1: 85.96%
[ Wed Jun 28 18:58:52 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:58:52 2023 ] Training epoch: 17
[ Wed Jun 28 18:58:55 2023 ] 	Training loss: 0.4587.  Training acc: 92.00%.
[ Wed Jun 28 18:58:55 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:58:55 2023 ] Eval epoch: 17
[ Wed Jun 28 18:58:55 2023 ] 	Mean test loss of 625 batches: 0.406691.
[ Wed Jun 28 18:58:55 2023 ] 	Top1: 96.49%
[ Wed Jun 28 18:58:55 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:58:55 2023 ] Training epoch: 18
[ Wed Jun 28 18:58:58 2023 ] 	Training loss: 0.4362.  Training acc: 93.11%.
[ Wed Jun 28 18:58:58 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:58:58 2023 ] Eval epoch: 18
[ Wed Jun 28 18:58:59 2023 ] 	Mean test loss of 625 batches: 0.440879.
[ Wed Jun 28 18:58:59 2023 ] 	Top1: 89.47%
[ Wed Jun 28 18:58:59 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:58:59 2023 ] Training epoch: 19
[ Wed Jun 28 18:59:02 2023 ] 	Training loss: 0.4663.  Training acc: 92.00%.
[ Wed Jun 28 18:59:02 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:59:02 2023 ] Eval epoch: 19
[ Wed Jun 28 18:59:03 2023 ] 	Mean test loss of 625 batches: 0.377462.
[ Wed Jun 28 18:59:03 2023 ] 	Top1: 98.25%
[ Wed Jun 28 18:59:03 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:59:03 2023 ] Training epoch: 20
[ Wed Jun 28 18:59:06 2023 ] 	Training loss: 0.4266.  Training acc: 93.11%.
[ Wed Jun 28 18:59:06 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:59:06 2023 ] Eval epoch: 20
[ Wed Jun 28 18:59:06 2023 ] 	Mean test loss of 625 batches: 0.402115.
[ Wed Jun 28 18:59:06 2023 ] 	Top1: 92.98%
[ Wed Jun 28 18:59:06 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:59:06 2023 ] Training epoch: 21
[ Wed Jun 28 18:59:09 2023 ] 	Training loss: 0.4009.  Training acc: 95.13%.
[ Wed Jun 28 18:59:09 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:59:09 2023 ] Eval epoch: 21
[ Wed Jun 28 18:59:10 2023 ] 	Mean test loss of 625 batches: 0.378019.
[ Wed Jun 28 18:59:10 2023 ] 	Top1: 96.49%
[ Wed Jun 28 18:59:10 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:59:10 2023 ] Training epoch: 22
[ Wed Jun 28 18:59:13 2023 ] 	Training loss: 0.3970.  Training acc: 95.96%.
[ Wed Jun 28 18:59:13 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:59:13 2023 ] Eval epoch: 22
[ Wed Jun 28 18:59:14 2023 ] 	Mean test loss of 625 batches: 0.388752.
[ Wed Jun 28 18:59:14 2023 ] 	Top1: 92.98%
[ Wed Jun 28 18:59:14 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:59:14 2023 ] Training epoch: 23
[ Wed Jun 28 18:59:17 2023 ] 	Training loss: 0.3919.  Training acc: 95.77%.
[ Wed Jun 28 18:59:17 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 18:59:17 2023 ] Eval epoch: 23
[ Wed Jun 28 18:59:17 2023 ] 	Mean test loss of 625 batches: 0.373988.
[ Wed Jun 28 18:59:17 2023 ] 	Top1: 96.49%
[ Wed Jun 28 18:59:17 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:59:17 2023 ] Training epoch: 24
[ Wed Jun 28 18:59:20 2023 ] 	Training loss: 0.3919.  Training acc: 95.77%.
[ Wed Jun 28 18:59:20 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Wed Jun 28 18:59:20 2023 ] Eval epoch: 24
[ Wed Jun 28 18:59:21 2023 ] 	Mean test loss of 625 batches: 0.377106.
[ Wed Jun 28 18:59:21 2023 ] 	Top1: 94.74%
[ Wed Jun 28 18:59:21 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:59:21 2023 ] Training epoch: 25
[ Wed Jun 28 18:59:24 2023 ] 	Training loss: 0.3933.  Training acc: 95.50%.
[ Wed Jun 28 18:59:24 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:59:24 2023 ] Eval epoch: 25
[ Wed Jun 28 18:59:25 2023 ] 	Mean test loss of 625 batches: 0.377729.
[ Wed Jun 28 18:59:25 2023 ] 	Top1: 94.74%
[ Wed Jun 28 18:59:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:59:25 2023 ] Training epoch: 26
[ Wed Jun 28 18:59:27 2023 ] 	Training loss: 0.3845.  Training acc: 96.51%.
[ Wed Jun 28 18:59:27 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:59:27 2023 ] Eval epoch: 26
[ Wed Jun 28 18:59:28 2023 ] 	Mean test loss of 625 batches: 0.380864.
[ Wed Jun 28 18:59:28 2023 ] 	Top1: 94.74%
[ Wed Jun 28 18:59:28 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:59:28 2023 ] Training epoch: 27
[ Wed Jun 28 18:59:31 2023 ] 	Training loss: 0.3768.  Training acc: 97.43%.
[ Wed Jun 28 18:59:31 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 18:59:31 2023 ] Eval epoch: 27
[ Wed Jun 28 18:59:32 2023 ] 	Mean test loss of 625 batches: 0.372142.
[ Wed Jun 28 18:59:32 2023 ] 	Top1: 94.74%
[ Wed Jun 28 18:59:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:59:32 2023 ] Training epoch: 28
[ Wed Jun 28 18:59:35 2023 ] 	Training loss: 0.3756.  Training acc: 97.06%.
[ Wed Jun 28 18:59:35 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 18:59:35 2023 ] Eval epoch: 28
[ Wed Jun 28 18:59:35 2023 ] 	Mean test loss of 625 batches: 0.369877.
[ Wed Jun 28 18:59:35 2023 ] 	Top1: 96.49%
[ Wed Jun 28 18:59:35 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:59:35 2023 ] Training epoch: 29
[ Wed Jun 28 18:59:38 2023 ] 	Training loss: 0.3902.  Training acc: 95.77%.
[ Wed Jun 28 18:59:38 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 18:59:38 2023 ] Eval epoch: 29
[ Wed Jun 28 18:59:39 2023 ] 	Mean test loss of 625 batches: 0.375744.
[ Wed Jun 28 18:59:39 2023 ] 	Top1: 92.98%
[ Wed Jun 28 18:59:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:59:39 2023 ] Training epoch: 30
[ Wed Jun 28 18:59:42 2023 ] 	Training loss: 0.3766.  Training acc: 97.06%.
[ Wed Jun 28 18:59:42 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 18:59:42 2023 ] Eval epoch: 30
[ Wed Jun 28 18:59:43 2023 ] 	Mean test loss of 625 batches: 0.389966.
[ Wed Jun 28 18:59:43 2023 ] 	Top1: 92.98%
[ Wed Jun 28 18:59:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:59:44 2023 ] Best accuracy: 0.9824561403508771
[ Wed Jun 28 18:59:44 2023 ] Epoch number: 19
[ Wed Jun 28 18:59:44 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 18:59:44 2023 ] Weight decay: 0.0005
[ Wed Jun 28 18:59:44 2023 ] Base LR: 0.1
[ Wed Jun 28 18:59:44 2023 ] Batch Size: 64
[ Wed Jun 28 18:59:44 2023 ] Test Batch Size: 64
[ Wed Jun 28 18:59:44 2023 ] seed: 1
[ Wed Jun 28 18:59:44 2023 ] Start training Corrector
[ Wed Jun 28 18:59:44 2023 ] # Parameters Corrector: 2407569
[ Wed Jun 28 18:59:45 2023 ] Training epoch: 1
[ Wed Jun 28 18:59:53 2023 ] 	Training loss: 18.8704.  Training acc: 39.97%.
[ Wed Jun 28 18:59:53 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 18:59:53 2023 ] Eval epoch: 1
[ Wed Jun 28 18:59:55 2023 ] 	Mean test loss of 625 batches: 2.356164.
[ Wed Jun 28 18:59:55 2023 ] 	Mean test label-loss of 625 batches: 72.137222.
[ Wed Jun 28 18:59:55 2023 ] 	Top1: 26.32%
[ Wed Jun 28 18:59:55 2023 ] 	Top5: 100.00%
[ Wed Jun 28 18:59:56 2023 ] Training epoch: 2
[ Wed Jun 28 19:00:03 2023 ] 	Training loss: 17.0236.  Training acc: 19.92%.
[ Wed Jun 28 19:00:03 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:00:03 2023 ] Eval epoch: 2
[ Wed Jun 28 19:00:04 2023 ] 	Mean test loss of 625 batches: 2.871657.
[ Wed Jun 28 19:00:04 2023 ] 	Mean test label-loss of 625 batches: 47.901400.
[ Wed Jun 28 19:00:04 2023 ] 	Top1: 0.00%
[ Wed Jun 28 19:00:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:00:05 2023 ] Training epoch: 3
[ Wed Jun 28 19:00:11 2023 ] 	Training loss: 15.8941.  Training acc: 26.30%.
[ Wed Jun 28 19:00:11 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:00:11 2023 ] Eval epoch: 3
[ Wed Jun 28 19:00:13 2023 ] 	Mean test loss of 625 batches: 5.983266.
[ Wed Jun 28 19:00:13 2023 ] 	Mean test label-loss of 625 batches: 38.060530.
[ Wed Jun 28 19:00:13 2023 ] 	Top1: 0.00%
[ Wed Jun 28 19:00:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:00:14 2023 ] Training epoch: 4
[ Wed Jun 28 19:00:20 2023 ] 	Training loss: 28.4656.  Training acc: 22.66%.
[ Wed Jun 28 19:00:20 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:00:20 2023 ] Eval epoch: 4
[ Wed Jun 28 19:00:22 2023 ] 	Mean test loss of 625 batches: 5.661796.
[ Wed Jun 28 19:00:22 2023 ] 	Mean test label-loss of 625 batches: 51.374607.
[ Wed Jun 28 19:00:22 2023 ] 	Top1: 21.05%
[ Wed Jun 28 19:00:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:00:23 2023 ] Training epoch: 5
[ Wed Jun 28 19:00:29 2023 ] 	Training loss: 45.9535.  Training acc: 25.91%.
[ Wed Jun 28 19:00:29 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:00:29 2023 ] Eval epoch: 5
[ Wed Jun 28 19:00:31 2023 ] 	Mean test loss of 625 batches: 2.634408.
[ Wed Jun 28 19:00:31 2023 ] 	Mean test label-loss of 625 batches: 87.840816.
[ Wed Jun 28 19:00:31 2023 ] 	Top1: 23.68%
[ Wed Jun 28 19:00:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:00:32 2023 ] Training epoch: 6
[ Wed Jun 28 19:00:39 2023 ] 	Training loss: 58.6105.  Training acc: 25.52%.
[ Wed Jun 28 19:00:39 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:00:39 2023 ] Eval epoch: 6
[ Wed Jun 28 19:00:41 2023 ] 	Mean test loss of 625 batches: 2.952890.
[ Wed Jun 28 19:00:41 2023 ] 	Mean test label-loss of 625 batches: 84.645386.
[ Wed Jun 28 19:00:41 2023 ] 	Top1: 21.05%
[ Wed Jun 28 19:00:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:00:41 2023 ] Training epoch: 7
[ Wed Jun 28 19:00:48 2023 ] 	Training loss: 58.7561.  Training acc: 24.61%.
[ Wed Jun 28 19:00:48 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:00:48 2023 ] Eval epoch: 7
[ Wed Jun 28 19:00:50 2023 ] 	Mean test loss of 625 batches: 2.769596.
[ Wed Jun 28 19:00:50 2023 ] 	Mean test label-loss of 625 batches: 84.060400.
[ Wed Jun 28 19:00:50 2023 ] 	Top1: 13.16%
[ Wed Jun 28 19:00:50 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:00:50 2023 ] Training epoch: 8
[ Wed Jun 28 19:00:57 2023 ] 	Training loss: 59.9246.  Training acc: 27.86%.
[ Wed Jun 28 19:00:57 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:00:57 2023 ] Eval epoch: 8
[ Wed Jun 28 19:00:59 2023 ] 	Mean test loss of 625 batches: 3.803584.
[ Wed Jun 28 19:00:59 2023 ] 	Mean test label-loss of 625 batches: 86.500623.
[ Wed Jun 28 19:00:59 2023 ] 	Top1: 23.68%
[ Wed Jun 28 19:00:59 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:00:59 2023 ] Training epoch: 9
[ Wed Jun 28 19:01:06 2023 ] 	Training loss: 61.4150.  Training acc: 27.99%.
[ Wed Jun 28 19:01:06 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:01:06 2023 ] Eval epoch: 9
[ Wed Jun 28 19:01:08 2023 ] 	Mean test loss of 625 batches: 3.761616.
[ Wed Jun 28 19:01:08 2023 ] 	Mean test label-loss of 625 batches: 86.354544.
[ Wed Jun 28 19:01:08 2023 ] 	Top1: 23.68%
[ Wed Jun 28 19:01:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:01:09 2023 ] Training epoch: 10
[ Wed Jun 28 19:01:15 2023 ] 	Training loss: 61.8367.  Training acc: 27.99%.
[ Wed Jun 28 19:01:15 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:01:15 2023 ] Eval epoch: 10
[ Wed Jun 28 19:01:17 2023 ] 	Mean test loss of 625 batches: 3.986247.
[ Wed Jun 28 19:01:17 2023 ] 	Mean test label-loss of 625 batches: 86.574775.
[ Wed Jun 28 19:01:17 2023 ] 	Top1: 23.68%
[ Wed Jun 28 19:01:17 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:01:18 2023 ] Training epoch: 11
[ Wed Jun 28 19:01:24 2023 ] 	Training loss: 62.1494.  Training acc: 27.73%.
[ Wed Jun 28 19:01:24 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:01:24 2023 ] Eval epoch: 11
[ Wed Jun 28 19:01:26 2023 ] 	Mean test loss of 625 batches: 3.905663.
[ Wed Jun 28 19:01:26 2023 ] 	Mean test label-loss of 625 batches: 86.584098.
[ Wed Jun 28 19:01:26 2023 ] 	Top1: 23.68%
[ Wed Jun 28 19:01:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:01:27 2023 ] Training epoch: 12
[ Wed Jun 28 19:01:33 2023 ] 	Training loss: 61.5146.  Training acc: 27.99%.
[ Wed Jun 28 19:01:33 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:01:33 2023 ] Eval epoch: 12
[ Wed Jun 28 19:01:35 2023 ] 	Mean test loss of 625 batches: 3.967294.
[ Wed Jun 28 19:01:35 2023 ] 	Mean test label-loss of 625 batches: 86.430473.
[ Wed Jun 28 19:01:35 2023 ] 	Top1: 23.68%
[ Wed Jun 28 19:01:35 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:01:36 2023 ] Training epoch: 13
[ Wed Jun 28 19:01:42 2023 ] 	Training loss: 61.6658.  Training acc: 27.99%.
[ Wed Jun 28 19:01:42 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:01:42 2023 ] Eval epoch: 13
[ Wed Jun 28 19:01:44 2023 ] 	Mean test loss of 625 batches: 3.955215.
[ Wed Jun 28 19:01:44 2023 ] 	Mean test label-loss of 625 batches: 86.494237.
[ Wed Jun 28 19:01:44 2023 ] 	Top1: 23.68%
[ Wed Jun 28 19:01:44 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:01:44 2023 ] Training epoch: 14
[ Wed Jun 28 19:01:51 2023 ] 	Training loss: 61.6458.  Training acc: 27.86%.
[ Wed Jun 28 19:01:51 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:01:51 2023 ] Eval epoch: 14
[ Wed Jun 28 19:01:53 2023 ] 	Mean test loss of 625 batches: 3.928351.
[ Wed Jun 28 19:01:53 2023 ] 	Mean test label-loss of 625 batches: 86.589609.
[ Wed Jun 28 19:01:53 2023 ] 	Top1: 23.68%
[ Wed Jun 28 19:01:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:01:53 2023 ] Training epoch: 15
[ Wed Jun 28 19:02:00 2023 ] 	Training loss: 61.7481.  Training acc: 27.99%.
[ Wed Jun 28 19:02:00 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:02:00 2023 ] Eval epoch: 15
[ Wed Jun 28 19:02:02 2023 ] 	Mean test loss of 625 batches: 3.937517.
[ Wed Jun 28 19:02:02 2023 ] 	Mean test label-loss of 625 batches: 86.399172.
[ Wed Jun 28 19:02:02 2023 ] 	Top1: 23.68%
[ Wed Jun 28 19:02:02 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:02:02 2023 ] Training epoch: 16
[ Wed Jun 28 19:02:09 2023 ] 	Training loss: 61.7350.  Training acc: 27.86%.
[ Wed Jun 28 19:02:09 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:02:09 2023 ] Eval epoch: 16
[ Wed Jun 28 19:02:11 2023 ] 	Mean test loss of 625 batches: 3.904943.
[ Wed Jun 28 19:02:11 2023 ] 	Mean test label-loss of 625 batches: 86.318250.
[ Wed Jun 28 19:02:11 2023 ] 	Top1: 23.68%
[ Wed Jun 28 19:02:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:02:11 2023 ] Training epoch: 17
[ Wed Jun 28 19:02:18 2023 ] 	Training loss: 61.8232.  Training acc: 27.73%.
[ Wed Jun 28 19:02:18 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:02:18 2023 ] Eval epoch: 17
[ Wed Jun 28 19:02:20 2023 ] 	Mean test loss of 625 batches: 3.947418.
[ Wed Jun 28 19:02:20 2023 ] 	Mean test label-loss of 625 batches: 86.311192.
[ Wed Jun 28 19:02:20 2023 ] 	Top1: 23.68%
[ Wed Jun 28 19:02:20 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:02:20 2023 ] Training epoch: 18
[ Wed Jun 28 19:02:27 2023 ] 	Training loss: 61.8615.  Training acc: 27.99%.
[ Wed Jun 28 19:02:27 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:02:27 2023 ] Eval epoch: 18
[ Wed Jun 28 19:02:29 2023 ] 	Mean test loss of 625 batches: 4.004222.
[ Wed Jun 28 19:02:29 2023 ] 	Mean test label-loss of 625 batches: 86.309696.
[ Wed Jun 28 19:02:29 2023 ] 	Top1: 23.68%
[ Wed Jun 28 19:02:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:02:30 2023 ] Training epoch: 19
[ Wed Jun 28 19:02:36 2023 ] 	Training loss: 61.8476.  Training acc: 27.99%.
[ Wed Jun 28 19:02:36 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:02:36 2023 ] Eval epoch: 19
[ Wed Jun 28 19:02:38 2023 ] 	Mean test loss of 625 batches: 4.069550.
[ Wed Jun 28 19:02:38 2023 ] 	Mean test label-loss of 625 batches: 86.287107.
[ Wed Jun 28 19:02:38 2023 ] 	Top1: 23.68%
[ Wed Jun 28 19:02:38 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:02:39 2023 ] Training epoch: 20
[ Wed Jun 28 19:05:24 2023 ] using warm up, epoch: 5
[ Wed Jun 28 19:05:24 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 19:05:24 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 19:05:24 2023 ] Start training Predictor
[ Wed Jun 28 19:05:24 2023 ] Training epoch: 1
[ Wed Jun 28 19:05:30 2023 ] 	Training loss: 105.7093.  Training acc: 38.14%.
[ Wed Jun 28 19:05:30 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 19:05:30 2023 ] Eval epoch: 1
[ Wed Jun 28 19:05:31 2023 ] 	Mean test loss of 625 batches: 19274.686719.
[ Wed Jun 28 19:05:31 2023 ] 	Top1: 29.82%
[ Wed Jun 28 19:05:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:05:31 2023 ] Training epoch: 2
[ Wed Jun 28 19:05:34 2023 ] 	Training loss: 22.8353.  Training acc: 40.53%.
[ Wed Jun 28 19:05:34 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 19:05:34 2023 ] Eval epoch: 2
[ Wed Jun 28 19:05:35 2023 ] 	Mean test loss of 625 batches: 1526.550488.
[ Wed Jun 28 19:05:35 2023 ] 	Top1: 29.82%
[ Wed Jun 28 19:05:35 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:05:35 2023 ] Training epoch: 3
[ Wed Jun 28 19:05:38 2023 ] 	Training loss: 5.8584.  Training acc: 47.98%.
[ Wed Jun 28 19:05:38 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 19:05:38 2023 ] Eval epoch: 3
[ Wed Jun 28 19:05:38 2023 ] 	Mean test loss of 625 batches: 12.164682.
[ Wed Jun 28 19:05:38 2023 ] 	Top1: 29.82%
[ Wed Jun 28 19:05:38 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:05:38 2023 ] Training epoch: 4
[ Wed Jun 28 19:05:41 2023 ] 	Training loss: 7.1705.  Training acc: 50.46%.
[ Wed Jun 28 19:05:41 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 19:05:41 2023 ] Eval epoch: 4
[ Wed Jun 28 19:05:42 2023 ] 	Mean test loss of 625 batches: 161.233481.
[ Wed Jun 28 19:05:42 2023 ] 	Top1: 31.58%
[ Wed Jun 28 19:05:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:05:42 2023 ] Training epoch: 5
[ Wed Jun 28 19:05:45 2023 ] 	Training loss: 4.9576.  Training acc: 48.07%.
[ Wed Jun 28 19:05:45 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:05:45 2023 ] Eval epoch: 5
[ Wed Jun 28 19:05:45 2023 ] 	Mean test loss of 625 batches: 4.577662.
[ Wed Jun 28 19:05:45 2023 ] 	Top1: 52.63%
[ Wed Jun 28 19:05:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:05:46 2023 ] Training epoch: 6
[ Wed Jun 28 19:05:48 2023 ] 	Training loss: 3.3014.  Training acc: 45.86%.
[ Wed Jun 28 19:05:48 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:05:48 2023 ] Eval epoch: 6
[ Wed Jun 28 19:05:49 2023 ] 	Mean test loss of 625 batches: 2.216378.
[ Wed Jun 28 19:05:49 2023 ] 	Top1: 35.09%
[ Wed Jun 28 19:05:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:05:49 2023 ] Training epoch: 7
[ Wed Jun 28 19:05:51 2023 ] 	Training loss: 2.8088.  Training acc: 45.86%.
[ Wed Jun 28 19:05:51 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Jun 28 19:05:51 2023 ] Eval epoch: 7
[ Wed Jun 28 19:05:52 2023 ] 	Mean test loss of 625 batches: 1.970682.
[ Wed Jun 28 19:05:52 2023 ] 	Top1: 61.40%
[ Wed Jun 28 19:05:52 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:05:52 2023 ] Training epoch: 8
[ Wed Jun 28 19:05:54 2023 ] 	Training loss: 3.0050.  Training acc: 51.56%.
[ Wed Jun 28 19:05:54 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 19:05:54 2023 ] Eval epoch: 8
[ Wed Jun 28 19:05:55 2023 ] 	Mean test loss of 625 batches: 1.883515.
[ Wed Jun 28 19:05:55 2023 ] 	Top1: 38.60%
[ Wed Jun 28 19:05:55 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:05:55 2023 ] Training epoch: 9
[ Wed Jun 28 19:05:57 2023 ] 	Training loss: 1.8784.  Training acc: 52.02%.
[ Wed Jun 28 19:05:57 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Wed Jun 28 19:05:57 2023 ] Eval epoch: 9
[ Wed Jun 28 19:05:58 2023 ] 	Mean test loss of 625 batches: 2.618247.
[ Wed Jun 28 19:05:58 2023 ] 	Top1: 35.09%
[ Wed Jun 28 19:05:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:05:58 2023 ] Training epoch: 10
[ Wed Jun 28 19:06:00 2023 ] 	Training loss: 1.6070.  Training acc: 54.60%.
[ Wed Jun 28 19:06:00 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Wed Jun 28 19:06:00 2023 ] Eval epoch: 10
[ Wed Jun 28 19:06:01 2023 ] 	Mean test loss of 625 batches: 2.082701.
[ Wed Jun 28 19:06:01 2023 ] 	Top1: 47.37%
[ Wed Jun 28 19:06:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:06:01 2023 ] Training epoch: 11
[ Wed Jun 28 19:06:03 2023 ] 	Training loss: 1.3544.  Training acc: 54.32%.
[ Wed Jun 28 19:06:03 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Wed Jun 28 19:06:03 2023 ] Eval epoch: 11
[ Wed Jun 28 19:06:03 2023 ] 	Mean test loss of 625 batches: 0.801771.
[ Wed Jun 28 19:06:03 2023 ] 	Top1: 64.91%
[ Wed Jun 28 19:06:03 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:06:03 2023 ] Training epoch: 12
[ Wed Jun 28 19:06:06 2023 ] 	Training loss: 1.1839.  Training acc: 54.78%.
[ Wed Jun 28 19:06:06 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 19:06:06 2023 ] Eval epoch: 12
[ Wed Jun 28 19:06:06 2023 ] 	Mean test loss of 625 batches: 0.708055.
[ Wed Jun 28 19:06:06 2023 ] 	Top1: 82.46%
[ Wed Jun 28 19:06:06 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:06:06 2023 ] Training epoch: 13
[ Wed Jun 28 19:06:08 2023 ] 	Training loss: 1.0354.  Training acc: 62.04%.
[ Wed Jun 28 19:06:08 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Jun 28 19:06:08 2023 ] Eval epoch: 13
[ Wed Jun 28 19:06:09 2023 ] 	Mean test loss of 625 batches: 0.755168.
[ Wed Jun 28 19:06:09 2023 ] 	Top1: 70.18%
[ Wed Jun 28 19:06:09 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:06:09 2023 ] Training epoch: 14
[ Wed Jun 28 19:06:11 2023 ] 	Training loss: 1.0078.  Training acc: 61.31%.
[ Wed Jun 28 19:06:11 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Wed Jun 28 19:06:11 2023 ] Eval epoch: 14
[ Wed Jun 28 19:06:12 2023 ] 	Mean test loss of 625 batches: 0.709621.
[ Wed Jun 28 19:06:12 2023 ] 	Top1: 80.70%
[ Wed Jun 28 19:06:12 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:06:12 2023 ] Training epoch: 15
[ Wed Jun 28 19:06:14 2023 ] 	Training loss: 0.9505.  Training acc: 63.88%.
[ Wed Jun 28 19:06:14 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Wed Jun 28 19:06:14 2023 ] Eval epoch: 15
[ Wed Jun 28 19:06:15 2023 ] 	Mean test loss of 625 batches: 0.641709.
[ Wed Jun 28 19:06:15 2023 ] 	Top1: 89.47%
[ Wed Jun 28 19:06:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:06:15 2023 ] Training epoch: 16
[ Wed Jun 28 19:06:17 2023 ] 	Training loss: 0.9614.  Training acc: 63.69%.
[ Wed Jun 28 19:06:17 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Wed Jun 28 19:06:17 2023 ] Eval epoch: 16
[ Wed Jun 28 19:06:18 2023 ] 	Mean test loss of 625 batches: 0.708934.
[ Wed Jun 28 19:06:18 2023 ] 	Top1: 71.93%
[ Wed Jun 28 19:06:18 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:06:18 2023 ] Training epoch: 17
[ Wed Jun 28 19:06:20 2023 ] 	Training loss: 0.8892.  Training acc: 67.10%.
[ Wed Jun 28 19:06:20 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Wed Jun 28 19:06:20 2023 ] Eval epoch: 17
[ Wed Jun 28 19:06:21 2023 ] 	Mean test loss of 625 batches: 0.652632.
[ Wed Jun 28 19:06:21 2023 ] 	Top1: 82.46%
[ Wed Jun 28 19:06:21 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:06:21 2023 ] Training epoch: 18
[ Wed Jun 28 19:06:23 2023 ] 	Training loss: 0.9099.  Training acc: 66.08%.
[ Wed Jun 28 19:06:23 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Wed Jun 28 19:06:23 2023 ] Eval epoch: 18
[ Wed Jun 28 19:06:23 2023 ] 	Mean test loss of 625 batches: 0.732371.
[ Wed Jun 28 19:06:23 2023 ] 	Top1: 77.19%
[ Wed Jun 28 19:06:23 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:06:23 2023 ] Training epoch: 19
[ Wed Jun 28 19:06:26 2023 ] 	Training loss: 0.8838.  Training acc: 66.91%.
[ Wed Jun 28 19:06:26 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 19:06:26 2023 ] Eval epoch: 19
[ Wed Jun 28 19:06:27 2023 ] 	Mean test loss of 625 batches: 0.764477.
[ Wed Jun 28 19:06:27 2023 ] 	Top1: 66.67%
[ Wed Jun 28 19:06:27 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:06:27 2023 ] Training epoch: 20
[ Wed Jun 28 19:06:30 2023 ] 	Training loss: 0.8460.  Training acc: 69.30%.
[ Wed Jun 28 19:06:30 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:06:30 2023 ] Eval epoch: 20
[ Wed Jun 28 19:06:31 2023 ] 	Mean test loss of 625 batches: 0.660833.
[ Wed Jun 28 19:06:31 2023 ] 	Top1: 89.47%
[ Wed Jun 28 19:06:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:06:31 2023 ] Training epoch: 21
[ Wed Jun 28 19:06:34 2023 ] 	Training loss: 0.7717.  Training acc: 73.07%.
[ Wed Jun 28 19:06:34 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:06:34 2023 ] Eval epoch: 21
[ Wed Jun 28 19:06:34 2023 ] 	Mean test loss of 625 batches: 0.637865.
[ Wed Jun 28 19:06:34 2023 ] 	Top1: 87.72%
[ Wed Jun 28 19:06:34 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:06:34 2023 ] Training epoch: 22
[ Wed Jun 28 19:06:37 2023 ] 	Training loss: 0.7773.  Training acc: 74.45%.
[ Wed Jun 28 19:06:37 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:06:37 2023 ] Eval epoch: 22
[ Wed Jun 28 19:06:38 2023 ] 	Mean test loss of 625 batches: 0.614348.
[ Wed Jun 28 19:06:38 2023 ] 	Top1: 89.47%
[ Wed Jun 28 19:06:38 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:06:38 2023 ] Training epoch: 23
[ Wed Jun 28 19:06:41 2023 ] 	Training loss: 0.7923.  Training acc: 72.52%.
[ Wed Jun 28 19:06:41 2023 ] 	Time consumption: [Data]18%, [Network]81%
[ Wed Jun 28 19:06:41 2023 ] Eval epoch: 23
[ Wed Jun 28 19:06:42 2023 ] 	Mean test loss of 625 batches: 0.636798.
[ Wed Jun 28 19:06:42 2023 ] 	Top1: 89.47%
[ Wed Jun 28 19:06:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:06:42 2023 ] Training epoch: 24
[ Wed Jun 28 19:06:45 2023 ] 	Training loss: 0.8005.  Training acc: 72.61%.
[ Wed Jun 28 19:06:45 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:06:45 2023 ] Eval epoch: 24
[ Wed Jun 28 19:06:45 2023 ] 	Mean test loss of 625 batches: 0.632301.
[ Wed Jun 28 19:06:45 2023 ] 	Top1: 87.72%
[ Wed Jun 28 19:06:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:06:45 2023 ] Training epoch: 25
[ Wed Jun 28 19:06:48 2023 ] 	Training loss: 0.7952.  Training acc: 71.42%.
[ Wed Jun 28 19:06:48 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:06:48 2023 ] Eval epoch: 25
[ Wed Jun 28 19:06:49 2023 ] 	Mean test loss of 625 batches: 0.624927.
[ Wed Jun 28 19:06:49 2023 ] 	Top1: 89.47%
[ Wed Jun 28 19:06:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:06:49 2023 ] Training epoch: 26
[ Wed Jun 28 19:06:52 2023 ] 	Training loss: 0.7665.  Training acc: 74.54%.
[ Wed Jun 28 19:06:52 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:06:52 2023 ] Eval epoch: 26
[ Wed Jun 28 19:06:53 2023 ] 	Mean test loss of 625 batches: 0.613545.
[ Wed Jun 28 19:06:53 2023 ] 	Top1: 89.47%
[ Wed Jun 28 19:06:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:06:53 2023 ] Training epoch: 27
[ Wed Jun 28 19:06:56 2023 ] 	Training loss: 0.7669.  Training acc: 73.25%.
[ Wed Jun 28 19:06:56 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:06:56 2023 ] Eval epoch: 27
[ Wed Jun 28 19:06:56 2023 ] 	Mean test loss of 625 batches: 0.626817.
[ Wed Jun 28 19:06:56 2023 ] 	Top1: 89.47%
[ Wed Jun 28 19:06:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:06:56 2023 ] Training epoch: 28
[ Wed Jun 28 19:06:59 2023 ] 	Training loss: 0.7500.  Training acc: 75.55%.
[ Wed Jun 28 19:06:59 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 19:06:59 2023 ] Eval epoch: 28
[ Wed Jun 28 19:07:00 2023 ] 	Mean test loss of 625 batches: 0.605529.
[ Wed Jun 28 19:07:00 2023 ] 	Top1: 89.47%
[ Wed Jun 28 19:07:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:07:00 2023 ] Training epoch: 29
[ Wed Jun 28 19:07:03 2023 ] 	Training loss: 0.7348.  Training acc: 78.03%.
[ Wed Jun 28 19:07:03 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:07:03 2023 ] Eval epoch: 29
[ Wed Jun 28 19:07:04 2023 ] 	Mean test loss of 625 batches: 0.593651.
[ Wed Jun 28 19:07:04 2023 ] 	Top1: 91.23%
[ Wed Jun 28 19:07:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:07:04 2023 ] Training epoch: 30
[ Wed Jun 28 19:07:07 2023 ] 	Training loss: 0.7308.  Training acc: 76.10%.
[ Wed Jun 28 19:07:07 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:07:07 2023 ] Eval epoch: 30
[ Wed Jun 28 19:07:07 2023 ] 	Mean test loss of 625 batches: 0.610472.
[ Wed Jun 28 19:07:07 2023 ] 	Top1: 89.47%
[ Wed Jun 28 19:07:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:07:08 2023 ] Best accuracy: 0.9122807017543859
[ Wed Jun 28 19:07:08 2023 ] Epoch number: 29
[ Wed Jun 28 19:07:08 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 19:07:08 2023 ] Weight decay: 0.0005
[ Wed Jun 28 19:07:08 2023 ] Base LR: 0.1
[ Wed Jun 28 19:07:08 2023 ] Batch Size: 64
[ Wed Jun 28 19:07:08 2023 ] Test Batch Size: 64
[ Wed Jun 28 19:07:08 2023 ] seed: 1
[ Wed Jun 28 19:07:08 2023 ] Start training Corrector
[ Wed Jun 28 19:07:08 2023 ] # Parameters Corrector: 2407569
[ Wed Jun 28 19:07:09 2023 ] Training epoch: 1
[ Wed Jun 28 19:07:17 2023 ] 	Training loss: 25.5626.  Training acc: 44.79%.
[ Wed Jun 28 19:07:17 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:07:17 2023 ] Eval epoch: 1
[ Wed Jun 28 19:07:20 2023 ] 	Mean test loss of 625 batches: 1.939861.
[ Wed Jun 28 19:07:20 2023 ] 	Mean test label-loss of 625 batches: 82.411241.
[ Wed Jun 28 19:07:20 2023 ] 	Top1: 28.95%
[ Wed Jun 28 19:07:20 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:07:20 2023 ] Training epoch: 2
[ Wed Jun 28 19:07:27 2023 ] 	Training loss: 22.8892.  Training acc: 37.89%.
[ Wed Jun 28 19:07:27 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:07:27 2023 ] Eval epoch: 2
[ Wed Jun 28 19:07:29 2023 ] 	Mean test loss of 625 batches: 2.321868.
[ Wed Jun 28 19:07:29 2023 ] 	Mean test label-loss of 625 batches: 64.027213.
[ Wed Jun 28 19:07:29 2023 ] 	Top1: 34.21%
[ Wed Jun 28 19:07:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:07:30 2023 ] Training epoch: 3
[ Wed Jun 28 19:07:36 2023 ] 	Training loss: 24.0897.  Training acc: 33.85%.
[ Wed Jun 28 19:07:36 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:07:36 2023 ] Eval epoch: 3
[ Wed Jun 28 19:07:38 2023 ] 	Mean test loss of 625 batches: 4.825615.
[ Wed Jun 28 19:07:38 2023 ] 	Mean test label-loss of 625 batches: 49.930499.
[ Wed Jun 28 19:07:38 2023 ] 	Top1: 31.58%
[ Wed Jun 28 19:07:38 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:07:39 2023 ] Training epoch: 4
[ Wed Jun 28 19:07:45 2023 ] 	Training loss: 40.4061.  Training acc: 34.24%.
[ Wed Jun 28 19:07:45 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:07:45 2023 ] Eval epoch: 4
[ Wed Jun 28 19:07:47 2023 ] 	Mean test loss of 625 batches: 5.845306.
[ Wed Jun 28 19:07:47 2023 ] 	Mean test label-loss of 625 batches: 96.812896.
[ Wed Jun 28 19:07:47 2023 ] 	Top1: 23.68%
[ Wed Jun 28 19:07:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:07:48 2023 ] Training epoch: 5
[ Wed Jun 28 19:07:54 2023 ] 	Training loss: 43.1263.  Training acc: 23.31%.
[ Wed Jun 28 19:07:54 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:07:54 2023 ] Eval epoch: 5
[ Wed Jun 28 19:07:56 2023 ] 	Mean test loss of 625 batches: 2.653810.
[ Wed Jun 28 19:07:56 2023 ] 	Mean test label-loss of 625 batches: 80.575056.
[ Wed Jun 28 19:07:56 2023 ] 	Top1: 31.58%
[ Wed Jun 28 19:07:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:07:57 2023 ] Training epoch: 6
[ Wed Jun 28 19:08:04 2023 ] using warm up, epoch: 5
[ Wed Jun 28 19:08:04 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 19:08:04 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 19:08:04 2023 ] Start training Predictor
[ Wed Jun 28 19:08:04 2023 ] Training epoch: 1
[ Wed Jun 28 19:08:10 2023 ] 	Training loss: 115.6535.  Training acc: 34.56%.
[ Wed Jun 28 19:08:10 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:08:10 2023 ] Eval epoch: 1
[ Wed Jun 28 19:08:11 2023 ] 	Mean test loss of 625 batches: 2233.486426.
[ Wed Jun 28 19:08:11 2023 ] 	Top1: 31.58%
[ Wed Jun 28 19:08:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:08:11 2023 ] Training epoch: 2
[ Wed Jun 28 19:08:14 2023 ] 	Training loss: 12.1075.  Training acc: 35.39%.
[ Wed Jun 28 19:08:14 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:08:14 2023 ] Eval epoch: 2
[ Wed Jun 28 19:08:15 2023 ] 	Mean test loss of 625 batches: 5.001493.
[ Wed Jun 28 19:08:15 2023 ] 	Top1: 31.58%
[ Wed Jun 28 19:08:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:08:15 2023 ] Training epoch: 3
[ Wed Jun 28 19:08:17 2023 ] 	Training loss: 5.4387.  Training acc: 48.25%.
[ Wed Jun 28 19:08:17 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:08:17 2023 ] Eval epoch: 3
[ Wed Jun 28 19:08:18 2023 ] 	Mean test loss of 625 batches: 23.123976.
[ Wed Jun 28 19:08:18 2023 ] 	Top1: 29.82%
[ Wed Jun 28 19:08:18 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:08:18 2023 ] Training epoch: 4
[ Wed Jun 28 19:08:21 2023 ] 	Training loss: 4.6642.  Training acc: 62.22%.
[ Wed Jun 28 19:08:21 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 19:08:21 2023 ] Eval epoch: 4
[ Wed Jun 28 19:08:22 2023 ] 	Mean test loss of 625 batches: 2.008853.
[ Wed Jun 28 19:08:22 2023 ] 	Top1: 80.70%
[ Wed Jun 28 19:08:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:08:22 2023 ] Training epoch: 5
[ Wed Jun 28 19:08:24 2023 ] 	Training loss: 3.0656.  Training acc: 53.86%.
[ Wed Jun 28 19:08:24 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 19:08:24 2023 ] Eval epoch: 5
[ Wed Jun 28 19:08:25 2023 ] 	Mean test loss of 625 batches: 225.038239.
[ Wed Jun 28 19:08:25 2023 ] 	Top1: 38.60%
[ Wed Jun 28 19:08:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:08:25 2023 ] Training epoch: 6
[ Wed Jun 28 19:08:28 2023 ] 	Training loss: 5.3578.  Training acc: 55.61%.
[ Wed Jun 28 19:08:28 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 19:08:28 2023 ] Eval epoch: 6
[ Wed Jun 28 19:08:29 2023 ] 	Mean test loss of 625 batches: 87.183450.
[ Wed Jun 28 19:08:29 2023 ] 	Top1: 38.60%
[ Wed Jun 28 19:08:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:08:29 2023 ] Training epoch: 7
[ Wed Jun 28 19:08:32 2023 ] 	Training loss: 3.1749.  Training acc: 56.53%.
[ Wed Jun 28 19:08:32 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:08:32 2023 ] Eval epoch: 7
[ Wed Jun 28 19:08:32 2023 ] 	Mean test loss of 625 batches: 3.025180.
[ Wed Jun 28 19:08:32 2023 ] 	Top1: 64.91%
[ Wed Jun 28 19:08:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:08:32 2023 ] Training epoch: 8
[ Wed Jun 28 19:08:35 2023 ] 	Training loss: 1.5495.  Training acc: 64.61%.
[ Wed Jun 28 19:08:35 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:08:35 2023 ] Eval epoch: 8
[ Wed Jun 28 19:08:36 2023 ] 	Mean test loss of 625 batches: 0.659637.
[ Wed Jun 28 19:08:36 2023 ] 	Top1: 73.68%
[ Wed Jun 28 19:08:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:08:36 2023 ] Training epoch: 9
[ Wed Jun 28 19:08:39 2023 ] 	Training loss: 0.8921.  Training acc: 75.28%.
[ Wed Jun 28 19:08:39 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 19:08:39 2023 ] Eval epoch: 9
[ Wed Jun 28 19:08:39 2023 ] 	Mean test loss of 625 batches: 1.474462.
[ Wed Jun 28 19:08:39 2023 ] 	Top1: 56.14%
[ Wed Jun 28 19:08:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:08:39 2023 ] Training epoch: 10
[ Wed Jun 28 19:08:42 2023 ] 	Training loss: 1.5608.  Training acc: 69.21%.
[ Wed Jun 28 19:08:42 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 19:08:42 2023 ] Eval epoch: 10
[ Wed Jun 28 19:08:43 2023 ] 	Mean test loss of 625 batches: 3.893072.
[ Wed Jun 28 19:08:43 2023 ] 	Top1: 31.58%
[ Wed Jun 28 19:08:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:08:43 2023 ] Training epoch: 11
[ Wed Jun 28 19:08:46 2023 ] 	Training loss: 1.1335.  Training acc: 77.76%.
[ Wed Jun 28 19:08:46 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:08:46 2023 ] Eval epoch: 11
[ Wed Jun 28 19:08:46 2023 ] 	Mean test loss of 625 batches: 0.660619.
[ Wed Jun 28 19:08:46 2023 ] 	Top1: 82.46%
[ Wed Jun 28 19:08:46 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:08:47 2023 ] Training epoch: 12
[ Wed Jun 28 19:08:49 2023 ] 	Training loss: 0.9217.  Training acc: 79.60%.
[ Wed Jun 28 19:08:49 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:08:49 2023 ] Eval epoch: 12
[ Wed Jun 28 19:08:50 2023 ] 	Mean test loss of 625 batches: 0.768848.
[ Wed Jun 28 19:08:50 2023 ] 	Top1: 80.70%
[ Wed Jun 28 19:08:50 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:08:50 2023 ] Training epoch: 13
[ Wed Jun 28 19:08:53 2023 ] 	Training loss: 0.7773.  Training acc: 83.00%.
[ Wed Jun 28 19:08:53 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 19:08:53 2023 ] Eval epoch: 13
[ Wed Jun 28 19:08:54 2023 ] 	Mean test loss of 625 batches: 0.789195.
[ Wed Jun 28 19:08:54 2023 ] 	Top1: 77.19%
[ Wed Jun 28 19:08:54 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:08:54 2023 ] Training epoch: 14
[ Wed Jun 28 19:08:57 2023 ] 	Training loss: 0.7580.  Training acc: 83.46%.
[ Wed Jun 28 19:08:57 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:08:57 2023 ] Eval epoch: 14
[ Wed Jun 28 19:08:58 2023 ] 	Mean test loss of 625 batches: 0.903162.
[ Wed Jun 28 19:08:58 2023 ] 	Top1: 75.44%
[ Wed Jun 28 19:08:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:08:58 2023 ] Training epoch: 15
[ Wed Jun 28 19:09:01 2023 ] 	Training loss: 0.8073.  Training acc: 80.88%.
[ Wed Jun 28 19:09:01 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:09:01 2023 ] Eval epoch: 15
[ Wed Jun 28 19:09:02 2023 ] 	Mean test loss of 625 batches: 0.712170.
[ Wed Jun 28 19:09:02 2023 ] 	Top1: 80.70%
[ Wed Jun 28 19:09:02 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:09:02 2023 ] Training epoch: 16
[ Wed Jun 28 19:09:04 2023 ] 	Training loss: 0.7777.  Training acc: 79.50%.
[ Wed Jun 28 19:09:04 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:09:04 2023 ] Eval epoch: 16
[ Wed Jun 28 19:09:05 2023 ] 	Mean test loss of 625 batches: 0.654561.
[ Wed Jun 28 19:09:05 2023 ] 	Top1: 80.70%
[ Wed Jun 28 19:09:05 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:09:05 2023 ] Training epoch: 17
[ Wed Jun 28 19:09:08 2023 ] 	Training loss: 0.7430.  Training acc: 81.80%.
[ Wed Jun 28 19:09:08 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 19:09:08 2023 ] Eval epoch: 17
[ Wed Jun 28 19:09:09 2023 ] 	Mean test loss of 625 batches: 0.845477.
[ Wed Jun 28 19:09:09 2023 ] 	Top1: 75.44%
[ Wed Jun 28 19:09:09 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:09:09 2023 ] Training epoch: 18
[ Wed Jun 28 19:09:12 2023 ] 	Training loss: 0.7542.  Training acc: 81.25%.
[ Wed Jun 28 19:09:12 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:09:12 2023 ] Eval epoch: 18
[ Wed Jun 28 19:09:12 2023 ] 	Mean test loss of 625 batches: 0.723504.
[ Wed Jun 28 19:09:12 2023 ] 	Top1: 78.95%
[ Wed Jun 28 19:09:12 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:09:12 2023 ] Training epoch: 19
[ Wed Jun 28 19:09:15 2023 ] 	Training loss: 0.7429.  Training acc: 81.62%.
[ Wed Jun 28 19:09:15 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 19:09:15 2023 ] Eval epoch: 19
[ Wed Jun 28 19:09:16 2023 ] 	Mean test loss of 625 batches: 0.522103.
[ Wed Jun 28 19:09:16 2023 ] 	Top1: 87.72%
[ Wed Jun 28 19:09:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:09:16 2023 ] Training epoch: 20
[ Wed Jun 28 19:09:19 2023 ] 	Training loss: 0.6257.  Training acc: 85.02%.
[ Wed Jun 28 19:09:19 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 19:09:19 2023 ] Eval epoch: 20
[ Wed Jun 28 19:09:20 2023 ] 	Mean test loss of 625 batches: 0.468389.
[ Wed Jun 28 19:09:20 2023 ] 	Top1: 92.98%
[ Wed Jun 28 19:09:20 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:09:20 2023 ] Training epoch: 21
[ Wed Jun 28 19:09:23 2023 ] 	Training loss: 0.6284.  Training acc: 86.21%.
[ Wed Jun 28 19:09:23 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:09:23 2023 ] Eval epoch: 21
[ Wed Jun 28 19:09:24 2023 ] 	Mean test loss of 625 batches: 0.418259.
[ Wed Jun 28 19:09:24 2023 ] 	Top1: 96.49%
[ Wed Jun 28 19:09:24 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:09:24 2023 ] Training epoch: 22
[ Wed Jun 28 19:09:26 2023 ] 	Training loss: 0.6145.  Training acc: 86.49%.
[ Wed Jun 28 19:09:26 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:09:26 2023 ] Eval epoch: 22
[ Wed Jun 28 19:09:27 2023 ] 	Mean test loss of 625 batches: 0.409906.
[ Wed Jun 28 19:09:27 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:09:27 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:09:27 2023 ] Training epoch: 23
[ Wed Jun 28 19:09:30 2023 ] 	Training loss: 0.6066.  Training acc: 86.86%.
[ Wed Jun 28 19:09:30 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 19:09:30 2023 ] Eval epoch: 23
[ Wed Jun 28 19:09:31 2023 ] 	Mean test loss of 625 batches: 0.420285.
[ Wed Jun 28 19:09:31 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:09:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:09:31 2023 ] Training epoch: 24
[ Wed Jun 28 19:09:34 2023 ] 	Training loss: 0.5866.  Training acc: 87.78%.
[ Wed Jun 28 19:09:34 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:09:34 2023 ] Eval epoch: 24
[ Wed Jun 28 19:09:35 2023 ] 	Mean test loss of 625 batches: 0.408977.
[ Wed Jun 28 19:09:35 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:09:35 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:09:35 2023 ] Training epoch: 25
[ Wed Jun 28 19:09:38 2023 ] 	Training loss: 0.5778.  Training acc: 87.22%.
[ Wed Jun 28 19:09:38 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 19:09:38 2023 ] Eval epoch: 25
[ Wed Jun 28 19:09:38 2023 ] 	Mean test loss of 625 batches: 0.394118.
[ Wed Jun 28 19:09:38 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:09:38 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:09:38 2023 ] Training epoch: 26
[ Wed Jun 28 19:09:41 2023 ] 	Training loss: 0.5600.  Training acc: 87.32%.
[ Wed Jun 28 19:09:41 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:09:41 2023 ] Eval epoch: 26
[ Wed Jun 28 19:09:42 2023 ] 	Mean test loss of 625 batches: 0.389383.
[ Wed Jun 28 19:09:42 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:09:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:09:42 2023 ] Training epoch: 27
[ Wed Jun 28 19:09:45 2023 ] 	Training loss: 0.5498.  Training acc: 87.78%.
[ Wed Jun 28 19:09:45 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 19:09:45 2023 ] Eval epoch: 27
[ Wed Jun 28 19:09:46 2023 ] 	Mean test loss of 625 batches: 0.380463.
[ Wed Jun 28 19:09:46 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:09:46 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:09:46 2023 ] Training epoch: 28
[ Wed Jun 28 19:09:48 2023 ] 	Training loss: 0.5657.  Training acc: 89.43%.
[ Wed Jun 28 19:09:48 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 19:09:48 2023 ] Eval epoch: 28
[ Wed Jun 28 19:09:49 2023 ] 	Mean test loss of 625 batches: 0.386325.
[ Wed Jun 28 19:09:49 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:09:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:09:49 2023 ] Training epoch: 29
[ Wed Jun 28 19:09:52 2023 ] 	Training loss: 0.5731.  Training acc: 87.78%.
[ Wed Jun 28 19:09:52 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 19:09:52 2023 ] Eval epoch: 29
[ Wed Jun 28 19:09:53 2023 ] 	Mean test loss of 625 batches: 0.415619.
[ Wed Jun 28 19:09:53 2023 ] 	Top1: 94.74%
[ Wed Jun 28 19:09:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:09:53 2023 ] Training epoch: 30
[ Wed Jun 28 19:09:56 2023 ] 	Training loss: 0.5296.  Training acc: 90.72%.
[ Wed Jun 28 19:09:56 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:09:56 2023 ] Eval epoch: 30
[ Wed Jun 28 19:09:56 2023 ] 	Mean test loss of 625 batches: 0.372135.
[ Wed Jun 28 19:09:56 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:09:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:09:57 2023 ] Best accuracy: 0.9824561403508771
[ Wed Jun 28 19:09:57 2023 ] Epoch number: 22
[ Wed Jun 28 19:09:57 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 19:09:57 2023 ] Weight decay: 0.0005
[ Wed Jun 28 19:09:57 2023 ] Base LR: 0.1
[ Wed Jun 28 19:09:57 2023 ] Batch Size: 64
[ Wed Jun 28 19:09:57 2023 ] Test Batch Size: 64
[ Wed Jun 28 19:09:57 2023 ] seed: 1
[ Wed Jun 28 19:09:57 2023 ] Start training Corrector
[ Wed Jun 28 19:09:57 2023 ] # Parameters Corrector: 2407569
[ Wed Jun 28 19:09:59 2023 ] Training epoch: 1
[ Wed Jun 28 19:10:07 2023 ] 	Training loss: 23.8229.  Training acc: 25.00%.
[ Wed Jun 28 19:10:07 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:10:07 2023 ] Training epoch: 2
[ Wed Jun 28 19:10:14 2023 ] 	Training loss: 22.1975.  Training acc: 36.98%.
[ Wed Jun 28 19:10:14 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:10:14 2023 ] Training epoch: 3
[ Wed Jun 28 19:10:21 2023 ] 	Training loss: 28.3260.  Training acc: 19.01%.
[ Wed Jun 28 19:10:21 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:10:21 2023 ] Training epoch: 4
[ Wed Jun 28 19:10:28 2023 ] 	Training loss: 27.9494.  Training acc: 21.61%.
[ Wed Jun 28 19:10:28 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 19:10:28 2023 ] Training epoch: 5
[ Wed Jun 28 19:10:35 2023 ] 	Training loss: 35.1888.  Training acc: 28.91%.
[ Wed Jun 28 19:10:35 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:10:36 2023 ] Training epoch: 6
[ Wed Jun 28 19:10:42 2023 ] 	Training loss: 32.6427.  Training acc: 27.86%.
[ Wed Jun 28 19:10:42 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:10:43 2023 ] Training epoch: 7
[ Wed Jun 28 19:10:49 2023 ] 	Training loss: 29.1603.  Training acc: 27.86%.
[ Wed Jun 28 19:10:49 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:10:50 2023 ] Training epoch: 8
[ Wed Jun 28 19:10:56 2023 ] 	Training loss: 25.2927.  Training acc: 27.86%.
[ Wed Jun 28 19:10:56 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 19:10:57 2023 ] Training epoch: 9
[ Wed Jun 28 19:11:03 2023 ] 	Training loss: 22.1026.  Training acc: 27.86%.
[ Wed Jun 28 19:11:03 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:11:04 2023 ] Training epoch: 10
[ Wed Jun 28 19:11:10 2023 ] 	Training loss: 20.3732.  Training acc: 27.86%.
[ Wed Jun 28 19:11:10 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:11:11 2023 ] Training epoch: 11
[ Wed Jun 28 19:11:17 2023 ] 	Training loss: 25.3377.  Training acc: 27.86%.
[ Wed Jun 28 19:11:17 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:11:18 2023 ] Training epoch: 12
[ Wed Jun 28 19:11:24 2023 ] 	Training loss: 23.7301.  Training acc: 27.99%.
[ Wed Jun 28 19:11:24 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:11:25 2023 ] Training epoch: 13
[ Wed Jun 28 19:11:31 2023 ] 	Training loss: 22.7037.  Training acc: 27.99%.
[ Wed Jun 28 19:11:31 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:11:32 2023 ] Training epoch: 14
[ Wed Jun 28 19:11:38 2023 ] 	Training loss: 31.7296.  Training acc: 25.78%.
[ Wed Jun 28 19:11:38 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 19:11:39 2023 ] Training epoch: 15
[ Wed Jun 28 19:11:46 2023 ] 	Training loss: 35.1442.  Training acc: 23.05%.
[ Wed Jun 28 19:11:46 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:11:46 2023 ] Training epoch: 16
[ Wed Jun 28 19:11:53 2023 ] 	Training loss: 34.3962.  Training acc: 24.35%.
[ Wed Jun 28 19:11:53 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:11:53 2023 ] Training epoch: 17
[ Wed Jun 28 19:12:00 2023 ] 	Training loss: 32.1905.  Training acc: 28.52%.
[ Wed Jun 28 19:12:00 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:12:00 2023 ] Training epoch: 18
[ Wed Jun 28 19:12:07 2023 ] 	Training loss: 30.9512.  Training acc: 29.43%.
[ Wed Jun 28 19:12:07 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:12:07 2023 ] Training epoch: 19
[ Wed Jun 28 19:12:14 2023 ] 	Training loss: 30.6435.  Training acc: 29.69%.
[ Wed Jun 28 19:12:14 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Wed Jun 28 19:12:15 2023 ] Training epoch: 20
[ Wed Jun 28 19:12:21 2023 ] 	Training loss: 29.2385.  Training acc: 28.39%.
[ Wed Jun 28 19:12:21 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:12:22 2023 ] Training epoch: 21
[ Wed Jun 28 19:12:28 2023 ] 	Training loss: 29.3518.  Training acc: 28.52%.
[ Wed Jun 28 19:12:28 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:12:29 2023 ] Training epoch: 22
[ Wed Jun 28 19:12:35 2023 ] 	Training loss: 29.1657.  Training acc: 28.26%.
[ Wed Jun 28 19:12:35 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:12:36 2023 ] Training epoch: 23
[ Wed Jun 28 19:12:42 2023 ] 	Training loss: 29.4937.  Training acc: 28.52%.
[ Wed Jun 28 19:12:42 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:12:43 2023 ] Training epoch: 24
[ Wed Jun 28 19:12:49 2023 ] 	Training loss: 29.9932.  Training acc: 28.39%.
[ Wed Jun 28 19:12:49 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:12:50 2023 ] Training epoch: 25
[ Wed Jun 28 19:12:57 2023 ] 	Training loss: 30.0663.  Training acc: 28.39%.
[ Wed Jun 28 19:12:57 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:12:57 2023 ] Training epoch: 26
[ Wed Jun 28 19:13:04 2023 ] 	Training loss: 30.0799.  Training acc: 29.04%.
[ Wed Jun 28 19:13:04 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:13:04 2023 ] Training epoch: 27
[ Wed Jun 28 19:13:11 2023 ] 	Training loss: 29.9801.  Training acc: 28.26%.
[ Wed Jun 28 19:13:11 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:13:11 2023 ] Training epoch: 28
[ Wed Jun 28 19:17:12 2023 ] using warm up, epoch: 5
[ Wed Jun 28 19:17:13 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 19:17:13 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 19:17:13 2023 ] Start training Predictor
[ Wed Jun 28 19:17:13 2023 ] Training epoch: 1
[ Wed Jun 28 19:18:32 2023 ] using warm up, epoch: 5
[ Wed Jun 28 19:18:32 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 19:18:32 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 19:18:32 2023 ] Start training Predictor
[ Wed Jun 28 19:18:32 2023 ] Training epoch: 1
[ Wed Jun 28 19:18:38 2023 ] 	Training loss: 111.7331.  Training acc: 34.19%.
[ Wed Jun 28 19:18:38 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:18:38 2023 ] Eval epoch: 1
[ Wed Jun 28 19:18:39 2023 ] 	Mean test loss of 625 batches: 491.195062.
[ Wed Jun 28 19:18:39 2023 ] 	Top1: 31.58%
[ Wed Jun 28 19:18:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:18:39 2023 ] Training epoch: 2
[ Wed Jun 28 19:18:42 2023 ] 	Training loss: 14.0828.  Training acc: 34.74%.
[ Wed Jun 28 19:18:42 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Wed Jun 28 19:18:42 2023 ] Eval epoch: 2
[ Wed Jun 28 19:18:42 2023 ] 	Mean test loss of 625 batches: 1.384067.
[ Wed Jun 28 19:18:42 2023 ] 	Top1: 31.58%
[ Wed Jun 28 19:18:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:18:42 2023 ] Training epoch: 3
[ Wed Jun 28 19:18:45 2023 ] 	Training loss: 6.1794.  Training acc: 45.68%.
[ Wed Jun 28 19:18:45 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:18:45 2023 ] Eval epoch: 3
[ Wed Jun 28 19:18:46 2023 ] 	Mean test loss of 625 batches: 5.839692.
[ Wed Jun 28 19:18:46 2023 ] 	Top1: 29.82%
[ Wed Jun 28 19:18:46 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:18:46 2023 ] Training epoch: 4
[ Wed Jun 28 19:18:49 2023 ] 	Training loss: 4.5162.  Training acc: 57.17%.
[ Wed Jun 28 19:18:49 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:18:49 2023 ] Eval epoch: 4
[ Wed Jun 28 19:18:49 2023 ] 	Mean test loss of 625 batches: 6.402538.
[ Wed Jun 28 19:18:49 2023 ] 	Top1: 38.60%
[ Wed Jun 28 19:18:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:18:50 2023 ] Training epoch: 5
[ Wed Jun 28 19:19:35 2023 ] using warm up, epoch: 5
[ Wed Jun 28 19:19:35 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 19:19:35 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 19:19:35 2023 ] Start training Predictor
[ Wed Jun 28 19:19:35 2023 ] Training epoch: 1
[ Wed Jun 28 19:19:41 2023 ] 	Training loss: 103.2507.  Training acc: 34.10%.
[ Wed Jun 28 19:19:41 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:19:41 2023 ] Eval epoch: 1
[ Wed Jun 28 19:19:42 2023 ] 	Mean test loss of 625 batches: 239.320648.
[ Wed Jun 28 19:19:42 2023 ] 	Top1: 31.58%
[ Wed Jun 28 19:19:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:19:42 2023 ] Training epoch: 2
[ Wed Jun 28 19:19:45 2023 ] 	Training loss: 8.8447.  Training acc: 32.90%.
[ Wed Jun 28 19:19:45 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 19:19:45 2023 ] Eval epoch: 2
[ Wed Jun 28 19:19:46 2023 ] 	Mean test loss of 625 batches: 2.254621.
[ Wed Jun 28 19:19:46 2023 ] 	Top1: 31.58%
[ Wed Jun 28 19:19:46 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:19:46 2023 ] Training epoch: 3
[ Wed Jun 28 19:19:49 2023 ] 	Training loss: 7.2759.  Training acc: 33.73%.
[ Wed Jun 28 19:19:49 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 19:19:49 2023 ] Eval epoch: 3
[ Wed Jun 28 19:19:49 2023 ] 	Mean test loss of 625 batches: 2.134441.
[ Wed Jun 28 19:19:49 2023 ] 	Top1: 31.58%
[ Wed Jun 28 19:19:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:19:49 2023 ] Training epoch: 4
[ Wed Jun 28 19:19:52 2023 ] 	Training loss: 6.2356.  Training acc: 32.54%.
[ Wed Jun 28 19:19:52 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:19:52 2023 ] Eval epoch: 4
[ Wed Jun 28 19:19:53 2023 ] 	Mean test loss of 625 batches: 2.315141.
[ Wed Jun 28 19:19:53 2023 ] 	Top1: 38.60%
[ Wed Jun 28 19:19:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:19:53 2023 ] Training epoch: 5
[ Wed Jun 28 19:19:56 2023 ] 	Training loss: 5.2041.  Training acc: 37.68%.
[ Wed Jun 28 19:19:56 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:19:56 2023 ] Eval epoch: 5
[ Wed Jun 28 19:19:57 2023 ] 	Mean test loss of 625 batches: 1.410261.
[ Wed Jun 28 19:19:57 2023 ] 	Top1: 29.82%
[ Wed Jun 28 19:19:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:19:57 2023 ] Training epoch: 6
[ Wed Jun 28 19:20:00 2023 ] 	Training loss: 3.9610.  Training acc: 36.58%.
[ Wed Jun 28 19:20:00 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:20:00 2023 ] Eval epoch: 6
[ Wed Jun 28 19:20:00 2023 ] 	Mean test loss of 625 batches: 1.114328.
[ Wed Jun 28 19:20:00 2023 ] 	Top1: 31.58%
[ Wed Jun 28 19:20:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:20:00 2023 ] Training epoch: 7
[ Wed Jun 28 19:20:03 2023 ] 	Training loss: 2.9721.  Training acc: 35.85%.
[ Wed Jun 28 19:20:03 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:20:03 2023 ] Eval epoch: 7
[ Wed Jun 28 19:20:04 2023 ] 	Mean test loss of 625 batches: 1.105528.
[ Wed Jun 28 19:20:04 2023 ] 	Top1: 31.58%
[ Wed Jun 28 19:20:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:20:04 2023 ] Training epoch: 8
[ Wed Jun 28 19:20:07 2023 ] 	Training loss: 2.8401.  Training acc: 34.56%.
[ Wed Jun 28 19:20:07 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 19:20:07 2023 ] Eval epoch: 8
[ Wed Jun 28 19:20:08 2023 ] 	Mean test loss of 625 batches: 1.183083.
[ Wed Jun 28 19:20:08 2023 ] 	Top1: 29.82%
[ Wed Jun 28 19:20:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:20:08 2023 ] Training epoch: 9
[ Wed Jun 28 19:20:11 2023 ] 	Training loss: 2.0683.  Training acc: 34.47%.
[ Wed Jun 28 19:20:11 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Wed Jun 28 19:20:11 2023 ] Eval epoch: 9
[ Wed Jun 28 19:20:11 2023 ] 	Mean test loss of 625 batches: 1.526505.
[ Wed Jun 28 19:20:11 2023 ] 	Top1: 42.11%
[ Wed Jun 28 19:20:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:20:11 2023 ] Training epoch: 10
[ Wed Jun 28 19:20:14 2023 ] 	Training loss: 1.7954.  Training acc: 42.10%.
[ Wed Jun 28 19:20:14 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:20:14 2023 ] Eval epoch: 10
[ Wed Jun 28 19:20:15 2023 ] 	Mean test loss of 625 batches: 1.251452.
[ Wed Jun 28 19:20:15 2023 ] 	Top1: 45.61%
[ Wed Jun 28 19:20:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:20:15 2023 ] Training epoch: 11
[ Wed Jun 28 19:20:18 2023 ] 	Training loss: 1.4027.  Training acc: 45.50%.
[ Wed Jun 28 19:20:18 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 19:20:18 2023 ] Eval epoch: 11
[ Wed Jun 28 19:20:19 2023 ] 	Mean test loss of 625 batches: 0.935909.
[ Wed Jun 28 19:20:19 2023 ] 	Top1: 54.39%
[ Wed Jun 28 19:20:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:20:19 2023 ] Training epoch: 12
[ Wed Jun 28 19:20:22 2023 ] 	Training loss: 1.2811.  Training acc: 50.74%.
[ Wed Jun 28 19:20:22 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Wed Jun 28 19:20:22 2023 ] Eval epoch: 12
[ Wed Jun 28 19:20:23 2023 ] 	Mean test loss of 625 batches: 0.734238.
[ Wed Jun 28 19:20:23 2023 ] 	Top1: 64.91%
[ Wed Jun 28 19:20:23 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:20:23 2023 ] Training epoch: 13
[ Wed Jun 28 19:20:25 2023 ] 	Training loss: 1.1142.  Training acc: 57.08%.
[ Wed Jun 28 19:20:25 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 19:20:25 2023 ] Eval epoch: 13
[ Wed Jun 28 19:20:26 2023 ] 	Mean test loss of 625 batches: 0.705489.
[ Wed Jun 28 19:20:26 2023 ] 	Top1: 61.40%
[ Wed Jun 28 19:20:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:20:26 2023 ] Training epoch: 14
[ Wed Jun 28 19:20:29 2023 ] 	Training loss: 1.0583.  Training acc: 56.53%.
[ Wed Jun 28 19:20:29 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:20:29 2023 ] Eval epoch: 14
[ Wed Jun 28 19:20:30 2023 ] 	Mean test loss of 625 batches: 0.672375.
[ Wed Jun 28 19:20:30 2023 ] 	Top1: 61.40%
[ Wed Jun 28 19:20:30 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:20:30 2023 ] Training epoch: 15
[ Wed Jun 28 19:20:33 2023 ] 	Training loss: 0.9735.  Training acc: 57.90%.
[ Wed Jun 28 19:20:33 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 19:20:33 2023 ] Eval epoch: 15
[ Wed Jun 28 19:20:34 2023 ] 	Mean test loss of 625 batches: 0.676019.
[ Wed Jun 28 19:20:34 2023 ] 	Top1: 61.40%
[ Wed Jun 28 19:20:34 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:20:34 2023 ] Training epoch: 16
[ Wed Jun 28 19:20:37 2023 ] 	Training loss: 0.9508.  Training acc: 59.83%.
[ Wed Jun 28 19:20:37 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:20:37 2023 ] Eval epoch: 16
[ Wed Jun 28 19:20:37 2023 ] 	Mean test loss of 625 batches: 0.723431.
[ Wed Jun 28 19:20:37 2023 ] 	Top1: 56.14%
[ Wed Jun 28 19:20:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:20:37 2023 ] Training epoch: 17
[ Wed Jun 28 19:20:40 2023 ] 	Training loss: 0.9000.  Training acc: 61.31%.
[ Wed Jun 28 19:20:40 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 19:20:40 2023 ] Eval epoch: 17
[ Wed Jun 28 19:20:41 2023 ] 	Mean test loss of 625 batches: 0.671927.
[ Wed Jun 28 19:20:41 2023 ] 	Top1: 61.40%
[ Wed Jun 28 19:20:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:20:41 2023 ] Training epoch: 18
[ Wed Jun 28 19:20:44 2023 ] 	Training loss: 0.8781.  Training acc: 61.31%.
[ Wed Jun 28 19:20:44 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:20:44 2023 ] Eval epoch: 18
[ Wed Jun 28 19:20:45 2023 ] 	Mean test loss of 625 batches: 0.670335.
[ Wed Jun 28 19:20:45 2023 ] 	Top1: 68.42%
[ Wed Jun 28 19:20:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:20:45 2023 ] Training epoch: 19
[ Wed Jun 28 19:20:48 2023 ] 	Training loss: 0.8823.  Training acc: 60.20%.
[ Wed Jun 28 19:20:48 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:20:48 2023 ] Eval epoch: 19
[ Wed Jun 28 19:20:49 2023 ] 	Mean test loss of 625 batches: 0.665409.
[ Wed Jun 28 19:20:49 2023 ] 	Top1: 77.19%
[ Wed Jun 28 19:20:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:20:49 2023 ] Training epoch: 20
[ Wed Jun 28 19:20:52 2023 ] 	Training loss: 0.8170.  Training acc: 62.78%.
[ Wed Jun 28 19:20:52 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 19:20:52 2023 ] Eval epoch: 20
[ Wed Jun 28 19:20:52 2023 ] 	Mean test loss of 625 batches: 0.653471.
[ Wed Jun 28 19:20:52 2023 ] 	Top1: 63.16%
[ Wed Jun 28 19:20:52 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:20:52 2023 ] Training epoch: 21
[ Wed Jun 28 19:20:55 2023 ] 	Training loss: 0.7875.  Training acc: 63.79%.
[ Wed Jun 28 19:20:55 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:20:55 2023 ] Eval epoch: 21
[ Wed Jun 28 19:20:56 2023 ] 	Mean test loss of 625 batches: 0.651288.
[ Wed Jun 28 19:20:56 2023 ] 	Top1: 63.16%
[ Wed Jun 28 19:20:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:20:56 2023 ] Training epoch: 22
[ Wed Jun 28 19:20:59 2023 ] 	Training loss: 0.7828.  Training acc: 65.62%.
[ Wed Jun 28 19:20:59 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 19:20:59 2023 ] Eval epoch: 22
[ Wed Jun 28 19:20:59 2023 ] 	Mean test loss of 625 batches: 0.650352.
[ Wed Jun 28 19:20:59 2023 ] 	Top1: 63.16%
[ Wed Jun 28 19:20:59 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:20:59 2023 ] Training epoch: 23
[ Wed Jun 28 19:21:02 2023 ] 	Training loss: 0.7784.  Training acc: 66.91%.
[ Wed Jun 28 19:21:02 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 19:21:02 2023 ] Eval epoch: 23
[ Wed Jun 28 19:21:03 2023 ] 	Mean test loss of 625 batches: 0.649078.
[ Wed Jun 28 19:21:03 2023 ] 	Top1: 87.72%
[ Wed Jun 28 19:21:03 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:21:03 2023 ] Training epoch: 24
[ Wed Jun 28 19:21:06 2023 ] 	Training loss: 0.7457.  Training acc: 67.74%.
[ Wed Jun 28 19:21:06 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 19:21:06 2023 ] Eval epoch: 24
[ Wed Jun 28 19:21:07 2023 ] 	Mean test loss of 625 batches: 0.644392.
[ Wed Jun 28 19:21:07 2023 ] 	Top1: 68.42%
[ Wed Jun 28 19:21:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:21:07 2023 ] Training epoch: 25
[ Wed Jun 28 19:21:10 2023 ] 	Training loss: 0.7507.  Training acc: 69.30%.
[ Wed Jun 28 19:21:10 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:21:10 2023 ] Eval epoch: 25
[ Wed Jun 28 19:21:11 2023 ] 	Mean test loss of 625 batches: 0.641976.
[ Wed Jun 28 19:21:11 2023 ] 	Top1: 64.91%
[ Wed Jun 28 19:21:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:21:11 2023 ] Training epoch: 26
[ Wed Jun 28 19:21:14 2023 ] 	Training loss: 0.7037.  Training acc: 75.64%.
[ Wed Jun 28 19:21:14 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:21:14 2023 ] Eval epoch: 26
[ Wed Jun 28 19:21:14 2023 ] 	Mean test loss of 625 batches: 0.632230.
[ Wed Jun 28 19:21:14 2023 ] 	Top1: 75.44%
[ Wed Jun 28 19:21:14 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:21:14 2023 ] Training epoch: 27
[ Wed Jun 28 19:21:17 2023 ] 	Training loss: 0.6707.  Training acc: 77.39%.
[ Wed Jun 28 19:21:17 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 19:21:17 2023 ] Eval epoch: 27
[ Wed Jun 28 19:21:18 2023 ] 	Mean test loss of 625 batches: 0.572141.
[ Wed Jun 28 19:21:18 2023 ] 	Top1: 85.96%
[ Wed Jun 28 19:21:18 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:21:18 2023 ] Training epoch: 28
[ Wed Jun 28 19:21:21 2023 ] 	Training loss: 0.5873.  Training acc: 87.68%.
[ Wed Jun 28 19:21:21 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:21:21 2023 ] Eval epoch: 28
[ Wed Jun 28 19:21:21 2023 ] 	Mean test loss of 625 batches: 0.437550.
[ Wed Jun 28 19:21:21 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:21:21 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:21:21 2023 ] Training epoch: 29
[ Wed Jun 28 19:21:24 2023 ] 	Training loss: 0.5221.  Training acc: 92.92%.
[ Wed Jun 28 19:21:24 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:21:24 2023 ] Eval epoch: 29
[ Wed Jun 28 19:21:25 2023 ] 	Mean test loss of 625 batches: 0.397492.
[ Wed Jun 28 19:21:25 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:21:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:21:25 2023 ] Training epoch: 30
[ Wed Jun 28 19:21:28 2023 ] 	Training loss: 0.4681.  Training acc: 96.05%.
[ Wed Jun 28 19:21:28 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:21:28 2023 ] Eval epoch: 30
[ Wed Jun 28 19:21:29 2023 ] 	Mean test loss of 625 batches: 0.370470.
[ Wed Jun 28 19:21:29 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:21:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:21:29 2023 ] Best accuracy: 1.0
[ Wed Jun 28 19:21:29 2023 ] Epoch number: 29
[ Wed Jun 28 19:21:29 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 19:21:29 2023 ] Weight decay: 0.0005
[ Wed Jun 28 19:21:29 2023 ] Base LR: 0.1
[ Wed Jun 28 19:21:29 2023 ] Batch Size: 64
[ Wed Jun 28 19:21:29 2023 ] Test Batch Size: 64
[ Wed Jun 28 19:21:29 2023 ] seed: 1
[ Wed Jun 28 19:21:29 2023 ] Start training Corrector
[ Wed Jun 28 19:21:29 2023 ] # Parameters Corrector: 2407569
[ Wed Jun 28 19:21:31 2023 ] Training epoch: 1
[ Wed Jun 28 19:22:23 2023 ] using warm up, epoch: 5
[ Wed Jun 28 19:22:23 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 19:22:23 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 19:22:23 2023 ] Start training Predictor
[ Wed Jun 28 19:22:23 2023 ] Training epoch: 1
[ Wed Jun 28 19:22:29 2023 ] 	Training loss: 112.8022.  Training acc: 31.99%.
[ Wed Jun 28 19:22:29 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:22:29 2023 ] Eval epoch: 1
[ Wed Jun 28 19:22:30 2023 ] 	Mean test loss of 625 batches: 18686.044922.
[ Wed Jun 28 19:22:30 2023 ] 	Top1: 38.60%
[ Wed Jun 28 19:22:30 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:22:30 2023 ] Training epoch: 2
[ Wed Jun 28 19:22:32 2023 ] 	Training loss: 9.6258.  Training acc: 39.71%.
[ Wed Jun 28 19:22:32 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 19:22:32 2023 ] Eval epoch: 2
[ Wed Jun 28 19:22:33 2023 ] 	Mean test loss of 625 batches: 27.068088.
[ Wed Jun 28 19:22:33 2023 ] 	Top1: 38.60%
[ Wed Jun 28 19:22:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:22:33 2023 ] Training epoch: 3
[ Wed Jun 28 19:22:36 2023 ] 	Training loss: 6.3809.  Training acc: 48.62%.
[ Wed Jun 28 19:22:36 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 19:22:36 2023 ] Eval epoch: 3
[ Wed Jun 28 19:22:36 2023 ] 	Mean test loss of 625 batches: 14.368012.
[ Wed Jun 28 19:22:36 2023 ] 	Top1: 61.40%
[ Wed Jun 28 19:22:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:22:36 2023 ] Training epoch: 4
[ Wed Jun 28 19:22:39 2023 ] 	Training loss: 7.6467.  Training acc: 56.80%.
[ Wed Jun 28 19:22:39 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:22:39 2023 ] Eval epoch: 4
[ Wed Jun 28 19:22:40 2023 ] 	Mean test loss of 625 batches: 14.763251.
[ Wed Jun 28 19:22:40 2023 ] 	Top1: 64.91%
[ Wed Jun 28 19:22:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:22:40 2023 ] Training epoch: 5
[ Wed Jun 28 19:22:43 2023 ] 	Training loss: 6.9719.  Training acc: 53.31%.
[ Wed Jun 28 19:22:43 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 19:22:43 2023 ] Eval epoch: 5
[ Wed Jun 28 19:22:43 2023 ] 	Mean test loss of 625 batches: 1.694144.
[ Wed Jun 28 19:22:43 2023 ] 	Top1: 68.42%
[ Wed Jun 28 19:22:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:22:43 2023 ] Training epoch: 6
[ Wed Jun 28 19:22:46 2023 ] 	Training loss: 3.5147.  Training acc: 54.32%.
[ Wed Jun 28 19:22:46 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:22:46 2023 ] Eval epoch: 6
[ Wed Jun 28 19:22:47 2023 ] 	Mean test loss of 625 batches: 1.103750.
[ Wed Jun 28 19:22:47 2023 ] 	Top1: 50.88%
[ Wed Jun 28 19:22:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:22:47 2023 ] Training epoch: 7
[ Wed Jun 28 19:22:50 2023 ] 	Training loss: 2.3097.  Training acc: 60.29%.
[ Wed Jun 28 19:22:50 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 19:22:50 2023 ] Eval epoch: 7
[ Wed Jun 28 19:22:50 2023 ] 	Mean test loss of 625 batches: 0.835492.
[ Wed Jun 28 19:22:50 2023 ] 	Top1: 63.16%
[ Wed Jun 28 19:22:50 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:22:50 2023 ] Training epoch: 8
[ Wed Jun 28 19:22:53 2023 ] 	Training loss: 1.9605.  Training acc: 60.85%.
[ Wed Jun 28 19:22:53 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:22:53 2023 ] Eval epoch: 8
[ Wed Jun 28 19:22:54 2023 ] 	Mean test loss of 625 batches: 0.834426.
[ Wed Jun 28 19:22:54 2023 ] 	Top1: 63.16%
[ Wed Jun 28 19:22:54 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:22:54 2023 ] Training epoch: 9
[ Wed Jun 28 19:22:57 2023 ] 	Training loss: 1.5254.  Training acc: 64.43%.
[ Wed Jun 28 19:22:57 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Jun 28 19:22:57 2023 ] Eval epoch: 9
[ Wed Jun 28 19:22:58 2023 ] 	Mean test loss of 625 batches: 0.687586.
[ Wed Jun 28 19:22:58 2023 ] 	Top1: 70.18%
[ Wed Jun 28 19:22:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:22:58 2023 ] Training epoch: 10
[ Wed Jun 28 19:23:00 2023 ] 	Training loss: 1.4285.  Training acc: 62.22%.
[ Wed Jun 28 19:23:00 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:23:00 2023 ] Eval epoch: 10
[ Wed Jun 28 19:23:01 2023 ] 	Mean test loss of 625 batches: 0.710655.
[ Wed Jun 28 19:23:01 2023 ] 	Top1: 73.68%
[ Wed Jun 28 19:23:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:23:01 2023 ] Training epoch: 11
[ Wed Jun 28 19:23:04 2023 ] 	Training loss: 1.2654.  Training acc: 64.06%.
[ Wed Jun 28 19:23:04 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 19:23:04 2023 ] Eval epoch: 11
[ Wed Jun 28 19:23:05 2023 ] 	Mean test loss of 625 batches: 0.719141.
[ Wed Jun 28 19:23:05 2023 ] 	Top1: 71.93%
[ Wed Jun 28 19:23:05 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:23:05 2023 ] Training epoch: 12
[ Wed Jun 28 19:23:07 2023 ] 	Training loss: 1.1584.  Training acc: 67.92%.
[ Wed Jun 28 19:23:07 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:23:07 2023 ] Eval epoch: 12
[ Wed Jun 28 19:23:08 2023 ] 	Mean test loss of 625 batches: 0.770946.
[ Wed Jun 28 19:23:08 2023 ] 	Top1: 80.70%
[ Wed Jun 28 19:23:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:23:08 2023 ] Training epoch: 13
[ Wed Jun 28 19:23:11 2023 ] 	Training loss: 1.0823.  Training acc: 70.77%.
[ Wed Jun 28 19:23:11 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 19:23:11 2023 ] Eval epoch: 13
[ Wed Jun 28 19:23:11 2023 ] 	Mean test loss of 625 batches: 0.724520.
[ Wed Jun 28 19:23:11 2023 ] 	Top1: 82.46%
[ Wed Jun 28 19:23:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:23:12 2023 ] Training epoch: 14
[ Wed Jun 28 19:23:14 2023 ] 	Training loss: 1.0164.  Training acc: 72.33%.
[ Wed Jun 28 19:23:14 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:23:14 2023 ] Eval epoch: 14
[ Wed Jun 28 19:23:15 2023 ] 	Mean test loss of 625 batches: 0.590063.
[ Wed Jun 28 19:23:15 2023 ] 	Top1: 89.47%
[ Wed Jun 28 19:23:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:23:15 2023 ] Training epoch: 15
[ Wed Jun 28 19:23:18 2023 ] 	Training loss: 1.0370.  Training acc: 73.99%.
[ Wed Jun 28 19:23:18 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 19:23:18 2023 ] Eval epoch: 15
[ Wed Jun 28 19:23:19 2023 ] 	Mean test loss of 625 batches: 0.584377.
[ Wed Jun 28 19:23:19 2023 ] 	Top1: 87.72%
[ Wed Jun 28 19:23:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:23:19 2023 ] Training epoch: 16
[ Wed Jun 28 19:23:21 2023 ] 	Training loss: 0.9373.  Training acc: 77.02%.
[ Wed Jun 28 19:23:21 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:23:21 2023 ] Eval epoch: 16
[ Wed Jun 28 19:23:22 2023 ] 	Mean test loss of 625 batches: 0.507738.
[ Wed Jun 28 19:23:22 2023 ] 	Top1: 91.23%
[ Wed Jun 28 19:23:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:23:22 2023 ] Training epoch: 17
[ Wed Jun 28 19:23:25 2023 ] 	Training loss: 0.8313.  Training acc: 79.87%.
[ Wed Jun 28 19:23:25 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 19:23:25 2023 ] Eval epoch: 17
[ Wed Jun 28 19:23:26 2023 ] 	Mean test loss of 625 batches: 0.585109.
[ Wed Jun 28 19:23:26 2023 ] 	Top1: 89.47%
[ Wed Jun 28 19:23:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:23:26 2023 ] Training epoch: 18
[ Wed Jun 28 19:23:28 2023 ] 	Training loss: 0.7510.  Training acc: 85.20%.
[ Wed Jun 28 19:23:28 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 19:23:28 2023 ] Eval epoch: 18
[ Wed Jun 28 19:23:29 2023 ] 	Mean test loss of 625 batches: 0.563578.
[ Wed Jun 28 19:23:29 2023 ] 	Top1: 94.74%
[ Wed Jun 28 19:23:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:23:29 2023 ] Training epoch: 19
[ Wed Jun 28 19:23:32 2023 ] 	Training loss: 0.8253.  Training acc: 82.81%.
[ Wed Jun 28 19:23:32 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:23:32 2023 ] Eval epoch: 19
[ Wed Jun 28 19:23:33 2023 ] 	Mean test loss of 625 batches: 0.491629.
[ Wed Jun 28 19:23:33 2023 ] 	Top1: 96.49%
[ Wed Jun 28 19:23:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:23:33 2023 ] Training epoch: 20
[ Wed Jun 28 19:23:35 2023 ] 	Training loss: 0.7210.  Training acc: 84.93%.
[ Wed Jun 28 19:23:35 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 19:23:35 2023 ] Eval epoch: 20
[ Wed Jun 28 19:23:36 2023 ] 	Mean test loss of 625 batches: 0.605162.
[ Wed Jun 28 19:23:36 2023 ] 	Top1: 91.23%
[ Wed Jun 28 19:23:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:23:36 2023 ] Training epoch: 21
[ Wed Jun 28 19:23:39 2023 ] 	Training loss: 0.6800.  Training acc: 87.32%.
[ Wed Jun 28 19:23:39 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 19:23:39 2023 ] Eval epoch: 21
[ Wed Jun 28 19:23:39 2023 ] 	Mean test loss of 625 batches: 0.524957.
[ Wed Jun 28 19:23:39 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:23:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:23:39 2023 ] Training epoch: 22
[ Wed Jun 28 19:23:42 2023 ] 	Training loss: 0.6556.  Training acc: 88.24%.
[ Wed Jun 28 19:23:42 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 19:23:42 2023 ] Eval epoch: 22
[ Wed Jun 28 19:23:43 2023 ] 	Mean test loss of 625 batches: 0.457253.
[ Wed Jun 28 19:23:43 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:23:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:23:43 2023 ] Training epoch: 23
[ Wed Jun 28 19:23:46 2023 ] 	Training loss: 0.6585.  Training acc: 88.79%.
[ Wed Jun 28 19:23:46 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 19:23:46 2023 ] Eval epoch: 23
[ Wed Jun 28 19:23:46 2023 ] 	Mean test loss of 625 batches: 0.476925.
[ Wed Jun 28 19:23:46 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:23:46 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:23:46 2023 ] Training epoch: 24
[ Wed Jun 28 19:23:49 2023 ] 	Training loss: 0.6085.  Training acc: 88.42%.
[ Wed Jun 28 19:23:49 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:23:49 2023 ] Eval epoch: 24
[ Wed Jun 28 19:23:50 2023 ] 	Mean test loss of 625 batches: 0.486850.
[ Wed Jun 28 19:23:50 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:23:50 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:23:50 2023 ] Training epoch: 25
[ Wed Jun 28 19:23:53 2023 ] 	Training loss: 0.6263.  Training acc: 89.25%.
[ Wed Jun 28 19:23:53 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 19:23:53 2023 ] Eval epoch: 25
[ Wed Jun 28 19:23:53 2023 ] 	Mean test loss of 625 batches: 0.488173.
[ Wed Jun 28 19:23:53 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:23:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:23:53 2023 ] Training epoch: 26
[ Wed Jun 28 19:23:56 2023 ] 	Training loss: 0.6357.  Training acc: 88.51%.
[ Wed Jun 28 19:23:56 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Wed Jun 28 19:23:56 2023 ] Eval epoch: 26
[ Wed Jun 28 19:23:57 2023 ] 	Mean test loss of 625 batches: 0.468396.
[ Wed Jun 28 19:23:57 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:23:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:23:57 2023 ] Training epoch: 27
[ Wed Jun 28 19:24:00 2023 ] 	Training loss: 0.6307.  Training acc: 88.60%.
[ Wed Jun 28 19:24:00 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 19:24:00 2023 ] Eval epoch: 27
[ Wed Jun 28 19:24:00 2023 ] 	Mean test loss of 625 batches: 0.487808.
[ Wed Jun 28 19:24:00 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:24:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:24:00 2023 ] Training epoch: 28
[ Wed Jun 28 19:24:03 2023 ] 	Training loss: 0.6217.  Training acc: 89.71%.
[ Wed Jun 28 19:24:03 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 19:24:03 2023 ] Eval epoch: 28
[ Wed Jun 28 19:24:04 2023 ] 	Mean test loss of 625 batches: 0.472051.
[ Wed Jun 28 19:24:04 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:24:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:24:04 2023 ] Training epoch: 29
[ Wed Jun 28 19:24:07 2023 ] 	Training loss: 0.6360.  Training acc: 88.60%.
[ Wed Jun 28 19:24:07 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 19:24:07 2023 ] Eval epoch: 29
[ Wed Jun 28 19:24:07 2023 ] 	Mean test loss of 625 batches: 0.440571.
[ Wed Jun 28 19:24:07 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:24:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:24:07 2023 ] Training epoch: 30
[ Wed Jun 28 19:24:10 2023 ] 	Training loss: 0.6090.  Training acc: 89.89%.
[ Wed Jun 28 19:24:10 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:24:10 2023 ] Eval epoch: 30
[ Wed Jun 28 19:24:11 2023 ] 	Mean test loss of 625 batches: 0.442184.
[ Wed Jun 28 19:24:11 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:24:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:24:12 2023 ] Best accuracy: 0.9824561403508771
[ Wed Jun 28 19:24:12 2023 ] Epoch number: 21
[ Wed Jun 28 19:24:12 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 19:24:12 2023 ] Weight decay: 0.0005
[ Wed Jun 28 19:24:12 2023 ] Base LR: 0.1
[ Wed Jun 28 19:24:12 2023 ] Batch Size: 64
[ Wed Jun 28 19:24:12 2023 ] Test Batch Size: 64
[ Wed Jun 28 19:24:12 2023 ] seed: 1
[ Wed Jun 28 19:24:12 2023 ] Start training Corrector
[ Wed Jun 28 19:24:12 2023 ] # Parameters Corrector: 2407569
[ Wed Jun 28 19:24:13 2023 ] Training epoch: 1
[ Wed Jun 28 19:24:21 2023 ] 	Training loss: 17.5910.  Training acc: 53.12%.
[ Wed Jun 28 19:24:21 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:24:21 2023 ] Training epoch: 2
[ Wed Jun 28 19:24:28 2023 ] 	Training loss: 13.5196.  Training acc: 38.41%.
[ Wed Jun 28 19:24:28 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:24:28 2023 ] Training epoch: 3
[ Wed Jun 28 19:24:35 2023 ] 	Training loss: 14.3789.  Training acc: 33.07%.
[ Wed Jun 28 19:24:35 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:24:35 2023 ] Training epoch: 4
[ Wed Jun 28 19:24:41 2023 ] 	Training loss: 12.3319.  Training acc: 38.28%.
[ Wed Jun 28 19:24:41 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:24:42 2023 ] Training epoch: 5
[ Wed Jun 28 19:24:48 2023 ] 	Training loss: 10.4572.  Training acc: 43.23%.
[ Wed Jun 28 19:24:48 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:24:49 2023 ] Training epoch: 6
[ Wed Jun 28 19:24:55 2023 ] 	Training loss: 9.9611.  Training acc: 27.21%.
[ Wed Jun 28 19:24:55 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:24:56 2023 ] Training epoch: 7
[ Wed Jun 28 19:25:02 2023 ] 	Training loss: 8.1663.  Training acc: 55.60%.
[ Wed Jun 28 19:25:02 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:25:03 2023 ] Training epoch: 8
[ Wed Jun 28 19:25:09 2023 ] 	Training loss: 8.1585.  Training acc: 57.29%.
[ Wed Jun 28 19:25:09 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:25:10 2023 ] Training epoch: 9
[ Wed Jun 28 19:25:16 2023 ] 	Training loss: 8.9040.  Training acc: 32.81%.
[ Wed Jun 28 19:25:16 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:25:17 2023 ] Training epoch: 10
[ Wed Jun 28 19:25:23 2023 ] 	Training loss: 7.8422.  Training acc: 49.87%.
[ Wed Jun 28 19:25:23 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:25:24 2023 ] Training epoch: 11
[ Wed Jun 28 19:25:30 2023 ] 	Training loss: 7.6395.  Training acc: 59.64%.
[ Wed Jun 28 19:25:30 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:25:30 2023 ] Training epoch: 12
[ Wed Jun 28 19:25:37 2023 ] 	Training loss: 7.4175.  Training acc: 65.49%.
[ Wed Jun 28 19:25:37 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:25:37 2023 ] Training epoch: 13
[ Wed Jun 28 19:25:44 2023 ] 	Training loss: 7.1819.  Training acc: 66.54%.
[ Wed Jun 28 19:25:44 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:25:44 2023 ] Training epoch: 14
[ Wed Jun 28 19:25:51 2023 ] 	Training loss: 7.1048.  Training acc: 75.39%.
[ Wed Jun 28 19:25:51 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:25:51 2023 ] Training epoch: 15
[ Wed Jun 28 19:25:57 2023 ] 	Training loss: 7.0739.  Training acc: 76.82%.
[ Wed Jun 28 19:25:57 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 19:25:58 2023 ] Training epoch: 16
[ Wed Jun 28 19:26:04 2023 ] 	Training loss: 7.1584.  Training acc: 77.34%.
[ Wed Jun 28 19:26:04 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:26:05 2023 ] Training epoch: 17
[ Wed Jun 28 19:26:11 2023 ] 	Training loss: 7.1034.  Training acc: 75.13%.
[ Wed Jun 28 19:26:11 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:26:12 2023 ] Training epoch: 18
[ Wed Jun 28 19:26:18 2023 ] 	Training loss: 6.8748.  Training acc: 77.08%.
[ Wed Jun 28 19:26:18 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:26:19 2023 ] Training epoch: 19
[ Wed Jun 28 19:26:25 2023 ] 	Training loss: 7.2445.  Training acc: 55.86%.
[ Wed Jun 28 19:26:25 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:26:26 2023 ] Training epoch: 20
[ Wed Jun 28 19:26:32 2023 ] 	Training loss: 7.3259.  Training acc: 64.97%.
[ Wed Jun 28 19:26:32 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:26:33 2023 ] Training epoch: 21
[ Wed Jun 28 19:26:39 2023 ] 	Training loss: 7.3576.  Training acc: 82.42%.
[ Wed Jun 28 19:26:39 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:26:40 2023 ] Training epoch: 22
[ Wed Jun 28 19:26:46 2023 ] 	Training loss: 7.1686.  Training acc: 82.42%.
[ Wed Jun 28 19:26:46 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:26:46 2023 ] Training epoch: 23
[ Wed Jun 28 19:26:53 2023 ] 	Training loss: 7.1409.  Training acc: 82.16%.
[ Wed Jun 28 19:26:53 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:26:53 2023 ] Training epoch: 24
[ Wed Jun 28 19:27:00 2023 ] 	Training loss: 7.1410.  Training acc: 82.29%.
[ Wed Jun 28 19:27:00 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:27:00 2023 ] Training epoch: 25
[ Wed Jun 28 19:27:07 2023 ] 	Training loss: 7.0980.  Training acc: 82.29%.
[ Wed Jun 28 19:27:07 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:27:07 2023 ] Training epoch: 26
[ Wed Jun 28 19:27:13 2023 ] 	Training loss: 7.0023.  Training acc: 81.77%.
[ Wed Jun 28 19:27:13 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:27:14 2023 ] Training epoch: 27
[ Wed Jun 28 19:27:20 2023 ] 	Training loss: 7.0097.  Training acc: 80.08%.
[ Wed Jun 28 19:27:20 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:27:21 2023 ] Training epoch: 28
[ Wed Jun 28 19:27:27 2023 ] 	Training loss: 7.1422.  Training acc: 78.39%.
[ Wed Jun 28 19:27:27 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:27:28 2023 ] Training epoch: 29
[ Wed Jun 28 19:27:34 2023 ] 	Training loss: 6.9676.  Training acc: 80.47%.
[ Wed Jun 28 19:27:34 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:27:35 2023 ] Training epoch: 30
[ Wed Jun 28 19:27:41 2023 ] 	Training loss: 7.1573.  Training acc: 80.99%.
[ Wed Jun 28 19:27:41 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:27:42 2023 ] Training epoch: 31
[ Wed Jun 28 19:27:48 2023 ] 	Training loss: 7.0431.  Training acc: 82.29%.
[ Wed Jun 28 19:27:48 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:27:49 2023 ] Training epoch: 32
[ Wed Jun 28 19:27:55 2023 ] 	Training loss: 6.8609.  Training acc: 82.42%.
[ Wed Jun 28 19:27:55 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:27:55 2023 ] Training epoch: 33
[ Wed Jun 28 19:28:02 2023 ] 	Training loss: 6.9870.  Training acc: 82.42%.
[ Wed Jun 28 19:28:02 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:28:02 2023 ] Training epoch: 34
[ Wed Jun 28 19:28:09 2023 ] 	Training loss: 6.9055.  Training acc: 81.90%.
[ Wed Jun 28 19:28:09 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:28:09 2023 ] Training epoch: 35
[ Wed Jun 28 19:28:16 2023 ] 	Training loss: 6.9896.  Training acc: 82.55%.
[ Wed Jun 28 19:28:16 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:28:16 2023 ] Training epoch: 36
[ Wed Jun 28 19:28:22 2023 ] 	Training loss: 6.9756.  Training acc: 81.12%.
[ Wed Jun 28 19:28:22 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:28:23 2023 ] Training epoch: 37
[ Wed Jun 28 19:28:29 2023 ] 	Training loss: 7.0759.  Training acc: 79.95%.
[ Wed Jun 28 19:28:29 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:28:30 2023 ] Training epoch: 38
[ Wed Jun 28 19:28:36 2023 ] 	Training loss: 7.0058.  Training acc: 81.64%.
[ Wed Jun 28 19:28:36 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:28:37 2023 ] Training epoch: 39
[ Wed Jun 28 19:28:43 2023 ] 	Training loss: 6.8786.  Training acc: 81.77%.
[ Wed Jun 28 19:28:43 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:28:44 2023 ] Training epoch: 40
[ Wed Jun 28 19:28:50 2023 ] 	Training loss: 6.9939.  Training acc: 82.29%.
[ Wed Jun 28 19:28:50 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:28:50 2023 ] Training epoch: 41
[ Wed Jun 28 19:28:57 2023 ] 	Training loss: 6.8521.  Training acc: 83.85%.
[ Wed Jun 28 19:28:57 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:28:57 2023 ] Training epoch: 42
[ Wed Jun 28 19:29:04 2023 ] 	Training loss: 6.8446.  Training acc: 83.07%.
[ Wed Jun 28 19:29:04 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:29:05 2023 ] Training epoch: 43
[ Wed Jun 28 19:29:11 2023 ] 	Training loss: 7.0113.  Training acc: 82.29%.
[ Wed Jun 28 19:29:11 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:29:12 2023 ] Training epoch: 44
[ Wed Jun 28 19:29:18 2023 ] 	Training loss: 6.7357.  Training acc: 84.64%.
[ Wed Jun 28 19:29:18 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:29:19 2023 ] Training epoch: 45
[ Wed Jun 28 19:29:25 2023 ] 	Training loss: 6.8715.  Training acc: 82.55%.
[ Wed Jun 28 19:29:25 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 19:29:25 2023 ] Training epoch: 46
[ Wed Jun 28 19:29:32 2023 ] 	Training loss: 6.7262.  Training acc: 83.33%.
[ Wed Jun 28 19:29:32 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:29:32 2023 ] Training epoch: 47
[ Wed Jun 28 19:29:39 2023 ] 	Training loss: 7.0473.  Training acc: 83.07%.
[ Wed Jun 28 19:29:39 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:29:39 2023 ] Training epoch: 48
[ Wed Jun 28 19:29:46 2023 ] 	Training loss: 7.0294.  Training acc: 83.20%.
[ Wed Jun 28 19:29:46 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:29:46 2023 ] Training epoch: 49
[ Wed Jun 28 19:29:53 2023 ] 	Training loss: 7.0867.  Training acc: 84.90%.
[ Wed Jun 28 19:29:53 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:29:53 2023 ] Training epoch: 50
[ Wed Jun 28 19:30:00 2023 ] 	Training loss: 6.8103.  Training acc: 83.98%.
[ Wed Jun 28 19:30:00 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 19:30:00 2023 ] Training epoch: 51
[ Wed Jun 28 19:30:07 2023 ] 	Training loss: 6.8582.  Training acc: 80.86%.
[ Wed Jun 28 19:30:07 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:30:07 2023 ] Training epoch: 52
[ Wed Jun 28 19:30:14 2023 ] 	Training loss: 6.7361.  Training acc: 83.07%.
[ Wed Jun 28 19:30:14 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:30:14 2023 ] Training epoch: 53
[ Wed Jun 28 19:30:20 2023 ] 	Training loss: 6.6935.  Training acc: 84.64%.
[ Wed Jun 28 19:30:20 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 19:30:21 2023 ] Training epoch: 54
[ Wed Jun 28 19:30:27 2023 ] 	Training loss: 6.7712.  Training acc: 86.07%.
[ Wed Jun 28 19:30:27 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:30:28 2023 ] Training epoch: 55
[ Wed Jun 28 19:30:34 2023 ] 	Training loss: 6.8734.  Training acc: 85.94%.
[ Wed Jun 28 19:30:34 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:30:35 2023 ] Training epoch: 56
[ Wed Jun 28 19:30:41 2023 ] 	Training loss: 6.8877.  Training acc: 86.59%.
[ Wed Jun 28 19:30:41 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:30:42 2023 ] Training epoch: 57
[ Wed Jun 28 19:30:48 2023 ] 	Training loss: 6.8355.  Training acc: 87.37%.
[ Wed Jun 28 19:30:48 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:30:49 2023 ] Training epoch: 58
[ Wed Jun 28 19:30:55 2023 ] 	Training loss: 6.9629.  Training acc: 85.16%.
[ Wed Jun 28 19:30:55 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:30:55 2023 ] Training epoch: 59
[ Wed Jun 28 19:31:02 2023 ] 	Training loss: 6.7631.  Training acc: 87.24%.
[ Wed Jun 28 19:31:02 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:31:02 2023 ] Training epoch: 60
[ Wed Jun 28 19:31:09 2023 ] 	Training loss: 6.8824.  Training acc: 87.11%.
[ Wed Jun 28 19:31:09 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:31:09 2023 ] Training epoch: 61
[ Wed Jun 28 19:31:16 2023 ] 	Training loss: 6.7882.  Training acc: 88.15%.
[ Wed Jun 28 19:31:16 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:31:16 2023 ] Training epoch: 62
[ Wed Jun 28 19:31:23 2023 ] 	Training loss: 6.6493.  Training acc: 89.06%.
[ Wed Jun 28 19:31:23 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:31:23 2023 ] Training epoch: 63
[ Wed Jun 28 19:31:30 2023 ] 	Training loss: 6.9338.  Training acc: 87.50%.
[ Wed Jun 28 19:31:30 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:31:30 2023 ] Training epoch: 64
[ Wed Jun 28 19:31:36 2023 ] 	Training loss: 6.8462.  Training acc: 87.50%.
[ Wed Jun 28 19:31:36 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:31:37 2023 ] Training epoch: 65
[ Wed Jun 28 19:31:43 2023 ] 	Training loss: 6.7439.  Training acc: 87.11%.
[ Wed Jun 28 19:31:43 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:31:44 2023 ] Training epoch: 66
[ Wed Jun 28 19:31:50 2023 ] 	Training loss: 6.7294.  Training acc: 90.10%.
[ Wed Jun 28 19:31:50 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:31:51 2023 ] Training epoch: 67
[ Wed Jun 28 19:31:57 2023 ] 	Training loss: 6.9316.  Training acc: 90.36%.
[ Wed Jun 28 19:31:57 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:31:58 2023 ] Training epoch: 68
[ Wed Jun 28 19:32:04 2023 ] 	Training loss: 6.8023.  Training acc: 88.41%.
[ Wed Jun 28 19:32:04 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:32:05 2023 ] Training epoch: 69
[ Wed Jun 28 19:32:11 2023 ] 	Training loss: 6.9219.  Training acc: 88.93%.
[ Wed Jun 28 19:32:11 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:32:12 2023 ] Training epoch: 70
[ Wed Jun 28 19:32:18 2023 ] 	Training loss: 6.7924.  Training acc: 87.50%.
[ Wed Jun 28 19:32:18 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:32:19 2023 ] Training epoch: 71
[ Wed Jun 28 19:32:25 2023 ] 	Training loss: 6.7503.  Training acc: 87.24%.
[ Wed Jun 28 19:32:25 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:32:25 2023 ] Training epoch: 72
[ Wed Jun 28 19:32:32 2023 ] 	Training loss: 6.8084.  Training acc: 87.89%.
[ Wed Jun 28 19:32:32 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:32:32 2023 ] Training epoch: 73
[ Wed Jun 28 19:32:38 2023 ] 	Training loss: 6.7863.  Training acc: 89.32%.
[ Wed Jun 28 19:32:38 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:32:39 2023 ] Training epoch: 74
[ Wed Jun 28 19:32:45 2023 ] 	Training loss: 6.8862.  Training acc: 89.19%.
[ Wed Jun 28 19:32:45 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:32:46 2023 ] Training epoch: 75
[ Wed Jun 28 19:32:52 2023 ] 	Training loss: 6.9079.  Training acc: 88.93%.
[ Wed Jun 28 19:32:52 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:32:53 2023 ] Training epoch: 76
[ Wed Jun 28 19:32:59 2023 ] 	Training loss: 6.6984.  Training acc: 91.02%.
[ Wed Jun 28 19:32:59 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:33:00 2023 ] Training epoch: 77
[ Wed Jun 28 19:33:06 2023 ] 	Training loss: 6.7716.  Training acc: 90.36%.
[ Wed Jun 28 19:33:06 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:33:07 2023 ] Training epoch: 78
[ Wed Jun 28 19:33:13 2023 ] 	Training loss: 6.8214.  Training acc: 89.84%.
[ Wed Jun 28 19:33:13 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 19:33:14 2023 ] Training epoch: 79
[ Wed Jun 28 19:33:20 2023 ] 	Training loss: 6.6577.  Training acc: 90.23%.
[ Wed Jun 28 19:33:20 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:33:21 2023 ] Training epoch: 80
[ Wed Jun 28 19:33:27 2023 ] 	Training loss: 6.8295.  Training acc: 88.93%.
[ Wed Jun 28 19:33:27 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:33:28 2023 ] Training epoch: 81
[ Wed Jun 28 19:33:34 2023 ] 	Training loss: 6.7259.  Training acc: 92.58%.
[ Wed Jun 28 19:33:34 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:33:35 2023 ] Training epoch: 82
[ Wed Jun 28 19:33:41 2023 ] 	Training loss: 6.8989.  Training acc: 88.41%.
[ Wed Jun 28 19:33:41 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:33:42 2023 ] Training epoch: 83
[ Wed Jun 28 19:33:48 2023 ] 	Training loss: 6.7063.  Training acc: 92.06%.
[ Wed Jun 28 19:33:48 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:33:48 2023 ] Training epoch: 84
[ Wed Jun 28 19:33:55 2023 ] 	Training loss: 6.8256.  Training acc: 92.32%.
[ Wed Jun 28 19:33:55 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:33:55 2023 ] Training epoch: 85
[ Wed Jun 28 19:34:02 2023 ] 	Training loss: 6.7333.  Training acc: 92.45%.
[ Wed Jun 28 19:34:02 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:34:02 2023 ] Training epoch: 86
[ Wed Jun 28 19:34:08 2023 ] 	Training loss: 6.6317.  Training acc: 89.58%.
[ Wed Jun 28 19:34:08 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:34:09 2023 ] Training epoch: 87
[ Wed Jun 28 19:34:15 2023 ] 	Training loss: 6.7909.  Training acc: 84.38%.
[ Wed Jun 28 19:34:15 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 19:34:16 2023 ] Training epoch: 88
[ Wed Jun 28 19:34:22 2023 ] 	Training loss: 6.8891.  Training acc: 91.41%.
[ Wed Jun 28 19:34:22 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:34:23 2023 ] Training epoch: 89
[ Wed Jun 28 19:34:29 2023 ] 	Training loss: 6.7807.  Training acc: 92.32%.
[ Wed Jun 28 19:34:29 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:34:30 2023 ] Training epoch: 90
[ Wed Jun 28 19:34:36 2023 ] 	Training loss: 6.8386.  Training acc: 92.19%.
[ Wed Jun 28 19:34:36 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:34:36 2023 ] Training epoch: 91
[ Wed Jun 28 19:34:43 2023 ] 	Training loss: 6.7631.  Training acc: 93.88%.
[ Wed Jun 28 19:34:43 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:34:43 2023 ] Training epoch: 92
[ Wed Jun 28 19:34:50 2023 ] 	Training loss: 6.7715.  Training acc: 93.23%.
[ Wed Jun 28 19:34:50 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:34:50 2023 ] Training epoch: 93
[ Wed Jun 28 19:34:57 2023 ] 	Training loss: 6.7030.  Training acc: 92.06%.
[ Wed Jun 28 19:34:57 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:34:57 2023 ] Training epoch: 94
[ Wed Jun 28 19:35:04 2023 ] 	Training loss: 6.5488.  Training acc: 90.76%.
[ Wed Jun 28 19:35:04 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:35:04 2023 ] Training epoch: 95
[ Wed Jun 28 19:35:10 2023 ] 	Training loss: 6.7487.  Training acc: 91.80%.
[ Wed Jun 28 19:35:10 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:35:11 2023 ] Training epoch: 96
[ Wed Jun 28 19:35:17 2023 ] 	Training loss: 6.7754.  Training acc: 93.10%.
[ Wed Jun 28 19:35:17 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:35:18 2023 ] Training epoch: 97
[ Wed Jun 28 19:35:24 2023 ] 	Training loss: 6.8051.  Training acc: 90.76%.
[ Wed Jun 28 19:35:24 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:35:25 2023 ] Training epoch: 98
[ Wed Jun 28 19:35:31 2023 ] 	Training loss: 6.6558.  Training acc: 90.62%.
[ Wed Jun 28 19:35:31 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:35:32 2023 ] Training epoch: 99
[ Wed Jun 28 19:35:38 2023 ] 	Training loss: 6.7492.  Training acc: 92.71%.
[ Wed Jun 28 19:35:38 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:35:39 2023 ] Training epoch: 100
[ Wed Jun 28 19:35:45 2023 ] 	Training loss: 6.7924.  Training acc: 92.84%.
[ Wed Jun 28 19:35:45 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:35:46 2023 ] Training epoch: 101
[ Wed Jun 28 19:35:52 2023 ] 	Training loss: 6.7662.  Training acc: 92.84%.
[ Wed Jun 28 19:35:52 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:35:53 2023 ] Training epoch: 102
[ Wed Jun 28 19:35:59 2023 ] 	Training loss: 6.7389.  Training acc: 91.41%.
[ Wed Jun 28 19:35:59 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:35:59 2023 ] Training epoch: 103
[ Wed Jun 28 19:36:06 2023 ] 	Training loss: 6.7618.  Training acc: 91.41%.
[ Wed Jun 28 19:36:06 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:36:06 2023 ] Training epoch: 104
[ Wed Jun 28 19:36:13 2023 ] 	Training loss: 6.8159.  Training acc: 93.49%.
[ Wed Jun 28 19:36:13 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:36:13 2023 ] Training epoch: 105
[ Wed Jun 28 19:36:19 2023 ] 	Training loss: 6.7270.  Training acc: 93.62%.
[ Wed Jun 28 19:36:19 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:36:20 2023 ] Training epoch: 106
[ Wed Jun 28 19:36:26 2023 ] 	Training loss: 6.7026.  Training acc: 93.88%.
[ Wed Jun 28 19:36:26 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:36:27 2023 ] Training epoch: 107
[ Wed Jun 28 19:36:33 2023 ] 	Training loss: 6.7334.  Training acc: 92.71%.
[ Wed Jun 28 19:36:33 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 19:36:34 2023 ] Training epoch: 108
[ Wed Jun 28 19:36:40 2023 ] 	Training loss: 6.8111.  Training acc: 89.32%.
[ Wed Jun 28 19:36:40 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:36:41 2023 ] Training epoch: 109
[ Wed Jun 28 19:36:47 2023 ] 	Training loss: 6.8830.  Training acc: 92.97%.
[ Wed Jun 28 19:36:47 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:36:48 2023 ] Training epoch: 110
[ Wed Jun 28 19:36:54 2023 ] 	Training loss: 6.8595.  Training acc: 94.27%.
[ Wed Jun 28 19:36:54 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:36:55 2023 ] Training epoch: 111
[ Wed Jun 28 19:37:01 2023 ] 	Training loss: 6.5917.  Training acc: 92.84%.
[ Wed Jun 28 19:37:01 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:37:02 2023 ] Training epoch: 112
[ Wed Jun 28 19:37:08 2023 ] 	Training loss: 6.7365.  Training acc: 93.10%.
[ Wed Jun 28 19:37:08 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:37:09 2023 ] Training epoch: 113
[ Wed Jun 28 19:37:15 2023 ] 	Training loss: 6.7120.  Training acc: 94.14%.
[ Wed Jun 28 19:37:15 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:37:15 2023 ] Training epoch: 114
[ Wed Jun 28 19:37:22 2023 ] 	Training loss: 6.5775.  Training acc: 92.71%.
[ Wed Jun 28 19:37:22 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 19:37:22 2023 ] Training epoch: 115
[ Wed Jun 28 19:37:29 2023 ] 	Training loss: 6.7302.  Training acc: 93.23%.
[ Wed Jun 28 19:37:29 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:37:29 2023 ] Training epoch: 116
[ Wed Jun 28 19:37:36 2023 ] 	Training loss: 6.7578.  Training acc: 95.70%.
[ Wed Jun 28 19:37:36 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 19:37:36 2023 ] Training epoch: 117
[ Wed Jun 28 19:37:43 2023 ] 	Training loss: 6.7290.  Training acc: 90.49%.
[ Wed Jun 28 19:37:43 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:37:43 2023 ] Training epoch: 118
[ Wed Jun 28 19:37:50 2023 ] 	Training loss: 6.5835.  Training acc: 93.88%.
[ Wed Jun 28 19:37:50 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:37:50 2023 ] Training epoch: 119
[ Wed Jun 28 19:37:57 2023 ] 	Training loss: 6.7134.  Training acc: 93.88%.
[ Wed Jun 28 19:37:57 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:37:57 2023 ] Training epoch: 120
[ Wed Jun 28 19:38:04 2023 ] 	Training loss: 6.5411.  Training acc: 93.23%.
[ Wed Jun 28 19:38:04 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:38:04 2023 ] Training epoch: 121
[ Wed Jun 28 19:38:11 2023 ] 	Training loss: 6.6661.  Training acc: 93.88%.
[ Wed Jun 28 19:38:11 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:38:11 2023 ] Training epoch: 122
[ Wed Jun 28 19:38:18 2023 ] 	Training loss: 6.6740.  Training acc: 94.92%.
[ Wed Jun 28 19:38:18 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:38:18 2023 ] Training epoch: 123
[ Wed Jun 28 19:38:25 2023 ] 	Training loss: 6.6861.  Training acc: 93.49%.
[ Wed Jun 28 19:38:25 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:38:25 2023 ] Training epoch: 124
[ Wed Jun 28 19:38:32 2023 ] 	Training loss: 6.6530.  Training acc: 91.80%.
[ Wed Jun 28 19:38:32 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:38:32 2023 ] Training epoch: 125
[ Wed Jun 28 19:38:39 2023 ] 	Training loss: 6.6259.  Training acc: 93.23%.
[ Wed Jun 28 19:38:39 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:38:39 2023 ] Training epoch: 126
[ Wed Jun 28 19:38:46 2023 ] 	Training loss: 6.7865.  Training acc: 92.97%.
[ Wed Jun 28 19:38:46 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:38:46 2023 ] Training epoch: 127
[ Wed Jun 28 19:38:53 2023 ] 	Training loss: 6.5961.  Training acc: 92.71%.
[ Wed Jun 28 19:38:53 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:38:53 2023 ] Training epoch: 128
[ Wed Jun 28 19:38:59 2023 ] 	Training loss: 6.5722.  Training acc: 94.27%.
[ Wed Jun 28 19:38:59 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:39:00 2023 ] Training epoch: 129
[ Wed Jun 28 19:39:06 2023 ] 	Training loss: 6.5812.  Training acc: 95.70%.
[ Wed Jun 28 19:39:06 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:39:07 2023 ] Training epoch: 130
[ Wed Jun 28 19:39:13 2023 ] 	Training loss: 6.7862.  Training acc: 92.84%.
[ Wed Jun 28 19:39:13 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:39:14 2023 ] Training epoch: 131
[ Wed Jun 28 19:39:20 2023 ] 	Training loss: 6.7171.  Training acc: 93.88%.
[ Wed Jun 28 19:39:20 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:39:21 2023 ] Training epoch: 132
[ Wed Jun 28 19:39:27 2023 ] 	Training loss: 6.6240.  Training acc: 94.01%.
[ Wed Jun 28 19:39:27 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:39:28 2023 ] Training epoch: 133
[ Wed Jun 28 19:39:34 2023 ] 	Training loss: 6.6611.  Training acc: 95.05%.
[ Wed Jun 28 19:39:34 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:39:35 2023 ] Training epoch: 134
[ Wed Jun 28 19:39:41 2023 ] 	Training loss: 6.7368.  Training acc: 94.53%.
[ Wed Jun 28 19:39:41 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:39:41 2023 ] Training epoch: 135
[ Wed Jun 28 19:39:48 2023 ] 	Training loss: 6.7816.  Training acc: 93.23%.
[ Wed Jun 28 19:39:48 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:39:48 2023 ] Training epoch: 136
[ Wed Jun 28 19:39:55 2023 ] 	Training loss: 6.7629.  Training acc: 93.75%.
[ Wed Jun 28 19:39:55 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:39:55 2023 ] Training epoch: 137
[ Wed Jun 28 19:40:01 2023 ] 	Training loss: 6.7140.  Training acc: 95.05%.
[ Wed Jun 28 19:40:01 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:40:02 2023 ] Training epoch: 138
[ Wed Jun 28 19:40:08 2023 ] 	Training loss: 6.7380.  Training acc: 95.44%.
[ Wed Jun 28 19:40:08 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:40:09 2023 ] Training epoch: 139
[ Wed Jun 28 19:40:15 2023 ] 	Training loss: 6.6596.  Training acc: 95.05%.
[ Wed Jun 28 19:40:15 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:40:16 2023 ] Training epoch: 140
[ Wed Jun 28 19:40:22 2023 ] 	Training loss: 6.7620.  Training acc: 96.22%.
[ Wed Jun 28 19:40:22 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:40:23 2023 ] Training epoch: 141
[ Wed Jun 28 19:40:29 2023 ] 	Training loss: 6.5498.  Training acc: 94.01%.
[ Wed Jun 28 19:40:29 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:40:30 2023 ] Training epoch: 142
[ Wed Jun 28 19:40:36 2023 ] 	Training loss: 6.6433.  Training acc: 93.49%.
[ Wed Jun 28 19:40:36 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:40:37 2023 ] Training epoch: 143
[ Wed Jun 28 19:40:43 2023 ] 	Training loss: 6.5749.  Training acc: 94.92%.
[ Wed Jun 28 19:40:43 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:40:44 2023 ] Training epoch: 144
[ Wed Jun 28 19:40:50 2023 ] 	Training loss: 6.7335.  Training acc: 93.88%.
[ Wed Jun 28 19:40:50 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 19:40:51 2023 ] Training epoch: 145
[ Wed Jun 28 19:40:57 2023 ] 	Training loss: 6.7008.  Training acc: 93.62%.
[ Wed Jun 28 19:40:57 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:40:58 2023 ] Training epoch: 146
[ Wed Jun 28 19:41:04 2023 ] 	Training loss: 6.7549.  Training acc: 93.10%.
[ Wed Jun 28 19:41:04 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:41:04 2023 ] Training epoch: 147
[ Wed Jun 28 19:41:11 2023 ] 	Training loss: 6.5805.  Training acc: 93.62%.
[ Wed Jun 28 19:41:11 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:41:11 2023 ] Training epoch: 148
[ Wed Jun 28 19:41:18 2023 ] 	Training loss: 6.7215.  Training acc: 92.58%.
[ Wed Jun 28 19:41:18 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:41:18 2023 ] Training epoch: 149
[ Wed Jun 28 19:41:25 2023 ] 	Training loss: 6.6244.  Training acc: 92.97%.
[ Wed Jun 28 19:41:25 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:41:25 2023 ] Training epoch: 150
[ Wed Jun 28 19:41:32 2023 ] 	Training loss: 6.7620.  Training acc: 94.14%.
[ Wed Jun 28 19:41:32 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:42:15 2023 ] using warm up, epoch: 5
[ Wed Jun 28 19:42:15 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'EC3D', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'in_channels': 3, 'num_head': 3, 'gain': 1, 'latent_dim': 256, 'out_channels': 3, 't_size': 42, 'base_lr': 0.1, 'step': [10, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_EC3D'}

[ Wed Jun 28 19:42:15 2023 ] # Parameters Predictor: 1538958
[ Wed Jun 28 19:42:15 2023 ] Start training Predictor
[ Wed Jun 28 19:42:15 2023 ] Training epoch: 1
[ Wed Jun 28 19:42:21 2023 ] 	Training loss: 104.3196.  Training acc: 34.47%.
[ Wed Jun 28 19:42:21 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 19:42:21 2023 ] Eval epoch: 1
[ Wed Jun 28 19:42:22 2023 ] 	Mean test loss of 625 batches: 2031.472852.
[ Wed Jun 28 19:42:22 2023 ] 	Top1: 38.60%
[ Wed Jun 28 19:42:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:42:22 2023 ] Training epoch: 2
[ Wed Jun 28 19:42:24 2023 ] 	Training loss: 8.9965.  Training acc: 38.60%.
[ Wed Jun 28 19:42:24 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 19:42:24 2023 ] Eval epoch: 2
[ Wed Jun 28 19:42:25 2023 ] 	Mean test loss of 625 batches: 20.602042.
[ Wed Jun 28 19:42:25 2023 ] 	Top1: 70.18%
[ Wed Jun 28 19:42:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:42:25 2023 ] Training epoch: 3
[ Wed Jun 28 19:42:28 2023 ] 	Training loss: 5.5883.  Training acc: 48.62%.
[ Wed Jun 28 19:42:28 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 19:42:28 2023 ] Eval epoch: 3
[ Wed Jun 28 19:42:28 2023 ] 	Mean test loss of 625 batches: 1.999855.
[ Wed Jun 28 19:42:28 2023 ] 	Top1: 70.18%
[ Wed Jun 28 19:42:28 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:42:28 2023 ] Training epoch: 4
[ Wed Jun 28 19:42:31 2023 ] 	Training loss: 4.2178.  Training acc: 59.19%.
[ Wed Jun 28 19:42:31 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 19:42:31 2023 ] Eval epoch: 4
[ Wed Jun 28 19:42:32 2023 ] 	Mean test loss of 625 batches: 5.821013.
[ Wed Jun 28 19:42:32 2023 ] 	Top1: 38.60%
[ Wed Jun 28 19:42:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:42:32 2023 ] Training epoch: 5
[ Wed Jun 28 19:42:35 2023 ] 	Training loss: 3.4677.  Training acc: 59.93%.
[ Wed Jun 28 19:42:35 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 19:42:35 2023 ] Eval epoch: 5
[ Wed Jun 28 19:42:35 2023 ] 	Mean test loss of 625 batches: 1.568023.
[ Wed Jun 28 19:42:35 2023 ] 	Top1: 68.42%
[ Wed Jun 28 19:42:35 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:42:35 2023 ] Training epoch: 6
[ Wed Jun 28 19:42:38 2023 ] 	Training loss: 6.1097.  Training acc: 58.00%.
[ Wed Jun 28 19:42:38 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:42:38 2023 ] Eval epoch: 6
[ Wed Jun 28 19:42:39 2023 ] 	Mean test loss of 625 batches: 10.066175.
[ Wed Jun 28 19:42:39 2023 ] 	Top1: 54.39%
[ Wed Jun 28 19:42:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:42:39 2023 ] Training epoch: 7
[ Wed Jun 28 19:42:42 2023 ] 	Training loss: 3.5019.  Training acc: 56.89%.
[ Wed Jun 28 19:42:42 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 19:42:42 2023 ] Eval epoch: 7
[ Wed Jun 28 19:42:42 2023 ] 	Mean test loss of 625 batches: 2.203347.
[ Wed Jun 28 19:42:42 2023 ] 	Top1: 68.42%
[ Wed Jun 28 19:42:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:42:42 2023 ] Training epoch: 8
[ Wed Jun 28 19:42:45 2023 ] 	Training loss: 1.7048.  Training acc: 61.03%.
[ Wed Jun 28 19:42:45 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:42:45 2023 ] Eval epoch: 8
[ Wed Jun 28 19:42:45 2023 ] 	Mean test loss of 625 batches: 2.223390.
[ Wed Jun 28 19:42:45 2023 ] 	Top1: 42.11%
[ Wed Jun 28 19:42:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:42:45 2023 ] Training epoch: 9
[ Wed Jun 28 19:42:48 2023 ] 	Training loss: 1.2658.  Training acc: 67.37%.
[ Wed Jun 28 19:42:48 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:42:48 2023 ] Eval epoch: 9
[ Wed Jun 28 19:42:49 2023 ] 	Mean test loss of 625 batches: 0.672122.
[ Wed Jun 28 19:42:49 2023 ] 	Top1: 77.19%
[ Wed Jun 28 19:42:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:42:49 2023 ] Training epoch: 10
[ Wed Jun 28 19:42:52 2023 ] 	Training loss: 0.9158.  Training acc: 74.72%.
[ Wed Jun 28 19:42:52 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:42:52 2023 ] Eval epoch: 10
[ Wed Jun 28 19:42:52 2023 ] 	Mean test loss of 625 batches: 0.589883.
[ Wed Jun 28 19:42:52 2023 ] 	Top1: 78.95%
[ Wed Jun 28 19:42:52 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:42:53 2023 ] Training epoch: 11
[ Wed Jun 28 19:42:55 2023 ] 	Training loss: 0.5622.  Training acc: 88.79%.
[ Wed Jun 28 19:42:55 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:42:55 2023 ] Eval epoch: 11
[ Wed Jun 28 19:42:56 2023 ] 	Mean test loss of 625 batches: 0.419064.
[ Wed Jun 28 19:42:56 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:42:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:42:56 2023 ] Training epoch: 12
[ Wed Jun 28 19:42:59 2023 ] 	Training loss: 0.5200.  Training acc: 89.52%.
[ Wed Jun 28 19:42:59 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:42:59 2023 ] Eval epoch: 12
[ Wed Jun 28 19:43:00 2023 ] 	Mean test loss of 625 batches: 0.398661.
[ Wed Jun 28 19:43:00 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:43:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:43:00 2023 ] Training epoch: 13
[ Wed Jun 28 19:43:02 2023 ] 	Training loss: 0.4606.  Training acc: 93.29%.
[ Wed Jun 28 19:43:02 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:43:02 2023 ] Eval epoch: 13
[ Wed Jun 28 19:43:03 2023 ] 	Mean test loss of 625 batches: 0.379244.
[ Wed Jun 28 19:43:03 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:43:03 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:43:03 2023 ] Training epoch: 14
[ Wed Jun 28 19:43:06 2023 ] 	Training loss: 0.4265.  Training acc: 95.68%.
[ Wed Jun 28 19:43:06 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 19:43:06 2023 ] Eval epoch: 14
[ Wed Jun 28 19:43:06 2023 ] 	Mean test loss of 625 batches: 0.354791.
[ Wed Jun 28 19:43:06 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:43:06 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:43:06 2023 ] Training epoch: 15
[ Wed Jun 28 19:43:09 2023 ] 	Training loss: 0.4256.  Training acc: 95.13%.
[ Wed Jun 28 19:43:09 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 19:43:09 2023 ] Eval epoch: 15
[ Wed Jun 28 19:43:10 2023 ] 	Mean test loss of 625 batches: 0.339037.
[ Wed Jun 28 19:43:10 2023 ] 	Top1: 98.25%
[ Wed Jun 28 19:43:10 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:43:10 2023 ] Training epoch: 16
[ Wed Jun 28 19:43:13 2023 ] 	Training loss: 0.4167.  Training acc: 95.96%.
[ Wed Jun 28 19:43:13 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 19:43:13 2023 ] Eval epoch: 16
[ Wed Jun 28 19:43:13 2023 ] 	Mean test loss of 625 batches: 0.352082.
[ Wed Jun 28 19:43:13 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:43:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:43:13 2023 ] Training epoch: 17
[ Wed Jun 28 19:43:16 2023 ] 	Training loss: 0.3959.  Training acc: 97.43%.
[ Wed Jun 28 19:43:16 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 19:43:16 2023 ] Eval epoch: 17
[ Wed Jun 28 19:43:17 2023 ] 	Mean test loss of 625 batches: 0.329492.
[ Wed Jun 28 19:43:17 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:43:17 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:43:17 2023 ] Training epoch: 18
[ Wed Jun 28 19:43:20 2023 ] 	Training loss: 0.4090.  Training acc: 96.51%.
[ Wed Jun 28 19:43:20 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:43:20 2023 ] Eval epoch: 18
[ Wed Jun 28 19:43:20 2023 ] 	Mean test loss of 625 batches: 0.320961.
[ Wed Jun 28 19:43:20 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:43:20 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:43:20 2023 ] Training epoch: 19
[ Wed Jun 28 19:43:23 2023 ] 	Training loss: 0.4104.  Training acc: 96.69%.
[ Wed Jun 28 19:43:23 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 19:43:23 2023 ] Eval epoch: 19
[ Wed Jun 28 19:43:24 2023 ] 	Mean test loss of 625 batches: 0.342222.
[ Wed Jun 28 19:43:24 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:43:24 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:43:24 2023 ] Training epoch: 20
[ Wed Jun 28 19:43:26 2023 ] 	Training loss: 0.3787.  Training acc: 98.16%.
[ Wed Jun 28 19:43:26 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 19:43:26 2023 ] Eval epoch: 20
[ Wed Jun 28 19:43:27 2023 ] 	Mean test loss of 625 batches: 0.316813.
[ Wed Jun 28 19:43:27 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:43:27 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:43:27 2023 ] Training epoch: 21
[ Wed Jun 28 19:43:30 2023 ] 	Training loss: 0.3855.  Training acc: 98.16%.
[ Wed Jun 28 19:43:30 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 19:43:30 2023 ] Eval epoch: 21
[ Wed Jun 28 19:43:31 2023 ] 	Mean test loss of 625 batches: 0.316660.
[ Wed Jun 28 19:43:31 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:43:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:43:31 2023 ] Training epoch: 22
[ Wed Jun 28 19:43:33 2023 ] 	Training loss: 0.3759.  Training acc: 97.98%.
[ Wed Jun 28 19:43:33 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Wed Jun 28 19:43:33 2023 ] Eval epoch: 22
[ Wed Jun 28 19:43:34 2023 ] 	Mean test loss of 625 batches: 0.319404.
[ Wed Jun 28 19:43:34 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:43:34 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:43:34 2023 ] Training epoch: 23
[ Wed Jun 28 19:43:37 2023 ] 	Training loss: 0.3811.  Training acc: 98.44%.
[ Wed Jun 28 19:43:37 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Wed Jun 28 19:43:37 2023 ] Eval epoch: 23
[ Wed Jun 28 19:43:38 2023 ] 	Mean test loss of 625 batches: 0.320156.
[ Wed Jun 28 19:43:38 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:43:38 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:43:38 2023 ] Training epoch: 24
[ Wed Jun 28 19:43:41 2023 ] 	Training loss: 0.3699.  Training acc: 98.16%.
[ Wed Jun 28 19:43:41 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:43:41 2023 ] Eval epoch: 24
[ Wed Jun 28 19:43:42 2023 ] 	Mean test loss of 625 batches: 0.315857.
[ Wed Jun 28 19:43:42 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:43:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:43:42 2023 ] Training epoch: 25
[ Wed Jun 28 19:43:44 2023 ] 	Training loss: 0.3726.  Training acc: 98.44%.
[ Wed Jun 28 19:43:44 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Wed Jun 28 19:43:44 2023 ] Eval epoch: 25
[ Wed Jun 28 19:43:45 2023 ] 	Mean test loss of 625 batches: 0.316371.
[ Wed Jun 28 19:43:45 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:43:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:43:45 2023 ] Training epoch: 26
[ Wed Jun 28 19:43:48 2023 ] 	Training loss: 0.3714.  Training acc: 98.53%.
[ Wed Jun 28 19:43:48 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:43:48 2023 ] Eval epoch: 26
[ Wed Jun 28 19:43:48 2023 ] 	Mean test loss of 625 batches: 0.318089.
[ Wed Jun 28 19:43:48 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:43:48 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:43:48 2023 ] Training epoch: 27
[ Wed Jun 28 19:43:51 2023 ] 	Training loss: 0.3694.  Training acc: 98.90%.
[ Wed Jun 28 19:43:51 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 19:43:51 2023 ] Eval epoch: 27
[ Wed Jun 28 19:43:52 2023 ] 	Mean test loss of 625 batches: 0.316465.
[ Wed Jun 28 19:43:52 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:43:52 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:43:52 2023 ] Training epoch: 28
[ Wed Jun 28 19:43:55 2023 ] 	Training loss: 0.3637.  Training acc: 98.81%.
[ Wed Jun 28 19:43:55 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Jun 28 19:43:55 2023 ] Eval epoch: 28
[ Wed Jun 28 19:43:55 2023 ] 	Mean test loss of 625 batches: 0.315817.
[ Wed Jun 28 19:43:55 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:43:55 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:43:55 2023 ] Training epoch: 29
[ Wed Jun 28 19:43:58 2023 ] 	Training loss: 0.3788.  Training acc: 97.98%.
[ Wed Jun 28 19:43:58 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Wed Jun 28 19:43:58 2023 ] Eval epoch: 29
[ Wed Jun 28 19:43:59 2023 ] 	Mean test loss of 625 batches: 0.316885.
[ Wed Jun 28 19:43:59 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:43:59 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:43:59 2023 ] Training epoch: 30
[ Wed Jun 28 19:44:02 2023 ] 	Training loss: 0.3724.  Training acc: 98.53%.
[ Wed Jun 28 19:44:02 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Jun 28 19:44:02 2023 ] Eval epoch: 30
[ Wed Jun 28 19:44:02 2023 ] 	Mean test loss of 625 batches: 0.320313.
[ Wed Jun 28 19:44:02 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:44:02 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:44:03 2023 ] Best accuracy: 1.0
[ Wed Jun 28 19:44:03 2023 ] Epoch number: 16
[ Wed Jun 28 19:44:03 2023 ] Model name: results/ec3d_EC3D
[ Wed Jun 28 19:44:03 2023 ] Weight decay: 0.0005
[ Wed Jun 28 19:44:03 2023 ] Base LR: 0.1
[ Wed Jun 28 19:44:03 2023 ] Batch Size: 64
[ Wed Jun 28 19:44:03 2023 ] Test Batch Size: 64
[ Wed Jun 28 19:44:03 2023 ] seed: 1
[ Wed Jun 28 19:44:03 2023 ] Start training Corrector
[ Wed Jun 28 19:44:03 2023 ] # Parameters Corrector: 2407569
[ Wed Jun 28 19:44:04 2023 ] Training epoch: 1
[ Wed Jun 28 19:44:12 2023 ] 	Training loss: 15.1477.  Training acc: 54.95%.
[ Wed Jun 28 19:44:12 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Wed Jun 28 19:44:12 2023 ] Eval epoch: 1
[ Wed Jun 28 19:44:15 2023 ] 	Mean test loss of 625 batches: 3.968151.
[ Wed Jun 28 19:44:15 2023 ] 	Mean test label-loss of 625 batches: 33.028921.
[ Wed Jun 28 19:44:15 2023 ] 	Top1: 31.58%
[ Wed Jun 28 19:44:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:44:15 2023 ] Training epoch: 2
[ Wed Jun 28 19:44:22 2023 ] 	Training loss: 10.5763.  Training acc: 66.67%.
[ Wed Jun 28 19:44:22 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:44:22 2023 ] Eval epoch: 2
[ Wed Jun 28 19:44:23 2023 ] 	Mean test loss of 625 batches: 1.269614.
[ Wed Jun 28 19:44:23 2023 ] 	Mean test label-loss of 625 batches: 16.103833.
[ Wed Jun 28 19:44:23 2023 ] 	Top1: 60.53%
[ Wed Jun 28 19:44:23 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:44:24 2023 ] Training epoch: 3
[ Wed Jun 28 19:44:30 2023 ] 	Training loss: 9.1849.  Training acc: 52.47%.
[ Wed Jun 28 19:44:30 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:44:30 2023 ] Eval epoch: 3
[ Wed Jun 28 19:44:32 2023 ] 	Mean test loss of 625 batches: 1.333810.
[ Wed Jun 28 19:44:32 2023 ] 	Mean test label-loss of 625 batches: 12.765079.
[ Wed Jun 28 19:44:32 2023 ] 	Top1: 23.68%
[ Wed Jun 28 19:44:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:44:33 2023 ] Training epoch: 4
[ Wed Jun 28 19:44:39 2023 ] 	Training loss: 8.6615.  Training acc: 48.31%.
[ Wed Jun 28 19:44:39 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:44:39 2023 ] Eval epoch: 4
[ Wed Jun 28 19:44:41 2023 ] 	Mean test loss of 625 batches: 1.378035.
[ Wed Jun 28 19:44:41 2023 ] 	Mean test label-loss of 625 batches: 10.338960.
[ Wed Jun 28 19:44:41 2023 ] 	Top1: 47.37%
[ Wed Jun 28 19:44:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:44:42 2023 ] Training epoch: 5
[ Wed Jun 28 19:44:48 2023 ] 	Training loss: 8.8227.  Training acc: 46.61%.
[ Wed Jun 28 19:44:48 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:44:48 2023 ] Eval epoch: 5
[ Wed Jun 28 19:44:50 2023 ] 	Mean test loss of 625 batches: 1.099593.
[ Wed Jun 28 19:44:50 2023 ] 	Mean test label-loss of 625 batches: 7.450074.
[ Wed Jun 28 19:44:50 2023 ] 	Top1: 52.63%
[ Wed Jun 28 19:44:50 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:44:51 2023 ] Training epoch: 6
[ Wed Jun 28 19:44:57 2023 ] 	Training loss: 7.8097.  Training acc: 43.49%.
[ Wed Jun 28 19:44:57 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:44:57 2023 ] Eval epoch: 6
[ Wed Jun 28 19:44:59 2023 ] 	Mean test loss of 625 batches: 1.070213.
[ Wed Jun 28 19:44:59 2023 ] 	Mean test label-loss of 625 batches: 8.172554.
[ Wed Jun 28 19:44:59 2023 ] 	Top1: 57.89%
[ Wed Jun 28 19:44:59 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:44:59 2023 ] Training epoch: 7
[ Wed Jun 28 19:45:06 2023 ] 	Training loss: 7.5492.  Training acc: 39.58%.
[ Wed Jun 28 19:45:06 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:45:06 2023 ] Eval epoch: 7
[ Wed Jun 28 19:45:08 2023 ] 	Mean test loss of 625 batches: 1.099961.
[ Wed Jun 28 19:45:08 2023 ] 	Mean test label-loss of 625 batches: 6.404876.
[ Wed Jun 28 19:45:08 2023 ] 	Top1: 50.00%
[ Wed Jun 28 19:45:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:45:08 2023 ] Training epoch: 8
[ Wed Jun 28 19:45:15 2023 ] 	Training loss: 7.1101.  Training acc: 61.85%.
[ Wed Jun 28 19:45:15 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 19:45:15 2023 ] Eval epoch: 8
[ Wed Jun 28 19:45:17 2023 ] 	Mean test loss of 625 batches: 0.708579.
[ Wed Jun 28 19:45:17 2023 ] 	Mean test label-loss of 625 batches: 6.243614.
[ Wed Jun 28 19:45:17 2023 ] 	Top1: 81.58%
[ Wed Jun 28 19:45:17 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:45:17 2023 ] Training epoch: 9
[ Wed Jun 28 19:45:24 2023 ] 	Training loss: 7.0105.  Training acc: 66.54%.
[ Wed Jun 28 19:45:24 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:45:24 2023 ] Eval epoch: 9
[ Wed Jun 28 19:45:25 2023 ] 	Mean test loss of 625 batches: 1.064224.
[ Wed Jun 28 19:45:25 2023 ] 	Mean test label-loss of 625 batches: 6.716727.
[ Wed Jun 28 19:45:25 2023 ] 	Top1: 50.00%
[ Wed Jun 28 19:45:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:45:26 2023 ] Training epoch: 10
[ Wed Jun 28 19:45:32 2023 ] 	Training loss: 6.9525.  Training acc: 75.52%.
[ Wed Jun 28 19:45:32 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:45:32 2023 ] Eval epoch: 10
[ Wed Jun 28 19:45:34 2023 ] 	Mean test loss of 625 batches: 1.452279.
[ Wed Jun 28 19:45:34 2023 ] 	Mean test label-loss of 625 batches: 6.087106.
[ Wed Jun 28 19:45:34 2023 ] 	Top1: 39.47%
[ Wed Jun 28 19:45:34 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:45:35 2023 ] Training epoch: 11
[ Wed Jun 28 19:45:41 2023 ] 	Training loss: 6.6620.  Training acc: 90.23%.
[ Wed Jun 28 19:45:41 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:45:41 2023 ] Eval epoch: 11
[ Wed Jun 28 19:45:43 2023 ] 	Mean test loss of 625 batches: 1.475617.
[ Wed Jun 28 19:45:43 2023 ] 	Mean test label-loss of 625 batches: 5.641722.
[ Wed Jun 28 19:45:43 2023 ] 	Top1: 50.00%
[ Wed Jun 28 19:45:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:45:44 2023 ] Training epoch: 12
[ Wed Jun 28 19:45:50 2023 ] 	Training loss: 6.5212.  Training acc: 89.45%.
[ Wed Jun 28 19:45:50 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:45:50 2023 ] Eval epoch: 12
[ Wed Jun 28 19:45:52 2023 ] 	Mean test loss of 625 batches: 0.763081.
[ Wed Jun 28 19:45:52 2023 ] 	Mean test label-loss of 625 batches: 5.754110.
[ Wed Jun 28 19:45:52 2023 ] 	Top1: 60.53%
[ Wed Jun 28 19:45:52 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:45:53 2023 ] Training epoch: 13
[ Wed Jun 28 19:45:59 2023 ] 	Training loss: 6.5331.  Training acc: 93.36%.
[ Wed Jun 28 19:45:59 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:45:59 2023 ] Eval epoch: 13
[ Wed Jun 28 19:46:01 2023 ] 	Mean test loss of 625 batches: 0.454654.
[ Wed Jun 28 19:46:01 2023 ] 	Mean test label-loss of 625 batches: 5.654638.
[ Wed Jun 28 19:46:01 2023 ] 	Top1: 78.95%
[ Wed Jun 28 19:46:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:46:01 2023 ] Training epoch: 14
[ Wed Jun 28 19:46:08 2023 ] 	Training loss: 6.3413.  Training acc: 92.58%.
[ Wed Jun 28 19:46:08 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:46:08 2023 ] Eval epoch: 14
[ Wed Jun 28 19:46:10 2023 ] 	Mean test loss of 625 batches: 0.362909.
[ Wed Jun 28 19:46:10 2023 ] 	Mean test label-loss of 625 batches: 5.344951.
[ Wed Jun 28 19:46:10 2023 ] 	Top1: 86.84%
[ Wed Jun 28 19:46:10 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:46:10 2023 ] Training epoch: 15
[ Wed Jun 28 19:46:16 2023 ] 	Training loss: 6.3952.  Training acc: 93.10%.
[ Wed Jun 28 19:46:16 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 19:46:16 2023 ] Eval epoch: 15
[ Wed Jun 28 19:46:18 2023 ] 	Mean test loss of 625 batches: 0.329311.
[ Wed Jun 28 19:46:18 2023 ] 	Mean test label-loss of 625 batches: 5.352686.
[ Wed Jun 28 19:46:18 2023 ] 	Top1: 89.47%
[ Wed Jun 28 19:46:18 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:46:19 2023 ] Training epoch: 16
[ Wed Jun 28 19:46:25 2023 ] 	Training loss: 6.3313.  Training acc: 91.41%.
[ Wed Jun 28 19:46:25 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:46:25 2023 ] Eval epoch: 16
[ Wed Jun 28 19:46:27 2023 ] 	Mean test loss of 625 batches: 0.130710.
[ Wed Jun 28 19:46:27 2023 ] 	Mean test label-loss of 625 batches: 5.341345.
[ Wed Jun 28 19:46:27 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:46:27 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:46:28 2023 ] Training epoch: 17
[ Wed Jun 28 19:46:34 2023 ] 	Training loss: 6.2910.  Training acc: 93.62%.
[ Wed Jun 28 19:46:34 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:46:34 2023 ] Eval epoch: 17
[ Wed Jun 28 19:46:36 2023 ] 	Mean test loss of 625 batches: 0.167319.
[ Wed Jun 28 19:46:36 2023 ] 	Mean test label-loss of 625 batches: 5.399582.
[ Wed Jun 28 19:46:36 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:46:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:46:37 2023 ] Training epoch: 18
[ Wed Jun 28 19:46:43 2023 ] 	Training loss: 6.1461.  Training acc: 93.49%.
[ Wed Jun 28 19:46:43 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 19:46:43 2023 ] Eval epoch: 18
[ Wed Jun 28 19:46:45 2023 ] 	Mean test loss of 625 batches: 0.459367.
[ Wed Jun 28 19:46:45 2023 ] 	Mean test label-loss of 625 batches: 5.175012.
[ Wed Jun 28 19:46:45 2023 ] 	Top1: 78.95%
[ Wed Jun 28 19:46:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:46:45 2023 ] Training epoch: 19
[ Wed Jun 28 19:46:52 2023 ] 	Training loss: 6.3880.  Training acc: 92.06%.
[ Wed Jun 28 19:46:52 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:46:52 2023 ] Eval epoch: 19
[ Wed Jun 28 19:46:54 2023 ] 	Mean test loss of 625 batches: 0.254720.
[ Wed Jun 28 19:46:54 2023 ] 	Mean test label-loss of 625 batches: 5.492865.
[ Wed Jun 28 19:46:54 2023 ] 	Top1: 86.84%
[ Wed Jun 28 19:46:54 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:46:54 2023 ] Training epoch: 20
[ Wed Jun 28 19:47:01 2023 ] 	Training loss: 6.2801.  Training acc: 91.80%.
[ Wed Jun 28 19:47:01 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:47:01 2023 ] Eval epoch: 20
[ Wed Jun 28 19:47:02 2023 ] 	Mean test loss of 625 batches: 0.450220.
[ Wed Jun 28 19:47:02 2023 ] 	Mean test label-loss of 625 batches: 5.285806.
[ Wed Jun 28 19:47:02 2023 ] 	Top1: 76.32%
[ Wed Jun 28 19:47:02 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:47:03 2023 ] Training epoch: 21
[ Wed Jun 28 19:47:10 2023 ] 	Training loss: 6.2630.  Training acc: 93.36%.
[ Wed Jun 28 19:47:10 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:47:10 2023 ] Eval epoch: 21
[ Wed Jun 28 19:47:11 2023 ] 	Mean test loss of 625 batches: 0.156889.
[ Wed Jun 28 19:47:11 2023 ] 	Mean test label-loss of 625 batches: 5.261403.
[ Wed Jun 28 19:47:11 2023 ] 	Top1: 97.37%
[ Wed Jun 28 19:47:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:47:12 2023 ] Training epoch: 22
[ Wed Jun 28 19:47:18 2023 ] 	Training loss: 6.1429.  Training acc: 93.49%.
[ Wed Jun 28 19:47:18 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:47:18 2023 ] Eval epoch: 22
[ Wed Jun 28 19:47:20 2023 ] 	Mean test loss of 625 batches: 0.090128.
[ Wed Jun 28 19:47:20 2023 ] 	Mean test label-loss of 625 batches: 5.321619.
[ Wed Jun 28 19:47:20 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:47:20 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:47:21 2023 ] Training epoch: 23
[ Wed Jun 28 19:47:27 2023 ] 	Training loss: 6.3564.  Training acc: 95.05%.
[ Wed Jun 28 19:47:27 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:47:27 2023 ] Eval epoch: 23
[ Wed Jun 28 19:47:29 2023 ] 	Mean test loss of 625 batches: 0.092917.
[ Wed Jun 28 19:47:29 2023 ] 	Mean test label-loss of 625 batches: 5.335233.
[ Wed Jun 28 19:47:29 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:47:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:47:30 2023 ] Training epoch: 24
[ Wed Jun 28 19:47:36 2023 ] 	Training loss: 6.3632.  Training acc: 94.14%.
[ Wed Jun 28 19:47:36 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:47:36 2023 ] Eval epoch: 24
[ Wed Jun 28 19:47:38 2023 ] 	Mean test loss of 625 batches: 0.105108.
[ Wed Jun 28 19:47:38 2023 ] 	Mean test label-loss of 625 batches: 5.406182.
[ Wed Jun 28 19:47:38 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:47:38 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:47:38 2023 ] Training epoch: 25
[ Wed Jun 28 19:47:45 2023 ] 	Training loss: 6.2211.  Training acc: 95.31%.
[ Wed Jun 28 19:47:45 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:47:45 2023 ] Eval epoch: 25
[ Wed Jun 28 19:47:47 2023 ] 	Mean test loss of 625 batches: 0.099175.
[ Wed Jun 28 19:47:47 2023 ] 	Mean test label-loss of 625 batches: 5.409765.
[ Wed Jun 28 19:47:47 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:47:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:47:47 2023 ] Training epoch: 26
[ Wed Jun 28 19:47:54 2023 ] 	Training loss: 6.2237.  Training acc: 94.40%.
[ Wed Jun 28 19:47:54 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:47:54 2023 ] Eval epoch: 26
[ Wed Jun 28 19:47:55 2023 ] 	Mean test loss of 625 batches: 0.102334.
[ Wed Jun 28 19:47:55 2023 ] 	Mean test label-loss of 625 batches: 5.429605.
[ Wed Jun 28 19:47:55 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:47:55 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:47:56 2023 ] Training epoch: 27
[ Wed Jun 28 19:48:02 2023 ] 	Training loss: 6.2234.  Training acc: 94.01%.
[ Wed Jun 28 19:48:02 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:48:02 2023 ] Eval epoch: 27
[ Wed Jun 28 19:48:04 2023 ] 	Mean test loss of 625 batches: 0.104791.
[ Wed Jun 28 19:48:04 2023 ] 	Mean test label-loss of 625 batches: 5.419722.
[ Wed Jun 28 19:48:04 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:48:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:48:05 2023 ] Training epoch: 28
[ Wed Jun 28 19:48:11 2023 ] 	Training loss: 6.3646.  Training acc: 93.75%.
[ Wed Jun 28 19:48:11 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 19:48:11 2023 ] Eval epoch: 28
[ Wed Jun 28 19:48:13 2023 ] 	Mean test loss of 625 batches: 0.100992.
[ Wed Jun 28 19:48:13 2023 ] 	Mean test label-loss of 625 batches: 5.402046.
[ Wed Jun 28 19:48:13 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:48:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:48:14 2023 ] Training epoch: 29
[ Wed Jun 28 19:48:20 2023 ] 	Training loss: 6.1615.  Training acc: 94.27%.
[ Wed Jun 28 19:48:20 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:48:20 2023 ] Eval epoch: 29
[ Wed Jun 28 19:48:22 2023 ] 	Mean test loss of 625 batches: 0.087456.
[ Wed Jun 28 19:48:22 2023 ] 	Mean test label-loss of 625 batches: 5.397269.
[ Wed Jun 28 19:48:22 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:48:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:48:23 2023 ] Training epoch: 30
[ Wed Jun 28 19:48:29 2023 ] 	Training loss: 6.2654.  Training acc: 94.27%.
[ Wed Jun 28 19:48:29 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:48:29 2023 ] Eval epoch: 30
[ Wed Jun 28 19:48:31 2023 ] 	Mean test loss of 625 batches: 0.069545.
[ Wed Jun 28 19:48:31 2023 ] 	Mean test label-loss of 625 batches: 5.438573.
[ Wed Jun 28 19:48:31 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:48:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:48:32 2023 ] Training epoch: 31
[ Wed Jun 28 19:48:38 2023 ] 	Training loss: 6.1099.  Training acc: 95.18%.
[ Wed Jun 28 19:48:38 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:48:38 2023 ] Eval epoch: 31
[ Wed Jun 28 19:48:40 2023 ] 	Mean test loss of 625 batches: 0.087137.
[ Wed Jun 28 19:48:40 2023 ] 	Mean test label-loss of 625 batches: 5.372713.
[ Wed Jun 28 19:48:40 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:48:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:48:40 2023 ] Training epoch: 32
[ Wed Jun 28 19:48:47 2023 ] 	Training loss: 6.0451.  Training acc: 94.79%.
[ Wed Jun 28 19:48:47 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:48:47 2023 ] Eval epoch: 32
[ Wed Jun 28 19:48:49 2023 ] 	Mean test loss of 625 batches: 0.094794.
[ Wed Jun 28 19:48:49 2023 ] 	Mean test label-loss of 625 batches: 5.345109.
[ Wed Jun 28 19:48:49 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:48:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:48:49 2023 ] Training epoch: 33
[ Wed Jun 28 19:48:55 2023 ] 	Training loss: 6.2213.  Training acc: 93.88%.
[ Wed Jun 28 19:48:55 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:48:55 2023 ] Eval epoch: 33
[ Wed Jun 28 19:48:57 2023 ] 	Mean test loss of 625 batches: 0.120998.
[ Wed Jun 28 19:48:57 2023 ] 	Mean test label-loss of 625 batches: 5.329346.
[ Wed Jun 28 19:48:57 2023 ] 	Top1: 97.37%
[ Wed Jun 28 19:48:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:48:58 2023 ] Training epoch: 34
[ Wed Jun 28 19:49:04 2023 ] 	Training loss: 6.1387.  Training acc: 94.40%.
[ Wed Jun 28 19:49:04 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:49:04 2023 ] Eval epoch: 34
[ Wed Jun 28 19:49:06 2023 ] 	Mean test loss of 625 batches: 0.087395.
[ Wed Jun 28 19:49:06 2023 ] 	Mean test label-loss of 625 batches: 5.333850.
[ Wed Jun 28 19:49:06 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:49:06 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:49:07 2023 ] Training epoch: 35
[ Wed Jun 28 19:49:13 2023 ] 	Training loss: 6.2161.  Training acc: 93.88%.
[ Wed Jun 28 19:49:13 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:49:13 2023 ] Eval epoch: 35
[ Wed Jun 28 19:49:15 2023 ] 	Mean test loss of 625 batches: 0.079902.
[ Wed Jun 28 19:49:15 2023 ] 	Mean test label-loss of 625 batches: 5.327800.
[ Wed Jun 28 19:49:15 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:49:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:49:15 2023 ] Training epoch: 36
[ Wed Jun 28 19:49:22 2023 ] 	Training loss: 6.1866.  Training acc: 93.62%.
[ Wed Jun 28 19:49:22 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:49:22 2023 ] Eval epoch: 36
[ Wed Jun 28 19:49:24 2023 ] 	Mean test loss of 625 batches: 0.188096.
[ Wed Jun 28 19:49:24 2023 ] 	Mean test label-loss of 625 batches: 5.298973.
[ Wed Jun 28 19:49:24 2023 ] 	Top1: 94.74%
[ Wed Jun 28 19:49:24 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:49:24 2023 ] Training epoch: 37
[ Wed Jun 28 19:49:30 2023 ] 	Training loss: 6.3237.  Training acc: 94.27%.
[ Wed Jun 28 19:49:30 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:49:30 2023 ] Eval epoch: 37
[ Wed Jun 28 19:49:32 2023 ] 	Mean test loss of 625 batches: 0.153949.
[ Wed Jun 28 19:49:32 2023 ] 	Mean test label-loss of 625 batches: 5.352765.
[ Wed Jun 28 19:49:32 2023 ] 	Top1: 94.74%
[ Wed Jun 28 19:49:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:49:33 2023 ] Training epoch: 38
[ Wed Jun 28 19:49:39 2023 ] 	Training loss: 6.0586.  Training acc: 93.75%.
[ Wed Jun 28 19:49:39 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:49:39 2023 ] Eval epoch: 38
[ Wed Jun 28 19:49:41 2023 ] 	Mean test loss of 625 batches: 0.117605.
[ Wed Jun 28 19:49:41 2023 ] 	Mean test label-loss of 625 batches: 5.363533.
[ Wed Jun 28 19:49:41 2023 ] 	Top1: 97.37%
[ Wed Jun 28 19:49:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:49:42 2023 ] Training epoch: 39
[ Wed Jun 28 19:49:48 2023 ] 	Training loss: 6.1986.  Training acc: 91.28%.
[ Wed Jun 28 19:49:48 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:49:48 2023 ] Eval epoch: 39
[ Wed Jun 28 19:49:50 2023 ] 	Mean test loss of 625 batches: 0.108019.
[ Wed Jun 28 19:49:50 2023 ] 	Mean test label-loss of 625 batches: 5.308295.
[ Wed Jun 28 19:49:50 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:49:50 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:49:51 2023 ] Training epoch: 40
[ Wed Jun 28 19:49:57 2023 ] 	Training loss: 5.9863.  Training acc: 94.92%.
[ Wed Jun 28 19:49:57 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:49:57 2023 ] Eval epoch: 40
[ Wed Jun 28 19:49:59 2023 ] 	Mean test loss of 625 batches: 0.112711.
[ Wed Jun 28 19:49:59 2023 ] 	Mean test label-loss of 625 batches: 5.285516.
[ Wed Jun 28 19:49:59 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:49:59 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:49:59 2023 ] Training epoch: 41
[ Wed Jun 28 19:50:06 2023 ] 	Training loss: 6.1414.  Training acc: 94.66%.
[ Wed Jun 28 19:50:06 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:50:06 2023 ] Eval epoch: 41
[ Wed Jun 28 19:50:08 2023 ] 	Mean test loss of 625 batches: 0.094608.
[ Wed Jun 28 19:50:08 2023 ] 	Mean test label-loss of 625 batches: 5.259545.
[ Wed Jun 28 19:50:08 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:50:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:50:08 2023 ] Training epoch: 42
[ Wed Jun 28 19:50:14 2023 ] 	Training loss: 6.1699.  Training acc: 94.92%.
[ Wed Jun 28 19:50:14 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:50:14 2023 ] Eval epoch: 42
[ Wed Jun 28 19:50:16 2023 ] 	Mean test loss of 625 batches: 0.106090.
[ Wed Jun 28 19:50:16 2023 ] 	Mean test label-loss of 625 batches: 5.249363.
[ Wed Jun 28 19:50:16 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:50:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:50:17 2023 ] Training epoch: 43
[ Wed Jun 28 19:50:23 2023 ] 	Training loss: 6.1226.  Training acc: 93.75%.
[ Wed Jun 28 19:50:23 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:50:23 2023 ] Eval epoch: 43
[ Wed Jun 28 19:50:25 2023 ] 	Mean test loss of 625 batches: 0.132198.
[ Wed Jun 28 19:50:25 2023 ] 	Mean test label-loss of 625 batches: 5.258933.
[ Wed Jun 28 19:50:25 2023 ] 	Top1: 97.37%
[ Wed Jun 28 19:50:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:50:26 2023 ] Training epoch: 44
[ Wed Jun 28 19:50:32 2023 ] 	Training loss: 6.1274.  Training acc: 95.31%.
[ Wed Jun 28 19:50:32 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:50:32 2023 ] Eval epoch: 44
[ Wed Jun 28 19:50:34 2023 ] 	Mean test loss of 625 batches: 0.112675.
[ Wed Jun 28 19:50:34 2023 ] 	Mean test label-loss of 625 batches: 5.265781.
[ Wed Jun 28 19:50:34 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:50:34 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:50:35 2023 ] Training epoch: 45
[ Wed Jun 28 19:50:41 2023 ] 	Training loss: 6.3326.  Training acc: 94.53%.
[ Wed Jun 28 19:50:41 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:50:41 2023 ] Eval epoch: 45
[ Wed Jun 28 19:50:43 2023 ] 	Mean test loss of 625 batches: 0.101991.
[ Wed Jun 28 19:50:43 2023 ] 	Mean test label-loss of 625 batches: 5.311135.
[ Wed Jun 28 19:50:43 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:50:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:50:43 2023 ] Training epoch: 46
[ Wed Jun 28 19:50:50 2023 ] 	Training loss: 6.1349.  Training acc: 93.75%.
[ Wed Jun 28 19:50:50 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 19:50:50 2023 ] Eval epoch: 46
[ Wed Jun 28 19:50:52 2023 ] 	Mean test loss of 625 batches: 0.394303.
[ Wed Jun 28 19:50:52 2023 ] 	Mean test label-loss of 625 batches: 5.314063.
[ Wed Jun 28 19:50:52 2023 ] 	Top1: 73.68%
[ Wed Jun 28 19:50:52 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:50:52 2023 ] Training epoch: 47
[ Wed Jun 28 19:50:59 2023 ] 	Training loss: 6.3065.  Training acc: 92.84%.
[ Wed Jun 28 19:50:59 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:50:59 2023 ] Eval epoch: 47
[ Wed Jun 28 19:51:00 2023 ] 	Mean test loss of 625 batches: 0.439667.
[ Wed Jun 28 19:51:00 2023 ] 	Mean test label-loss of 625 batches: 5.269804.
[ Wed Jun 28 19:51:00 2023 ] 	Top1: 71.05%
[ Wed Jun 28 19:51:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:51:01 2023 ] Training epoch: 48
[ Wed Jun 28 19:51:08 2023 ] 	Training loss: 6.1265.  Training acc: 93.36%.
[ Wed Jun 28 19:51:08 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 19:51:08 2023 ] Eval epoch: 48
[ Wed Jun 28 19:51:10 2023 ] 	Mean test loss of 625 batches: 0.365409.
[ Wed Jun 28 19:51:10 2023 ] 	Mean test label-loss of 625 batches: 5.238436.
[ Wed Jun 28 19:51:10 2023 ] 	Top1: 76.32%
[ Wed Jun 28 19:51:10 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:51:10 2023 ] Training epoch: 49
[ Wed Jun 28 19:51:16 2023 ] 	Training loss: 6.0761.  Training acc: 92.97%.
[ Wed Jun 28 19:51:16 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:51:16 2023 ] Eval epoch: 49
[ Wed Jun 28 19:51:18 2023 ] 	Mean test loss of 625 batches: 0.280755.
[ Wed Jun 28 19:51:18 2023 ] 	Mean test label-loss of 625 batches: 5.273983.
[ Wed Jun 28 19:51:18 2023 ] 	Top1: 81.58%
[ Wed Jun 28 19:51:18 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:51:19 2023 ] Training epoch: 50
[ Wed Jun 28 19:51:25 2023 ] 	Training loss: 6.0523.  Training acc: 94.14%.
[ Wed Jun 28 19:51:25 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:51:25 2023 ] Eval epoch: 50
[ Wed Jun 28 19:51:27 2023 ] 	Mean test loss of 625 batches: 0.219164.
[ Wed Jun 28 19:51:27 2023 ] 	Mean test label-loss of 625 batches: 5.258181.
[ Wed Jun 28 19:51:27 2023 ] 	Top1: 92.11%
[ Wed Jun 28 19:51:27 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:51:28 2023 ] Training epoch: 51
[ Wed Jun 28 19:51:34 2023 ] 	Training loss: 6.1324.  Training acc: 94.01%.
[ Wed Jun 28 19:51:34 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:51:34 2023 ] Eval epoch: 51
[ Wed Jun 28 19:51:36 2023 ] 	Mean test loss of 625 batches: 0.138509.
[ Wed Jun 28 19:51:36 2023 ] 	Mean test label-loss of 625 batches: 5.303335.
[ Wed Jun 28 19:51:36 2023 ] 	Top1: 97.37%
[ Wed Jun 28 19:51:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:51:36 2023 ] Training epoch: 52
[ Wed Jun 28 19:51:43 2023 ] 	Training loss: 6.3047.  Training acc: 94.66%.
[ Wed Jun 28 19:51:43 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:51:43 2023 ] Eval epoch: 52
[ Wed Jun 28 19:51:44 2023 ] 	Mean test loss of 625 batches: 0.068972.
[ Wed Jun 28 19:51:44 2023 ] 	Mean test label-loss of 625 batches: 5.391889.
[ Wed Jun 28 19:51:44 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:51:44 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:51:45 2023 ] Training epoch: 53
[ Wed Jun 28 19:51:51 2023 ] 	Training loss: 6.1327.  Training acc: 93.23%.
[ Wed Jun 28 19:51:51 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 19:51:51 2023 ] Eval epoch: 53
[ Wed Jun 28 19:51:53 2023 ] 	Mean test loss of 625 batches: 0.100008.
[ Wed Jun 28 19:51:53 2023 ] 	Mean test label-loss of 625 batches: 5.534425.
[ Wed Jun 28 19:51:53 2023 ] 	Top1: 97.37%
[ Wed Jun 28 19:51:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:51:54 2023 ] Training epoch: 54
[ Wed Jun 28 19:52:00 2023 ] 	Training loss: 6.2946.  Training acc: 92.84%.
[ Wed Jun 28 19:52:00 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:52:00 2023 ] Eval epoch: 54
[ Wed Jun 28 19:52:02 2023 ] 	Mean test loss of 625 batches: 0.077939.
[ Wed Jun 28 19:52:02 2023 ] 	Mean test label-loss of 625 batches: 5.456800.
[ Wed Jun 28 19:52:02 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:52:02 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:52:03 2023 ] Training epoch: 55
[ Wed Jun 28 19:52:09 2023 ] 	Training loss: 6.1783.  Training acc: 94.14%.
[ Wed Jun 28 19:52:09 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:52:09 2023 ] Eval epoch: 55
[ Wed Jun 28 19:52:11 2023 ] 	Mean test loss of 625 batches: 0.166610.
[ Wed Jun 28 19:52:11 2023 ] 	Mean test label-loss of 625 batches: 5.334669.
[ Wed Jun 28 19:52:11 2023 ] 	Top1: 97.37%
[ Wed Jun 28 19:52:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:52:11 2023 ] Training epoch: 56
[ Wed Jun 28 19:52:18 2023 ] 	Training loss: 6.1112.  Training acc: 94.40%.
[ Wed Jun 28 19:52:18 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:52:18 2023 ] Eval epoch: 56
[ Wed Jun 28 19:52:19 2023 ] 	Mean test loss of 625 batches: 0.134823.
[ Wed Jun 28 19:52:19 2023 ] 	Mean test label-loss of 625 batches: 5.329035.
[ Wed Jun 28 19:52:19 2023 ] 	Top1: 97.37%
[ Wed Jun 28 19:52:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:52:20 2023 ] Training epoch: 57
[ Wed Jun 28 19:52:25 2023 ] 	Training loss: 6.2883.  Training acc: 94.14%.
[ Wed Jun 28 19:52:25 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 19:52:25 2023 ] Eval epoch: 57
[ Wed Jun 28 19:52:26 2023 ] 	Mean test loss of 625 batches: 0.132690.
[ Wed Jun 28 19:52:26 2023 ] 	Mean test label-loss of 625 batches: 5.383501.
[ Wed Jun 28 19:52:26 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:52:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:52:26 2023 ] Training epoch: 58
[ Wed Jun 28 19:52:31 2023 ] 	Training loss: 6.0735.  Training acc: 93.49%.
[ Wed Jun 28 19:52:31 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:52:31 2023 ] Eval epoch: 58
[ Wed Jun 28 19:52:32 2023 ] 	Mean test loss of 625 batches: 0.111269.
[ Wed Jun 28 19:52:32 2023 ] 	Mean test label-loss of 625 batches: 5.394527.
[ Wed Jun 28 19:52:32 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:52:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:52:33 2023 ] Training epoch: 59
[ Wed Jun 28 19:52:38 2023 ] 	Training loss: 6.2095.  Training acc: 94.92%.
[ Wed Jun 28 19:52:38 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 19:52:38 2023 ] Eval epoch: 59
[ Wed Jun 28 19:52:39 2023 ] 	Mean test loss of 625 batches: 0.085935.
[ Wed Jun 28 19:52:39 2023 ] 	Mean test label-loss of 625 batches: 5.378145.
[ Wed Jun 28 19:52:39 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:52:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:52:40 2023 ] Training epoch: 60
[ Wed Jun 28 19:52:44 2023 ] 	Training loss: 6.1944.  Training acc: 93.49%.
[ Wed Jun 28 19:52:44 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Wed Jun 28 19:52:45 2023 ] Eval epoch: 60
[ Wed Jun 28 19:52:46 2023 ] 	Mean test loss of 625 batches: 0.140204.
[ Wed Jun 28 19:52:46 2023 ] 	Mean test label-loss of 625 batches: 5.337558.
[ Wed Jun 28 19:52:46 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:52:46 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:52:47 2023 ] Training epoch: 61
[ Wed Jun 28 19:52:52 2023 ] 	Training loss: 6.0745.  Training acc: 93.10%.
[ Wed Jun 28 19:52:52 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Wed Jun 28 19:52:52 2023 ] Eval epoch: 61
[ Wed Jun 28 19:52:54 2023 ] 	Mean test loss of 625 batches: 0.133511.
[ Wed Jun 28 19:52:54 2023 ] 	Mean test label-loss of 625 batches: 5.266569.
[ Wed Jun 28 19:52:54 2023 ] 	Top1: 97.37%
[ Wed Jun 28 19:52:54 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:52:54 2023 ] Training epoch: 62
[ Wed Jun 28 19:53:01 2023 ] 	Training loss: 6.2147.  Training acc: 95.31%.
[ Wed Jun 28 19:53:01 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:53:01 2023 ] Eval epoch: 62
[ Wed Jun 28 19:53:03 2023 ] 	Mean test loss of 625 batches: 0.244095.
[ Wed Jun 28 19:53:03 2023 ] 	Mean test label-loss of 625 batches: 5.234447.
[ Wed Jun 28 19:53:03 2023 ] 	Top1: 89.47%
[ Wed Jun 28 19:53:03 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:53:03 2023 ] Training epoch: 63
[ Wed Jun 28 19:53:10 2023 ] 	Training loss: 6.1567.  Training acc: 95.05%.
[ Wed Jun 28 19:53:10 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:53:10 2023 ] Eval epoch: 63
[ Wed Jun 28 19:53:12 2023 ] 	Mean test loss of 625 batches: 0.237429.
[ Wed Jun 28 19:53:12 2023 ] 	Mean test label-loss of 625 batches: 5.263452.
[ Wed Jun 28 19:53:12 2023 ] 	Top1: 89.47%
[ Wed Jun 28 19:53:12 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:53:12 2023 ] Training epoch: 64
[ Wed Jun 28 19:53:19 2023 ] 	Training loss: 6.1442.  Training acc: 95.31%.
[ Wed Jun 28 19:53:19 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:53:19 2023 ] Eval epoch: 64
[ Wed Jun 28 19:53:20 2023 ] 	Mean test loss of 625 batches: 0.157468.
[ Wed Jun 28 19:53:20 2023 ] 	Mean test label-loss of 625 batches: 5.253039.
[ Wed Jun 28 19:53:20 2023 ] 	Top1: 97.37%
[ Wed Jun 28 19:53:20 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:53:21 2023 ] Training epoch: 65
[ Wed Jun 28 19:53:27 2023 ] 	Training loss: 6.1920.  Training acc: 94.92%.
[ Wed Jun 28 19:53:27 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:53:27 2023 ] Eval epoch: 65
[ Wed Jun 28 19:53:29 2023 ] 	Mean test loss of 625 batches: 0.119663.
[ Wed Jun 28 19:53:29 2023 ] 	Mean test label-loss of 625 batches: 5.266034.
[ Wed Jun 28 19:53:29 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:53:29 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:53:30 2023 ] Training epoch: 66
[ Wed Jun 28 19:53:36 2023 ] 	Training loss: 6.0283.  Training acc: 95.83%.
[ Wed Jun 28 19:53:36 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:53:36 2023 ] Eval epoch: 66
[ Wed Jun 28 19:53:38 2023 ] 	Mean test loss of 625 batches: 0.134617.
[ Wed Jun 28 19:53:38 2023 ] 	Mean test label-loss of 625 batches: 5.288206.
[ Wed Jun 28 19:53:38 2023 ] 	Top1: 97.37%
[ Wed Jun 28 19:53:38 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:53:39 2023 ] Training epoch: 67
[ Wed Jun 28 19:53:45 2023 ] 	Training loss: 6.2053.  Training acc: 94.92%.
[ Wed Jun 28 19:53:45 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:53:45 2023 ] Eval epoch: 67
[ Wed Jun 28 19:53:47 2023 ] 	Mean test loss of 625 batches: 0.121843.
[ Wed Jun 28 19:53:47 2023 ] 	Mean test label-loss of 625 batches: 5.290467.
[ Wed Jun 28 19:53:47 2023 ] 	Top1: 97.37%
[ Wed Jun 28 19:53:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:53:47 2023 ] Training epoch: 68
[ Wed Jun 28 19:53:53 2023 ] 	Training loss: 6.1480.  Training acc: 93.62%.
[ Wed Jun 28 19:53:53 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:53:53 2023 ] Eval epoch: 68
[ Wed Jun 28 19:53:55 2023 ] 	Mean test loss of 625 batches: 0.321797.
[ Wed Jun 28 19:53:55 2023 ] 	Mean test label-loss of 625 batches: 5.280443.
[ Wed Jun 28 19:53:55 2023 ] 	Top1: 81.58%
[ Wed Jun 28 19:53:55 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:53:56 2023 ] Training epoch: 69
[ Wed Jun 28 19:54:02 2023 ] 	Training loss: 6.1831.  Training acc: 95.05%.
[ Wed Jun 28 19:54:02 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:54:02 2023 ] Eval epoch: 69
[ Wed Jun 28 19:54:04 2023 ] 	Mean test loss of 625 batches: 0.277333.
[ Wed Jun 28 19:54:04 2023 ] 	Mean test label-loss of 625 batches: 5.292313.
[ Wed Jun 28 19:54:04 2023 ] 	Top1: 84.21%
[ Wed Jun 28 19:54:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:54:05 2023 ] Training epoch: 70
[ Wed Jun 28 19:54:11 2023 ] 	Training loss: 6.0697.  Training acc: 95.05%.
[ Wed Jun 28 19:54:11 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:54:11 2023 ] Eval epoch: 70
[ Wed Jun 28 19:54:13 2023 ] 	Mean test loss of 625 batches: 0.432809.
[ Wed Jun 28 19:54:13 2023 ] 	Mean test label-loss of 625 batches: 5.322826.
[ Wed Jun 28 19:54:13 2023 ] 	Top1: 76.32%
[ Wed Jun 28 19:54:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:54:13 2023 ] Training epoch: 71
[ Wed Jun 28 19:54:20 2023 ] 	Training loss: 6.0874.  Training acc: 93.88%.
[ Wed Jun 28 19:54:20 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:54:20 2023 ] Eval epoch: 71
[ Wed Jun 28 19:54:22 2023 ] 	Mean test loss of 625 batches: 0.128381.
[ Wed Jun 28 19:54:22 2023 ] 	Mean test label-loss of 625 batches: 5.623558.
[ Wed Jun 28 19:54:22 2023 ] 	Top1: 94.74%
[ Wed Jun 28 19:54:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:54:22 2023 ] Training epoch: 72
[ Wed Jun 28 19:54:29 2023 ] 	Training loss: 6.1567.  Training acc: 94.79%.
[ Wed Jun 28 19:54:29 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:54:29 2023 ] Eval epoch: 72
[ Wed Jun 28 19:54:30 2023 ] 	Mean test loss of 625 batches: 0.810048.
[ Wed Jun 28 19:54:30 2023 ] 	Mean test label-loss of 625 batches: 5.711251.
[ Wed Jun 28 19:54:30 2023 ] 	Top1: 73.68%
[ Wed Jun 28 19:54:30 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:54:31 2023 ] Training epoch: 73
[ Wed Jun 28 19:54:37 2023 ] 	Training loss: 6.1998.  Training acc: 94.27%.
[ Wed Jun 28 19:54:37 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:54:37 2023 ] Eval epoch: 73
[ Wed Jun 28 19:54:39 2023 ] 	Mean test loss of 625 batches: 0.064062.
[ Wed Jun 28 19:54:39 2023 ] 	Mean test label-loss of 625 batches: 5.413586.
[ Wed Jun 28 19:54:39 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:54:39 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:54:40 2023 ] Training epoch: 74
[ Wed Jun 28 19:54:46 2023 ] 	Training loss: 6.2794.  Training acc: 66.80%.
[ Wed Jun 28 19:54:46 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:54:46 2023 ] Eval epoch: 74
[ Wed Jun 28 19:54:48 2023 ] 	Mean test loss of 625 batches: 0.220235.
[ Wed Jun 28 19:54:48 2023 ] 	Mean test label-loss of 625 batches: 5.395697.
[ Wed Jun 28 19:54:48 2023 ] 	Top1: 92.11%
[ Wed Jun 28 19:54:48 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:54:48 2023 ] Training epoch: 75
[ Wed Jun 28 19:54:54 2023 ] 	Training loss: 6.2855.  Training acc: 80.73%.
[ Wed Jun 28 19:54:54 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:54:54 2023 ] Eval epoch: 75
[ Wed Jun 28 19:54:56 2023 ] 	Mean test loss of 625 batches: 0.276473.
[ Wed Jun 28 19:54:56 2023 ] 	Mean test label-loss of 625 batches: 5.419669.
[ Wed Jun 28 19:54:56 2023 ] 	Top1: 86.84%
[ Wed Jun 28 19:54:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:54:57 2023 ] Training epoch: 76
[ Wed Jun 28 19:55:03 2023 ] 	Training loss: 6.3536.  Training acc: 87.11%.
[ Wed Jun 28 19:55:03 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:55:03 2023 ] Eval epoch: 76
[ Wed Jun 28 19:55:05 2023 ] 	Mean test loss of 625 batches: 0.246691.
[ Wed Jun 28 19:55:05 2023 ] 	Mean test label-loss of 625 batches: 5.457065.
[ Wed Jun 28 19:55:05 2023 ] 	Top1: 94.74%
[ Wed Jun 28 19:55:05 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:55:06 2023 ] Training epoch: 77
[ Wed Jun 28 19:55:12 2023 ] 	Training loss: 6.3847.  Training acc: 86.98%.
[ Wed Jun 28 19:55:12 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:55:12 2023 ] Eval epoch: 77
[ Wed Jun 28 19:55:14 2023 ] 	Mean test loss of 625 batches: 0.237093.
[ Wed Jun 28 19:55:14 2023 ] 	Mean test label-loss of 625 batches: 5.417004.
[ Wed Jun 28 19:55:14 2023 ] 	Top1: 94.74%
[ Wed Jun 28 19:55:14 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:55:14 2023 ] Training epoch: 78
[ Wed Jun 28 19:55:21 2023 ] 	Training loss: 6.2293.  Training acc: 90.36%.
[ Wed Jun 28 19:55:21 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:55:21 2023 ] Eval epoch: 78
[ Wed Jun 28 19:55:23 2023 ] 	Mean test loss of 625 batches: 0.228533.
[ Wed Jun 28 19:55:23 2023 ] 	Mean test label-loss of 625 batches: 5.427985.
[ Wed Jun 28 19:55:23 2023 ] 	Top1: 92.11%
[ Wed Jun 28 19:55:23 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:55:23 2023 ] Training epoch: 79
[ Wed Jun 28 19:55:29 2023 ] 	Training loss: 6.2698.  Training acc: 92.45%.
[ Wed Jun 28 19:55:29 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:55:29 2023 ] Eval epoch: 79
[ Wed Jun 28 19:55:31 2023 ] 	Mean test loss of 625 batches: 0.181969.
[ Wed Jun 28 19:55:31 2023 ] 	Mean test label-loss of 625 batches: 5.382649.
[ Wed Jun 28 19:55:31 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:55:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:55:32 2023 ] Training epoch: 80
[ Wed Jun 28 19:55:38 2023 ] 	Training loss: 6.3370.  Training acc: 91.93%.
[ Wed Jun 28 19:55:38 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:55:38 2023 ] Eval epoch: 80
[ Wed Jun 28 19:55:40 2023 ] 	Mean test loss of 625 batches: 0.144034.
[ Wed Jun 28 19:55:40 2023 ] 	Mean test label-loss of 625 batches: 5.326025.
[ Wed Jun 28 19:55:40 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:55:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:55:40 2023 ] Training epoch: 81
[ Wed Jun 28 19:55:47 2023 ] 	Training loss: 6.2616.  Training acc: 90.49%.
[ Wed Jun 28 19:55:47 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:55:47 2023 ] Eval epoch: 81
[ Wed Jun 28 19:55:48 2023 ] 	Mean test loss of 625 batches: 0.178318.
[ Wed Jun 28 19:55:48 2023 ] 	Mean test label-loss of 625 batches: 5.322683.
[ Wed Jun 28 19:55:48 2023 ] 	Top1: 97.37%
[ Wed Jun 28 19:55:48 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:55:49 2023 ] Training epoch: 82
[ Wed Jun 28 19:55:55 2023 ] 	Training loss: 6.3168.  Training acc: 91.41%.
[ Wed Jun 28 19:55:55 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:55:55 2023 ] Eval epoch: 82
[ Wed Jun 28 19:55:57 2023 ] 	Mean test loss of 625 batches: 0.148862.
[ Wed Jun 28 19:55:57 2023 ] 	Mean test label-loss of 625 batches: 5.402389.
[ Wed Jun 28 19:55:57 2023 ] 	Top1: 97.37%
[ Wed Jun 28 19:55:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:55:58 2023 ] Training epoch: 83
[ Wed Jun 28 19:56:04 2023 ] 	Training loss: 6.1882.  Training acc: 90.89%.
[ Wed Jun 28 19:56:04 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:56:04 2023 ] Eval epoch: 83
[ Wed Jun 28 19:56:06 2023 ] 	Mean test loss of 625 batches: 0.173318.
[ Wed Jun 28 19:56:06 2023 ] 	Mean test label-loss of 625 batches: 5.389297.
[ Wed Jun 28 19:56:06 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:56:06 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:56:07 2023 ] Training epoch: 84
[ Wed Jun 28 19:56:13 2023 ] 	Training loss: 5.9916.  Training acc: 93.36%.
[ Wed Jun 28 19:56:13 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 19:56:13 2023 ] Eval epoch: 84
[ Wed Jun 28 19:56:15 2023 ] 	Mean test loss of 625 batches: 0.160600.
[ Wed Jun 28 19:56:15 2023 ] 	Mean test label-loss of 625 batches: 5.307476.
[ Wed Jun 28 19:56:15 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:56:15 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:56:15 2023 ] Training epoch: 85
[ Wed Jun 28 19:56:22 2023 ] 	Training loss: 6.2418.  Training acc: 91.28%.
[ Wed Jun 28 19:56:22 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:56:22 2023 ] Eval epoch: 85
[ Wed Jun 28 19:56:23 2023 ] 	Mean test loss of 625 batches: 0.128164.
[ Wed Jun 28 19:56:23 2023 ] 	Mean test label-loss of 625 batches: 5.255540.
[ Wed Jun 28 19:56:23 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:56:23 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:56:24 2023 ] Training epoch: 86
[ Wed Jun 28 19:56:30 2023 ] 	Training loss: 6.1900.  Training acc: 90.23%.
[ Wed Jun 28 19:56:30 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:56:30 2023 ] Eval epoch: 86
[ Wed Jun 28 19:56:32 2023 ] 	Mean test loss of 625 batches: 0.138644.
[ Wed Jun 28 19:56:32 2023 ] 	Mean test label-loss of 625 batches: 5.268370.
[ Wed Jun 28 19:56:32 2023 ] 	Top1: 97.37%
[ Wed Jun 28 19:56:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:56:33 2023 ] Training epoch: 87
[ Wed Jun 28 19:56:39 2023 ] 	Training loss: 6.0832.  Training acc: 92.45%.
[ Wed Jun 28 19:56:39 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 19:56:39 2023 ] Eval epoch: 87
[ Wed Jun 28 19:56:41 2023 ] 	Mean test loss of 625 batches: 0.125228.
[ Wed Jun 28 19:56:41 2023 ] 	Mean test label-loss of 625 batches: 5.256313.
[ Wed Jun 28 19:56:41 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:56:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:56:41 2023 ] Training epoch: 88
[ Wed Jun 28 19:56:48 2023 ] 	Training loss: 6.1791.  Training acc: 93.62%.
[ Wed Jun 28 19:56:48 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:56:48 2023 ] Eval epoch: 88
[ Wed Jun 28 19:56:49 2023 ] 	Mean test loss of 625 batches: 0.123506.
[ Wed Jun 28 19:56:49 2023 ] 	Mean test label-loss of 625 batches: 5.259089.
[ Wed Jun 28 19:56:49 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:56:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:56:50 2023 ] Training epoch: 89
[ Wed Jun 28 19:56:56 2023 ] 	Training loss: 5.9371.  Training acc: 94.01%.
[ Wed Jun 28 19:56:56 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:56:56 2023 ] Eval epoch: 89
[ Wed Jun 28 19:56:58 2023 ] 	Mean test loss of 625 batches: 0.130552.
[ Wed Jun 28 19:56:58 2023 ] 	Mean test label-loss of 625 batches: 5.278646.
[ Wed Jun 28 19:56:58 2023 ] 	Top1: 97.37%
[ Wed Jun 28 19:56:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:56:59 2023 ] Training epoch: 90
[ Wed Jun 28 19:57:05 2023 ] 	Training loss: 6.0826.  Training acc: 94.66%.
[ Wed Jun 28 19:57:05 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:57:05 2023 ] Eval epoch: 90
[ Wed Jun 28 19:57:07 2023 ] 	Mean test loss of 625 batches: 0.115286.
[ Wed Jun 28 19:57:07 2023 ] 	Mean test label-loss of 625 batches: 5.270235.
[ Wed Jun 28 19:57:07 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:57:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:57:07 2023 ] Training epoch: 91
[ Wed Jun 28 19:57:14 2023 ] 	Training loss: 6.1188.  Training acc: 94.66%.
[ Wed Jun 28 19:57:14 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:57:14 2023 ] Eval epoch: 91
[ Wed Jun 28 19:57:16 2023 ] 	Mean test loss of 625 batches: 0.112070.
[ Wed Jun 28 19:57:16 2023 ] 	Mean test label-loss of 625 batches: 5.265174.
[ Wed Jun 28 19:57:16 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:57:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:57:16 2023 ] Training epoch: 92
[ Wed Jun 28 19:57:23 2023 ] 	Training loss: 6.1968.  Training acc: 93.23%.
[ Wed Jun 28 19:57:23 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:57:23 2023 ] Eval epoch: 92
[ Wed Jun 28 19:57:25 2023 ] 	Mean test loss of 625 batches: 0.092072.
[ Wed Jun 28 19:57:25 2023 ] 	Mean test label-loss of 625 batches: 5.319902.
[ Wed Jun 28 19:57:25 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:57:25 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:57:25 2023 ] Training epoch: 93
[ Wed Jun 28 19:57:32 2023 ] 	Training loss: 6.1987.  Training acc: 93.36%.
[ Wed Jun 28 19:57:32 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:57:32 2023 ] Eval epoch: 93
[ Wed Jun 28 19:57:33 2023 ] 	Mean test loss of 625 batches: 0.088115.
[ Wed Jun 28 19:57:33 2023 ] 	Mean test label-loss of 625 batches: 5.321797.
[ Wed Jun 28 19:57:33 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:57:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:57:34 2023 ] Training epoch: 94
[ Wed Jun 28 19:57:40 2023 ] 	Training loss: 6.0110.  Training acc: 94.92%.
[ Wed Jun 28 19:57:40 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:57:40 2023 ] Eval epoch: 94
[ Wed Jun 28 19:57:42 2023 ] 	Mean test loss of 625 batches: 0.100198.
[ Wed Jun 28 19:57:42 2023 ] 	Mean test label-loss of 625 batches: 5.296175.
[ Wed Jun 28 19:57:42 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:57:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:57:43 2023 ] Training epoch: 95
[ Wed Jun 28 19:57:49 2023 ] 	Training loss: 6.1782.  Training acc: 93.75%.
[ Wed Jun 28 19:57:49 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:57:49 2023 ] Eval epoch: 95
[ Wed Jun 28 19:57:51 2023 ] 	Mean test loss of 625 batches: 0.103762.
[ Wed Jun 28 19:57:51 2023 ] 	Mean test label-loss of 625 batches: 5.304472.
[ Wed Jun 28 19:57:51 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:57:51 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:57:52 2023 ] Training epoch: 96
[ Wed Jun 28 19:57:58 2023 ] 	Training loss: 6.2519.  Training acc: 94.27%.
[ Wed Jun 28 19:57:58 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:57:58 2023 ] Eval epoch: 96
[ Wed Jun 28 19:58:00 2023 ] 	Mean test loss of 625 batches: 0.099605.
[ Wed Jun 28 19:58:00 2023 ] 	Mean test label-loss of 625 batches: 5.306501.
[ Wed Jun 28 19:58:00 2023 ] 	Top1: 97.37%
[ Wed Jun 28 19:58:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:58:00 2023 ] Training epoch: 97
[ Wed Jun 28 19:58:07 2023 ] 	Training loss: 6.0876.  Training acc: 94.40%.
[ Wed Jun 28 19:58:07 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:58:07 2023 ] Eval epoch: 97
[ Wed Jun 28 19:58:08 2023 ] 	Mean test loss of 625 batches: 0.094354.
[ Wed Jun 28 19:58:08 2023 ] 	Mean test label-loss of 625 batches: 5.330327.
[ Wed Jun 28 19:58:08 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:58:08 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:58:09 2023 ] Training epoch: 98
[ Wed Jun 28 19:58:15 2023 ] 	Training loss: 6.0428.  Training acc: 93.23%.
[ Wed Jun 28 19:58:15 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:58:15 2023 ] Eval epoch: 98
[ Wed Jun 28 19:58:17 2023 ] 	Mean test loss of 625 batches: 0.100389.
[ Wed Jun 28 19:58:17 2023 ] 	Mean test label-loss of 625 batches: 5.289317.
[ Wed Jun 28 19:58:17 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:58:17 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:58:18 2023 ] Training epoch: 99
[ Wed Jun 28 19:58:24 2023 ] 	Training loss: 6.2472.  Training acc: 94.79%.
[ Wed Jun 28 19:58:24 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:58:24 2023 ] Eval epoch: 99
[ Wed Jun 28 19:58:26 2023 ] 	Mean test loss of 625 batches: 0.130239.
[ Wed Jun 28 19:58:26 2023 ] 	Mean test label-loss of 625 batches: 5.299351.
[ Wed Jun 28 19:58:26 2023 ] 	Top1: 97.37%
[ Wed Jun 28 19:58:26 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:58:26 2023 ] Training epoch: 100
[ Wed Jun 28 19:58:33 2023 ] 	Training loss: 6.1252.  Training acc: 93.75%.
[ Wed Jun 28 19:58:33 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:58:33 2023 ] Eval epoch: 100
[ Wed Jun 28 19:58:34 2023 ] 	Mean test loss of 625 batches: 0.073315.
[ Wed Jun 28 19:58:34 2023 ] 	Mean test label-loss of 625 batches: 5.333154.
[ Wed Jun 28 19:58:34 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:58:34 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:58:35 2023 ] Training epoch: 101
[ Wed Jun 28 19:58:41 2023 ] 	Training loss: 6.0656.  Training acc: 94.53%.
[ Wed Jun 28 19:58:41 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:58:41 2023 ] Eval epoch: 101
[ Wed Jun 28 19:58:43 2023 ] 	Mean test loss of 625 batches: 0.108133.
[ Wed Jun 28 19:58:43 2023 ] 	Mean test label-loss of 625 batches: 5.306644.
[ Wed Jun 28 19:58:43 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:58:43 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:58:44 2023 ] Training epoch: 102
[ Wed Jun 28 19:58:50 2023 ] 	Training loss: 5.9918.  Training acc: 94.01%.
[ Wed Jun 28 19:58:50 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:58:50 2023 ] Eval epoch: 102
[ Wed Jun 28 19:58:52 2023 ] 	Mean test loss of 625 batches: 0.089076.
[ Wed Jun 28 19:58:52 2023 ] 	Mean test label-loss of 625 batches: 5.302599.
[ Wed Jun 28 19:58:52 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:58:52 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:58:52 2023 ] Training epoch: 103
[ Wed Jun 28 19:58:59 2023 ] 	Training loss: 6.1877.  Training acc: 93.36%.
[ Wed Jun 28 19:58:59 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:58:59 2023 ] Eval epoch: 103
[ Wed Jun 28 19:59:00 2023 ] 	Mean test loss of 625 batches: 0.095113.
[ Wed Jun 28 19:59:00 2023 ] 	Mean test label-loss of 625 batches: 5.323714.
[ Wed Jun 28 19:59:00 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:59:00 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:59:01 2023 ] Training epoch: 104
[ Wed Jun 28 19:59:07 2023 ] 	Training loss: 6.1826.  Training acc: 94.66%.
[ Wed Jun 28 19:59:07 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:59:07 2023 ] Eval epoch: 104
[ Wed Jun 28 19:59:09 2023 ] 	Mean test loss of 625 batches: 0.098581.
[ Wed Jun 28 19:59:09 2023 ] 	Mean test label-loss of 625 batches: 5.330375.
[ Wed Jun 28 19:59:09 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:59:09 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:59:10 2023 ] Training epoch: 105
[ Wed Jun 28 19:59:16 2023 ] 	Training loss: 6.1588.  Training acc: 93.23%.
[ Wed Jun 28 19:59:16 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:59:16 2023 ] Eval epoch: 105
[ Wed Jun 28 19:59:18 2023 ] 	Mean test loss of 625 batches: 0.076984.
[ Wed Jun 28 19:59:18 2023 ] 	Mean test label-loss of 625 batches: 5.375511.
[ Wed Jun 28 19:59:18 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:59:18 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:59:18 2023 ] Training epoch: 106
[ Wed Jun 28 19:59:25 2023 ] 	Training loss: 5.9886.  Training acc: 95.18%.
[ Wed Jun 28 19:59:25 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:59:25 2023 ] Eval epoch: 106
[ Wed Jun 28 19:59:27 2023 ] 	Mean test loss of 625 batches: 0.087962.
[ Wed Jun 28 19:59:27 2023 ] 	Mean test label-loss of 625 batches: 5.367199.
[ Wed Jun 28 19:59:27 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:59:27 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:59:27 2023 ] Training epoch: 107
[ Wed Jun 28 19:59:33 2023 ] 	Training loss: 6.1175.  Training acc: 94.01%.
[ Wed Jun 28 19:59:33 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 19:59:33 2023 ] Eval epoch: 107
[ Wed Jun 28 19:59:35 2023 ] 	Mean test loss of 625 batches: 0.085165.
[ Wed Jun 28 19:59:35 2023 ] 	Mean test label-loss of 625 batches: 5.327107.
[ Wed Jun 28 19:59:35 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:59:35 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:59:36 2023 ] Training epoch: 108
[ Wed Jun 28 19:59:42 2023 ] 	Training loss: 6.1374.  Training acc: 92.58%.
[ Wed Jun 28 19:59:42 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:59:42 2023 ] Eval epoch: 108
[ Wed Jun 28 19:59:44 2023 ] 	Mean test loss of 625 batches: 0.127114.
[ Wed Jun 28 19:59:44 2023 ] 	Mean test label-loss of 625 batches: 5.270790.
[ Wed Jun 28 19:59:44 2023 ] 	Top1: 94.74%
[ Wed Jun 28 19:59:44 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:59:45 2023 ] Training epoch: 109
[ Wed Jun 28 19:59:51 2023 ] 	Training loss: 6.1426.  Training acc: 95.05%.
[ Wed Jun 28 19:59:51 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 19:59:51 2023 ] Eval epoch: 109
[ Wed Jun 28 19:59:53 2023 ] 	Mean test loss of 625 batches: 0.097904.
[ Wed Jun 28 19:59:53 2023 ] 	Mean test label-loss of 625 batches: 5.284289.
[ Wed Jun 28 19:59:53 2023 ] 	Top1: 100.00%
[ Wed Jun 28 19:59:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 19:59:53 2023 ] Training epoch: 110
[ Wed Jun 28 20:00:00 2023 ] 	Training loss: 6.1465.  Training acc: 94.66%.
[ Wed Jun 28 20:00:00 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:00:00 2023 ] Eval epoch: 110
[ Wed Jun 28 20:00:01 2023 ] 	Mean test loss of 625 batches: 0.096387.
[ Wed Jun 28 20:00:01 2023 ] 	Mean test label-loss of 625 batches: 5.345162.
[ Wed Jun 28 20:00:01 2023 ] 	Top1: 100.00%
[ Wed Jun 28 20:00:01 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:00:02 2023 ] Training epoch: 111
[ Wed Jun 28 20:00:08 2023 ] 	Training loss: 6.1369.  Training acc: 95.18%.
[ Wed Jun 28 20:00:08 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 20:00:08 2023 ] Eval epoch: 111
[ Wed Jun 28 20:00:10 2023 ] 	Mean test loss of 625 batches: 0.076499.
[ Wed Jun 28 20:00:10 2023 ] 	Mean test label-loss of 625 batches: 5.374242.
[ Wed Jun 28 20:00:10 2023 ] 	Top1: 100.00%
[ Wed Jun 28 20:00:10 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:00:11 2023 ] Training epoch: 112
[ Wed Jun 28 20:00:17 2023 ] 	Training loss: 6.0650.  Training acc: 95.05%.
[ Wed Jun 28 20:00:17 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:00:17 2023 ] Eval epoch: 112
[ Wed Jun 28 20:00:19 2023 ] 	Mean test loss of 625 batches: 0.084802.
[ Wed Jun 28 20:00:19 2023 ] 	Mean test label-loss of 625 batches: 5.344481.
[ Wed Jun 28 20:00:19 2023 ] 	Top1: 100.00%
[ Wed Jun 28 20:00:19 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:00:19 2023 ] Training epoch: 113
[ Wed Jun 28 20:00:26 2023 ] 	Training loss: 6.0370.  Training acc: 95.57%.
[ Wed Jun 28 20:00:26 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:00:26 2023 ] Eval epoch: 113
[ Wed Jun 28 20:00:27 2023 ] 	Mean test loss of 625 batches: 0.111359.
[ Wed Jun 28 20:00:27 2023 ] 	Mean test label-loss of 625 batches: 5.309633.
[ Wed Jun 28 20:00:27 2023 ] 	Top1: 97.37%
[ Wed Jun 28 20:00:27 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:00:28 2023 ] Training epoch: 114
[ Wed Jun 28 20:00:34 2023 ] 	Training loss: 6.0517.  Training acc: 95.57%.
[ Wed Jun 28 20:00:34 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:00:34 2023 ] Eval epoch: 114
[ Wed Jun 28 20:00:36 2023 ] 	Mean test loss of 625 batches: 0.087970.
[ Wed Jun 28 20:00:36 2023 ] 	Mean test label-loss of 625 batches: 5.309306.
[ Wed Jun 28 20:00:36 2023 ] 	Top1: 100.00%
[ Wed Jun 28 20:00:36 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:00:37 2023 ] Training epoch: 115
[ Wed Jun 28 20:00:43 2023 ] 	Training loss: 6.1674.  Training acc: 93.62%.
[ Wed Jun 28 20:00:43 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:00:43 2023 ] Eval epoch: 115
[ Wed Jun 28 20:00:45 2023 ] 	Mean test loss of 625 batches: 0.077165.
[ Wed Jun 28 20:00:45 2023 ] 	Mean test label-loss of 625 batches: 5.314056.
[ Wed Jun 28 20:00:45 2023 ] 	Top1: 100.00%
[ Wed Jun 28 20:00:45 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:00:45 2023 ] Training epoch: 116
[ Wed Jun 28 20:00:52 2023 ] 	Training loss: 6.1215.  Training acc: 93.62%.
[ Wed Jun 28 20:00:52 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 20:00:52 2023 ] Eval epoch: 116
[ Wed Jun 28 20:00:53 2023 ] 	Mean test loss of 625 batches: 0.090463.
[ Wed Jun 28 20:00:53 2023 ] 	Mean test label-loss of 625 batches: 5.264039.
[ Wed Jun 28 20:00:53 2023 ] 	Top1: 100.00%
[ Wed Jun 28 20:00:53 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:00:54 2023 ] Training epoch: 117
[ Wed Jun 28 20:01:00 2023 ] 	Training loss: 6.0533.  Training acc: 94.79%.
[ Wed Jun 28 20:01:00 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:01:00 2023 ] Eval epoch: 117
[ Wed Jun 28 20:01:02 2023 ] 	Mean test loss of 625 batches: 0.111988.
[ Wed Jun 28 20:01:02 2023 ] 	Mean test label-loss of 625 batches: 5.241817.
[ Wed Jun 28 20:01:02 2023 ] 	Top1: 97.37%
[ Wed Jun 28 20:01:02 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:01:03 2023 ] Training epoch: 118
[ Wed Jun 28 20:01:09 2023 ] 	Training loss: 6.0587.  Training acc: 94.40%.
[ Wed Jun 28 20:01:09 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:01:09 2023 ] Eval epoch: 118
[ Wed Jun 28 20:01:11 2023 ] 	Mean test loss of 625 batches: 0.080610.
[ Wed Jun 28 20:01:11 2023 ] 	Mean test label-loss of 625 batches: 5.205908.
[ Wed Jun 28 20:01:11 2023 ] 	Top1: 100.00%
[ Wed Jun 28 20:01:11 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:01:12 2023 ] Training epoch: 119
[ Wed Jun 28 20:01:18 2023 ] 	Training loss: 5.9957.  Training acc: 94.79%.
[ Wed Jun 28 20:01:18 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:01:18 2023 ] Eval epoch: 119
[ Wed Jun 28 20:01:20 2023 ] 	Mean test loss of 625 batches: 0.093100.
[ Wed Jun 28 20:01:20 2023 ] 	Mean test label-loss of 625 batches: 5.203298.
[ Wed Jun 28 20:01:20 2023 ] 	Top1: 100.00%
[ Wed Jun 28 20:01:20 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:01:20 2023 ] Training epoch: 120
[ Wed Jun 28 20:01:27 2023 ] 	Training loss: 6.0075.  Training acc: 93.10%.
[ Wed Jun 28 20:01:27 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:01:27 2023 ] Eval epoch: 120
[ Wed Jun 28 20:01:28 2023 ] 	Mean test loss of 625 batches: 0.087118.
[ Wed Jun 28 20:01:28 2023 ] 	Mean test label-loss of 625 batches: 5.216872.
[ Wed Jun 28 20:01:28 2023 ] 	Top1: 100.00%
[ Wed Jun 28 20:01:28 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:01:29 2023 ] Training epoch: 121
[ Wed Jun 28 20:01:35 2023 ] 	Training loss: 6.1595.  Training acc: 95.44%.
[ Wed Jun 28 20:01:35 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 20:01:35 2023 ] Eval epoch: 121
[ Wed Jun 28 20:01:37 2023 ] 	Mean test loss of 625 batches: 0.093078.
[ Wed Jun 28 20:01:37 2023 ] 	Mean test label-loss of 625 batches: 5.278529.
[ Wed Jun 28 20:01:37 2023 ] 	Top1: 100.00%
[ Wed Jun 28 20:01:37 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:01:38 2023 ] Training epoch: 122
[ Wed Jun 28 20:01:44 2023 ] 	Training loss: 6.0547.  Training acc: 95.05%.
[ Wed Jun 28 20:01:44 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 20:01:44 2023 ] Eval epoch: 122
[ Wed Jun 28 20:01:46 2023 ] 	Mean test loss of 625 batches: 0.067561.
[ Wed Jun 28 20:01:46 2023 ] 	Mean test label-loss of 625 batches: 5.296701.
[ Wed Jun 28 20:01:46 2023 ] 	Top1: 100.00%
[ Wed Jun 28 20:01:46 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:01:47 2023 ] Training epoch: 123
[ Wed Jun 28 20:01:53 2023 ] 	Training loss: 6.1842.  Training acc: 94.01%.
[ Wed Jun 28 20:01:53 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:01:53 2023 ] Eval epoch: 123
[ Wed Jun 28 20:01:55 2023 ] 	Mean test loss of 625 batches: 0.088549.
[ Wed Jun 28 20:01:55 2023 ] 	Mean test label-loss of 625 batches: 5.312836.
[ Wed Jun 28 20:01:55 2023 ] 	Top1: 100.00%
[ Wed Jun 28 20:01:55 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:01:55 2023 ] Training epoch: 124
[ Wed Jun 28 20:02:01 2023 ] 	Training loss: 6.0203.  Training acc: 94.01%.
[ Wed Jun 28 20:02:01 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 20:02:01 2023 ] Eval epoch: 124
[ Wed Jun 28 20:02:03 2023 ] 	Mean test loss of 625 batches: 0.098069.
[ Wed Jun 28 20:02:03 2023 ] 	Mean test label-loss of 625 batches: 5.347551.
[ Wed Jun 28 20:02:03 2023 ] 	Top1: 97.37%
[ Wed Jun 28 20:02:03 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:02:04 2023 ] Training epoch: 125
[ Wed Jun 28 20:02:10 2023 ] 	Training loss: 5.9612.  Training acc: 94.92%.
[ Wed Jun 28 20:02:10 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:02:10 2023 ] Eval epoch: 125
[ Wed Jun 28 20:02:12 2023 ] 	Mean test loss of 625 batches: 0.072123.
[ Wed Jun 28 20:02:12 2023 ] 	Mean test label-loss of 625 batches: 5.322090.
[ Wed Jun 28 20:02:12 2023 ] 	Top1: 100.00%
[ Wed Jun 28 20:02:12 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:02:13 2023 ] Training epoch: 126
[ Wed Jun 28 20:02:19 2023 ] 	Training loss: 6.1164.  Training acc: 95.57%.
[ Wed Jun 28 20:02:19 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 20:02:19 2023 ] Eval epoch: 126
[ Wed Jun 28 20:02:21 2023 ] 	Mean test loss of 625 batches: 0.089111.
[ Wed Jun 28 20:02:21 2023 ] 	Mean test label-loss of 625 batches: 5.244761.
[ Wed Jun 28 20:02:21 2023 ] 	Top1: 100.00%
[ Wed Jun 28 20:02:21 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:02:22 2023 ] Training epoch: 127
[ Wed Jun 28 20:02:28 2023 ] 	Training loss: 6.1673.  Training acc: 94.01%.
[ Wed Jun 28 20:02:28 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:02:28 2023 ] Eval epoch: 127
[ Wed Jun 28 20:02:30 2023 ] 	Mean test loss of 625 batches: 0.109892.
[ Wed Jun 28 20:02:30 2023 ] 	Mean test label-loss of 625 batches: 5.276700.
[ Wed Jun 28 20:02:30 2023 ] 	Top1: 97.37%
[ Wed Jun 28 20:02:30 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:02:30 2023 ] Training epoch: 128
[ Wed Jun 28 20:02:36 2023 ] 	Training loss: 6.0444.  Training acc: 94.14%.
[ Wed Jun 28 20:02:36 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:02:36 2023 ] Eval epoch: 128
[ Wed Jun 28 20:02:38 2023 ] 	Mean test loss of 625 batches: 0.096548.
[ Wed Jun 28 20:02:38 2023 ] 	Mean test label-loss of 625 batches: 5.252375.
[ Wed Jun 28 20:02:38 2023 ] 	Top1: 100.00%
[ Wed Jun 28 20:02:38 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:02:39 2023 ] Training epoch: 129
[ Wed Jun 28 20:02:45 2023 ] 	Training loss: 5.9785.  Training acc: 94.66%.
[ Wed Jun 28 20:02:45 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 20:02:45 2023 ] Eval epoch: 129
[ Wed Jun 28 20:02:47 2023 ] 	Mean test loss of 625 batches: 0.087746.
[ Wed Jun 28 20:02:47 2023 ] 	Mean test label-loss of 625 batches: 5.154709.
[ Wed Jun 28 20:02:47 2023 ] 	Top1: 100.00%
[ Wed Jun 28 20:02:47 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:02:48 2023 ] Training epoch: 130
[ Wed Jun 28 20:02:54 2023 ] 	Training loss: 5.9684.  Training acc: 95.57%.
[ Wed Jun 28 20:02:54 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:02:54 2023 ] Eval epoch: 130
[ Wed Jun 28 20:02:56 2023 ] 	Mean test loss of 625 batches: 0.178049.
[ Wed Jun 28 20:02:56 2023 ] 	Mean test label-loss of 625 batches: 5.158628.
[ Wed Jun 28 20:02:56 2023 ] 	Top1: 92.11%
[ Wed Jun 28 20:02:56 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:02:56 2023 ] Training epoch: 131
[ Wed Jun 28 20:03:03 2023 ] 	Training loss: 6.1858.  Training acc: 94.53%.
[ Wed Jun 28 20:03:03 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:03:03 2023 ] Eval epoch: 131
[ Wed Jun 28 20:03:04 2023 ] 	Mean test loss of 625 batches: 0.129157.
[ Wed Jun 28 20:03:04 2023 ] 	Mean test label-loss of 625 batches: 5.211192.
[ Wed Jun 28 20:03:04 2023 ] 	Top1: 97.37%
[ Wed Jun 28 20:03:04 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:03:05 2023 ] Training epoch: 132
[ Wed Jun 28 20:03:11 2023 ] 	Training loss: 6.1709.  Training acc: 92.84%.
[ Wed Jun 28 20:03:11 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:03:11 2023 ] Eval epoch: 132
[ Wed Jun 28 20:03:13 2023 ] 	Mean test loss of 625 batches: 2.793092.
[ Wed Jun 28 20:03:13 2023 ] 	Mean test label-loss of 625 batches: 5.818793.
[ Wed Jun 28 20:03:13 2023 ] 	Top1: 39.47%
[ Wed Jun 28 20:03:13 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:03:14 2023 ] Training epoch: 133
[ Wed Jun 28 20:03:20 2023 ] 	Training loss: 6.8665.  Training acc: 51.56%.
[ Wed Jun 28 20:03:20 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:03:20 2023 ] Eval epoch: 133
[ Wed Jun 28 20:03:22 2023 ] 	Mean test loss of 625 batches: 2.293368.
[ Wed Jun 28 20:03:22 2023 ] 	Mean test label-loss of 625 batches: 6.758955.
[ Wed Jun 28 20:03:22 2023 ] 	Top1: 44.74%
[ Wed Jun 28 20:03:22 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:03:23 2023 ] Training epoch: 134
[ Wed Jun 28 20:03:29 2023 ] 	Training loss: 6.8074.  Training acc: 72.01%.
[ Wed Jun 28 20:03:29 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:03:29 2023 ] Eval epoch: 134
[ Wed Jun 28 20:03:31 2023 ] 	Mean test loss of 625 batches: 0.315655.
[ Wed Jun 28 20:03:31 2023 ] 	Mean test label-loss of 625 batches: 6.595311.
[ Wed Jun 28 20:03:31 2023 ] 	Top1: 89.47%
[ Wed Jun 28 20:03:31 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:03:31 2023 ] Training epoch: 135
[ Wed Jun 28 20:03:38 2023 ] 	Training loss: 6.5560.  Training acc: 83.72%.
[ Wed Jun 28 20:03:38 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:03:38 2023 ] Eval epoch: 135
[ Wed Jun 28 20:03:40 2023 ] 	Mean test loss of 625 batches: 0.291478.
[ Wed Jun 28 20:03:40 2023 ] 	Mean test label-loss of 625 batches: 6.330210.
[ Wed Jun 28 20:03:40 2023 ] 	Top1: 94.74%
[ Wed Jun 28 20:03:40 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:03:40 2023 ] Training epoch: 136
[ Wed Jun 28 20:03:46 2023 ] 	Training loss: 6.5819.  Training acc: 88.28%.
[ Wed Jun 28 20:03:46 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:03:46 2023 ] Eval epoch: 136
[ Wed Jun 28 20:03:48 2023 ] 	Mean test loss of 625 batches: 0.240345.
[ Wed Jun 28 20:03:48 2023 ] 	Mean test label-loss of 625 batches: 6.053950.
[ Wed Jun 28 20:03:48 2023 ] 	Top1: 94.74%
[ Wed Jun 28 20:03:48 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:03:49 2023 ] Training epoch: 137
[ Wed Jun 28 20:03:55 2023 ] 	Training loss: 6.4953.  Training acc: 88.67%.
[ Wed Jun 28 20:03:55 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 20:03:55 2023 ] Eval epoch: 137
[ Wed Jun 28 20:03:57 2023 ] 	Mean test loss of 625 batches: 0.230642.
[ Wed Jun 28 20:03:57 2023 ] 	Mean test label-loss of 625 batches: 5.882810.
[ Wed Jun 28 20:03:57 2023 ] 	Top1: 100.00%
[ Wed Jun 28 20:03:57 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:03:58 2023 ] Training epoch: 138
[ Wed Jun 28 20:04:04 2023 ] 	Training loss: 6.3596.  Training acc: 87.37%.
[ Wed Jun 28 20:04:04 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:04:04 2023 ] Eval epoch: 138
[ Wed Jun 28 20:04:06 2023 ] 	Mean test loss of 625 batches: 0.231118.
[ Wed Jun 28 20:04:06 2023 ] 	Mean test label-loss of 625 batches: 5.803511.
[ Wed Jun 28 20:04:06 2023 ] 	Top1: 94.74%
[ Wed Jun 28 20:04:06 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:04:06 2023 ] Training epoch: 139
[ Wed Jun 28 20:04:13 2023 ] 	Training loss: 6.4337.  Training acc: 90.62%.
[ Wed Jun 28 20:04:13 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 20:04:13 2023 ] Eval epoch: 139
[ Wed Jun 28 20:04:14 2023 ] 	Mean test loss of 625 batches: 0.215970.
[ Wed Jun 28 20:04:14 2023 ] 	Mean test label-loss of 625 batches: 5.730640.
[ Wed Jun 28 20:04:14 2023 ] 	Top1: 100.00%
[ Wed Jun 28 20:04:14 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:04:15 2023 ] Training epoch: 140
[ Wed Jun 28 20:04:21 2023 ] 	Training loss: 6.4811.  Training acc: 90.62%.
[ Wed Jun 28 20:04:21 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Wed Jun 28 20:04:21 2023 ] Eval epoch: 140
[ Wed Jun 28 20:04:23 2023 ] 	Mean test loss of 625 batches: 0.195434.
[ Wed Jun 28 20:04:23 2023 ] 	Mean test label-loss of 625 batches: 5.735141.
[ Wed Jun 28 20:04:23 2023 ] 	Top1: 97.37%
[ Wed Jun 28 20:04:23 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:04:24 2023 ] Training epoch: 141
[ Wed Jun 28 20:04:30 2023 ] 	Training loss: 6.3955.  Training acc: 87.89%.
[ Wed Jun 28 20:04:30 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:04:30 2023 ] Eval epoch: 141
[ Wed Jun 28 20:04:32 2023 ] 	Mean test loss of 625 batches: 0.220637.
[ Wed Jun 28 20:04:32 2023 ] 	Mean test label-loss of 625 batches: 5.712483.
[ Wed Jun 28 20:04:32 2023 ] 	Top1: 94.74%
[ Wed Jun 28 20:04:32 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:04:32 2023 ] Training epoch: 142
[ Wed Jun 28 20:04:39 2023 ] 	Training loss: 6.2523.  Training acc: 90.10%.
[ Wed Jun 28 20:04:39 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:04:39 2023 ] Eval epoch: 142
[ Wed Jun 28 20:04:41 2023 ] 	Mean test loss of 625 batches: 0.233786.
[ Wed Jun 28 20:04:41 2023 ] 	Mean test label-loss of 625 batches: 5.621665.
[ Wed Jun 28 20:04:41 2023 ] 	Top1: 92.11%
[ Wed Jun 28 20:04:41 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:04:41 2023 ] Training epoch: 143
[ Wed Jun 28 20:04:48 2023 ] 	Training loss: 6.5346.  Training acc: 90.49%.
[ Wed Jun 28 20:04:48 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:04:48 2023 ] Eval epoch: 143
[ Wed Jun 28 20:04:49 2023 ] 	Mean test loss of 625 batches: 0.218527.
[ Wed Jun 28 20:04:49 2023 ] 	Mean test label-loss of 625 batches: 5.555887.
[ Wed Jun 28 20:04:49 2023 ] 	Top1: 97.37%
[ Wed Jun 28 20:04:49 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:04:50 2023 ] Training epoch: 144
[ Wed Jun 28 20:04:56 2023 ] 	Training loss: 6.4098.  Training acc: 92.06%.
[ Wed Jun 28 20:04:56 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:04:56 2023 ] Eval epoch: 144
[ Wed Jun 28 20:04:58 2023 ] 	Mean test loss of 625 batches: 0.197230.
[ Wed Jun 28 20:04:58 2023 ] 	Mean test label-loss of 625 batches: 5.557835.
[ Wed Jun 28 20:04:58 2023 ] 	Top1: 97.37%
[ Wed Jun 28 20:04:58 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:04:59 2023 ] Training epoch: 145
[ Wed Jun 28 20:05:05 2023 ] 	Training loss: 6.2439.  Training acc: 91.28%.
[ Wed Jun 28 20:05:05 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:05:05 2023 ] Eval epoch: 145
[ Wed Jun 28 20:05:07 2023 ] 	Mean test loss of 625 batches: 0.228179.
[ Wed Jun 28 20:05:07 2023 ] 	Mean test label-loss of 625 batches: 5.545792.
[ Wed Jun 28 20:05:07 2023 ] 	Top1: 92.11%
[ Wed Jun 28 20:05:07 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:05:07 2023 ] Training epoch: 146
[ Wed Jun 28 20:05:14 2023 ] 	Training loss: 6.1875.  Training acc: 89.45%.
[ Wed Jun 28 20:05:14 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:05:14 2023 ] Eval epoch: 146
[ Wed Jun 28 20:05:16 2023 ] 	Mean test loss of 625 batches: 0.193026.
[ Wed Jun 28 20:05:16 2023 ] 	Mean test label-loss of 625 batches: 5.557803.
[ Wed Jun 28 20:05:16 2023 ] 	Top1: 94.74%
[ Wed Jun 28 20:05:16 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:05:16 2023 ] Training epoch: 147
[ Wed Jun 28 20:05:22 2023 ] 	Training loss: 6.1685.  Training acc: 87.37%.
[ Wed Jun 28 20:05:22 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:05:22 2023 ] Eval epoch: 147
[ Wed Jun 28 20:05:24 2023 ] 	Mean test loss of 625 batches: 0.194551.
[ Wed Jun 28 20:05:24 2023 ] 	Mean test label-loss of 625 batches: 5.576040.
[ Wed Jun 28 20:05:24 2023 ] 	Top1: 92.11%
[ Wed Jun 28 20:05:24 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:05:25 2023 ] Training epoch: 148
[ Wed Jun 28 20:05:31 2023 ] 	Training loss: 6.3935.  Training acc: 89.45%.
[ Wed Jun 28 20:05:31 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Wed Jun 28 20:05:31 2023 ] Eval epoch: 148
[ Wed Jun 28 20:05:33 2023 ] 	Mean test loss of 625 batches: 0.170624.
[ Wed Jun 28 20:05:33 2023 ] 	Mean test label-loss of 625 batches: 5.553160.
[ Wed Jun 28 20:05:33 2023 ] 	Top1: 97.37%
[ Wed Jun 28 20:05:33 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:05:33 2023 ] Training epoch: 149
[ Wed Jun 28 20:05:40 2023 ] 	Training loss: 6.1267.  Training acc: 93.23%.
[ Wed Jun 28 20:05:40 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 20:05:40 2023 ] Eval epoch: 149
[ Wed Jun 28 20:05:42 2023 ] 	Mean test loss of 625 batches: 0.158890.
[ Wed Jun 28 20:05:42 2023 ] 	Mean test label-loss of 625 batches: 5.509690.
[ Wed Jun 28 20:05:42 2023 ] 	Top1: 100.00%
[ Wed Jun 28 20:05:42 2023 ] 	Top5: 100.00%
[ Wed Jun 28 20:05:42 2023 ] Training epoch: 150
[ Wed Jun 28 20:05:48 2023 ] 	Training loss: 6.1812.  Training acc: 89.84%.
[ Wed Jun 28 20:05:48 2023 ] 	Time consumption: [Data]06%, [Network]93%
[ Wed Jun 28 20:05:48 2023 ] Eval epoch: 150
[ Wed Jun 28 20:05:50 2023 ] 	Mean test loss of 625 batches: 0.180259.
[ Wed Jun 28 20:05:50 2023 ] 	Mean test label-loss of 625 batches: 5.442846.
[ Wed Jun 28 20:05:50 2023 ] 	Top1: 97.37%
[ Wed Jun 28 20:05:50 2023 ] 	Top5: 100.00%
