[ Mon Jun 19 15:20:14 2023 ] using warm up, epoch: 5
[ Mon Jun 19 15:23:05 2023 ] using warm up, epoch: 5
[ Mon Jun 19 15:23:19 2023 ] using warm up, epoch: 5
[ Mon Jun 19 15:25:18 2023 ] using warm up, epoch: 5
[ Mon Jun 19 15:25:20 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 20, 'num_person': 1, 'num_class': 60, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Mon Jun 19 15:25:20 2023 ] # Parameters: 1546572
[ Mon Jun 19 15:25:20 2023 ] Training epoch: 1
[ Mon Jun 19 17:31:08 2023 ] using warm up, epoch: 5
[ Mon Jun 19 17:31:10 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 60, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Mon Jun 19 17:31:10 2023 ] # Parameters: 1553607
[ Mon Jun 19 17:31:10 2023 ] Training epoch: 1
[ Mon Jun 19 17:31:14 2023 ] 	Training loss: 36.8678.  Training acc: 19.79%.
[ Mon Jun 19 17:31:14 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Mon Jun 19 17:31:14 2023 ] Eval epoch: 1
[ Mon Jun 19 17:35:36 2023 ] using warm up, epoch: 5
[ Mon Jun 19 17:35:38 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 60, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Mon Jun 19 17:35:38 2023 ] # Parameters: 1553607
[ Mon Jun 19 17:35:38 2023 ] Training epoch: 1
[ Mon Jun 19 17:35:42 2023 ] 	Training loss: 36.8801.  Training acc: 20.31%.
[ Mon Jun 19 17:35:42 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Mon Jun 19 17:35:42 2023 ] Eval epoch: 1
[ Mon Jun 19 17:35:42 2023 ] 	Mean test loss of 625 batches: 305.277435.
[ Mon Jun 19 17:36:27 2023 ] using warm up, epoch: 5
[ Mon Jun 19 17:36:29 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 60, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Mon Jun 19 17:36:29 2023 ] # Parameters: 1553607
[ Mon Jun 19 17:36:29 2023 ] Training epoch: 1
[ Mon Jun 19 17:36:32 2023 ] 	Training loss: 37.1535.  Training acc: 19.79%.
[ Mon Jun 19 17:36:32 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Mon Jun 19 17:36:32 2023 ] Eval epoch: 1
[ Mon Jun 19 17:36:33 2023 ] 	Mean test loss of 625 batches: 404.175415.
[ Mon Jun 19 17:37:24 2023 ] using warm up, epoch: 5
[ Mon Jun 19 17:37:35 2023 ] using warm up, epoch: 5
[ Mon Jun 19 17:37:45 2023 ] using warm up, epoch: 5
[ Mon Jun 19 17:37:47 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 60, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Mon Jun 19 17:37:47 2023 ] # Parameters: 1553607
[ Mon Jun 19 17:37:47 2023 ] Training epoch: 1
[ Mon Jun 19 17:37:51 2023 ] 	Training loss: 36.8636.  Training acc: 19.79%.
[ Mon Jun 19 17:37:51 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Mon Jun 19 17:37:51 2023 ] Eval epoch: 1
[ Mon Jun 19 17:37:51 2023 ] 	Mean test loss of 625 batches: 428.155121.
[ Mon Jun 19 17:37:51 2023 ] 	Top1: 40.35%
[ Mon Jun 19 17:37:51 2023 ] 	Top5: 71.93%
[ Mon Jun 19 17:37:51 2023 ] Training epoch: 2
[ Mon Jun 19 17:37:52 2023 ] 	Training loss: 41.1281.  Training acc: 32.29%.
[ Mon Jun 19 17:37:52 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Mon Jun 19 17:37:52 2023 ] Eval epoch: 2
[ Mon Jun 19 17:37:52 2023 ] 	Mean test loss of 625 batches: 61925.511719.
[ Mon Jun 19 17:37:52 2023 ] 	Top1: 31.58%
[ Mon Jun 19 17:37:52 2023 ] 	Top5: 71.93%
[ Mon Jun 19 17:37:52 2023 ] Training epoch: 3
[ Mon Jun 19 17:37:53 2023 ] 	Training loss: 15.3116.  Training acc: 29.69%.
[ Mon Jun 19 17:37:53 2023 ] 	Time consumption: [Data]26%, [Network]73%
[ Mon Jun 19 17:37:53 2023 ] Eval epoch: 3
[ Mon Jun 19 17:37:53 2023 ] 	Mean test loss of 625 batches: 512.908875.
[ Mon Jun 19 17:37:53 2023 ] 	Top1: 0.00%
[ Mon Jun 19 17:37:53 2023 ] 	Top5: 0.00%
[ Mon Jun 19 17:37:53 2023 ] Training epoch: 4
[ Mon Jun 19 17:37:54 2023 ] 	Training loss: 9.2179.  Training acc: 30.73%.
[ Mon Jun 19 17:37:54 2023 ] 	Time consumption: [Data]26%, [Network]73%
[ Mon Jun 19 17:37:54 2023 ] Eval epoch: 4
[ Mon Jun 19 17:37:54 2023 ] 	Mean test loss of 625 batches: 606.476196.
[ Mon Jun 19 17:37:54 2023 ] 	Top1: 40.35%
[ Mon Jun 19 17:37:54 2023 ] 	Top5: 40.35%
[ Mon Jun 19 17:37:54 2023 ] Training epoch: 5
[ Mon Jun 19 17:37:55 2023 ] 	Training loss: 8.8355.  Training acc: 33.85%.
[ Mon Jun 19 17:37:55 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Mon Jun 19 17:37:55 2023 ] Eval epoch: 5
[ Mon Jun 19 17:37:55 2023 ] 	Mean test loss of 625 batches: 137.097473.
[ Mon Jun 19 17:37:55 2023 ] 	Top1: 0.00%
[ Mon Jun 19 17:37:55 2023 ] 	Top5: 0.00%
[ Mon Jun 19 17:37:55 2023 ] Training epoch: 6
[ Mon Jun 19 17:37:56 2023 ] 	Training loss: 9.3583.  Training acc: 34.90%.
[ Mon Jun 19 17:37:56 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Mon Jun 19 17:37:56 2023 ] Eval epoch: 6
[ Mon Jun 19 17:37:56 2023 ] 	Mean test loss of 625 batches: 64.673386.
[ Mon Jun 19 17:37:56 2023 ] 	Top1: 0.00%
[ Mon Jun 19 17:37:56 2023 ] 	Top5: 0.00%
[ Mon Jun 19 17:37:56 2023 ] Training epoch: 7
[ Mon Jun 19 17:37:57 2023 ] 	Training loss: 11.7666.  Training acc: 29.69%.
[ Mon Jun 19 17:37:57 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Mon Jun 19 17:37:57 2023 ] Eval epoch: 7
[ Mon Jun 19 17:37:57 2023 ] 	Mean test loss of 625 batches: 15.011700.
[ Mon Jun 19 17:37:57 2023 ] 	Top1: 40.35%
[ Mon Jun 19 17:37:57 2023 ] 	Top5: 57.89%
[ Mon Jun 19 17:37:57 2023 ] Training epoch: 8
[ Mon Jun 19 17:37:58 2023 ] 	Training loss: 11.4710.  Training acc: 31.25%.
[ Mon Jun 19 17:37:58 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Mon Jun 19 17:37:58 2023 ] Eval epoch: 8
[ Mon Jun 19 17:37:58 2023 ] 	Mean test loss of 625 batches: 22.644619.
[ Mon Jun 19 17:37:58 2023 ] 	Top1: 31.58%
[ Mon Jun 19 17:37:58 2023 ] 	Top5: 78.95%
[ Mon Jun 19 17:37:58 2023 ] Training epoch: 9
[ Mon Jun 19 17:37:59 2023 ] 	Training loss: 11.6280.  Training acc: 31.25%.
[ Mon Jun 19 17:37:59 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Mon Jun 19 17:37:59 2023 ] Eval epoch: 9
[ Mon Jun 19 17:37:59 2023 ] 	Mean test loss of 625 batches: 22.517485.
[ Mon Jun 19 17:37:59 2023 ] 	Top1: 31.58%
[ Mon Jun 19 17:37:59 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:37:59 2023 ] Training epoch: 10
[ Mon Jun 19 17:38:00 2023 ] 	Training loss: 10.7862.  Training acc: 30.21%.
[ Mon Jun 19 17:38:00 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Mon Jun 19 17:38:00 2023 ] Eval epoch: 10
[ Mon Jun 19 17:38:00 2023 ] 	Mean test loss of 625 batches: 11.228007.
[ Mon Jun 19 17:38:00 2023 ] 	Top1: 31.58%
[ Mon Jun 19 17:38:00 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:00 2023 ] Training epoch: 11
[ Mon Jun 19 17:38:01 2023 ] 	Training loss: 8.7572.  Training acc: 31.25%.
[ Mon Jun 19 17:38:01 2023 ] 	Time consumption: [Data]29%, [Network]70%
[ Mon Jun 19 17:38:01 2023 ] Eval epoch: 11
[ Mon Jun 19 17:38:01 2023 ] 	Mean test loss of 625 batches: 6.145443.
[ Mon Jun 19 17:38:01 2023 ] 	Top1: 40.35%
[ Mon Jun 19 17:38:01 2023 ] 	Top5: 98.25%
[ Mon Jun 19 17:38:01 2023 ] Training epoch: 12
[ Mon Jun 19 17:38:02 2023 ] 	Training loss: 28.7824.  Training acc: 26.04%.
[ Mon Jun 19 17:38:02 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Mon Jun 19 17:38:02 2023 ] Eval epoch: 12
[ Mon Jun 19 17:38:02 2023 ] 	Mean test loss of 625 batches: 39.531448.
[ Mon Jun 19 17:38:02 2023 ] 	Top1: 31.58%
[ Mon Jun 19 17:38:02 2023 ] 	Top5: 31.58%
[ Mon Jun 19 17:38:02 2023 ] Training epoch: 13
[ Mon Jun 19 17:38:03 2023 ] 	Training loss: 22.5388.  Training acc: 29.17%.
[ Mon Jun 19 17:38:03 2023 ] 	Time consumption: [Data]25%, [Network]75%
[ Mon Jun 19 17:38:03 2023 ] Eval epoch: 13
[ Mon Jun 19 17:38:03 2023 ] 	Mean test loss of 625 batches: 7.207154.
[ Mon Jun 19 17:38:03 2023 ] 	Top1: 42.11%
[ Mon Jun 19 17:38:03 2023 ] 	Top5: 77.19%
[ Mon Jun 19 17:38:03 2023 ] Training epoch: 14
[ Mon Jun 19 17:38:04 2023 ] 	Training loss: 8.5865.  Training acc: 32.81%.
[ Mon Jun 19 17:38:04 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Mon Jun 19 17:38:04 2023 ] Eval epoch: 14
[ Mon Jun 19 17:38:04 2023 ] 	Mean test loss of 625 batches: 4.562278.
[ Mon Jun 19 17:38:04 2023 ] 	Top1: 31.58%
[ Mon Jun 19 17:38:04 2023 ] 	Top5: 73.68%
[ Mon Jun 19 17:38:04 2023 ] Training epoch: 15
[ Mon Jun 19 17:38:05 2023 ] 	Training loss: 7.9846.  Training acc: 32.81%.
[ Mon Jun 19 17:38:05 2023 ] 	Time consumption: [Data]28%, [Network]71%
[ Mon Jun 19 17:38:05 2023 ] Eval epoch: 15
[ Mon Jun 19 17:38:05 2023 ] 	Mean test loss of 625 batches: 26.242262.
[ Mon Jun 19 17:38:05 2023 ] 	Top1: 40.35%
[ Mon Jun 19 17:38:05 2023 ] 	Top5: 68.42%
[ Mon Jun 19 17:38:05 2023 ] Training epoch: 16
[ Mon Jun 19 17:38:06 2023 ] 	Training loss: 8.9179.  Training acc: 42.19%.
[ Mon Jun 19 17:38:06 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Mon Jun 19 17:38:06 2023 ] Eval epoch: 16
[ Mon Jun 19 17:38:06 2023 ] 	Mean test loss of 625 batches: 6.353689.
[ Mon Jun 19 17:38:06 2023 ] 	Top1: 40.35%
[ Mon Jun 19 17:38:06 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:06 2023 ] Training epoch: 17
[ Mon Jun 19 17:38:07 2023 ] 	Training loss: 7.6054.  Training acc: 30.73%.
[ Mon Jun 19 17:38:07 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Mon Jun 19 17:38:07 2023 ] Eval epoch: 17
[ Mon Jun 19 17:38:07 2023 ] 	Mean test loss of 625 batches: 7.199335.
[ Mon Jun 19 17:38:07 2023 ] 	Top1: 31.58%
[ Mon Jun 19 17:38:07 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:07 2023 ] Training epoch: 18
[ Mon Jun 19 17:38:08 2023 ] 	Training loss: 8.0039.  Training acc: 35.94%.
[ Mon Jun 19 17:38:08 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Mon Jun 19 17:38:08 2023 ] Eval epoch: 18
[ Mon Jun 19 17:38:08 2023 ] 	Mean test loss of 625 batches: 4.966346.
[ Mon Jun 19 17:38:08 2023 ] 	Top1: 43.86%
[ Mon Jun 19 17:38:08 2023 ] 	Top5: 85.96%
[ Mon Jun 19 17:38:08 2023 ] Training epoch: 19
[ Mon Jun 19 17:38:09 2023 ] 	Training loss: 5.7359.  Training acc: 40.10%.
[ Mon Jun 19 17:38:09 2023 ] 	Time consumption: [Data]27%, [Network]72%
[ Mon Jun 19 17:38:09 2023 ] Eval epoch: 19
[ Mon Jun 19 17:38:09 2023 ] 	Mean test loss of 625 batches: 3.884236.
[ Mon Jun 19 17:38:09 2023 ] 	Top1: 52.63%
[ Mon Jun 19 17:38:09 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:09 2023 ] Training epoch: 20
[ Mon Jun 19 17:38:10 2023 ] 	Training loss: 6.0871.  Training acc: 43.23%.
[ Mon Jun 19 17:38:10 2023 ] 	Time consumption: [Data]29%, [Network]70%
[ Mon Jun 19 17:38:10 2023 ] Eval epoch: 20
[ Mon Jun 19 17:38:10 2023 ] 	Mean test loss of 625 batches: 7.304194.
[ Mon Jun 19 17:38:10 2023 ] 	Top1: 66.67%
[ Mon Jun 19 17:38:10 2023 ] 	Top5: 71.93%
[ Mon Jun 19 17:38:10 2023 ] Training epoch: 21
[ Mon Jun 19 17:38:11 2023 ] 	Training loss: 7.8863.  Training acc: 43.23%.
[ Mon Jun 19 17:38:11 2023 ] 	Time consumption: [Data]32%, [Network]68%
[ Mon Jun 19 17:38:11 2023 ] Eval epoch: 21
[ Mon Jun 19 17:38:11 2023 ] 	Mean test loss of 625 batches: 10.070175.
[ Mon Jun 19 17:38:11 2023 ] 	Top1: 28.07%
[ Mon Jun 19 17:38:11 2023 ] 	Top5: 73.68%
[ Mon Jun 19 17:38:11 2023 ] Training epoch: 22
[ Mon Jun 19 17:38:12 2023 ] 	Training loss: 7.9790.  Training acc: 42.71%.
[ Mon Jun 19 17:38:12 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Mon Jun 19 17:38:12 2023 ] Eval epoch: 22
[ Mon Jun 19 17:38:12 2023 ] 	Mean test loss of 625 batches: 2.663132.
[ Mon Jun 19 17:38:12 2023 ] 	Top1: 52.63%
[ Mon Jun 19 17:38:12 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:12 2023 ] Training epoch: 23
[ Mon Jun 19 17:38:13 2023 ] 	Training loss: 4.3633.  Training acc: 41.15%.
[ Mon Jun 19 17:38:13 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Mon Jun 19 17:38:13 2023 ] Eval epoch: 23
[ Mon Jun 19 17:38:14 2023 ] 	Mean test loss of 625 batches: 4.652156.
[ Mon Jun 19 17:38:14 2023 ] 	Top1: 31.58%
[ Mon Jun 19 17:38:14 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:14 2023 ] Training epoch: 24
[ Mon Jun 19 17:38:15 2023 ] 	Training loss: 5.9443.  Training acc: 39.06%.
[ Mon Jun 19 17:38:15 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Mon Jun 19 17:38:15 2023 ] Eval epoch: 24
[ Mon Jun 19 17:38:15 2023 ] 	Mean test loss of 625 batches: 5.318343.
[ Mon Jun 19 17:38:15 2023 ] 	Top1: 40.35%
[ Mon Jun 19 17:38:15 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:15 2023 ] Training epoch: 25
[ Mon Jun 19 17:38:16 2023 ] 	Training loss: 4.5714.  Training acc: 41.67%.
[ Mon Jun 19 17:38:16 2023 ] 	Time consumption: [Data]22%, [Network]77%
[ Mon Jun 19 17:38:16 2023 ] Eval epoch: 25
[ Mon Jun 19 17:38:16 2023 ] 	Mean test loss of 625 batches: 2.804785.
[ Mon Jun 19 17:38:16 2023 ] 	Top1: 40.35%
[ Mon Jun 19 17:38:16 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:16 2023 ] Training epoch: 26
[ Mon Jun 19 17:38:17 2023 ] 	Training loss: 4.7523.  Training acc: 45.31%.
[ Mon Jun 19 17:38:17 2023 ] 	Time consumption: [Data]26%, [Network]73%
[ Mon Jun 19 17:38:17 2023 ] Eval epoch: 26
[ Mon Jun 19 17:38:17 2023 ] 	Mean test loss of 625 batches: 2.641121.
[ Mon Jun 19 17:38:17 2023 ] 	Top1: 40.35%
[ Mon Jun 19 17:38:17 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:17 2023 ] Training epoch: 27
[ Mon Jun 19 17:38:18 2023 ] 	Training loss: 3.5280.  Training acc: 50.00%.
[ Mon Jun 19 17:38:18 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Mon Jun 19 17:38:18 2023 ] Eval epoch: 27
[ Mon Jun 19 17:38:18 2023 ] 	Mean test loss of 625 batches: 1.992669.
[ Mon Jun 19 17:38:18 2023 ] 	Top1: 40.35%
[ Mon Jun 19 17:38:18 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:18 2023 ] Training epoch: 28
[ Mon Jun 19 17:38:19 2023 ] 	Training loss: 3.7477.  Training acc: 43.23%.
[ Mon Jun 19 17:38:19 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Mon Jun 19 17:38:19 2023 ] Eval epoch: 28
[ Mon Jun 19 17:38:19 2023 ] 	Mean test loss of 625 batches: 3.307498.
[ Mon Jun 19 17:38:19 2023 ] 	Top1: 28.07%
[ Mon Jun 19 17:38:19 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:19 2023 ] Training epoch: 29
[ Mon Jun 19 17:38:20 2023 ] 	Training loss: 3.9706.  Training acc: 39.58%.
[ Mon Jun 19 17:38:20 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Mon Jun 19 17:38:20 2023 ] Eval epoch: 29
[ Mon Jun 19 17:38:20 2023 ] 	Mean test loss of 625 batches: 2.526957.
[ Mon Jun 19 17:38:20 2023 ] 	Top1: 31.58%
[ Mon Jun 19 17:38:20 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:20 2023 ] Training epoch: 30
[ Mon Jun 19 17:38:21 2023 ] 	Training loss: 3.4173.  Training acc: 45.83%.
[ Mon Jun 19 17:38:21 2023 ] 	Time consumption: [Data]27%, [Network]72%
[ Mon Jun 19 17:38:21 2023 ] Eval epoch: 30
[ Mon Jun 19 17:38:21 2023 ] 	Mean test loss of 625 batches: 1.603680.
[ Mon Jun 19 17:38:21 2023 ] 	Top1: 71.93%
[ Mon Jun 19 17:38:21 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:21 2023 ] Training epoch: 31
[ Mon Jun 19 17:38:22 2023 ] 	Training loss: 3.4377.  Training acc: 48.96%.
[ Mon Jun 19 17:38:22 2023 ] 	Time consumption: [Data]27%, [Network]72%
[ Mon Jun 19 17:38:22 2023 ] Eval epoch: 31
[ Mon Jun 19 17:38:22 2023 ] 	Mean test loss of 625 batches: 1.502682.
[ Mon Jun 19 17:38:22 2023 ] 	Top1: 71.93%
[ Mon Jun 19 17:38:22 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:22 2023 ] Training epoch: 32
[ Mon Jun 19 17:38:23 2023 ] 	Training loss: 3.1016.  Training acc: 48.96%.
[ Mon Jun 19 17:38:23 2023 ] 	Time consumption: [Data]29%, [Network]70%
[ Mon Jun 19 17:38:23 2023 ] Eval epoch: 32
[ Mon Jun 19 17:38:23 2023 ] 	Mean test loss of 625 batches: 1.692318.
[ Mon Jun 19 17:38:23 2023 ] 	Top1: 71.93%
[ Mon Jun 19 17:38:23 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:23 2023 ] Training epoch: 33
[ Mon Jun 19 17:38:24 2023 ] 	Training loss: 2.6048.  Training acc: 54.17%.
[ Mon Jun 19 17:38:24 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Mon Jun 19 17:38:24 2023 ] Eval epoch: 33
[ Mon Jun 19 17:38:24 2023 ] 	Mean test loss of 625 batches: 1.658474.
[ Mon Jun 19 17:38:24 2023 ] 	Top1: 71.93%
[ Mon Jun 19 17:38:24 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:24 2023 ] Training epoch: 34
[ Mon Jun 19 17:38:25 2023 ] 	Training loss: 2.6991.  Training acc: 56.77%.
[ Mon Jun 19 17:38:25 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Mon Jun 19 17:38:25 2023 ] Eval epoch: 34
[ Mon Jun 19 17:38:25 2023 ] 	Mean test loss of 625 batches: 1.578167.
[ Mon Jun 19 17:38:25 2023 ] 	Top1: 71.93%
[ Mon Jun 19 17:38:25 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:25 2023 ] Training epoch: 35
[ Mon Jun 19 17:38:26 2023 ] 	Training loss: 2.5192.  Training acc: 51.04%.
[ Mon Jun 19 17:38:26 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Mon Jun 19 17:38:26 2023 ] Eval epoch: 35
[ Mon Jun 19 17:38:26 2023 ] 	Mean test loss of 625 batches: 1.416576.
[ Mon Jun 19 17:38:26 2023 ] 	Top1: 71.93%
[ Mon Jun 19 17:38:26 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:26 2023 ] Training epoch: 36
[ Mon Jun 19 17:38:27 2023 ] 	Training loss: 2.3130.  Training acc: 56.77%.
[ Mon Jun 19 17:38:27 2023 ] 	Time consumption: [Data]24%, [Network]76%
[ Mon Jun 19 17:38:27 2023 ] Eval epoch: 36
[ Mon Jun 19 17:38:28 2023 ] 	Mean test loss of 625 batches: 1.791679.
[ Mon Jun 19 17:38:28 2023 ] 	Top1: 59.65%
[ Mon Jun 19 17:38:28 2023 ] 	Top5: 98.25%
[ Mon Jun 19 17:38:28 2023 ] Training epoch: 37
[ Mon Jun 19 17:38:28 2023 ] 	Training loss: 2.1228.  Training acc: 63.02%.
[ Mon Jun 19 17:38:28 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Mon Jun 19 17:38:28 2023 ] Eval epoch: 37
[ Mon Jun 19 17:38:29 2023 ] 	Mean test loss of 625 batches: 2.093450.
[ Mon Jun 19 17:38:29 2023 ] 	Top1: 64.91%
[ Mon Jun 19 17:38:29 2023 ] 	Top5: 96.49%
[ Mon Jun 19 17:38:29 2023 ] Training epoch: 38
[ Mon Jun 19 17:38:29 2023 ] 	Training loss: 2.1137.  Training acc: 65.10%.
[ Mon Jun 19 17:38:29 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Mon Jun 19 17:38:29 2023 ] Eval epoch: 38
[ Mon Jun 19 17:38:30 2023 ] 	Mean test loss of 625 batches: 1.825123.
[ Mon Jun 19 17:38:30 2023 ] 	Top1: 66.67%
[ Mon Jun 19 17:38:30 2023 ] 	Top5: 98.25%
[ Mon Jun 19 17:38:30 2023 ] Training epoch: 39
[ Mon Jun 19 17:38:30 2023 ] 	Training loss: 1.9219.  Training acc: 66.15%.
[ Mon Jun 19 17:38:30 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Mon Jun 19 17:38:30 2023 ] Eval epoch: 39
[ Mon Jun 19 17:38:31 2023 ] 	Mean test loss of 625 batches: 1.659010.
[ Mon Jun 19 17:38:31 2023 ] 	Top1: 70.18%
[ Mon Jun 19 17:38:31 2023 ] 	Top5: 98.25%
[ Mon Jun 19 17:38:31 2023 ] Training epoch: 40
[ Mon Jun 19 17:38:31 2023 ] 	Training loss: 2.1782.  Training acc: 61.98%.
[ Mon Jun 19 17:38:31 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Mon Jun 19 17:38:31 2023 ] Eval epoch: 40
[ Mon Jun 19 17:38:32 2023 ] 	Mean test loss of 625 batches: 1.976815.
[ Mon Jun 19 17:38:32 2023 ] 	Top1: 50.88%
[ Mon Jun 19 17:38:32 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:32 2023 ] Training epoch: 41
[ Mon Jun 19 17:38:32 2023 ] 	Training loss: 2.1309.  Training acc: 59.38%.
[ Mon Jun 19 17:38:32 2023 ] 	Time consumption: [Data]28%, [Network]71%
[ Mon Jun 19 17:38:32 2023 ] Eval epoch: 41
[ Mon Jun 19 17:38:33 2023 ] 	Mean test loss of 625 batches: 1.468832.
[ Mon Jun 19 17:38:33 2023 ] 	Top1: 54.39%
[ Mon Jun 19 17:38:33 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:33 2023 ] Training epoch: 42
[ Mon Jun 19 17:38:33 2023 ] 	Training loss: 2.0335.  Training acc: 59.90%.
[ Mon Jun 19 17:38:33 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Mon Jun 19 17:38:33 2023 ] Eval epoch: 42
[ Mon Jun 19 17:38:34 2023 ] 	Mean test loss of 625 batches: 1.574723.
[ Mon Jun 19 17:38:34 2023 ] 	Top1: 71.93%
[ Mon Jun 19 17:38:34 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:34 2023 ] Training epoch: 43
[ Mon Jun 19 17:38:34 2023 ] 	Training loss: 2.1480.  Training acc: 58.33%.
[ Mon Jun 19 17:38:34 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Mon Jun 19 17:38:34 2023 ] Eval epoch: 43
[ Mon Jun 19 17:38:35 2023 ] 	Mean test loss of 625 batches: 1.450881.
[ Mon Jun 19 17:38:35 2023 ] 	Top1: 75.44%
[ Mon Jun 19 17:38:35 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:35 2023 ] Training epoch: 44
[ Mon Jun 19 17:38:35 2023 ] 	Training loss: 1.8913.  Training acc: 66.15%.
[ Mon Jun 19 17:38:35 2023 ] 	Time consumption: [Data]31%, [Network]69%
[ Mon Jun 19 17:38:35 2023 ] Eval epoch: 44
[ Mon Jun 19 17:38:36 2023 ] 	Mean test loss of 625 batches: 1.581196.
[ Mon Jun 19 17:38:36 2023 ] 	Top1: 71.93%
[ Mon Jun 19 17:38:36 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:36 2023 ] Training epoch: 45
[ Mon Jun 19 17:38:36 2023 ] 	Training loss: 1.8641.  Training acc: 70.31%.
[ Mon Jun 19 17:38:36 2023 ] 	Time consumption: [Data]32%, [Network]68%
[ Mon Jun 19 17:38:36 2023 ] Eval epoch: 45
[ Mon Jun 19 17:38:37 2023 ] 	Mean test loss of 625 batches: 1.399066.
[ Mon Jun 19 17:38:37 2023 ] 	Top1: 71.93%
[ Mon Jun 19 17:38:37 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:37 2023 ] Training epoch: 46
[ Mon Jun 19 17:38:37 2023 ] 	Training loss: 1.7326.  Training acc: 70.83%.
[ Mon Jun 19 17:38:37 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Mon Jun 19 17:38:37 2023 ] Eval epoch: 46
[ Mon Jun 19 17:38:38 2023 ] 	Mean test loss of 625 batches: 1.366141.
[ Mon Jun 19 17:38:38 2023 ] 	Top1: 82.46%
[ Mon Jun 19 17:38:38 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:38 2023 ] Training epoch: 47
[ Mon Jun 19 17:38:38 2023 ] 	Training loss: 1.8944.  Training acc: 63.02%.
[ Mon Jun 19 17:38:38 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Mon Jun 19 17:38:38 2023 ] Eval epoch: 47
[ Mon Jun 19 17:38:39 2023 ] 	Mean test loss of 625 batches: 1.307021.
[ Mon Jun 19 17:38:39 2023 ] 	Top1: 71.93%
[ Mon Jun 19 17:38:39 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:39 2023 ] Training epoch: 48
[ Mon Jun 19 17:38:39 2023 ] 	Training loss: 1.7680.  Training acc: 71.35%.
[ Mon Jun 19 17:38:39 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Mon Jun 19 17:38:39 2023 ] Eval epoch: 48
[ Mon Jun 19 17:38:40 2023 ] 	Mean test loss of 625 batches: 1.474550.
[ Mon Jun 19 17:38:40 2023 ] 	Top1: 54.39%
[ Mon Jun 19 17:38:40 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:40 2023 ] Training epoch: 49
[ Mon Jun 19 17:38:40 2023 ] 	Training loss: 1.9542.  Training acc: 61.46%.
[ Mon Jun 19 17:38:40 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Mon Jun 19 17:38:40 2023 ] Eval epoch: 49
[ Mon Jun 19 17:38:41 2023 ] 	Mean test loss of 625 batches: 1.252128.
[ Mon Jun 19 17:38:41 2023 ] 	Top1: 78.95%
[ Mon Jun 19 17:38:41 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:41 2023 ] Training epoch: 50
[ Mon Jun 19 17:38:41 2023 ] 	Training loss: 1.7914.  Training acc: 67.71%.
[ Mon Jun 19 17:38:41 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Mon Jun 19 17:38:41 2023 ] Eval epoch: 50
[ Mon Jun 19 17:38:42 2023 ] 	Mean test loss of 625 batches: 1.206127.
[ Mon Jun 19 17:38:42 2023 ] 	Top1: 94.74%
[ Mon Jun 19 17:38:42 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:42 2023 ] Training epoch: 51
[ Mon Jun 19 17:38:42 2023 ] 	Training loss: 1.7090.  Training acc: 67.19%.
[ Mon Jun 19 17:38:42 2023 ] 	Time consumption: [Data]32%, [Network]68%
[ Mon Jun 19 17:38:42 2023 ] Eval epoch: 51
[ Mon Jun 19 17:38:43 2023 ] 	Mean test loss of 625 batches: 1.361136.
[ Mon Jun 19 17:38:43 2023 ] 	Top1: 84.21%
[ Mon Jun 19 17:38:43 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:43 2023 ] Training epoch: 52
[ Mon Jun 19 17:38:43 2023 ] 	Training loss: 1.7378.  Training acc: 64.06%.
[ Mon Jun 19 17:38:43 2023 ] 	Time consumption: [Data]32%, [Network]68%
[ Mon Jun 19 17:38:43 2023 ] Eval epoch: 52
[ Mon Jun 19 17:38:43 2023 ] 	Mean test loss of 625 batches: 1.313355.
[ Mon Jun 19 17:38:44 2023 ] 	Top1: 84.21%
[ Mon Jun 19 17:38:44 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:44 2023 ] Training epoch: 53
[ Mon Jun 19 17:38:44 2023 ] 	Training loss: 1.6249.  Training acc: 69.79%.
[ Mon Jun 19 17:38:44 2023 ] 	Time consumption: [Data]27%, [Network]72%
[ Mon Jun 19 17:38:44 2023 ] Eval epoch: 53
[ Mon Jun 19 17:38:45 2023 ] 	Mean test loss of 625 batches: 1.183808.
[ Mon Jun 19 17:38:45 2023 ] 	Top1: 89.47%
[ Mon Jun 19 17:38:45 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:45 2023 ] Training epoch: 54
[ Mon Jun 19 17:38:45 2023 ] 	Training loss: 1.6692.  Training acc: 66.15%.
[ Mon Jun 19 17:38:45 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Mon Jun 19 17:38:45 2023 ] Eval epoch: 54
[ Mon Jun 19 17:38:46 2023 ] 	Mean test loss of 625 batches: 1.212040.
[ Mon Jun 19 17:38:46 2023 ] 	Top1: 87.72%
[ Mon Jun 19 17:38:46 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:46 2023 ] Training epoch: 55
[ Mon Jun 19 17:38:46 2023 ] 	Training loss: 1.7124.  Training acc: 68.23%.
[ Mon Jun 19 17:38:46 2023 ] 	Time consumption: [Data]26%, [Network]73%
[ Mon Jun 19 17:38:46 2023 ] Eval epoch: 55
[ Mon Jun 19 17:38:47 2023 ] 	Mean test loss of 625 batches: 1.849761.
[ Mon Jun 19 17:38:47 2023 ] 	Top1: 64.91%
[ Mon Jun 19 17:38:47 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:47 2023 ] Training epoch: 56
[ Mon Jun 19 17:38:47 2023 ] 	Training loss: 1.7457.  Training acc: 66.15%.
[ Mon Jun 19 17:38:47 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Mon Jun 19 17:38:47 2023 ] Eval epoch: 56
[ Mon Jun 19 17:38:47 2023 ] 	Mean test loss of 625 batches: 1.208856.
[ Mon Jun 19 17:38:47 2023 ] 	Top1: 59.65%
[ Mon Jun 19 17:38:47 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:47 2023 ] Training epoch: 57
[ Mon Jun 19 17:38:48 2023 ] 	Training loss: 1.6145.  Training acc: 67.19%.
[ Mon Jun 19 17:38:48 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Mon Jun 19 17:38:48 2023 ] Eval epoch: 57
[ Mon Jun 19 17:38:48 2023 ] 	Mean test loss of 625 batches: 1.239632.
[ Mon Jun 19 17:38:48 2023 ] 	Top1: 87.72%
[ Mon Jun 19 17:38:48 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:48 2023 ] Training epoch: 58
[ Mon Jun 19 17:38:49 2023 ] 	Training loss: 1.7358.  Training acc: 63.54%.
[ Mon Jun 19 17:38:49 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Mon Jun 19 17:38:49 2023 ] Eval epoch: 58
[ Mon Jun 19 17:38:49 2023 ] 	Mean test loss of 625 batches: 1.109071.
[ Mon Jun 19 17:38:49 2023 ] 	Top1: 92.98%
[ Mon Jun 19 17:38:49 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:49 2023 ] Training epoch: 59
[ Mon Jun 19 17:38:50 2023 ] 	Training loss: 1.6062.  Training acc: 69.27%.
[ Mon Jun 19 17:38:50 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Mon Jun 19 17:38:50 2023 ] Eval epoch: 59
[ Mon Jun 19 17:38:50 2023 ] 	Mean test loss of 625 batches: 1.090265.
[ Mon Jun 19 17:38:50 2023 ] 	Top1: 94.74%
[ Mon Jun 19 17:38:50 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:50 2023 ] Training epoch: 60
[ Mon Jun 19 17:38:51 2023 ] 	Training loss: 1.5311.  Training acc: 69.27%.
[ Mon Jun 19 17:38:51 2023 ] 	Time consumption: [Data]26%, [Network]73%
[ Mon Jun 19 17:38:51 2023 ] Eval epoch: 60
[ Mon Jun 19 17:38:51 2023 ] 	Mean test loss of 625 batches: 1.198949.
[ Mon Jun 19 17:38:51 2023 ] 	Top1: 89.47%
[ Mon Jun 19 17:38:51 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:52 2023 ] Training epoch: 61
[ Mon Jun 19 17:38:52 2023 ] 	Training loss: 1.6008.  Training acc: 65.62%.
[ Mon Jun 19 17:38:52 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Mon Jun 19 17:38:52 2023 ] Eval epoch: 61
[ Mon Jun 19 17:38:52 2023 ] 	Mean test loss of 625 batches: 1.267823.
[ Mon Jun 19 17:38:52 2023 ] 	Top1: 89.47%
[ Mon Jun 19 17:38:52 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:52 2023 ] Training epoch: 62
[ Mon Jun 19 17:38:53 2023 ] 	Training loss: 1.6167.  Training acc: 64.58%.
[ Mon Jun 19 17:38:53 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Mon Jun 19 17:38:53 2023 ] Eval epoch: 62
[ Mon Jun 19 17:38:53 2023 ] 	Mean test loss of 625 batches: 1.360107.
[ Mon Jun 19 17:38:53 2023 ] 	Top1: 78.95%
[ Mon Jun 19 17:38:53 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:53 2023 ] Training epoch: 63
[ Mon Jun 19 17:38:54 2023 ] 	Training loss: 1.6025.  Training acc: 63.54%.
[ Mon Jun 19 17:38:54 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Mon Jun 19 17:38:54 2023 ] Eval epoch: 63
[ Mon Jun 19 17:38:54 2023 ] 	Mean test loss of 625 batches: 1.773412.
[ Mon Jun 19 17:38:54 2023 ] 	Top1: 68.42%
[ Mon Jun 19 17:38:54 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:54 2023 ] Training epoch: 64
[ Mon Jun 19 17:38:55 2023 ] 	Training loss: 1.6322.  Training acc: 64.58%.
[ Mon Jun 19 17:38:55 2023 ] 	Time consumption: [Data]27%, [Network]72%
[ Mon Jun 19 17:38:55 2023 ] Eval epoch: 64
[ Mon Jun 19 17:38:55 2023 ] 	Mean test loss of 625 batches: 1.187044.
[ Mon Jun 19 17:38:55 2023 ] 	Top1: 77.19%
[ Mon Jun 19 17:38:55 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:55 2023 ] Training epoch: 65
[ Mon Jun 19 17:38:56 2023 ] 	Training loss: 1.4370.  Training acc: 77.08%.
[ Mon Jun 19 17:38:56 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Mon Jun 19 17:38:56 2023 ] Eval epoch: 65
[ Mon Jun 19 17:38:56 2023 ] 	Mean test loss of 625 batches: 1.422404.
[ Mon Jun 19 17:38:56 2023 ] 	Top1: 47.37%
[ Mon Jun 19 17:38:56 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:56 2023 ] Training epoch: 66
[ Mon Jun 19 17:38:57 2023 ] 	Training loss: 1.4931.  Training acc: 75.52%.
[ Mon Jun 19 17:38:57 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Mon Jun 19 17:38:57 2023 ] Eval epoch: 66
[ Mon Jun 19 17:38:57 2023 ] 	Mean test loss of 625 batches: 1.520242.
[ Mon Jun 19 17:38:57 2023 ] 	Top1: 61.40%
[ Mon Jun 19 17:38:57 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:57 2023 ] Training epoch: 67
[ Mon Jun 19 17:38:58 2023 ] 	Training loss: 1.5267.  Training acc: 73.96%.
[ Mon Jun 19 17:38:58 2023 ] 	Time consumption: [Data]29%, [Network]70%
[ Mon Jun 19 17:38:58 2023 ] Eval epoch: 67
[ Mon Jun 19 17:38:58 2023 ] 	Mean test loss of 625 batches: 1.322119.
[ Mon Jun 19 17:38:58 2023 ] 	Top1: 78.95%
[ Mon Jun 19 17:38:58 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:58 2023 ] Training epoch: 68
[ Mon Jun 19 17:38:59 2023 ] 	Training loss: 1.3985.  Training acc: 79.69%.
[ Mon Jun 19 17:38:59 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Mon Jun 19 17:38:59 2023 ] Eval epoch: 68
[ Mon Jun 19 17:38:59 2023 ] 	Mean test loss of 625 batches: 1.101667.
[ Mon Jun 19 17:38:59 2023 ] 	Top1: 84.21%
[ Mon Jun 19 17:38:59 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:38:59 2023 ] Training epoch: 69
[ Mon Jun 19 17:39:00 2023 ] 	Training loss: 1.4599.  Training acc: 75.52%.
[ Mon Jun 19 17:39:00 2023 ] 	Time consumption: [Data]31%, [Network]69%
[ Mon Jun 19 17:39:00 2023 ] Eval epoch: 69
[ Mon Jun 19 17:39:00 2023 ] 	Mean test loss of 625 batches: 2.546721.
[ Mon Jun 19 17:39:00 2023 ] 	Top1: 71.93%
[ Mon Jun 19 17:39:00 2023 ] 	Top5: 85.96%
[ Mon Jun 19 17:39:00 2023 ] Training epoch: 70
[ Mon Jun 19 17:39:01 2023 ] 	Training loss: 1.7604.  Training acc: 73.44%.
[ Mon Jun 19 17:39:01 2023 ] 	Time consumption: [Data]32%, [Network]68%
[ Mon Jun 19 17:39:01 2023 ] Eval epoch: 70
[ Mon Jun 19 17:39:01 2023 ] 	Mean test loss of 625 batches: 1.292467.
[ Mon Jun 19 17:39:01 2023 ] 	Top1: 59.65%
[ Mon Jun 19 17:39:01 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:01 2023 ] Training epoch: 71
[ Mon Jun 19 17:39:02 2023 ] 	Training loss: 1.5557.  Training acc: 65.62%.
[ Mon Jun 19 17:39:02 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Mon Jun 19 17:39:02 2023 ] Eval epoch: 71
[ Mon Jun 19 17:39:02 2023 ] 	Mean test loss of 625 batches: 1.161947.
[ Mon Jun 19 17:39:02 2023 ] 	Top1: 92.98%
[ Mon Jun 19 17:39:02 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:02 2023 ] Training epoch: 72
[ Mon Jun 19 17:39:03 2023 ] 	Training loss: 1.6092.  Training acc: 66.67%.
[ Mon Jun 19 17:39:03 2023 ] 	Time consumption: [Data]31%, [Network]69%
[ Mon Jun 19 17:39:03 2023 ] Eval epoch: 72
[ Mon Jun 19 17:39:03 2023 ] 	Mean test loss of 625 batches: 0.939635.
[ Mon Jun 19 17:39:03 2023 ] 	Top1: 96.49%
[ Mon Jun 19 17:39:03 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:03 2023 ] Training epoch: 73
[ Mon Jun 19 17:39:04 2023 ] 	Training loss: 1.4746.  Training acc: 75.00%.
[ Mon Jun 19 17:39:04 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Mon Jun 19 17:39:04 2023 ] Eval epoch: 73
[ Mon Jun 19 17:39:05 2023 ] 	Mean test loss of 625 batches: 0.941265.
[ Mon Jun 19 17:39:05 2023 ] 	Top1: 96.49%
[ Mon Jun 19 17:39:05 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:05 2023 ] Training epoch: 74
[ Mon Jun 19 17:39:05 2023 ] 	Training loss: 1.3355.  Training acc: 80.73%.
[ Mon Jun 19 17:39:05 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Mon Jun 19 17:39:05 2023 ] Eval epoch: 74
[ Mon Jun 19 17:39:06 2023 ] 	Mean test loss of 625 batches: 1.180208.
[ Mon Jun 19 17:39:06 2023 ] 	Top1: 82.46%
[ Mon Jun 19 17:39:06 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:06 2023 ] Training epoch: 75
[ Mon Jun 19 17:39:07 2023 ] 	Training loss: 1.4596.  Training acc: 79.69%.
[ Mon Jun 19 17:39:07 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Mon Jun 19 17:39:07 2023 ] Eval epoch: 75
[ Mon Jun 19 17:39:07 2023 ] 	Mean test loss of 625 batches: 1.059914.
[ Mon Jun 19 17:39:07 2023 ] 	Top1: 84.21%
[ Mon Jun 19 17:39:07 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:07 2023 ] Training epoch: 76
[ Mon Jun 19 17:39:08 2023 ] 	Training loss: 1.4176.  Training acc: 77.60%.
[ Mon Jun 19 17:39:08 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Mon Jun 19 17:39:08 2023 ] Eval epoch: 76
[ Mon Jun 19 17:39:08 2023 ] 	Mean test loss of 625 batches: 1.193571.
[ Mon Jun 19 17:39:08 2023 ] 	Top1: 100.00%
[ Mon Jun 19 17:39:08 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:08 2023 ] Training epoch: 77
[ Mon Jun 19 17:39:09 2023 ] 	Training loss: 1.3810.  Training acc: 76.56%.
[ Mon Jun 19 17:39:09 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Mon Jun 19 17:39:09 2023 ] Eval epoch: 77
[ Mon Jun 19 17:39:09 2023 ] 	Mean test loss of 625 batches: 0.932632.
[ Mon Jun 19 17:39:09 2023 ] 	Top1: 100.00%
[ Mon Jun 19 17:39:09 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:09 2023 ] Training epoch: 78
[ Mon Jun 19 17:39:10 2023 ] 	Training loss: 1.2833.  Training acc: 82.29%.
[ Mon Jun 19 17:39:10 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Mon Jun 19 17:39:10 2023 ] Eval epoch: 78
[ Mon Jun 19 17:39:10 2023 ] 	Mean test loss of 625 batches: 1.046841.
[ Mon Jun 19 17:39:10 2023 ] 	Top1: 92.98%
[ Mon Jun 19 17:39:10 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:10 2023 ] Training epoch: 79
[ Mon Jun 19 17:39:11 2023 ] 	Training loss: 1.5361.  Training acc: 77.08%.
[ Mon Jun 19 17:39:11 2023 ] 	Time consumption: [Data]28%, [Network]71%
[ Mon Jun 19 17:39:11 2023 ] Eval epoch: 79
[ Mon Jun 19 17:39:11 2023 ] 	Mean test loss of 625 batches: 0.928546.
[ Mon Jun 19 17:39:11 2023 ] 	Top1: 100.00%
[ Mon Jun 19 17:39:11 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:11 2023 ] Training epoch: 80
[ Mon Jun 19 17:39:12 2023 ] 	Training loss: 1.3408.  Training acc: 82.81%.
[ Mon Jun 19 17:39:12 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Mon Jun 19 17:39:12 2023 ] Eval epoch: 80
[ Mon Jun 19 17:39:12 2023 ] 	Mean test loss of 625 batches: 2.453810.
[ Mon Jun 19 17:39:12 2023 ] 	Top1: 71.93%
[ Mon Jun 19 17:39:12 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:12 2023 ] Training epoch: 81
[ Mon Jun 19 17:39:13 2023 ] 	Training loss: 2.1622.  Training acc: 65.10%.
[ Mon Jun 19 17:39:13 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Mon Jun 19 17:39:13 2023 ] Eval epoch: 81
[ Mon Jun 19 17:39:14 2023 ] 	Mean test loss of 625 batches: 1.383125.
[ Mon Jun 19 17:39:14 2023 ] 	Top1: 59.65%
[ Mon Jun 19 17:39:14 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:14 2023 ] Training epoch: 82
[ Mon Jun 19 17:39:14 2023 ] 	Training loss: 1.6046.  Training acc: 66.67%.
[ Mon Jun 19 17:39:14 2023 ] 	Time consumption: [Data]25%, [Network]75%
[ Mon Jun 19 17:39:14 2023 ] Eval epoch: 82
[ Mon Jun 19 17:39:15 2023 ] 	Mean test loss of 625 batches: 1.219998.
[ Mon Jun 19 17:39:15 2023 ] 	Top1: 71.93%
[ Mon Jun 19 17:39:15 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:15 2023 ] Training epoch: 83
[ Mon Jun 19 17:39:15 2023 ] 	Training loss: 1.6066.  Training acc: 67.71%.
[ Mon Jun 19 17:39:15 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Mon Jun 19 17:39:15 2023 ] Eval epoch: 83
[ Mon Jun 19 17:39:16 2023 ] 	Mean test loss of 625 batches: 1.225129.
[ Mon Jun 19 17:39:16 2023 ] 	Top1: 71.93%
[ Mon Jun 19 17:39:16 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:16 2023 ] Training epoch: 84
[ Mon Jun 19 17:39:16 2023 ] 	Training loss: 1.6938.  Training acc: 62.50%.
[ Mon Jun 19 17:39:16 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Mon Jun 19 17:39:16 2023 ] Eval epoch: 84
[ Mon Jun 19 17:39:17 2023 ] 	Mean test loss of 625 batches: 1.242131.
[ Mon Jun 19 17:39:17 2023 ] 	Top1: 71.93%
[ Mon Jun 19 17:39:17 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:17 2023 ] Training epoch: 85
[ Mon Jun 19 17:39:17 2023 ] 	Training loss: 1.5452.  Training acc: 65.10%.
[ Mon Jun 19 17:39:17 2023 ] 	Time consumption: [Data]28%, [Network]71%
[ Mon Jun 19 17:39:17 2023 ] Eval epoch: 85
[ Mon Jun 19 17:39:18 2023 ] 	Mean test loss of 625 batches: 1.262080.
[ Mon Jun 19 17:39:18 2023 ] 	Top1: 71.93%
[ Mon Jun 19 17:39:18 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:18 2023 ] Training epoch: 86
[ Mon Jun 19 17:39:18 2023 ] 	Training loss: 1.4284.  Training acc: 68.75%.
[ Mon Jun 19 17:39:18 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Mon Jun 19 17:39:18 2023 ] Eval epoch: 86
[ Mon Jun 19 17:39:18 2023 ] 	Mean test loss of 625 batches: 1.260085.
[ Mon Jun 19 17:39:18 2023 ] 	Top1: 71.93%
[ Mon Jun 19 17:39:18 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:18 2023 ] Training epoch: 87
[ Mon Jun 19 17:39:19 2023 ] 	Training loss: 1.4053.  Training acc: 69.27%.
[ Mon Jun 19 17:39:19 2023 ] 	Time consumption: [Data]30%, [Network]69%
[ Mon Jun 19 17:39:19 2023 ] Eval epoch: 87
[ Mon Jun 19 17:39:19 2023 ] 	Mean test loss of 625 batches: 1.168397.
[ Mon Jun 19 17:39:19 2023 ] 	Top1: 89.47%
[ Mon Jun 19 17:39:19 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:19 2023 ] Training epoch: 88
[ Mon Jun 19 17:39:20 2023 ] 	Training loss: 1.2946.  Training acc: 76.04%.
[ Mon Jun 19 17:39:20 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Mon Jun 19 17:39:20 2023 ] Eval epoch: 88
[ Mon Jun 19 17:39:20 2023 ] 	Mean test loss of 625 batches: 0.939675.
[ Mon Jun 19 17:39:20 2023 ] 	Top1: 100.00%
[ Mon Jun 19 17:39:20 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:20 2023 ] Training epoch: 89
[ Mon Jun 19 17:39:21 2023 ] 	Training loss: 1.4412.  Training acc: 80.73%.
[ Mon Jun 19 17:39:21 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Mon Jun 19 17:39:21 2023 ] Eval epoch: 89
[ Mon Jun 19 17:39:21 2023 ] 	Mean test loss of 625 batches: 0.913579.
[ Mon Jun 19 17:39:21 2023 ] 	Top1: 94.74%
[ Mon Jun 19 17:39:21 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:21 2023 ] Training epoch: 90
[ Mon Jun 19 17:39:22 2023 ] 	Training loss: 1.3193.  Training acc: 88.54%.
[ Mon Jun 19 17:39:22 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Mon Jun 19 17:39:22 2023 ] Eval epoch: 90
[ Mon Jun 19 17:39:22 2023 ] 	Mean test loss of 625 batches: 1.102380.
[ Mon Jun 19 17:39:22 2023 ] 	Top1: 85.96%
[ Mon Jun 19 17:39:22 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:22 2023 ] Training epoch: 91
[ Mon Jun 19 17:39:23 2023 ] 	Training loss: 1.2093.  Training acc: 88.54%.
[ Mon Jun 19 17:39:23 2023 ] 	Time consumption: [Data]32%, [Network]68%
[ Mon Jun 19 17:39:23 2023 ] Eval epoch: 91
[ Mon Jun 19 17:39:23 2023 ] 	Mean test loss of 625 batches: 0.968464.
[ Mon Jun 19 17:39:23 2023 ] 	Top1: 96.49%
[ Mon Jun 19 17:39:23 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:23 2023 ] Training epoch: 92
[ Mon Jun 19 17:39:24 2023 ] 	Training loss: 1.1652.  Training acc: 89.06%.
[ Mon Jun 19 17:39:24 2023 ] 	Time consumption: [Data]24%, [Network]75%
[ Mon Jun 19 17:39:24 2023 ] Eval epoch: 92
[ Mon Jun 19 17:39:24 2023 ] 	Mean test loss of 625 batches: 0.900532.
[ Mon Jun 19 17:39:24 2023 ] 	Top1: 98.25%
[ Mon Jun 19 17:39:24 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:24 2023 ] Training epoch: 93
[ Mon Jun 19 17:39:25 2023 ] 	Training loss: 1.1467.  Training acc: 90.62%.
[ Mon Jun 19 17:39:25 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Mon Jun 19 17:39:25 2023 ] Eval epoch: 93
[ Mon Jun 19 17:39:25 2023 ] 	Mean test loss of 625 batches: 0.880289.
[ Mon Jun 19 17:39:25 2023 ] 	Top1: 96.49%
[ Mon Jun 19 17:39:25 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:25 2023 ] Training epoch: 94
[ Mon Jun 19 17:39:26 2023 ] 	Training loss: 1.1114.  Training acc: 91.15%.
[ Mon Jun 19 17:39:26 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Mon Jun 19 17:39:26 2023 ] Eval epoch: 94
[ Mon Jun 19 17:39:26 2023 ] 	Mean test loss of 625 batches: 0.868611.
[ Mon Jun 19 17:39:26 2023 ] 	Top1: 96.49%
[ Mon Jun 19 17:39:26 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:26 2023 ] Training epoch: 95
[ Mon Jun 19 17:39:27 2023 ] 	Training loss: 1.1599.  Training acc: 88.54%.
[ Mon Jun 19 17:39:27 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Mon Jun 19 17:39:27 2023 ] Eval epoch: 95
[ Mon Jun 19 17:39:27 2023 ] 	Mean test loss of 625 batches: 0.870647.
[ Mon Jun 19 17:39:27 2023 ] 	Top1: 96.49%
[ Mon Jun 19 17:39:27 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:27 2023 ] Training epoch: 96
[ Mon Jun 19 17:39:28 2023 ] 	Training loss: 1.0359.  Training acc: 95.83%.
[ Mon Jun 19 17:39:28 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Mon Jun 19 17:39:28 2023 ] Eval epoch: 96
[ Mon Jun 19 17:39:28 2023 ] 	Mean test loss of 625 batches: 0.875300.
[ Mon Jun 19 17:39:28 2023 ] 	Top1: 96.49%
[ Mon Jun 19 17:39:28 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:28 2023 ] Training epoch: 97
[ Mon Jun 19 17:39:29 2023 ] 	Training loss: 1.0276.  Training acc: 95.83%.
[ Mon Jun 19 17:39:29 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Mon Jun 19 17:39:29 2023 ] Eval epoch: 97
[ Mon Jun 19 17:39:29 2023 ] 	Mean test loss of 625 batches: 0.879132.
[ Mon Jun 19 17:39:29 2023 ] 	Top1: 96.49%
[ Mon Jun 19 17:39:30 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:30 2023 ] Training epoch: 98
[ Mon Jun 19 17:39:30 2023 ] 	Training loss: 1.1127.  Training acc: 92.19%.
[ Mon Jun 19 17:39:30 2023 ] 	Time consumption: [Data]30%, [Network]69%
[ Mon Jun 19 17:39:30 2023 ] Eval epoch: 98
[ Mon Jun 19 17:39:30 2023 ] 	Mean test loss of 625 batches: 0.880446.
[ Mon Jun 19 17:39:30 2023 ] 	Top1: 98.25%
[ Mon Jun 19 17:39:30 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:30 2023 ] Training epoch: 99
[ Mon Jun 19 17:39:31 2023 ] 	Training loss: 1.0415.  Training acc: 95.83%.
[ Mon Jun 19 17:39:31 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Mon Jun 19 17:39:31 2023 ] Eval epoch: 99
[ Mon Jun 19 17:39:32 2023 ] 	Mean test loss of 625 batches: 0.870212.
[ Mon Jun 19 17:39:32 2023 ] 	Top1: 98.25%
[ Mon Jun 19 17:39:32 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:32 2023 ] Training epoch: 100
[ Mon Jun 19 17:39:32 2023 ] 	Training loss: 1.1164.  Training acc: 92.71%.
[ Mon Jun 19 17:39:32 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Mon Jun 19 17:39:32 2023 ] Eval epoch: 100
[ Mon Jun 19 17:39:33 2023 ] 	Mean test loss of 625 batches: 0.847746.
[ Mon Jun 19 17:39:33 2023 ] 	Top1: 100.00%
[ Mon Jun 19 17:39:33 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:33 2023 ] Training epoch: 101
[ Mon Jun 19 17:39:33 2023 ] 	Training loss: 1.0987.  Training acc: 91.15%.
[ Mon Jun 19 17:39:33 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Mon Jun 19 17:39:33 2023 ] Eval epoch: 101
[ Mon Jun 19 17:39:34 2023 ] 	Mean test loss of 625 batches: 0.848677.
[ Mon Jun 19 17:39:34 2023 ] 	Top1: 100.00%
[ Mon Jun 19 17:39:34 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:34 2023 ] Training epoch: 102
[ Mon Jun 19 17:39:34 2023 ] 	Training loss: 1.1626.  Training acc: 86.98%.
[ Mon Jun 19 17:39:34 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Mon Jun 19 17:39:34 2023 ] Eval epoch: 102
[ Mon Jun 19 17:39:35 2023 ] 	Mean test loss of 625 batches: 0.851497.
[ Mon Jun 19 17:39:35 2023 ] 	Top1: 100.00%
[ Mon Jun 19 17:39:35 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:35 2023 ] Training epoch: 103
[ Mon Jun 19 17:39:35 2023 ] 	Training loss: 1.0464.  Training acc: 93.23%.
[ Mon Jun 19 17:39:35 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Mon Jun 19 17:39:35 2023 ] Eval epoch: 103
[ Mon Jun 19 17:39:36 2023 ] 	Mean test loss of 625 batches: 0.864629.
[ Mon Jun 19 17:39:36 2023 ] 	Top1: 96.49%
[ Mon Jun 19 17:39:36 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:36 2023 ] Training epoch: 104
[ Mon Jun 19 17:39:36 2023 ] 	Training loss: 1.0699.  Training acc: 93.75%.
[ Mon Jun 19 17:39:36 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Mon Jun 19 17:39:36 2023 ] Eval epoch: 104
[ Mon Jun 19 17:39:37 2023 ] 	Mean test loss of 625 batches: 0.864768.
[ Mon Jun 19 17:39:37 2023 ] 	Top1: 96.49%
[ Mon Jun 19 17:39:37 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:37 2023 ] Training epoch: 105
[ Mon Jun 19 17:39:37 2023 ] 	Training loss: 1.0190.  Training acc: 94.79%.
[ Mon Jun 19 17:39:37 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Mon Jun 19 17:39:37 2023 ] Eval epoch: 105
[ Mon Jun 19 17:39:38 2023 ] 	Mean test loss of 625 batches: 0.867797.
[ Mon Jun 19 17:39:38 2023 ] 	Top1: 96.49%
[ Mon Jun 19 17:39:38 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:38 2023 ] Training epoch: 106
[ Mon Jun 19 17:39:38 2023 ] 	Training loss: 1.1554.  Training acc: 91.15%.
[ Mon Jun 19 17:39:38 2023 ] 	Time consumption: [Data]32%, [Network]68%
[ Mon Jun 19 17:39:38 2023 ] Eval epoch: 106
[ Mon Jun 19 17:39:39 2023 ] 	Mean test loss of 625 batches: 0.872954.
[ Mon Jun 19 17:39:39 2023 ] 	Top1: 96.49%
[ Mon Jun 19 17:39:39 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:39 2023 ] Training epoch: 107
[ Mon Jun 19 17:39:39 2023 ] 	Training loss: 1.0959.  Training acc: 89.58%.
[ Mon Jun 19 17:39:39 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Mon Jun 19 17:39:39 2023 ] Eval epoch: 107
[ Mon Jun 19 17:39:40 2023 ] 	Mean test loss of 625 batches: 0.861928.
[ Mon Jun 19 17:39:40 2023 ] 	Top1: 96.49%
[ Mon Jun 19 17:39:40 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:40 2023 ] Training epoch: 108
[ Mon Jun 19 17:39:40 2023 ] 	Training loss: 1.0283.  Training acc: 95.31%.
[ Mon Jun 19 17:39:40 2023 ] 	Time consumption: [Data]31%, [Network]69%
[ Mon Jun 19 17:39:40 2023 ] Eval epoch: 108
[ Mon Jun 19 17:39:41 2023 ] 	Mean test loss of 625 batches: 0.857883.
[ Mon Jun 19 17:39:41 2023 ] 	Top1: 96.49%
[ Mon Jun 19 17:39:41 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:41 2023 ] Training epoch: 109
[ Mon Jun 19 17:39:41 2023 ] 	Training loss: 1.0745.  Training acc: 91.67%.
[ Mon Jun 19 17:39:41 2023 ] 	Time consumption: [Data]31%, [Network]69%
[ Mon Jun 19 17:39:41 2023 ] Eval epoch: 109
[ Mon Jun 19 17:39:41 2023 ] 	Mean test loss of 625 batches: 0.858808.
[ Mon Jun 19 17:39:41 2023 ] 	Top1: 98.25%
[ Mon Jun 19 17:39:41 2023 ] 	Top5: 100.00%
[ Mon Jun 19 17:39:41 2023 ] Training epoch: 110
[ Mon Jun 19 17:39:42 2023 ] 	Training loss: 1.1295.  Training acc: 91.15%.
[ Mon Jun 19 17:39:42 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Mon Jun 19 17:39:42 2023 ] Eval epoch: 110
[ Mon Jun 19 17:39:42 2023 ] 	Mean test loss of 625 batches: 0.857643.
[ Mon Jun 19 17:39:42 2023 ] 	Top1: 98.25%
[ Mon Jun 19 17:39:42 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:46:10 2023 ] using warm up, epoch: 5
[ Tue Jun 20 02:46:12 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 60, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 02:46:12 2023 ] # Parameters: 1553607
[ Tue Jun 20 02:46:12 2023 ] Training epoch: 1
[ Tue Jun 20 02:46:16 2023 ] 	Training loss: 36.8625.  Training acc: 19.79%.
[ Tue Jun 20 02:46:16 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 20 02:46:16 2023 ] Eval epoch: 1
[ Tue Jun 20 02:46:17 2023 ] 	Mean test loss of 625 batches: 419.462860.
[ Tue Jun 20 02:46:17 2023 ] 	Top1: 40.35%
[ Tue Jun 20 02:46:17 2023 ] 	Top5: 71.93%
[ Tue Jun 20 02:46:17 2023 ] Training epoch: 2
[ Tue Jun 20 02:46:17 2023 ] 	Training loss: 43.1260.  Training acc: 32.29%.
[ Tue Jun 20 02:46:17 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Tue Jun 20 02:46:17 2023 ] Eval epoch: 2
[ Tue Jun 20 02:46:18 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:18 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:18 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:18 2023 ] Training epoch: 3
[ Tue Jun 20 02:46:19 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:19 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 20 02:46:19 2023 ] Eval epoch: 3
[ Tue Jun 20 02:46:19 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:19 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:19 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:19 2023 ] Training epoch: 4
[ Tue Jun 20 02:46:20 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:20 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Tue Jun 20 02:46:20 2023 ] Eval epoch: 4
[ Tue Jun 20 02:46:20 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:20 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:20 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:20 2023 ] Training epoch: 5
[ Tue Jun 20 02:46:21 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:21 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 20 02:46:21 2023 ] Eval epoch: 5
[ Tue Jun 20 02:46:22 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:22 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:22 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:22 2023 ] Training epoch: 6
[ Tue Jun 20 02:46:23 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:23 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 20 02:46:23 2023 ] Eval epoch: 6
[ Tue Jun 20 02:46:23 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:23 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:23 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:23 2023 ] Training epoch: 7
[ Tue Jun 20 02:46:24 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:24 2023 ] 	Time consumption: [Data]22%, [Network]77%
[ Tue Jun 20 02:46:24 2023 ] Eval epoch: 7
[ Tue Jun 20 02:46:25 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:25 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:25 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:25 2023 ] Training epoch: 8
[ Tue Jun 20 02:46:25 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:25 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 20 02:46:25 2023 ] Eval epoch: 8
[ Tue Jun 20 02:46:26 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:26 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:26 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:26 2023 ] Training epoch: 9
[ Tue Jun 20 02:46:27 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:27 2023 ] 	Time consumption: [Data]22%, [Network]77%
[ Tue Jun 20 02:46:27 2023 ] Eval epoch: 9
[ Tue Jun 20 02:46:27 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:27 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:27 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:27 2023 ] Training epoch: 10
[ Tue Jun 20 02:46:28 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:28 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Tue Jun 20 02:46:28 2023 ] Eval epoch: 10
[ Tue Jun 20 02:46:28 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:28 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:28 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:28 2023 ] Training epoch: 11
[ Tue Jun 20 02:46:29 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:29 2023 ] 	Time consumption: [Data]25%, [Network]75%
[ Tue Jun 20 02:46:29 2023 ] Eval epoch: 11
[ Tue Jun 20 02:46:29 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:29 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:29 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:29 2023 ] Training epoch: 12
[ Tue Jun 20 02:46:30 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:30 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Tue Jun 20 02:46:30 2023 ] Eval epoch: 12
[ Tue Jun 20 02:46:30 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:30 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:30 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:30 2023 ] Training epoch: 13
[ Tue Jun 20 02:46:31 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:31 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Tue Jun 20 02:46:31 2023 ] Eval epoch: 13
[ Tue Jun 20 02:46:31 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:31 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:31 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:31 2023 ] Training epoch: 14
[ Tue Jun 20 02:46:32 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:32 2023 ] 	Time consumption: [Data]24%, [Network]76%
[ Tue Jun 20 02:46:32 2023 ] Eval epoch: 14
[ Tue Jun 20 02:46:33 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:33 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:33 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:33 2023 ] Training epoch: 15
[ Tue Jun 20 02:46:33 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:33 2023 ] 	Time consumption: [Data]30%, [Network]69%
[ Tue Jun 20 02:46:33 2023 ] Eval epoch: 15
[ Tue Jun 20 02:46:34 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:34 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:34 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:34 2023 ] Training epoch: 16
[ Tue Jun 20 02:46:34 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:34 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 02:46:34 2023 ] Eval epoch: 16
[ Tue Jun 20 02:46:35 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:35 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:35 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:35 2023 ] Training epoch: 17
[ Tue Jun 20 02:46:35 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:35 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Tue Jun 20 02:46:35 2023 ] Eval epoch: 17
[ Tue Jun 20 02:46:36 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:36 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:36 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:36 2023 ] Training epoch: 18
[ Tue Jun 20 02:46:37 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:37 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Tue Jun 20 02:46:37 2023 ] Eval epoch: 18
[ Tue Jun 20 02:46:37 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:37 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:37 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:37 2023 ] Training epoch: 19
[ Tue Jun 20 02:46:38 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:38 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 02:46:38 2023 ] Eval epoch: 19
[ Tue Jun 20 02:46:38 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:38 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:38 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:38 2023 ] Training epoch: 20
[ Tue Jun 20 02:46:39 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:39 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 02:46:39 2023 ] Eval epoch: 20
[ Tue Jun 20 02:46:39 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:39 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:39 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:39 2023 ] Training epoch: 21
[ Tue Jun 20 02:46:40 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:40 2023 ] 	Time consumption: [Data]29%, [Network]70%
[ Tue Jun 20 02:46:40 2023 ] Eval epoch: 21
[ Tue Jun 20 02:46:40 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:40 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:40 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:40 2023 ] Training epoch: 22
[ Tue Jun 20 02:46:41 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:41 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Tue Jun 20 02:46:41 2023 ] Eval epoch: 22
[ Tue Jun 20 02:46:41 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:41 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:41 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:41 2023 ] Training epoch: 23
[ Tue Jun 20 02:46:42 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:42 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 02:46:42 2023 ] Eval epoch: 23
[ Tue Jun 20 02:46:42 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:42 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:42 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:42 2023 ] Training epoch: 24
[ Tue Jun 20 02:46:43 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:43 2023 ] 	Time consumption: [Data]25%, [Network]74%
[ Tue Jun 20 02:46:43 2023 ] Eval epoch: 24
[ Tue Jun 20 02:46:43 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:43 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:43 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:43 2023 ] Training epoch: 25
[ Tue Jun 20 02:46:44 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:44 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 02:46:44 2023 ] Eval epoch: 25
[ Tue Jun 20 02:46:44 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:44 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:44 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:44 2023 ] Training epoch: 26
[ Tue Jun 20 02:46:45 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:45 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 02:46:45 2023 ] Eval epoch: 26
[ Tue Jun 20 02:46:45 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:45 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:45 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:45 2023 ] Training epoch: 27
[ Tue Jun 20 02:46:46 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:46 2023 ] 	Time consumption: [Data]25%, [Network]75%
[ Tue Jun 20 02:46:46 2023 ] Eval epoch: 27
[ Tue Jun 20 02:46:46 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:46 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:46 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:46 2023 ] Training epoch: 28
[ Tue Jun 20 02:46:47 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:47 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 02:46:47 2023 ] Eval epoch: 28
[ Tue Jun 20 02:46:47 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:47 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:47 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:47 2023 ] Training epoch: 29
[ Tue Jun 20 02:46:48 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:48 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 20 02:46:48 2023 ] Eval epoch: 29
[ Tue Jun 20 02:46:49 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:49 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:49 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:49 2023 ] Training epoch: 30
[ Tue Jun 20 02:46:49 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:49 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 02:46:49 2023 ] Eval epoch: 30
[ Tue Jun 20 02:46:50 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:50 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:50 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:50 2023 ] Training epoch: 31
[ Tue Jun 20 02:46:50 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:50 2023 ] 	Time consumption: [Data]27%, [Network]72%
[ Tue Jun 20 02:46:50 2023 ] Eval epoch: 31
[ Tue Jun 20 02:46:51 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:51 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:51 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:51 2023 ] Training epoch: 32
[ Tue Jun 20 02:46:52 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:52 2023 ] 	Time consumption: [Data]25%, [Network]75%
[ Tue Jun 20 02:46:52 2023 ] Eval epoch: 32
[ Tue Jun 20 02:46:52 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:52 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:52 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:52 2023 ] Training epoch: 33
[ Tue Jun 20 02:46:53 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:53 2023 ] 	Time consumption: [Data]32%, [Network]68%
[ Tue Jun 20 02:46:53 2023 ] Eval epoch: 33
[ Tue Jun 20 02:46:53 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:53 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:53 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:53 2023 ] Training epoch: 34
[ Tue Jun 20 02:46:54 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:54 2023 ] 	Time consumption: [Data]27%, [Network]72%
[ Tue Jun 20 02:46:54 2023 ] Eval epoch: 34
[ Tue Jun 20 02:46:54 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:54 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:54 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:54 2023 ] Training epoch: 35
[ Tue Jun 20 02:46:55 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:55 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Tue Jun 20 02:46:55 2023 ] Eval epoch: 35
[ Tue Jun 20 02:46:55 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:55 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:55 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:55 2023 ] Training epoch: 36
[ Tue Jun 20 02:46:56 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:56 2023 ] 	Time consumption: [Data]25%, [Network]75%
[ Tue Jun 20 02:46:56 2023 ] Eval epoch: 36
[ Tue Jun 20 02:46:56 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:56 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:56 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:56 2023 ] Training epoch: 37
[ Tue Jun 20 02:46:57 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:57 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 02:46:57 2023 ] Eval epoch: 37
[ Tue Jun 20 02:46:57 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:57 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:57 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:57 2023 ] Training epoch: 38
[ Tue Jun 20 02:46:58 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:58 2023 ] 	Time consumption: [Data]30%, [Network]69%
[ Tue Jun 20 02:46:58 2023 ] Eval epoch: 38
[ Tue Jun 20 02:46:58 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:58 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:58 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:58 2023 ] Training epoch: 39
[ Tue Jun 20 02:46:59 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:46:59 2023 ] 	Time consumption: [Data]25%, [Network]75%
[ Tue Jun 20 02:46:59 2023 ] Eval epoch: 39
[ Tue Jun 20 02:46:59 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:46:59 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:46:59 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:46:59 2023 ] Training epoch: 40
[ Tue Jun 20 02:47:00 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:00 2023 ] 	Time consumption: [Data]29%, [Network]70%
[ Tue Jun 20 02:47:00 2023 ] Eval epoch: 40
[ Tue Jun 20 02:47:00 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:00 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:00 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:00 2023 ] Training epoch: 41
[ Tue Jun 20 02:47:01 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:01 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Tue Jun 20 02:47:01 2023 ] Eval epoch: 41
[ Tue Jun 20 02:47:01 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:01 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:01 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:01 2023 ] Training epoch: 42
[ Tue Jun 20 02:47:02 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:02 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 02:47:02 2023 ] Eval epoch: 42
[ Tue Jun 20 02:47:03 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:03 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:03 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:03 2023 ] Training epoch: 43
[ Tue Jun 20 02:47:03 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:03 2023 ] 	Time consumption: [Data]26%, [Network]73%
[ Tue Jun 20 02:47:03 2023 ] Eval epoch: 43
[ Tue Jun 20 02:47:04 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:04 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:04 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:04 2023 ] Training epoch: 44
[ Tue Jun 20 02:47:04 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:04 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 02:47:04 2023 ] Eval epoch: 44
[ Tue Jun 20 02:47:05 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:05 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:05 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:05 2023 ] Training epoch: 45
[ Tue Jun 20 02:47:05 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:05 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Tue Jun 20 02:47:05 2023 ] Eval epoch: 45
[ Tue Jun 20 02:47:06 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:06 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:06 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:06 2023 ] Training epoch: 46
[ Tue Jun 20 02:47:06 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:06 2023 ] 	Time consumption: [Data]31%, [Network]69%
[ Tue Jun 20 02:47:06 2023 ] Eval epoch: 46
[ Tue Jun 20 02:47:07 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:07 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:07 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:07 2023 ] Training epoch: 47
[ Tue Jun 20 02:47:08 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:08 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Tue Jun 20 02:47:08 2023 ] Eval epoch: 47
[ Tue Jun 20 02:47:08 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:08 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:08 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:08 2023 ] Training epoch: 48
[ Tue Jun 20 02:47:08 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:08 2023 ] 	Time consumption: [Data]29%, [Network]70%
[ Tue Jun 20 02:47:08 2023 ] Eval epoch: 48
[ Tue Jun 20 02:47:09 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:09 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:09 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:09 2023 ] Training epoch: 49
[ Tue Jun 20 02:47:10 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:10 2023 ] 	Time consumption: [Data]26%, [Network]73%
[ Tue Jun 20 02:47:10 2023 ] Eval epoch: 49
[ Tue Jun 20 02:47:10 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:10 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:10 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:10 2023 ] Training epoch: 50
[ Tue Jun 20 02:47:11 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:11 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Tue Jun 20 02:47:11 2023 ] Eval epoch: 50
[ Tue Jun 20 02:47:11 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:11 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:11 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:11 2023 ] Training epoch: 51
[ Tue Jun 20 02:47:12 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:12 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Tue Jun 20 02:47:12 2023 ] Eval epoch: 51
[ Tue Jun 20 02:47:12 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:12 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:12 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:12 2023 ] Training epoch: 52
[ Tue Jun 20 02:47:13 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:13 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Tue Jun 20 02:47:13 2023 ] Eval epoch: 52
[ Tue Jun 20 02:47:13 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:13 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:13 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:13 2023 ] Training epoch: 53
[ Tue Jun 20 02:47:14 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:14 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 20 02:47:14 2023 ] Eval epoch: 53
[ Tue Jun 20 02:47:15 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:15 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:15 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:15 2023 ] Training epoch: 54
[ Tue Jun 20 02:47:16 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:16 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 20 02:47:16 2023 ] Eval epoch: 54
[ Tue Jun 20 02:47:16 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:16 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:16 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:16 2023 ] Training epoch: 55
[ Tue Jun 20 02:47:17 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:17 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 20 02:47:17 2023 ] Eval epoch: 55
[ Tue Jun 20 02:47:17 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:17 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:17 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:17 2023 ] Training epoch: 56
[ Tue Jun 20 02:47:18 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:18 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 20 02:47:18 2023 ] Eval epoch: 56
[ Tue Jun 20 02:47:18 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:18 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:18 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:18 2023 ] Training epoch: 57
[ Tue Jun 20 02:47:19 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:19 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 20 02:47:19 2023 ] Eval epoch: 57
[ Tue Jun 20 02:47:20 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:20 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:20 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:20 2023 ] Training epoch: 58
[ Tue Jun 20 02:47:21 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:21 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Tue Jun 20 02:47:21 2023 ] Eval epoch: 58
[ Tue Jun 20 02:47:21 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:21 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:21 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:21 2023 ] Training epoch: 59
[ Tue Jun 20 02:47:22 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:22 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Tue Jun 20 02:47:22 2023 ] Eval epoch: 59
[ Tue Jun 20 02:47:22 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:22 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:22 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:22 2023 ] Training epoch: 60
[ Tue Jun 20 02:47:23 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:23 2023 ] 	Time consumption: [Data]23%, [Network]76%
[ Tue Jun 20 02:47:23 2023 ] Eval epoch: 60
[ Tue Jun 20 02:47:23 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:23 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:23 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:23 2023 ] Training epoch: 61
[ Tue Jun 20 02:47:24 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:24 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Tue Jun 20 02:47:24 2023 ] Eval epoch: 61
[ Tue Jun 20 02:47:24 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:24 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:24 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:24 2023 ] Training epoch: 62
[ Tue Jun 20 02:47:25 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:25 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Tue Jun 20 02:47:25 2023 ] Eval epoch: 62
[ Tue Jun 20 02:47:25 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:25 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:25 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:25 2023 ] Training epoch: 63
[ Tue Jun 20 02:47:26 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:26 2023 ] 	Time consumption: [Data]24%, [Network]76%
[ Tue Jun 20 02:47:26 2023 ] Eval epoch: 63
[ Tue Jun 20 02:47:26 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:26 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:26 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:26 2023 ] Training epoch: 64
[ Tue Jun 20 02:47:27 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:27 2023 ] 	Time consumption: [Data]26%, [Network]73%
[ Tue Jun 20 02:47:27 2023 ] Eval epoch: 64
[ Tue Jun 20 02:47:28 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:28 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:28 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:28 2023 ] Training epoch: 65
[ Tue Jun 20 02:47:28 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:28 2023 ] 	Time consumption: [Data]25%, [Network]74%
[ Tue Jun 20 02:47:28 2023 ] Eval epoch: 65
[ Tue Jun 20 02:47:29 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:29 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:29 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:29 2023 ] Training epoch: 66
[ Tue Jun 20 02:47:30 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:30 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Tue Jun 20 02:47:30 2023 ] Eval epoch: 66
[ Tue Jun 20 02:47:30 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:30 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:30 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:30 2023 ] Training epoch: 67
[ Tue Jun 20 02:47:31 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:31 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Tue Jun 20 02:47:31 2023 ] Eval epoch: 67
[ Tue Jun 20 02:47:31 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:31 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:31 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:31 2023 ] Training epoch: 68
[ Tue Jun 20 02:47:32 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:32 2023 ] 	Time consumption: [Data]25%, [Network]75%
[ Tue Jun 20 02:47:32 2023 ] Eval epoch: 68
[ Tue Jun 20 02:47:32 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:32 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:32 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:32 2023 ] Training epoch: 69
[ Tue Jun 20 02:47:33 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:33 2023 ] 	Time consumption: [Data]24%, [Network]76%
[ Tue Jun 20 02:47:33 2023 ] Eval epoch: 69
[ Tue Jun 20 02:47:33 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:33 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:33 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:33 2023 ] Training epoch: 70
[ Tue Jun 20 02:47:34 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:34 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Tue Jun 20 02:47:34 2023 ] Eval epoch: 70
[ Tue Jun 20 02:47:34 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:34 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:34 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:34 2023 ] Training epoch: 71
[ Tue Jun 20 02:47:35 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:35 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Tue Jun 20 02:47:35 2023 ] Eval epoch: 71
[ Tue Jun 20 02:47:35 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:35 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:35 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:35 2023 ] Training epoch: 72
[ Tue Jun 20 02:47:36 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:36 2023 ] 	Time consumption: [Data]25%, [Network]75%
[ Tue Jun 20 02:47:36 2023 ] Eval epoch: 72
[ Tue Jun 20 02:47:37 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:37 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:37 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:37 2023 ] Training epoch: 73
[ Tue Jun 20 02:47:37 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:37 2023 ] 	Time consumption: [Data]25%, [Network]75%
[ Tue Jun 20 02:47:37 2023 ] Eval epoch: 73
[ Tue Jun 20 02:47:38 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:38 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:38 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:38 2023 ] Training epoch: 74
[ Tue Jun 20 02:47:38 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:38 2023 ] 	Time consumption: [Data]25%, [Network]75%
[ Tue Jun 20 02:47:38 2023 ] Eval epoch: 74
[ Tue Jun 20 02:47:39 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:39 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:39 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:39 2023 ] Training epoch: 75
[ Tue Jun 20 02:47:40 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:40 2023 ] 	Time consumption: [Data]24%, [Network]76%
[ Tue Jun 20 02:47:40 2023 ] Eval epoch: 75
[ Tue Jun 20 02:47:40 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:40 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:40 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:40 2023 ] Training epoch: 76
[ Tue Jun 20 02:47:41 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:41 2023 ] 	Time consumption: [Data]28%, [Network]71%
[ Tue Jun 20 02:47:41 2023 ] Eval epoch: 76
[ Tue Jun 20 02:47:41 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:41 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:41 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:41 2023 ] Training epoch: 77
[ Tue Jun 20 02:47:42 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:42 2023 ] 	Time consumption: [Data]25%, [Network]75%
[ Tue Jun 20 02:47:42 2023 ] Eval epoch: 77
[ Tue Jun 20 02:47:42 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:42 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:42 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:42 2023 ] Training epoch: 78
[ Tue Jun 20 02:47:43 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:43 2023 ] 	Time consumption: [Data]24%, [Network]76%
[ Tue Jun 20 02:47:43 2023 ] Eval epoch: 78
[ Tue Jun 20 02:47:43 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:43 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:43 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:43 2023 ] Training epoch: 79
[ Tue Jun 20 02:47:44 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:44 2023 ] 	Time consumption: [Data]24%, [Network]75%
[ Tue Jun 20 02:47:44 2023 ] Eval epoch: 79
[ Tue Jun 20 02:47:44 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:44 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:44 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:44 2023 ] Training epoch: 80
[ Tue Jun 20 02:47:45 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:45 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Tue Jun 20 02:47:45 2023 ] Eval epoch: 80
[ Tue Jun 20 02:47:46 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:46 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:46 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:46 2023 ] Training epoch: 81
[ Tue Jun 20 02:47:46 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:46 2023 ] 	Time consumption: [Data]27%, [Network]72%
[ Tue Jun 20 02:47:46 2023 ] Eval epoch: 81
[ Tue Jun 20 02:47:47 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:47 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:47 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:47 2023 ] Training epoch: 82
[ Tue Jun 20 02:47:47 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:47 2023 ] 	Time consumption: [Data]25%, [Network]75%
[ Tue Jun 20 02:47:47 2023 ] Eval epoch: 82
[ Tue Jun 20 02:47:48 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:48 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:48 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:48 2023 ] Training epoch: 83
[ Tue Jun 20 02:47:48 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:48 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Tue Jun 20 02:47:48 2023 ] Eval epoch: 83
[ Tue Jun 20 02:47:49 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:49 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:49 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:49 2023 ] Training epoch: 84
[ Tue Jun 20 02:47:50 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:50 2023 ] 	Time consumption: [Data]24%, [Network]76%
[ Tue Jun 20 02:47:50 2023 ] Eval epoch: 84
[ Tue Jun 20 02:47:50 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:50 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:50 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:50 2023 ] Training epoch: 85
[ Tue Jun 20 02:47:51 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:51 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Tue Jun 20 02:47:51 2023 ] Eval epoch: 85
[ Tue Jun 20 02:47:51 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:51 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:51 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:51 2023 ] Training epoch: 86
[ Tue Jun 20 02:47:52 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:52 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 02:47:52 2023 ] Eval epoch: 86
[ Tue Jun 20 02:47:52 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:52 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:52 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:52 2023 ] Training epoch: 87
[ Tue Jun 20 02:47:53 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:53 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 02:47:53 2023 ] Eval epoch: 87
[ Tue Jun 20 02:47:53 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:53 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:53 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:53 2023 ] Training epoch: 88
[ Tue Jun 20 02:47:54 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:54 2023 ] 	Time consumption: [Data]28%, [Network]71%
[ Tue Jun 20 02:47:54 2023 ] Eval epoch: 88
[ Tue Jun 20 02:47:54 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:54 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:54 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:54 2023 ] Training epoch: 89
[ Tue Jun 20 02:47:55 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:55 2023 ] 	Time consumption: [Data]26%, [Network]73%
[ Tue Jun 20 02:47:55 2023 ] Eval epoch: 89
[ Tue Jun 20 02:47:55 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:55 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:55 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:55 2023 ] Training epoch: 90
[ Tue Jun 20 02:47:56 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:56 2023 ] 	Time consumption: [Data]26%, [Network]73%
[ Tue Jun 20 02:47:56 2023 ] Eval epoch: 90
[ Tue Jun 20 02:47:56 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:56 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:56 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:56 2023 ] Training epoch: 91
[ Tue Jun 20 02:47:57 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:57 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 02:47:57 2023 ] Eval epoch: 91
[ Tue Jun 20 02:47:57 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:57 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:57 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:57 2023 ] Training epoch: 92
[ Tue Jun 20 02:47:58 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:58 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 02:47:58 2023 ] Eval epoch: 92
[ Tue Jun 20 02:47:58 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:47:58 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:47:58 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:47:58 2023 ] Training epoch: 93
[ Tue Jun 20 02:47:59 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:47:59 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Tue Jun 20 02:47:59 2023 ] Eval epoch: 93
[ Tue Jun 20 02:48:00 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:48:00 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:48:00 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:48:00 2023 ] Training epoch: 94
[ Tue Jun 20 02:48:00 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:48:00 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Tue Jun 20 02:48:00 2023 ] Eval epoch: 94
[ Tue Jun 20 02:48:01 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:48:01 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:48:01 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:48:01 2023 ] Training epoch: 95
[ Tue Jun 20 02:48:01 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:48:01 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Tue Jun 20 02:48:01 2023 ] Eval epoch: 95
[ Tue Jun 20 02:48:02 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:48:02 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:48:02 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:48:02 2023 ] Training epoch: 96
[ Tue Jun 20 02:48:03 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:48:03 2023 ] 	Time consumption: [Data]25%, [Network]75%
[ Tue Jun 20 02:48:03 2023 ] Eval epoch: 96
[ Tue Jun 20 02:48:03 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:48:03 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:48:03 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:48:03 2023 ] Training epoch: 97
[ Tue Jun 20 02:48:04 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:48:04 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Tue Jun 20 02:48:04 2023 ] Eval epoch: 97
[ Tue Jun 20 02:48:04 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:48:04 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:48:04 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:48:04 2023 ] Training epoch: 98
[ Tue Jun 20 02:48:05 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:48:05 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Tue Jun 20 02:48:05 2023 ] Eval epoch: 98
[ Tue Jun 20 02:48:05 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:48:05 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:48:05 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:48:05 2023 ] Training epoch: 99
[ Tue Jun 20 02:48:06 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:48:06 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 02:48:06 2023 ] Eval epoch: 99
[ Tue Jun 20 02:48:06 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:48:06 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:48:06 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:48:06 2023 ] Training epoch: 100
[ Tue Jun 20 02:48:07 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:48:07 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 02:48:07 2023 ] Eval epoch: 100
[ Tue Jun 20 02:48:07 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:48:07 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:48:07 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:48:07 2023 ] Training epoch: 101
[ Tue Jun 20 02:48:08 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:48:08 2023 ] 	Time consumption: [Data]22%, [Network]77%
[ Tue Jun 20 02:48:08 2023 ] Eval epoch: 101
[ Tue Jun 20 02:48:09 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:48:09 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:48:09 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:48:09 2023 ] Training epoch: 102
[ Tue Jun 20 02:48:10 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:48:10 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 20 02:48:10 2023 ] Eval epoch: 102
[ Tue Jun 20 02:48:10 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:48:10 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:48:10 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:48:10 2023 ] Training epoch: 103
[ Tue Jun 20 02:48:11 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:48:11 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 20 02:48:11 2023 ] Eval epoch: 103
[ Tue Jun 20 02:48:11 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:48:11 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:48:11 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:48:11 2023 ] Training epoch: 104
[ Tue Jun 20 02:48:12 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:48:12 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 20 02:48:12 2023 ] Eval epoch: 104
[ Tue Jun 20 02:48:13 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:48:13 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:48:13 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:48:13 2023 ] Training epoch: 105
[ Tue Jun 20 02:48:14 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:48:14 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 20 02:48:14 2023 ] Eval epoch: 105
[ Tue Jun 20 02:48:14 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:48:14 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:48:14 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:48:14 2023 ] Training epoch: 106
[ Tue Jun 20 02:48:15 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:48:15 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 02:48:15 2023 ] Eval epoch: 106
[ Tue Jun 20 02:48:16 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:48:16 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:48:16 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:48:16 2023 ] Training epoch: 107
[ Tue Jun 20 02:48:16 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:48:16 2023 ] 	Time consumption: [Data]25%, [Network]75%
[ Tue Jun 20 02:48:16 2023 ] Eval epoch: 107
[ Tue Jun 20 02:48:17 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:48:17 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:48:17 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:48:17 2023 ] Training epoch: 108
[ Tue Jun 20 02:48:17 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:48:17 2023 ] 	Time consumption: [Data]24%, [Network]76%
[ Tue Jun 20 02:48:17 2023 ] Eval epoch: 108
[ Tue Jun 20 02:48:18 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:48:18 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:48:18 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:48:18 2023 ] Training epoch: 109
[ Tue Jun 20 02:48:18 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:48:18 2023 ] 	Time consumption: [Data]29%, [Network]70%
[ Tue Jun 20 02:48:18 2023 ] Eval epoch: 109
[ Tue Jun 20 02:48:19 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:48:19 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:48:19 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:48:19 2023 ] Training epoch: 110
[ Tue Jun 20 02:48:20 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:48:20 2023 ] 	Time consumption: [Data]24%, [Network]76%
[ Tue Jun 20 02:48:20 2023 ] Eval epoch: 110
[ Tue Jun 20 02:48:20 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:48:20 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:48:20 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:48:20 2023 ] Best accuracy: 0.40350877192982454
[ Tue Jun 20 02:48:20 2023 ] Epoch number: 1
[ Tue Jun 20 02:48:20 2023 ] Model name: results/ec3d_NTU60_CS
[ Tue Jun 20 02:48:20 2023 ] Model total number of params: 1553607
[ Tue Jun 20 02:48:20 2023 ] Weight decay: 0.0005
[ Tue Jun 20 02:48:20 2023 ] Base LR: 0.1
[ Tue Jun 20 02:48:20 2023 ] Batch Size: 64
[ Tue Jun 20 02:48:20 2023 ] Test Batch Size: 64
[ Tue Jun 20 02:48:20 2023 ] seed: 1
[ Tue Jun 20 02:49:32 2023 ] using warm up, epoch: 5
[ Tue Jun 20 02:49:34 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 60, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 02:49:34 2023 ] # Parameters: 1553607
[ Tue Jun 20 02:49:34 2023 ] Training epoch: 1
[ Tue Jun 20 02:49:37 2023 ] 	Training loss: 37.2136.  Training acc: 19.79%.
[ Tue Jun 20 02:49:37 2023 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue Jun 20 02:49:37 2023 ] Eval epoch: 1
[ Tue Jun 20 02:49:38 2023 ] 	Mean test loss of 625 batches: 431.843048.
[ Tue Jun 20 02:49:38 2023 ] 	Top1: 40.35%
[ Tue Jun 20 02:49:38 2023 ] 	Top5: 71.93%
[ Tue Jun 20 02:49:38 2023 ] Training epoch: 2
[ Tue Jun 20 02:49:39 2023 ] 	Training loss: nan.  Training acc: 15.10%.
[ Tue Jun 20 02:49:39 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 02:49:39 2023 ] Eval epoch: 2
[ Tue Jun 20 02:49:39 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:49:39 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:49:39 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:49:39 2023 ] Training epoch: 3
[ Tue Jun 20 02:49:40 2023 ] 	Training loss: nan.  Training acc: 0.00%.
[ Tue Jun 20 02:49:40 2023 ] 	Time consumption: [Data]31%, [Network]68%
[ Tue Jun 20 02:49:40 2023 ] Eval epoch: 3
[ Tue Jun 20 02:49:40 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:49:40 2023 ] 	Top1: 0.00%
[ Tue Jun 20 02:49:40 2023 ] 	Top5: 0.00%
[ Tue Jun 20 02:50:02 2023 ] using warm up, epoch: 5
[ Tue Jun 20 02:50:04 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 02:50:04 2023 ] # Parameters: 1538958
[ Tue Jun 20 02:50:04 2023 ] Training epoch: 1
[ Tue Jun 20 02:52:38 2023 ] using warm up, epoch: 5
[ Tue Jun 20 02:52:40 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 02:52:40 2023 ] # Parameters: 1538958
[ Tue Jun 20 02:52:40 2023 ] Training epoch: 1
[ Tue Jun 20 02:59:34 2023 ] using warm up, epoch: 5
[ Tue Jun 20 02:59:36 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 02:59:36 2023 ] # Parameters: 1538958
[ Tue Jun 20 02:59:36 2023 ] Training epoch: 1
[ Tue Jun 20 02:59:39 2023 ] 	Training loss: 716.7338.  Training acc: 33.33%.
[ Tue Jun 20 02:59:39 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 20 02:59:39 2023 ] Eval epoch: 1
[ Tue Jun 20 02:59:40 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:40 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:40 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:40 2023 ] Training epoch: 2
[ Tue Jun 20 02:59:41 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 02:59:41 2023 ] 	Time consumption: [Data]34%, [Network]66%
[ Tue Jun 20 02:59:41 2023 ] Eval epoch: 2
[ Tue Jun 20 02:59:41 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:41 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:41 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:41 2023 ] Training epoch: 3
[ Tue Jun 20 02:59:41 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 02:59:41 2023 ] 	Time consumption: [Data]36%, [Network]63%
[ Tue Jun 20 02:59:41 2023 ] Eval epoch: 3
[ Tue Jun 20 02:59:41 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:41 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:42 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:42 2023 ] Training epoch: 4
[ Tue Jun 20 02:59:42 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 02:59:42 2023 ] 	Time consumption: [Data]36%, [Network]63%
[ Tue Jun 20 02:59:42 2023 ] Eval epoch: 4
[ Tue Jun 20 02:59:42 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:42 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:42 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:42 2023 ] Training epoch: 5
[ Tue Jun 20 02:59:43 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 02:59:43 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 02:59:43 2023 ] Eval epoch: 5
[ Tue Jun 20 02:59:43 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:43 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:43 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:43 2023 ] Training epoch: 6
[ Tue Jun 20 02:59:44 2023 ] 	Training loss: nan.  Training acc: 42.71%.
[ Tue Jun 20 02:59:44 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 02:59:44 2023 ] Eval epoch: 6
[ Tue Jun 20 02:59:44 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:44 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:44 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:44 2023 ] Training epoch: 7
[ Tue Jun 20 02:59:44 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 02:59:44 2023 ] 	Time consumption: [Data]38%, [Network]61%
[ Tue Jun 20 02:59:44 2023 ] Eval epoch: 7
[ Tue Jun 20 02:59:45 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:45 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:45 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:45 2023 ] Training epoch: 8
[ Tue Jun 20 02:59:45 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 02:59:45 2023 ] 	Time consumption: [Data]40%, [Network]60%
[ Tue Jun 20 02:59:45 2023 ] Eval epoch: 8
[ Tue Jun 20 02:59:45 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:45 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:45 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:45 2023 ] Training epoch: 9
[ Tue Jun 20 02:59:46 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 02:59:46 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 02:59:46 2023 ] Eval epoch: 9
[ Tue Jun 20 02:59:46 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:46 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:46 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:46 2023 ] Training epoch: 10
[ Tue Jun 20 02:59:47 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 02:59:47 2023 ] 	Time consumption: [Data]34%, [Network]65%
[ Tue Jun 20 02:59:47 2023 ] Eval epoch: 10
[ Tue Jun 20 02:59:47 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:47 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:47 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:47 2023 ] Training epoch: 11
[ Tue Jun 20 02:59:47 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 02:59:47 2023 ] 	Time consumption: [Data]38%, [Network]61%
[ Tue Jun 20 02:59:47 2023 ] Eval epoch: 11
[ Tue Jun 20 02:59:48 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:48 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:48 2023 ] Training epoch: 12
[ Tue Jun 20 02:59:48 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 02:59:48 2023 ] 	Time consumption: [Data]38%, [Network]61%
[ Tue Jun 20 02:59:48 2023 ] Eval epoch: 12
[ Tue Jun 20 02:59:48 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:48 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:48 2023 ] Training epoch: 13
[ Tue Jun 20 02:59:49 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 02:59:49 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 02:59:49 2023 ] Eval epoch: 13
[ Tue Jun 20 02:59:49 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:49 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:49 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:49 2023 ] Training epoch: 14
[ Tue Jun 20 02:59:50 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 02:59:50 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 02:59:50 2023 ] Eval epoch: 14
[ Tue Jun 20 02:59:50 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:50 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:50 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:50 2023 ] Training epoch: 15
[ Tue Jun 20 02:59:51 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 02:59:51 2023 ] 	Time consumption: [Data]37%, [Network]62%
[ Tue Jun 20 02:59:51 2023 ] Eval epoch: 15
[ Tue Jun 20 02:59:51 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:51 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:51 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:51 2023 ] Training epoch: 16
[ Tue Jun 20 02:59:51 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 02:59:51 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 02:59:51 2023 ] Eval epoch: 16
[ Tue Jun 20 02:59:52 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:52 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:52 2023 ] Training epoch: 17
[ Tue Jun 20 02:59:52 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 02:59:52 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 02:59:52 2023 ] Eval epoch: 17
[ Tue Jun 20 02:59:52 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:52 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:52 2023 ] Training epoch: 18
[ Tue Jun 20 02:59:53 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 02:59:53 2023 ] 	Time consumption: [Data]37%, [Network]62%
[ Tue Jun 20 02:59:53 2023 ] Eval epoch: 18
[ Tue Jun 20 02:59:53 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:53 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:53 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:53 2023 ] Training epoch: 19
[ Tue Jun 20 02:59:54 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 02:59:54 2023 ] 	Time consumption: [Data]40%, [Network]59%
[ Tue Jun 20 02:59:54 2023 ] Eval epoch: 19
[ Tue Jun 20 02:59:54 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:54 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:54 2023 ] Training epoch: 20
[ Tue Jun 20 02:59:55 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 02:59:55 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 02:59:55 2023 ] Eval epoch: 20
[ Tue Jun 20 02:59:55 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:55 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:55 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:55 2023 ] Training epoch: 21
[ Tue Jun 20 02:59:55 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 02:59:55 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 02:59:55 2023 ] Eval epoch: 21
[ Tue Jun 20 02:59:56 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:56 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:56 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:56 2023 ] Training epoch: 22
[ Tue Jun 20 02:59:56 2023 ] 	Training loss: nan.  Training acc: 38.54%.
[ Tue Jun 20 02:59:56 2023 ] 	Time consumption: [Data]37%, [Network]62%
[ Tue Jun 20 02:59:56 2023 ] Eval epoch: 22
[ Tue Jun 20 02:59:56 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:56 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:56 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:56 2023 ] Training epoch: 23
[ Tue Jun 20 02:59:57 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 02:59:57 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 02:59:57 2023 ] Eval epoch: 23
[ Tue Jun 20 02:59:57 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:57 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:57 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:57 2023 ] Training epoch: 24
[ Tue Jun 20 02:59:58 2023 ] 	Training loss: nan.  Training acc: 42.71%.
[ Tue Jun 20 02:59:58 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 02:59:58 2023 ] Eval epoch: 24
[ Tue Jun 20 02:59:58 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:58 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:58 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:58 2023 ] Training epoch: 25
[ Tue Jun 20 02:59:58 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 02:59:58 2023 ] 	Time consumption: [Data]37%, [Network]62%
[ Tue Jun 20 02:59:58 2023 ] Eval epoch: 25
[ Tue Jun 20 02:59:59 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:59 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:59 2023 ] Training epoch: 26
[ Tue Jun 20 02:59:59 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 02:59:59 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 02:59:59 2023 ] Eval epoch: 26
[ Tue Jun 20 02:59:59 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 02:59:59 2023 ] 	Top1: 29.82%
[ Tue Jun 20 02:59:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 02:59:59 2023 ] Training epoch: 27
[ Tue Jun 20 03:00:00 2023 ] 	Training loss: nan.  Training acc: 42.71%.
[ Tue Jun 20 03:00:00 2023 ] 	Time consumption: [Data]34%, [Network]65%
[ Tue Jun 20 03:00:00 2023 ] Eval epoch: 27
[ Tue Jun 20 03:00:00 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:00 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:00 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:00 2023 ] Training epoch: 28
[ Tue Jun 20 03:00:01 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:00:01 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:00:01 2023 ] Eval epoch: 28
[ Tue Jun 20 03:00:01 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:01 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:01 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:01 2023 ] Training epoch: 29
[ Tue Jun 20 03:00:02 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:00:02 2023 ] 	Time consumption: [Data]40%, [Network]60%
[ Tue Jun 20 03:00:02 2023 ] Eval epoch: 29
[ Tue Jun 20 03:00:02 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:02 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:02 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:02 2023 ] Training epoch: 30
[ Tue Jun 20 03:00:02 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:00:02 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:00:02 2023 ] Eval epoch: 30
[ Tue Jun 20 03:00:03 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:03 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:03 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:03 2023 ] Training epoch: 31
[ Tue Jun 20 03:00:03 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:00:03 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:00:03 2023 ] Eval epoch: 31
[ Tue Jun 20 03:00:03 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:03 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:03 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:03 2023 ] Training epoch: 32
[ Tue Jun 20 03:00:04 2023 ] 	Training loss: nan.  Training acc: 44.79%.
[ Tue Jun 20 03:00:04 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:00:04 2023 ] Eval epoch: 32
[ Tue Jun 20 03:00:04 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:04 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:04 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:04 2023 ] Training epoch: 33
[ Tue Jun 20 03:00:05 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:00:05 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:00:05 2023 ] Eval epoch: 33
[ Tue Jun 20 03:00:05 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:05 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:05 2023 ] Training epoch: 34
[ Tue Jun 20 03:00:05 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:00:05 2023 ] 	Time consumption: [Data]39%, [Network]60%
[ Tue Jun 20 03:00:05 2023 ] Eval epoch: 34
[ Tue Jun 20 03:00:06 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:06 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:06 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:06 2023 ] Training epoch: 35
[ Tue Jun 20 03:00:06 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:00:06 2023 ] 	Time consumption: [Data]33%, [Network]67%
[ Tue Jun 20 03:00:06 2023 ] Eval epoch: 35
[ Tue Jun 20 03:00:07 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:07 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:07 2023 ] Training epoch: 36
[ Tue Jun 20 03:00:07 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:00:07 2023 ] 	Time consumption: [Data]36%, [Network]63%
[ Tue Jun 20 03:00:07 2023 ] Eval epoch: 36
[ Tue Jun 20 03:00:07 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:07 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:07 2023 ] Training epoch: 37
[ Tue Jun 20 03:00:08 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:00:08 2023 ] 	Time consumption: [Data]34%, [Network]66%
[ Tue Jun 20 03:00:08 2023 ] Eval epoch: 37
[ Tue Jun 20 03:00:08 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:08 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:08 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:08 2023 ] Training epoch: 38
[ Tue Jun 20 03:00:09 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:00:09 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:00:09 2023 ] Eval epoch: 38
[ Tue Jun 20 03:00:09 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:09 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:09 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:09 2023 ] Training epoch: 39
[ Tue Jun 20 03:00:09 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:00:09 2023 ] 	Time consumption: [Data]37%, [Network]62%
[ Tue Jun 20 03:00:09 2023 ] Eval epoch: 39
[ Tue Jun 20 03:00:10 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:10 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:10 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:10 2023 ] Training epoch: 40
[ Tue Jun 20 03:00:10 2023 ] 	Training loss: nan.  Training acc: 42.71%.
[ Tue Jun 20 03:00:10 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:00:10 2023 ] Eval epoch: 40
[ Tue Jun 20 03:00:11 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:11 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:11 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:11 2023 ] Training epoch: 41
[ Tue Jun 20 03:00:11 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:00:11 2023 ] 	Time consumption: [Data]36%, [Network]63%
[ Tue Jun 20 03:00:11 2023 ] Eval epoch: 41
[ Tue Jun 20 03:00:11 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:11 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:11 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:11 2023 ] Training epoch: 42
[ Tue Jun 20 03:00:12 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:00:12 2023 ] 	Time consumption: [Data]38%, [Network]61%
[ Tue Jun 20 03:00:12 2023 ] Eval epoch: 42
[ Tue Jun 20 03:00:12 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:12 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:12 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:12 2023 ] Training epoch: 43
[ Tue Jun 20 03:00:13 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:00:13 2023 ] 	Time consumption: [Data]37%, [Network]62%
[ Tue Jun 20 03:00:13 2023 ] Eval epoch: 43
[ Tue Jun 20 03:00:13 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:13 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:13 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:13 2023 ] Training epoch: 44
[ Tue Jun 20 03:00:13 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:00:13 2023 ] 	Time consumption: [Data]36%, [Network]63%
[ Tue Jun 20 03:00:13 2023 ] Eval epoch: 44
[ Tue Jun 20 03:00:14 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:14 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:14 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:14 2023 ] Training epoch: 45
[ Tue Jun 20 03:00:14 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:00:14 2023 ] 	Time consumption: [Data]35%, [Network]64%
[ Tue Jun 20 03:00:14 2023 ] Eval epoch: 45
[ Tue Jun 20 03:00:14 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:14 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:14 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:14 2023 ] Training epoch: 46
[ Tue Jun 20 03:00:15 2023 ] 	Training loss: nan.  Training acc: 42.71%.
[ Tue Jun 20 03:00:15 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 03:00:15 2023 ] Eval epoch: 46
[ Tue Jun 20 03:00:15 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:15 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:15 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:15 2023 ] Training epoch: 47
[ Tue Jun 20 03:00:16 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:00:16 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:00:16 2023 ] Eval epoch: 47
[ Tue Jun 20 03:00:16 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:16 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:16 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:16 2023 ] Training epoch: 48
[ Tue Jun 20 03:00:17 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:00:17 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:00:17 2023 ] Eval epoch: 48
[ Tue Jun 20 03:00:17 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:17 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:17 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:17 2023 ] Training epoch: 49
[ Tue Jun 20 03:00:17 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:00:17 2023 ] 	Time consumption: [Data]34%, [Network]66%
[ Tue Jun 20 03:00:17 2023 ] Eval epoch: 49
[ Tue Jun 20 03:00:18 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:18 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:18 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:18 2023 ] Training epoch: 50
[ Tue Jun 20 03:00:18 2023 ] 	Training loss: nan.  Training acc: 38.54%.
[ Tue Jun 20 03:00:18 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:00:18 2023 ] Eval epoch: 50
[ Tue Jun 20 03:00:18 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:18 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:18 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:18 2023 ] Training epoch: 51
[ Tue Jun 20 03:00:19 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:00:19 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:00:19 2023 ] Eval epoch: 51
[ Tue Jun 20 03:00:19 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:19 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:19 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:19 2023 ] Training epoch: 52
[ Tue Jun 20 03:00:20 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:00:20 2023 ] 	Time consumption: [Data]37%, [Network]62%
[ Tue Jun 20 03:00:20 2023 ] Eval epoch: 52
[ Tue Jun 20 03:00:20 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:20 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:20 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:20 2023 ] Training epoch: 53
[ Tue Jun 20 03:00:20 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:00:20 2023 ] 	Time consumption: [Data]35%, [Network]65%
[ Tue Jun 20 03:00:20 2023 ] Eval epoch: 53
[ Tue Jun 20 03:00:21 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:21 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:21 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:21 2023 ] Training epoch: 54
[ Tue Jun 20 03:00:21 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:00:21 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:00:21 2023 ] Eval epoch: 54
[ Tue Jun 20 03:00:21 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:21 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:21 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:21 2023 ] Training epoch: 55
[ Tue Jun 20 03:00:22 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:00:22 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 03:00:22 2023 ] Eval epoch: 55
[ Tue Jun 20 03:00:22 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:22 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:22 2023 ] Training epoch: 56
[ Tue Jun 20 03:00:23 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:00:23 2023 ] 	Time consumption: [Data]36%, [Network]63%
[ Tue Jun 20 03:00:23 2023 ] Eval epoch: 56
[ Tue Jun 20 03:00:23 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:23 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:23 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:23 2023 ] Training epoch: 57
[ Tue Jun 20 03:00:24 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:00:24 2023 ] 	Time consumption: [Data]29%, [Network]70%
[ Tue Jun 20 03:00:24 2023 ] Eval epoch: 57
[ Tue Jun 20 03:00:24 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:24 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:24 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:24 2023 ] Training epoch: 58
[ Tue Jun 20 03:00:25 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:00:25 2023 ] 	Time consumption: [Data]29%, [Network]70%
[ Tue Jun 20 03:00:25 2023 ] Eval epoch: 58
[ Tue Jun 20 03:00:25 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:25 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:25 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:25 2023 ] Training epoch: 59
[ Tue Jun 20 03:00:26 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:00:26 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 03:00:26 2023 ] Eval epoch: 59
[ Tue Jun 20 03:00:26 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:26 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:26 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:26 2023 ] Training epoch: 60
[ Tue Jun 20 03:00:27 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:00:27 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 03:00:27 2023 ] Eval epoch: 60
[ Tue Jun 20 03:00:27 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:27 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:27 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:27 2023 ] Training epoch: 61
[ Tue Jun 20 03:00:27 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:00:27 2023 ] 	Time consumption: [Data]28%, [Network]71%
[ Tue Jun 20 03:00:27 2023 ] Eval epoch: 61
[ Tue Jun 20 03:00:28 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:28 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:28 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:28 2023 ] Training epoch: 62
[ Tue Jun 20 03:00:28 2023 ] 	Training loss: nan.  Training acc: 38.02%.
[ Tue Jun 20 03:00:28 2023 ] 	Time consumption: [Data]32%, [Network]68%
[ Tue Jun 20 03:00:28 2023 ] Eval epoch: 62
[ Tue Jun 20 03:00:29 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:29 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:29 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:29 2023 ] Training epoch: 63
[ Tue Jun 20 03:00:29 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:00:29 2023 ] 	Time consumption: [Data]31%, [Network]69%
[ Tue Jun 20 03:00:29 2023 ] Eval epoch: 63
[ Tue Jun 20 03:00:30 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:30 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:30 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:30 2023 ] Training epoch: 64
[ Tue Jun 20 03:00:30 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:00:30 2023 ] 	Time consumption: [Data]29%, [Network]70%
[ Tue Jun 20 03:00:30 2023 ] Eval epoch: 64
[ Tue Jun 20 03:00:31 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:31 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:31 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:31 2023 ] Training epoch: 65
[ Tue Jun 20 03:00:31 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:00:31 2023 ] 	Time consumption: [Data]28%, [Network]71%
[ Tue Jun 20 03:00:31 2023 ] Eval epoch: 65
[ Tue Jun 20 03:00:32 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:32 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:32 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:32 2023 ] Training epoch: 66
[ Tue Jun 20 03:00:32 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:00:32 2023 ] 	Time consumption: [Data]31%, [Network]69%
[ Tue Jun 20 03:00:32 2023 ] Eval epoch: 66
[ Tue Jun 20 03:00:32 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:32 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:32 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:32 2023 ] Training epoch: 67
[ Tue Jun 20 03:00:33 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:00:33 2023 ] 	Time consumption: [Data]32%, [Network]67%
[ Tue Jun 20 03:00:33 2023 ] Eval epoch: 67
[ Tue Jun 20 03:00:33 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:33 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:33 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:33 2023 ] Training epoch: 68
[ Tue Jun 20 03:00:34 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:00:34 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:00:34 2023 ] Eval epoch: 68
[ Tue Jun 20 03:00:34 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:34 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:34 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:34 2023 ] Training epoch: 69
[ Tue Jun 20 03:00:35 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:00:35 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:00:35 2023 ] Eval epoch: 69
[ Tue Jun 20 03:00:35 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:35 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:35 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:35 2023 ] Training epoch: 70
[ Tue Jun 20 03:00:36 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:00:36 2023 ] 	Time consumption: [Data]35%, [Network]65%
[ Tue Jun 20 03:00:36 2023 ] Eval epoch: 70
[ Tue Jun 20 03:00:36 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:36 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:36 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:36 2023 ] Training epoch: 71
[ Tue Jun 20 03:00:36 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:00:36 2023 ] 	Time consumption: [Data]38%, [Network]61%
[ Tue Jun 20 03:00:36 2023 ] Eval epoch: 71
[ Tue Jun 20 03:00:37 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:37 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:37 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:37 2023 ] Training epoch: 72
[ Tue Jun 20 03:00:37 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:00:37 2023 ] 	Time consumption: [Data]38%, [Network]61%
[ Tue Jun 20 03:00:37 2023 ] Eval epoch: 72
[ Tue Jun 20 03:00:37 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:37 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:37 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:37 2023 ] Training epoch: 73
[ Tue Jun 20 03:00:38 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:00:38 2023 ] 	Time consumption: [Data]35%, [Network]64%
[ Tue Jun 20 03:00:38 2023 ] Eval epoch: 73
[ Tue Jun 20 03:00:38 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:38 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:38 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:38 2023 ] Training epoch: 74
[ Tue Jun 20 03:00:39 2023 ] 	Training loss: nan.  Training acc: 38.54%.
[ Tue Jun 20 03:00:39 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:00:39 2023 ] Eval epoch: 74
[ Tue Jun 20 03:00:39 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:39 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:39 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:39 2023 ] Training epoch: 75
[ Tue Jun 20 03:00:39 2023 ] 	Training loss: nan.  Training acc: 38.02%.
[ Tue Jun 20 03:00:39 2023 ] 	Time consumption: [Data]38%, [Network]61%
[ Tue Jun 20 03:00:39 2023 ] Eval epoch: 75
[ Tue Jun 20 03:00:40 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:40 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:40 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:40 2023 ] Training epoch: 76
[ Tue Jun 20 03:00:40 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:00:40 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:00:40 2023 ] Eval epoch: 76
[ Tue Jun 20 03:00:40 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:40 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:40 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:40 2023 ] Training epoch: 77
[ Tue Jun 20 03:00:41 2023 ] 	Training loss: nan.  Training acc: 44.79%.
[ Tue Jun 20 03:00:41 2023 ] 	Time consumption: [Data]38%, [Network]61%
[ Tue Jun 20 03:00:41 2023 ] Eval epoch: 77
[ Tue Jun 20 03:00:41 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:41 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:41 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:41 2023 ] Training epoch: 78
[ Tue Jun 20 03:00:42 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:00:42 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:00:42 2023 ] Eval epoch: 78
[ Tue Jun 20 03:00:42 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:42 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:42 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:42 2023 ] Training epoch: 79
[ Tue Jun 20 03:00:42 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:00:42 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:00:43 2023 ] Eval epoch: 79
[ Tue Jun 20 03:00:43 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:43 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:43 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:43 2023 ] Training epoch: 80
[ Tue Jun 20 03:00:43 2023 ] 	Training loss: nan.  Training acc: 38.54%.
[ Tue Jun 20 03:00:43 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:00:43 2023 ] Eval epoch: 80
[ Tue Jun 20 03:00:44 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:44 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:44 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:44 2023 ] Training epoch: 81
[ Tue Jun 20 03:00:44 2023 ] 	Training loss: nan.  Training acc: 37.50%.
[ Tue Jun 20 03:00:44 2023 ] 	Time consumption: [Data]36%, [Network]63%
[ Tue Jun 20 03:00:44 2023 ] Eval epoch: 81
[ Tue Jun 20 03:00:44 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:44 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:44 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:44 2023 ] Training epoch: 82
[ Tue Jun 20 03:00:45 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:00:45 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:00:45 2023 ] Eval epoch: 82
[ Tue Jun 20 03:00:45 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:45 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:45 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:45 2023 ] Training epoch: 83
[ Tue Jun 20 03:00:46 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:00:46 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:00:46 2023 ] Eval epoch: 83
[ Tue Jun 20 03:00:46 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:46 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:46 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:46 2023 ] Training epoch: 84
[ Tue Jun 20 03:00:46 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:00:46 2023 ] 	Time consumption: [Data]37%, [Network]62%
[ Tue Jun 20 03:00:46 2023 ] Eval epoch: 84
[ Tue Jun 20 03:00:47 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:47 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:47 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:47 2023 ] Training epoch: 85
[ Tue Jun 20 03:00:47 2023 ] 	Training loss: nan.  Training acc: 42.71%.
[ Tue Jun 20 03:00:47 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:00:47 2023 ] Eval epoch: 85
[ Tue Jun 20 03:00:47 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:47 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:47 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:47 2023 ] Training epoch: 86
[ Tue Jun 20 03:00:48 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:00:48 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:00:48 2023 ] Eval epoch: 86
[ Tue Jun 20 03:00:48 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:48 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:48 2023 ] Training epoch: 87
[ Tue Jun 20 03:00:49 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:00:49 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:00:49 2023 ] Eval epoch: 87
[ Tue Jun 20 03:00:49 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:49 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:49 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:49 2023 ] Training epoch: 88
[ Tue Jun 20 03:00:50 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:00:50 2023 ] 	Time consumption: [Data]38%, [Network]61%
[ Tue Jun 20 03:00:50 2023 ] Eval epoch: 88
[ Tue Jun 20 03:00:50 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:50 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:50 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:50 2023 ] Training epoch: 89
[ Tue Jun 20 03:00:50 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:00:50 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 03:00:50 2023 ] Eval epoch: 89
[ Tue Jun 20 03:00:51 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:51 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:51 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:51 2023 ] Training epoch: 90
[ Tue Jun 20 03:00:51 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:00:51 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:00:51 2023 ] Eval epoch: 90
[ Tue Jun 20 03:00:51 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:51 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:51 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:51 2023 ] Training epoch: 91
[ Tue Jun 20 03:00:52 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:00:52 2023 ] 	Time consumption: [Data]35%, [Network]65%
[ Tue Jun 20 03:00:52 2023 ] Eval epoch: 91
[ Tue Jun 20 03:00:52 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:52 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:52 2023 ] Training epoch: 92
[ Tue Jun 20 03:00:53 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:00:53 2023 ] 	Time consumption: [Data]36%, [Network]63%
[ Tue Jun 20 03:00:53 2023 ] Eval epoch: 92
[ Tue Jun 20 03:00:53 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:53 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:53 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:53 2023 ] Training epoch: 93
[ Tue Jun 20 03:00:53 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:00:53 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:00:53 2023 ] Eval epoch: 93
[ Tue Jun 20 03:00:54 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:54 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:54 2023 ] Training epoch: 94
[ Tue Jun 20 03:00:54 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:00:54 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 03:00:54 2023 ] Eval epoch: 94
[ Tue Jun 20 03:00:54 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:54 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:54 2023 ] Training epoch: 95
[ Tue Jun 20 03:00:55 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:00:55 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:00:55 2023 ] Eval epoch: 95
[ Tue Jun 20 03:00:55 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:55 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:55 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:55 2023 ] Training epoch: 96
[ Tue Jun 20 03:00:56 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:00:56 2023 ] 	Time consumption: [Data]39%, [Network]60%
[ Tue Jun 20 03:00:56 2023 ] Eval epoch: 96
[ Tue Jun 20 03:00:56 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:56 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:56 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:56 2023 ] Training epoch: 97
[ Tue Jun 20 03:00:57 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:00:57 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:00:57 2023 ] Eval epoch: 97
[ Tue Jun 20 03:00:57 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:57 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:57 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:57 2023 ] Training epoch: 98
[ Tue Jun 20 03:00:57 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:00:57 2023 ] 	Time consumption: [Data]36%, [Network]63%
[ Tue Jun 20 03:00:57 2023 ] Eval epoch: 98
[ Tue Jun 20 03:00:58 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:58 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:58 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:58 2023 ] Training epoch: 99
[ Tue Jun 20 03:00:58 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:00:58 2023 ] 	Time consumption: [Data]40%, [Network]60%
[ Tue Jun 20 03:00:58 2023 ] Eval epoch: 99
[ Tue Jun 20 03:00:58 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:58 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:58 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:58 2023 ] Training epoch: 100
[ Tue Jun 20 03:00:59 2023 ] 	Training loss: nan.  Training acc: 38.54%.
[ Tue Jun 20 03:00:59 2023 ] 	Time consumption: [Data]34%, [Network]65%
[ Tue Jun 20 03:00:59 2023 ] Eval epoch: 100
[ Tue Jun 20 03:00:59 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:00:59 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:00:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:00:59 2023 ] Training epoch: 101
[ Tue Jun 20 03:01:00 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:01:00 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:01:00 2023 ] Eval epoch: 101
[ Tue Jun 20 03:01:00 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:01:00 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:01:00 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:01:00 2023 ] Training epoch: 102
[ Tue Jun 20 03:01:01 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:01:01 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:01:01 2023 ] Eval epoch: 102
[ Tue Jun 20 03:01:01 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:01:01 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:01:01 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:01:01 2023 ] Training epoch: 103
[ Tue Jun 20 03:01:01 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:01:01 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:01:01 2023 ] Eval epoch: 103
[ Tue Jun 20 03:01:02 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:01:02 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:01:02 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:01:02 2023 ] Training epoch: 104
[ Tue Jun 20 03:01:02 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:01:02 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:01:02 2023 ] Eval epoch: 104
[ Tue Jun 20 03:01:02 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:01:02 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:01:02 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:01:02 2023 ] Training epoch: 105
[ Tue Jun 20 03:01:03 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:01:03 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:01:03 2023 ] Eval epoch: 105
[ Tue Jun 20 03:01:03 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:01:03 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:01:03 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:01:03 2023 ] Training epoch: 106
[ Tue Jun 20 03:01:04 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:01:04 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:01:04 2023 ] Eval epoch: 106
[ Tue Jun 20 03:01:04 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:01:04 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:01:04 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:01:04 2023 ] Training epoch: 107
[ Tue Jun 20 03:01:05 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:01:05 2023 ] 	Time consumption: [Data]34%, [Network]66%
[ Tue Jun 20 03:01:05 2023 ] Eval epoch: 107
[ Tue Jun 20 03:01:05 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:01:05 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:01:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:01:05 2023 ] Training epoch: 108
[ Tue Jun 20 03:01:05 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:01:05 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:01:05 2023 ] Eval epoch: 108
[ Tue Jun 20 03:01:06 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:01:06 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:01:06 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:01:06 2023 ] Training epoch: 109
[ Tue Jun 20 03:01:06 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:01:06 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:01:06 2023 ] Eval epoch: 109
[ Tue Jun 20 03:01:06 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:01:06 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:01:06 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:01:06 2023 ] Training epoch: 110
[ Tue Jun 20 03:01:07 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:01:07 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:01:07 2023 ] Eval epoch: 110
[ Tue Jun 20 03:01:07 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:01:07 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:01:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:01:08 2023 ] Best accuracy: 0.2982456140350877
[ Tue Jun 20 03:01:08 2023 ] Epoch number: 1
[ Tue Jun 20 03:01:08 2023 ] Model name: results/ec3d_NTU60_CS
[ Tue Jun 20 03:01:08 2023 ] Model total number of params: 1538958
[ Tue Jun 20 03:01:08 2023 ] Weight decay: 0.0005
[ Tue Jun 20 03:01:08 2023 ] Base LR: 0.1
[ Tue Jun 20 03:01:08 2023 ] Batch Size: 64
[ Tue Jun 20 03:01:08 2023 ] Test Batch Size: 64
[ Tue Jun 20 03:01:08 2023 ] seed: 1
[ Tue Jun 20 03:02:55 2023 ] using warm up, epoch: 5
[ Tue Jun 20 03:02:57 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 03:02:57 2023 ] # Parameters: 1538958
[ Tue Jun 20 03:02:57 2023 ] Training epoch: 1
[ Tue Jun 20 03:03:01 2023 ] 	Training loss: 717.0567.  Training acc: 33.33%.
[ Tue Jun 20 03:03:01 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 20 03:03:01 2023 ] Eval epoch: 1
[ Tue Jun 20 03:03:01 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:01 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:01 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:01 2023 ] Training epoch: 2
[ Tue Jun 20 03:03:02 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:03:02 2023 ] 	Time consumption: [Data]35%, [Network]64%
[ Tue Jun 20 03:03:02 2023 ] Eval epoch: 2
[ Tue Jun 20 03:03:02 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:02 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:02 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:02 2023 ] Training epoch: 3
[ Tue Jun 20 03:03:03 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:03:03 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:03:03 2023 ] Eval epoch: 3
[ Tue Jun 20 03:03:03 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:03 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:03 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:03 2023 ] Training epoch: 4
[ Tue Jun 20 03:03:03 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:03:03 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:03:03 2023 ] Eval epoch: 4
[ Tue Jun 20 03:03:04 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:04 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:04 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:04 2023 ] Training epoch: 5
[ Tue Jun 20 03:03:04 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:03:04 2023 ] 	Time consumption: [Data]41%, [Network]58%
[ Tue Jun 20 03:03:04 2023 ] Eval epoch: 5
[ Tue Jun 20 03:03:04 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:04 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:04 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:04 2023 ] Training epoch: 6
[ Tue Jun 20 03:03:05 2023 ] 	Training loss: nan.  Training acc: 42.71%.
[ Tue Jun 20 03:03:05 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:03:05 2023 ] Eval epoch: 6
[ Tue Jun 20 03:03:05 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:05 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:05 2023 ] Training epoch: 7
[ Tue Jun 20 03:03:06 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:03:06 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 03:03:06 2023 ] Eval epoch: 7
[ Tue Jun 20 03:03:06 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:06 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:06 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:06 2023 ] Training epoch: 8
[ Tue Jun 20 03:03:07 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:03:07 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 03:03:07 2023 ] Eval epoch: 8
[ Tue Jun 20 03:03:07 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:07 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:07 2023 ] Training epoch: 9
[ Tue Jun 20 03:03:08 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:03:08 2023 ] 	Time consumption: [Data]40%, [Network]60%
[ Tue Jun 20 03:03:08 2023 ] Eval epoch: 9
[ Tue Jun 20 03:03:08 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:08 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:08 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:08 2023 ] Training epoch: 10
[ Tue Jun 20 03:03:08 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:03:08 2023 ] 	Time consumption: [Data]37%, [Network]62%
[ Tue Jun 20 03:03:08 2023 ] Eval epoch: 10
[ Tue Jun 20 03:03:09 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:09 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:09 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:09 2023 ] Training epoch: 11
[ Tue Jun 20 03:03:09 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:03:09 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:03:09 2023 ] Eval epoch: 11
[ Tue Jun 20 03:03:09 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:09 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:09 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:09 2023 ] Training epoch: 12
[ Tue Jun 20 03:03:10 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:03:10 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:03:10 2023 ] Eval epoch: 12
[ Tue Jun 20 03:03:10 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:10 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:10 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:10 2023 ] Training epoch: 13
[ Tue Jun 20 03:03:11 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:03:11 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:03:11 2023 ] Eval epoch: 13
[ Tue Jun 20 03:03:11 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:11 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:11 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:11 2023 ] Training epoch: 14
[ Tue Jun 20 03:03:12 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:03:12 2023 ] 	Time consumption: [Data]35%, [Network]65%
[ Tue Jun 20 03:03:12 2023 ] Eval epoch: 14
[ Tue Jun 20 03:03:12 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:12 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:12 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:12 2023 ] Training epoch: 15
[ Tue Jun 20 03:03:12 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:03:12 2023 ] 	Time consumption: [Data]41%, [Network]59%
[ Tue Jun 20 03:03:12 2023 ] Eval epoch: 15
[ Tue Jun 20 03:03:13 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:13 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:13 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:13 2023 ] Training epoch: 16
[ Tue Jun 20 03:03:13 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:03:13 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:03:13 2023 ] Eval epoch: 16
[ Tue Jun 20 03:03:14 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:14 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:14 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:14 2023 ] Training epoch: 17
[ Tue Jun 20 03:03:14 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:03:14 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:03:14 2023 ] Eval epoch: 17
[ Tue Jun 20 03:03:14 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:14 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:14 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:14 2023 ] Training epoch: 18
[ Tue Jun 20 03:03:15 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:03:15 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 03:03:15 2023 ] Eval epoch: 18
[ Tue Jun 20 03:03:15 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:15 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:15 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:15 2023 ] Training epoch: 19
[ Tue Jun 20 03:03:16 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:03:16 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 03:03:16 2023 ] Eval epoch: 19
[ Tue Jun 20 03:03:16 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:16 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:16 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:16 2023 ] Training epoch: 20
[ Tue Jun 20 03:03:17 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:03:17 2023 ] 	Time consumption: [Data]28%, [Network]71%
[ Tue Jun 20 03:03:17 2023 ] Eval epoch: 20
[ Tue Jun 20 03:03:17 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:17 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:17 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:17 2023 ] Training epoch: 21
[ Tue Jun 20 03:03:18 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:03:18 2023 ] 	Time consumption: [Data]30%, [Network]69%
[ Tue Jun 20 03:03:18 2023 ] Eval epoch: 21
[ Tue Jun 20 03:03:18 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:18 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:18 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:18 2023 ] Training epoch: 22
[ Tue Jun 20 03:03:19 2023 ] 	Training loss: nan.  Training acc: 38.54%.
[ Tue Jun 20 03:03:19 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 03:03:19 2023 ] Eval epoch: 22
[ Tue Jun 20 03:03:19 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:19 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:19 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:19 2023 ] Training epoch: 23
[ Tue Jun 20 03:03:20 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:03:20 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 03:03:20 2023 ] Eval epoch: 23
[ Tue Jun 20 03:03:20 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:20 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:20 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:20 2023 ] Training epoch: 24
[ Tue Jun 20 03:03:21 2023 ] 	Training loss: nan.  Training acc: 42.71%.
[ Tue Jun 20 03:03:21 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 03:03:21 2023 ] Eval epoch: 24
[ Tue Jun 20 03:03:21 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:21 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:21 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:21 2023 ] Training epoch: 25
[ Tue Jun 20 03:03:22 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:03:22 2023 ] 	Time consumption: [Data]30%, [Network]69%
[ Tue Jun 20 03:03:22 2023 ] Eval epoch: 25
[ Tue Jun 20 03:03:22 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:22 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:22 2023 ] Training epoch: 26
[ Tue Jun 20 03:03:23 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:03:23 2023 ] 	Time consumption: [Data]32%, [Network]67%
[ Tue Jun 20 03:03:23 2023 ] Eval epoch: 26
[ Tue Jun 20 03:03:23 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:23 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:23 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:23 2023 ] Training epoch: 27
[ Tue Jun 20 03:03:24 2023 ] 	Training loss: nan.  Training acc: 42.71%.
[ Tue Jun 20 03:03:24 2023 ] 	Time consumption: [Data]29%, [Network]70%
[ Tue Jun 20 03:03:24 2023 ] Eval epoch: 27
[ Tue Jun 20 03:03:24 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:24 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:24 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:24 2023 ] Training epoch: 28
[ Tue Jun 20 03:03:25 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:03:25 2023 ] 	Time consumption: [Data]33%, [Network]67%
[ Tue Jun 20 03:03:25 2023 ] Eval epoch: 28
[ Tue Jun 20 03:03:25 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:25 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:25 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:25 2023 ] Training epoch: 29
[ Tue Jun 20 03:03:26 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:03:26 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:03:26 2023 ] Eval epoch: 29
[ Tue Jun 20 03:03:26 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:26 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:26 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:26 2023 ] Training epoch: 30
[ Tue Jun 20 03:03:26 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:03:26 2023 ] 	Time consumption: [Data]39%, [Network]60%
[ Tue Jun 20 03:03:26 2023 ] Eval epoch: 30
[ Tue Jun 20 03:03:27 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:27 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:27 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:27 2023 ] Training epoch: 31
[ Tue Jun 20 03:03:27 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:03:27 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:03:27 2023 ] Eval epoch: 31
[ Tue Jun 20 03:03:27 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:27 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:27 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:27 2023 ] Training epoch: 32
[ Tue Jun 20 03:03:28 2023 ] 	Training loss: nan.  Training acc: 44.79%.
[ Tue Jun 20 03:03:28 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 03:03:28 2023 ] Eval epoch: 32
[ Tue Jun 20 03:03:28 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:28 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:28 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:28 2023 ] Training epoch: 33
[ Tue Jun 20 03:03:29 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:03:29 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 03:03:29 2023 ] Eval epoch: 33
[ Tue Jun 20 03:03:29 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:29 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:29 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:29 2023 ] Training epoch: 34
[ Tue Jun 20 03:03:30 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:03:30 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 03:03:30 2023 ] Eval epoch: 34
[ Tue Jun 20 03:03:30 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:30 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:30 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:30 2023 ] Training epoch: 35
[ Tue Jun 20 03:03:30 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:03:30 2023 ] 	Time consumption: [Data]35%, [Network]65%
[ Tue Jun 20 03:03:30 2023 ] Eval epoch: 35
[ Tue Jun 20 03:03:31 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:31 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:31 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:31 2023 ] Training epoch: 36
[ Tue Jun 20 03:03:31 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:03:31 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:03:31 2023 ] Eval epoch: 36
[ Tue Jun 20 03:03:31 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:31 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:31 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:31 2023 ] Training epoch: 37
[ Tue Jun 20 03:03:32 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:03:32 2023 ] 	Time consumption: [Data]38%, [Network]61%
[ Tue Jun 20 03:03:32 2023 ] Eval epoch: 37
[ Tue Jun 20 03:03:32 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:32 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:32 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:32 2023 ] Training epoch: 38
[ Tue Jun 20 03:03:33 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:03:33 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 03:03:33 2023 ] Eval epoch: 38
[ Tue Jun 20 03:03:33 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:33 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:33 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:33 2023 ] Training epoch: 39
[ Tue Jun 20 03:03:34 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:03:34 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:03:34 2023 ] Eval epoch: 39
[ Tue Jun 20 03:03:34 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:34 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:34 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:34 2023 ] Training epoch: 40
[ Tue Jun 20 03:03:34 2023 ] 	Training loss: nan.  Training acc: 42.71%.
[ Tue Jun 20 03:03:34 2023 ] 	Time consumption: [Data]40%, [Network]60%
[ Tue Jun 20 03:03:34 2023 ] Eval epoch: 40
[ Tue Jun 20 03:03:35 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:35 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:35 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:35 2023 ] Training epoch: 41
[ Tue Jun 20 03:03:35 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:03:35 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 03:03:35 2023 ] Eval epoch: 41
[ Tue Jun 20 03:03:36 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:36 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:36 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:36 2023 ] Training epoch: 42
[ Tue Jun 20 03:03:36 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:03:36 2023 ] 	Time consumption: [Data]37%, [Network]62%
[ Tue Jun 20 03:03:36 2023 ] Eval epoch: 42
[ Tue Jun 20 03:03:36 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:36 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:36 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:36 2023 ] Training epoch: 43
[ Tue Jun 20 03:03:37 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:03:37 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:03:37 2023 ] Eval epoch: 43
[ Tue Jun 20 03:03:37 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:37 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:37 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:37 2023 ] Training epoch: 44
[ Tue Jun 20 03:03:38 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:03:38 2023 ] 	Time consumption: [Data]38%, [Network]61%
[ Tue Jun 20 03:03:38 2023 ] Eval epoch: 44
[ Tue Jun 20 03:03:38 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:38 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:38 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:38 2023 ] Training epoch: 45
[ Tue Jun 20 03:03:38 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:03:38 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 03:03:38 2023 ] Eval epoch: 45
[ Tue Jun 20 03:03:39 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:39 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:39 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:39 2023 ] Training epoch: 46
[ Tue Jun 20 03:03:39 2023 ] 	Training loss: nan.  Training acc: 42.71%.
[ Tue Jun 20 03:03:39 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:03:39 2023 ] Eval epoch: 46
[ Tue Jun 20 03:03:40 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:40 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:40 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:40 2023 ] Training epoch: 47
[ Tue Jun 20 03:03:40 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:03:40 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:03:40 2023 ] Eval epoch: 47
[ Tue Jun 20 03:03:40 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:40 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:40 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:40 2023 ] Training epoch: 48
[ Tue Jun 20 03:03:41 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:03:41 2023 ] 	Time consumption: [Data]37%, [Network]62%
[ Tue Jun 20 03:03:41 2023 ] Eval epoch: 48
[ Tue Jun 20 03:03:41 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:41 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:41 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:41 2023 ] Training epoch: 49
[ Tue Jun 20 03:03:42 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:03:42 2023 ] 	Time consumption: [Data]39%, [Network]60%
[ Tue Jun 20 03:03:42 2023 ] Eval epoch: 49
[ Tue Jun 20 03:03:42 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:42 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:42 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:42 2023 ] Training epoch: 50
[ Tue Jun 20 03:03:42 2023 ] 	Training loss: nan.  Training acc: 38.54%.
[ Tue Jun 20 03:03:42 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:03:42 2023 ] Eval epoch: 50
[ Tue Jun 20 03:03:43 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:43 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:43 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:43 2023 ] Training epoch: 51
[ Tue Jun 20 03:03:43 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:03:43 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:03:43 2023 ] Eval epoch: 51
[ Tue Jun 20 03:03:44 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:44 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:44 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:44 2023 ] Training epoch: 52
[ Tue Jun 20 03:03:44 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:03:44 2023 ] 	Time consumption: [Data]40%, [Network]60%
[ Tue Jun 20 03:03:44 2023 ] Eval epoch: 52
[ Tue Jun 20 03:03:44 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:44 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:44 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:44 2023 ] Training epoch: 53
[ Tue Jun 20 03:03:45 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:03:45 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:03:45 2023 ] Eval epoch: 53
[ Tue Jun 20 03:03:45 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:45 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:45 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:45 2023 ] Training epoch: 54
[ Tue Jun 20 03:03:46 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:03:46 2023 ] 	Time consumption: [Data]41%, [Network]59%
[ Tue Jun 20 03:03:46 2023 ] Eval epoch: 54
[ Tue Jun 20 03:03:46 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:46 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:46 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:46 2023 ] Training epoch: 55
[ Tue Jun 20 03:03:47 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:03:47 2023 ] 	Time consumption: [Data]37%, [Network]62%
[ Tue Jun 20 03:03:47 2023 ] Eval epoch: 55
[ Tue Jun 20 03:03:47 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:47 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:47 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:47 2023 ] Training epoch: 56
[ Tue Jun 20 03:03:47 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:03:47 2023 ] 	Time consumption: [Data]38%, [Network]61%
[ Tue Jun 20 03:03:47 2023 ] Eval epoch: 56
[ Tue Jun 20 03:03:48 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:48 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:48 2023 ] Training epoch: 57
[ Tue Jun 20 03:03:48 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:03:48 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 03:03:48 2023 ] Eval epoch: 57
[ Tue Jun 20 03:03:48 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:48 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:48 2023 ] Training epoch: 58
[ Tue Jun 20 03:03:49 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:03:49 2023 ] 	Time consumption: [Data]38%, [Network]61%
[ Tue Jun 20 03:03:49 2023 ] Eval epoch: 58
[ Tue Jun 20 03:03:49 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:49 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:49 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:49 2023 ] Training epoch: 59
[ Tue Jun 20 03:03:50 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:03:50 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:03:50 2023 ] Eval epoch: 59
[ Tue Jun 20 03:03:50 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:50 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:50 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:50 2023 ] Training epoch: 60
[ Tue Jun 20 03:03:51 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:03:51 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 03:03:51 2023 ] Eval epoch: 60
[ Tue Jun 20 03:03:51 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:51 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:51 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:51 2023 ] Training epoch: 61
[ Tue Jun 20 03:03:51 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:03:51 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:03:51 2023 ] Eval epoch: 61
[ Tue Jun 20 03:03:52 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:52 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:52 2023 ] Training epoch: 62
[ Tue Jun 20 03:03:52 2023 ] 	Training loss: nan.  Training acc: 38.02%.
[ Tue Jun 20 03:03:52 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:03:52 2023 ] Eval epoch: 62
[ Tue Jun 20 03:03:52 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:52 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:52 2023 ] Training epoch: 63
[ Tue Jun 20 03:03:53 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:03:53 2023 ] 	Time consumption: [Data]38%, [Network]61%
[ Tue Jun 20 03:03:53 2023 ] Eval epoch: 63
[ Tue Jun 20 03:03:53 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:53 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:53 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:53 2023 ] Training epoch: 64
[ Tue Jun 20 03:03:54 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:03:54 2023 ] 	Time consumption: [Data]40%, [Network]60%
[ Tue Jun 20 03:03:54 2023 ] Eval epoch: 64
[ Tue Jun 20 03:03:54 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:54 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:54 2023 ] Training epoch: 65
[ Tue Jun 20 03:03:55 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:03:55 2023 ] 	Time consumption: [Data]40%, [Network]60%
[ Tue Jun 20 03:03:55 2023 ] Eval epoch: 65
[ Tue Jun 20 03:03:55 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:55 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:55 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:55 2023 ] Training epoch: 66
[ Tue Jun 20 03:03:55 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:03:55 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 03:03:55 2023 ] Eval epoch: 66
[ Tue Jun 20 03:03:56 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:56 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:56 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:56 2023 ] Training epoch: 67
[ Tue Jun 20 03:03:56 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:03:56 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 03:03:56 2023 ] Eval epoch: 67
[ Tue Jun 20 03:03:57 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:57 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:57 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:57 2023 ] Training epoch: 68
[ Tue Jun 20 03:03:57 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:03:57 2023 ] 	Time consumption: [Data]35%, [Network]64%
[ Tue Jun 20 03:03:57 2023 ] Eval epoch: 68
[ Tue Jun 20 03:03:57 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:57 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:57 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:57 2023 ] Training epoch: 69
[ Tue Jun 20 03:03:58 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:03:58 2023 ] 	Time consumption: [Data]39%, [Network]60%
[ Tue Jun 20 03:03:58 2023 ] Eval epoch: 69
[ Tue Jun 20 03:03:58 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:58 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:58 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:58 2023 ] Training epoch: 70
[ Tue Jun 20 03:03:59 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:03:59 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 03:03:59 2023 ] Eval epoch: 70
[ Tue Jun 20 03:03:59 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:03:59 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:03:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:03:59 2023 ] Training epoch: 71
[ Tue Jun 20 03:04:00 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:04:00 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:04:00 2023 ] Eval epoch: 71
[ Tue Jun 20 03:04:00 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:00 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:00 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:00 2023 ] Training epoch: 72
[ Tue Jun 20 03:04:00 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:04:00 2023 ] 	Time consumption: [Data]39%, [Network]60%
[ Tue Jun 20 03:04:00 2023 ] Eval epoch: 72
[ Tue Jun 20 03:04:01 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:01 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:01 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:01 2023 ] Training epoch: 73
[ Tue Jun 20 03:04:01 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:04:01 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:04:01 2023 ] Eval epoch: 73
[ Tue Jun 20 03:04:01 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:01 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:01 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:01 2023 ] Training epoch: 74
[ Tue Jun 20 03:04:02 2023 ] 	Training loss: nan.  Training acc: 38.54%.
[ Tue Jun 20 03:04:02 2023 ] 	Time consumption: [Data]41%, [Network]59%
[ Tue Jun 20 03:04:02 2023 ] Eval epoch: 74
[ Tue Jun 20 03:04:02 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:02 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:02 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:02 2023 ] Training epoch: 75
[ Tue Jun 20 03:04:03 2023 ] 	Training loss: nan.  Training acc: 38.02%.
[ Tue Jun 20 03:04:03 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:04:03 2023 ] Eval epoch: 75
[ Tue Jun 20 03:04:03 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:03 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:03 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:03 2023 ] Training epoch: 76
[ Tue Jun 20 03:04:04 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:04:04 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:04:04 2023 ] Eval epoch: 76
[ Tue Jun 20 03:04:04 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:04 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:04 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:04 2023 ] Training epoch: 77
[ Tue Jun 20 03:04:04 2023 ] 	Training loss: nan.  Training acc: 44.79%.
[ Tue Jun 20 03:04:04 2023 ] 	Time consumption: [Data]41%, [Network]59%
[ Tue Jun 20 03:04:04 2023 ] Eval epoch: 77
[ Tue Jun 20 03:04:05 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:05 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:05 2023 ] Training epoch: 78
[ Tue Jun 20 03:04:05 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:04:05 2023 ] 	Time consumption: [Data]37%, [Network]62%
[ Tue Jun 20 03:04:05 2023 ] Eval epoch: 78
[ Tue Jun 20 03:04:05 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:05 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:05 2023 ] Training epoch: 79
[ Tue Jun 20 03:04:06 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:04:06 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:04:06 2023 ] Eval epoch: 79
[ Tue Jun 20 03:04:06 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:06 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:06 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:06 2023 ] Training epoch: 80
[ Tue Jun 20 03:04:07 2023 ] 	Training loss: nan.  Training acc: 38.54%.
[ Tue Jun 20 03:04:07 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:04:07 2023 ] Eval epoch: 80
[ Tue Jun 20 03:04:07 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:07 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:07 2023 ] Training epoch: 81
[ Tue Jun 20 03:04:08 2023 ] 	Training loss: nan.  Training acc: 37.50%.
[ Tue Jun 20 03:04:08 2023 ] 	Time consumption: [Data]37%, [Network]62%
[ Tue Jun 20 03:04:08 2023 ] Eval epoch: 81
[ Tue Jun 20 03:04:08 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:08 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:08 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:08 2023 ] Training epoch: 82
[ Tue Jun 20 03:04:08 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:04:08 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:04:08 2023 ] Eval epoch: 82
[ Tue Jun 20 03:04:09 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:09 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:09 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:09 2023 ] Training epoch: 83
[ Tue Jun 20 03:04:09 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:04:09 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:04:09 2023 ] Eval epoch: 83
[ Tue Jun 20 03:04:10 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:10 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:10 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:10 2023 ] Training epoch: 84
[ Tue Jun 20 03:04:10 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:04:10 2023 ] 	Time consumption: [Data]38%, [Network]61%
[ Tue Jun 20 03:04:10 2023 ] Eval epoch: 84
[ Tue Jun 20 03:04:10 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:10 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:10 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:10 2023 ] Training epoch: 85
[ Tue Jun 20 03:04:11 2023 ] 	Training loss: nan.  Training acc: 42.71%.
[ Tue Jun 20 03:04:11 2023 ] 	Time consumption: [Data]40%, [Network]59%
[ Tue Jun 20 03:04:11 2023 ] Eval epoch: 85
[ Tue Jun 20 03:04:11 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:11 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:11 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:11 2023 ] Training epoch: 86
[ Tue Jun 20 03:04:12 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:04:12 2023 ] 	Time consumption: [Data]33%, [Network]67%
[ Tue Jun 20 03:04:12 2023 ] Eval epoch: 86
[ Tue Jun 20 03:04:12 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:12 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:12 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:12 2023 ] Training epoch: 87
[ Tue Jun 20 03:04:13 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:04:13 2023 ] 	Time consumption: [Data]32%, [Network]68%
[ Tue Jun 20 03:04:13 2023 ] Eval epoch: 87
[ Tue Jun 20 03:04:13 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:13 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:13 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:13 2023 ] Training epoch: 88
[ Tue Jun 20 03:04:14 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:04:14 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 03:04:14 2023 ] Eval epoch: 88
[ Tue Jun 20 03:04:14 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:14 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:14 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:14 2023 ] Training epoch: 89
[ Tue Jun 20 03:04:15 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:04:15 2023 ] 	Time consumption: [Data]28%, [Network]71%
[ Tue Jun 20 03:04:15 2023 ] Eval epoch: 89
[ Tue Jun 20 03:04:15 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:15 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:15 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:15 2023 ] Training epoch: 90
[ Tue Jun 20 03:04:16 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:04:16 2023 ] 	Time consumption: [Data]32%, [Network]67%
[ Tue Jun 20 03:04:16 2023 ] Eval epoch: 90
[ Tue Jun 20 03:04:16 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:16 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:16 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:16 2023 ] Training epoch: 91
[ Tue Jun 20 03:04:17 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:04:17 2023 ] 	Time consumption: [Data]30%, [Network]69%
[ Tue Jun 20 03:04:17 2023 ] Eval epoch: 91
[ Tue Jun 20 03:04:17 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:17 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:17 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:17 2023 ] Training epoch: 92
[ Tue Jun 20 03:04:18 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:04:18 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 03:04:18 2023 ] Eval epoch: 92
[ Tue Jun 20 03:04:18 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:18 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:18 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:18 2023 ] Training epoch: 93
[ Tue Jun 20 03:04:19 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:04:19 2023 ] 	Time consumption: [Data]31%, [Network]69%
[ Tue Jun 20 03:04:19 2023 ] Eval epoch: 93
[ Tue Jun 20 03:04:19 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:19 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:19 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:19 2023 ] Training epoch: 94
[ Tue Jun 20 03:04:20 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:04:20 2023 ] 	Time consumption: [Data]28%, [Network]71%
[ Tue Jun 20 03:04:20 2023 ] Eval epoch: 94
[ Tue Jun 20 03:04:20 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:20 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:20 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:20 2023 ] Training epoch: 95
[ Tue Jun 20 03:04:21 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:04:21 2023 ] 	Time consumption: [Data]29%, [Network]70%
[ Tue Jun 20 03:04:21 2023 ] Eval epoch: 95
[ Tue Jun 20 03:04:21 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:21 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:21 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:21 2023 ] Training epoch: 96
[ Tue Jun 20 03:04:21 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:04:21 2023 ] 	Time consumption: [Data]30%, [Network]69%
[ Tue Jun 20 03:04:21 2023 ] Eval epoch: 96
[ Tue Jun 20 03:04:22 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:22 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:22 2023 ] Training epoch: 97
[ Tue Jun 20 03:04:22 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:04:22 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:04:22 2023 ] Eval epoch: 97
[ Tue Jun 20 03:04:23 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:23 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:23 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:23 2023 ] Training epoch: 98
[ Tue Jun 20 03:04:23 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:04:23 2023 ] 	Time consumption: [Data]37%, [Network]62%
[ Tue Jun 20 03:04:23 2023 ] Eval epoch: 98
[ Tue Jun 20 03:04:23 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:23 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:23 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:23 2023 ] Training epoch: 99
[ Tue Jun 20 03:04:24 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:04:24 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:04:24 2023 ] Eval epoch: 99
[ Tue Jun 20 03:04:24 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:24 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:24 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:24 2023 ] Training epoch: 100
[ Tue Jun 20 03:04:25 2023 ] 	Training loss: nan.  Training acc: 38.54%.
[ Tue Jun 20 03:04:25 2023 ] 	Time consumption: [Data]39%, [Network]61%
[ Tue Jun 20 03:04:25 2023 ] Eval epoch: 100
[ Tue Jun 20 03:04:25 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:25 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:25 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:25 2023 ] Training epoch: 101
[ Tue Jun 20 03:04:26 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:04:26 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:04:26 2023 ] Eval epoch: 101
[ Tue Jun 20 03:04:26 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:26 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:26 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:26 2023 ] Training epoch: 102
[ Tue Jun 20 03:04:26 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:04:26 2023 ] 	Time consumption: [Data]39%, [Network]60%
[ Tue Jun 20 03:04:26 2023 ] Eval epoch: 102
[ Tue Jun 20 03:04:27 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:27 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:27 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:27 2023 ] Training epoch: 103
[ Tue Jun 20 03:04:27 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:04:27 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:04:27 2023 ] Eval epoch: 103
[ Tue Jun 20 03:04:27 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:27 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:27 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:27 2023 ] Training epoch: 104
[ Tue Jun 20 03:04:28 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:04:28 2023 ] 	Time consumption: [Data]41%, [Network]59%
[ Tue Jun 20 03:04:28 2023 ] Eval epoch: 104
[ Tue Jun 20 03:04:28 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:28 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:28 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:28 2023 ] Training epoch: 105
[ Tue Jun 20 03:04:29 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:04:29 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:04:29 2023 ] Eval epoch: 105
[ Tue Jun 20 03:04:29 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:29 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:29 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:29 2023 ] Training epoch: 106
[ Tue Jun 20 03:04:30 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:04:30 2023 ] 	Time consumption: [Data]37%, [Network]62%
[ Tue Jun 20 03:04:30 2023 ] Eval epoch: 106
[ Tue Jun 20 03:04:30 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:30 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:30 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:30 2023 ] Training epoch: 107
[ Tue Jun 20 03:04:30 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:04:30 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:04:30 2023 ] Eval epoch: 107
[ Tue Jun 20 03:04:31 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:31 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:31 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:31 2023 ] Training epoch: 108
[ Tue Jun 20 03:04:31 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:04:31 2023 ] 	Time consumption: [Data]40%, [Network]60%
[ Tue Jun 20 03:04:31 2023 ] Eval epoch: 108
[ Tue Jun 20 03:04:31 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:31 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:31 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:31 2023 ] Training epoch: 109
[ Tue Jun 20 03:04:32 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:04:32 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:04:32 2023 ] Eval epoch: 109
[ Tue Jun 20 03:04:32 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:32 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:32 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:32 2023 ] Training epoch: 110
[ Tue Jun 20 03:04:33 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:04:33 2023 ] 	Time consumption: [Data]37%, [Network]63%
[ Tue Jun 20 03:04:33 2023 ] Eval epoch: 110
[ Tue Jun 20 03:04:33 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:04:33 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:04:33 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:04:33 2023 ] Best accuracy: 0.2982456140350877
[ Tue Jun 20 03:04:33 2023 ] Epoch number: 1
[ Tue Jun 20 03:04:33 2023 ] Model name: results/ec3d_NTU60_CS
[ Tue Jun 20 03:04:33 2023 ] Model total number of params: 1538958
[ Tue Jun 20 03:04:33 2023 ] Weight decay: 0.0005
[ Tue Jun 20 03:04:33 2023 ] Base LR: 0.1
[ Tue Jun 20 03:04:33 2023 ] Batch Size: 64
[ Tue Jun 20 03:04:33 2023 ] Test Batch Size: 64
[ Tue Jun 20 03:04:33 2023 ] seed: 1
[ Tue Jun 20 03:04:56 2023 ] using warm up, epoch: 5
[ Tue Jun 20 03:04:58 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 60, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 03:04:58 2023 ] # Parameters: 1553607
[ Tue Jun 20 03:04:58 2023 ] Training epoch: 1
[ Tue Jun 20 03:05:02 2023 ] 	Training loss: 50.0735.  Training acc: 16.15%.
[ Tue Jun 20 03:05:02 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 20 03:05:02 2023 ] Eval epoch: 1
[ Tue Jun 20 03:05:03 2023 ] 	Mean test loss of 625 batches: 2218.051514.
[ Tue Jun 20 03:05:03 2023 ] 	Top1: 31.58%
[ Tue Jun 20 03:05:03 2023 ] 	Top5: 61.40%
[ Tue Jun 20 03:05:03 2023 ] Training epoch: 2
[ Tue Jun 20 03:05:03 2023 ] 	Training loss: 61.9353.  Training acc: 29.69%.
[ Tue Jun 20 03:05:03 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 03:05:03 2023 ] Eval epoch: 2
[ Tue Jun 20 03:05:04 2023 ] 	Mean test loss of 625 batches: 11402.947266.
[ Tue Jun 20 03:05:04 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:05:04 2023 ] 	Top5: 68.42%
[ Tue Jun 20 03:05:04 2023 ] Training epoch: 3
[ Tue Jun 20 03:05:04 2023 ] 	Training loss: 15.8767.  Training acc: 35.42%.
[ Tue Jun 20 03:05:04 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Tue Jun 20 03:05:04 2023 ] Eval epoch: 3
[ Tue Jun 20 03:05:05 2023 ] 	Mean test loss of 625 batches: 12404.558594.
[ Tue Jun 20 03:05:05 2023 ] 	Top1: 38.60%
[ Tue Jun 20 03:05:05 2023 ] 	Top5: 68.42%
[ Tue Jun 20 03:05:05 2023 ] Training epoch: 4
[ Tue Jun 20 03:05:06 2023 ] 	Training loss: 16.7089.  Training acc: 26.56%.
[ Tue Jun 20 03:05:06 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Tue Jun 20 03:05:06 2023 ] Eval epoch: 4
[ Tue Jun 20 03:05:06 2023 ] 	Mean test loss of 625 batches: 3846.207764.
[ Tue Jun 20 03:05:06 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:05:06 2023 ] 	Top5: 68.42%
[ Tue Jun 20 03:05:06 2023 ] Training epoch: 5
[ Tue Jun 20 03:05:07 2023 ] 	Training loss: 21.7190.  Training acc: 38.02%.
[ Tue Jun 20 03:05:07 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 03:05:07 2023 ] Eval epoch: 5
[ Tue Jun 20 03:05:07 2023 ] 	Mean test loss of 625 batches: 174.851364.
[ Tue Jun 20 03:05:07 2023 ] 	Top1: 31.58%
[ Tue Jun 20 03:05:07 2023 ] 	Top5: 61.40%
[ Tue Jun 20 03:05:07 2023 ] Training epoch: 6
[ Tue Jun 20 03:05:08 2023 ] 	Training loss: 17.3450.  Training acc: 38.54%.
[ Tue Jun 20 03:05:08 2023 ] 	Time consumption: [Data]26%, [Network]73%
[ Tue Jun 20 03:05:08 2023 ] Eval epoch: 6
[ Tue Jun 20 03:05:08 2023 ] 	Mean test loss of 625 batches: 57.933674.
[ Tue Jun 20 03:05:08 2023 ] 	Top1: 31.58%
[ Tue Jun 20 03:05:08 2023 ] 	Top5: 61.40%
[ Tue Jun 20 03:05:08 2023 ] Training epoch: 7
[ Tue Jun 20 03:05:09 2023 ] 	Training loss: 14.7937.  Training acc: 28.65%.
[ Tue Jun 20 03:05:09 2023 ] 	Time consumption: [Data]25%, [Network]75%
[ Tue Jun 20 03:05:09 2023 ] Eval epoch: 7
[ Tue Jun 20 03:05:10 2023 ] 	Mean test loss of 625 batches: 60.553921.
[ Tue Jun 20 03:05:10 2023 ] 	Top1: 31.58%
[ Tue Jun 20 03:05:10 2023 ] 	Top5: 31.58%
[ Tue Jun 20 03:05:10 2023 ] Training epoch: 8
[ Tue Jun 20 03:05:11 2023 ] 	Training loss: 23.9580.  Training acc: 36.98%.
[ Tue Jun 20 03:05:11 2023 ] 	Time consumption: [Data]22%, [Network]77%
[ Tue Jun 20 03:05:11 2023 ] Eval epoch: 8
[ Tue Jun 20 03:05:11 2023 ] 	Mean test loss of 625 batches: 24.110806.
[ Tue Jun 20 03:05:11 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:05:11 2023 ] 	Top5: 68.42%
[ Tue Jun 20 03:05:11 2023 ] Training epoch: 9
[ Tue Jun 20 03:05:12 2023 ] 	Training loss: 25.6995.  Training acc: 31.77%.
[ Tue Jun 20 03:05:12 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 20 03:05:12 2023 ] Eval epoch: 9
[ Tue Jun 20 03:05:12 2023 ] 	Mean test loss of 625 batches: 17.804577.
[ Tue Jun 20 03:05:12 2023 ] 	Top1: 38.60%
[ Tue Jun 20 03:05:12 2023 ] 	Top5: 68.42%
[ Tue Jun 20 03:05:12 2023 ] Training epoch: 10
[ Tue Jun 20 03:05:13 2023 ] 	Training loss: 19.2551.  Training acc: 32.29%.
[ Tue Jun 20 03:05:13 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 20 03:05:13 2023 ] Eval epoch: 10
[ Tue Jun 20 03:05:14 2023 ] 	Mean test loss of 625 batches: 25.840500.
[ Tue Jun 20 03:05:14 2023 ] 	Top1: 38.60%
[ Tue Jun 20 03:05:14 2023 ] 	Top5: 38.60%
[ Tue Jun 20 03:05:14 2023 ] Training epoch: 11
[ Tue Jun 20 03:05:15 2023 ] 	Training loss: 32.9856.  Training acc: 31.77%.
[ Tue Jun 20 03:05:15 2023 ] 	Time consumption: [Data]21%, [Network]78%
[ Tue Jun 20 03:05:15 2023 ] Eval epoch: 11
[ Tue Jun 20 03:05:15 2023 ] 	Mean test loss of 625 batches: 9.929368.
[ Tue Jun 20 03:05:15 2023 ] 	Top1: 38.60%
[ Tue Jun 20 03:05:15 2023 ] 	Top5: 70.18%
[ Tue Jun 20 03:05:15 2023 ] Training epoch: 12
[ Tue Jun 20 03:05:16 2023 ] 	Training loss: 16.1486.  Training acc: 31.77%.
[ Tue Jun 20 03:05:16 2023 ] 	Time consumption: [Data]22%, [Network]77%
[ Tue Jun 20 03:05:16 2023 ] Eval epoch: 12
[ Tue Jun 20 03:05:17 2023 ] 	Mean test loss of 625 batches: 21.958788.
[ Tue Jun 20 03:05:17 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:05:17 2023 ] 	Top5: 61.40%
[ Tue Jun 20 03:05:17 2023 ] Training epoch: 13
[ Tue Jun 20 03:05:18 2023 ] 	Training loss: 28.1806.  Training acc: 31.25%.
[ Tue Jun 20 03:05:18 2023 ] 	Time consumption: [Data]20%, [Network]79%
[ Tue Jun 20 03:05:18 2023 ] Eval epoch: 13
[ Tue Jun 20 03:05:18 2023 ] 	Mean test loss of 625 batches: 16.225769.
[ Tue Jun 20 03:05:18 2023 ] 	Top1: 31.58%
[ Tue Jun 20 03:05:18 2023 ] 	Top5: 61.40%
[ Tue Jun 20 03:05:18 2023 ] Training epoch: 14
[ Tue Jun 20 03:05:19 2023 ] 	Training loss: 24.6118.  Training acc: 30.21%.
[ Tue Jun 20 03:05:19 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Tue Jun 20 03:05:19 2023 ] Eval epoch: 14
[ Tue Jun 20 03:05:19 2023 ] 	Mean test loss of 625 batches: 31.218719.
[ Tue Jun 20 03:05:19 2023 ] 	Top1: 31.58%
[ Tue Jun 20 03:05:19 2023 ] 	Top5: 31.58%
[ Tue Jun 20 03:05:19 2023 ] Training epoch: 15
[ Tue Jun 20 03:05:20 2023 ] 	Training loss: 18.8728.  Training acc: 27.08%.
[ Tue Jun 20 03:05:20 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Tue Jun 20 03:05:20 2023 ] Eval epoch: 15
[ Tue Jun 20 03:05:21 2023 ] 	Mean test loss of 625 batches: 14.114919.
[ Tue Jun 20 03:05:21 2023 ] 	Top1: 31.58%
[ Tue Jun 20 03:05:21 2023 ] 	Top5: 61.40%
[ Tue Jun 20 03:05:21 2023 ] Training epoch: 16
[ Tue Jun 20 03:05:21 2023 ] 	Training loss: 16.9056.  Training acc: 26.04%.
[ Tue Jun 20 03:05:21 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 03:05:21 2023 ] Eval epoch: 16
[ Tue Jun 20 03:05:22 2023 ] 	Mean test loss of 625 batches: 13.793571.
[ Tue Jun 20 03:05:22 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:05:22 2023 ] 	Top5: 68.42%
[ Tue Jun 20 03:05:22 2023 ] Training epoch: 17
[ Tue Jun 20 03:05:23 2023 ] 	Training loss: 14.5177.  Training acc: 33.33%.
[ Tue Jun 20 03:05:23 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 03:05:23 2023 ] Eval epoch: 17
[ Tue Jun 20 03:05:23 2023 ] 	Mean test loss of 625 batches: 12.626045.
[ Tue Jun 20 03:05:23 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:05:23 2023 ] 	Top5: 68.42%
[ Tue Jun 20 03:05:23 2023 ] Training epoch: 18
[ Tue Jun 20 03:05:24 2023 ] 	Training loss: 14.1716.  Training acc: 30.73%.
[ Tue Jun 20 03:05:24 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 03:05:24 2023 ] Eval epoch: 18
[ Tue Jun 20 03:05:24 2023 ] 	Mean test loss of 625 batches: 11.660578.
[ Tue Jun 20 03:05:24 2023 ] 	Top1: 31.58%
[ Tue Jun 20 03:05:24 2023 ] 	Top5: 61.40%
[ Tue Jun 20 03:05:24 2023 ] Training epoch: 19
[ Tue Jun 20 03:05:25 2023 ] 	Training loss: 12.3652.  Training acc: 32.81%.
[ Tue Jun 20 03:05:25 2023 ] 	Time consumption: [Data]31%, [Network]68%
[ Tue Jun 20 03:05:25 2023 ] Eval epoch: 19
[ Tue Jun 20 03:05:25 2023 ] 	Mean test loss of 625 batches: 8.864155.
[ Tue Jun 20 03:05:25 2023 ] 	Top1: 38.60%
[ Tue Jun 20 03:05:25 2023 ] 	Top5: 38.60%
[ Tue Jun 20 03:05:25 2023 ] Training epoch: 20
[ Tue Jun 20 03:05:26 2023 ] 	Training loss: 9.1793.  Training acc: 20.31%.
[ Tue Jun 20 03:05:26 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 03:05:26 2023 ] Eval epoch: 20
[ Tue Jun 20 03:05:27 2023 ] 	Mean test loss of 625 batches: 11.868410.
[ Tue Jun 20 03:05:27 2023 ] 	Top1: 31.58%
[ Tue Jun 20 03:05:27 2023 ] 	Top5: 70.18%
[ Tue Jun 20 03:05:27 2023 ] Training epoch: 21
[ Tue Jun 20 03:05:27 2023 ] 	Training loss: 10.3275.  Training acc: 32.29%.
[ Tue Jun 20 03:05:27 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 03:05:27 2023 ] Eval epoch: 21
[ Tue Jun 20 03:05:28 2023 ] 	Mean test loss of 625 batches: 4.649253.
[ Tue Jun 20 03:05:28 2023 ] 	Top1: 31.58%
[ Tue Jun 20 03:05:28 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:28 2023 ] Training epoch: 22
[ Tue Jun 20 03:05:29 2023 ] 	Training loss: 8.0728.  Training acc: 32.29%.
[ Tue Jun 20 03:05:29 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 03:05:29 2023 ] Eval epoch: 22
[ Tue Jun 20 03:05:29 2023 ] 	Mean test loss of 625 batches: 1.989764.
[ Tue Jun 20 03:05:29 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:05:29 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:29 2023 ] Training epoch: 23
[ Tue Jun 20 03:05:30 2023 ] 	Training loss: 5.9800.  Training acc: 30.73%.
[ Tue Jun 20 03:05:30 2023 ] 	Time consumption: [Data]31%, [Network]69%
[ Tue Jun 20 03:05:30 2023 ] Eval epoch: 23
[ Tue Jun 20 03:05:30 2023 ] 	Mean test loss of 625 batches: 3.660187.
[ Tue Jun 20 03:05:30 2023 ] 	Top1: 31.58%
[ Tue Jun 20 03:05:30 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:30 2023 ] Training epoch: 24
[ Tue Jun 20 03:05:31 2023 ] 	Training loss: 5.9205.  Training acc: 34.38%.
[ Tue Jun 20 03:05:31 2023 ] 	Time consumption: [Data]31%, [Network]69%
[ Tue Jun 20 03:05:31 2023 ] Eval epoch: 24
[ Tue Jun 20 03:05:31 2023 ] 	Mean test loss of 625 batches: 2.065525.
[ Tue Jun 20 03:05:31 2023 ] 	Top1: 38.60%
[ Tue Jun 20 03:05:31 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:31 2023 ] Training epoch: 25
[ Tue Jun 20 03:05:32 2023 ] 	Training loss: 5.2945.  Training acc: 28.12%.
[ Tue Jun 20 03:05:32 2023 ] 	Time consumption: [Data]31%, [Network]68%
[ Tue Jun 20 03:05:32 2023 ] Eval epoch: 25
[ Tue Jun 20 03:05:32 2023 ] 	Mean test loss of 625 batches: 2.235184.
[ Tue Jun 20 03:05:32 2023 ] 	Top1: 31.58%
[ Tue Jun 20 03:05:32 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:32 2023 ] Training epoch: 26
[ Tue Jun 20 03:05:33 2023 ] 	Training loss: 5.3464.  Training acc: 32.81%.
[ Tue Jun 20 03:05:33 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 03:05:33 2023 ] Eval epoch: 26
[ Tue Jun 20 03:05:33 2023 ] 	Mean test loss of 625 batches: 2.690150.
[ Tue Jun 20 03:05:33 2023 ] 	Top1: 31.58%
[ Tue Jun 20 03:05:33 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:33 2023 ] Training epoch: 27
[ Tue Jun 20 03:05:34 2023 ] 	Training loss: 4.5688.  Training acc: 36.98%.
[ Tue Jun 20 03:05:34 2023 ] 	Time consumption: [Data]31%, [Network]69%
[ Tue Jun 20 03:05:34 2023 ] Eval epoch: 27
[ Tue Jun 20 03:05:35 2023 ] 	Mean test loss of 625 batches: 3.624442.
[ Tue Jun 20 03:05:35 2023 ] 	Top1: 31.58%
[ Tue Jun 20 03:05:35 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:35 2023 ] Training epoch: 28
[ Tue Jun 20 03:05:35 2023 ] 	Training loss: 4.4153.  Training acc: 39.06%.
[ Tue Jun 20 03:05:35 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Tue Jun 20 03:05:35 2023 ] Eval epoch: 28
[ Tue Jun 20 03:05:36 2023 ] 	Mean test loss of 625 batches: 3.261819.
[ Tue Jun 20 03:05:36 2023 ] 	Top1: 31.58%
[ Tue Jun 20 03:05:36 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:36 2023 ] Training epoch: 29
[ Tue Jun 20 03:05:37 2023 ] 	Training loss: 4.9602.  Training acc: 34.90%.
[ Tue Jun 20 03:05:37 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 03:05:37 2023 ] Eval epoch: 29
[ Tue Jun 20 03:05:37 2023 ] 	Mean test loss of 625 batches: 3.574039.
[ Tue Jun 20 03:05:37 2023 ] 	Top1: 38.60%
[ Tue Jun 20 03:05:37 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:37 2023 ] Training epoch: 30
[ Tue Jun 20 03:05:38 2023 ] 	Training loss: 4.9196.  Training acc: 30.21%.
[ Tue Jun 20 03:05:38 2023 ] 	Time consumption: [Data]28%, [Network]71%
[ Tue Jun 20 03:05:38 2023 ] Eval epoch: 30
[ Tue Jun 20 03:05:38 2023 ] 	Mean test loss of 625 batches: 3.303653.
[ Tue Jun 20 03:05:38 2023 ] 	Top1: 38.60%
[ Tue Jun 20 03:05:38 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:38 2023 ] Training epoch: 31
[ Tue Jun 20 03:05:39 2023 ] 	Training loss: 4.2092.  Training acc: 31.77%.
[ Tue Jun 20 03:05:39 2023 ] 	Time consumption: [Data]28%, [Network]71%
[ Tue Jun 20 03:05:39 2023 ] Eval epoch: 31
[ Tue Jun 20 03:05:39 2023 ] 	Mean test loss of 625 batches: 4.202777.
[ Tue Jun 20 03:05:39 2023 ] 	Top1: 45.61%
[ Tue Jun 20 03:05:39 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:39 2023 ] Training epoch: 32
[ Tue Jun 20 03:05:40 2023 ] 	Training loss: 3.8251.  Training acc: 46.35%.
[ Tue Jun 20 03:05:40 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 03:05:40 2023 ] Eval epoch: 32
[ Tue Jun 20 03:05:40 2023 ] 	Mean test loss of 625 batches: 4.326105.
[ Tue Jun 20 03:05:40 2023 ] 	Top1: 38.60%
[ Tue Jun 20 03:05:40 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:40 2023 ] Training epoch: 33
[ Tue Jun 20 03:05:41 2023 ] 	Training loss: 3.7789.  Training acc: 47.40%.
[ Tue Jun 20 03:05:41 2023 ] 	Time consumption: [Data]31%, [Network]69%
[ Tue Jun 20 03:05:41 2023 ] Eval epoch: 33
[ Tue Jun 20 03:05:42 2023 ] 	Mean test loss of 625 batches: 3.620483.
[ Tue Jun 20 03:05:42 2023 ] 	Top1: 38.60%
[ Tue Jun 20 03:05:42 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:42 2023 ] Training epoch: 34
[ Tue Jun 20 03:05:42 2023 ] 	Training loss: 2.8491.  Training acc: 53.65%.
[ Tue Jun 20 03:05:42 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 03:05:42 2023 ] Eval epoch: 34
[ Tue Jun 20 03:05:43 2023 ] 	Mean test loss of 625 batches: 5.972988.
[ Tue Jun 20 03:05:43 2023 ] 	Top1: 38.60%
[ Tue Jun 20 03:05:43 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:43 2023 ] Training epoch: 35
[ Tue Jun 20 03:05:44 2023 ] 	Training loss: 3.2248.  Training acc: 58.33%.
[ Tue Jun 20 03:05:44 2023 ] 	Time consumption: [Data]31%, [Network]69%
[ Tue Jun 20 03:05:44 2023 ] Eval epoch: 35
[ Tue Jun 20 03:05:44 2023 ] 	Mean test loss of 625 batches: 3.049495.
[ Tue Jun 20 03:05:44 2023 ] 	Top1: 61.40%
[ Tue Jun 20 03:05:44 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:44 2023 ] Training epoch: 36
[ Tue Jun 20 03:05:45 2023 ] 	Training loss: 3.4536.  Training acc: 44.79%.
[ Tue Jun 20 03:05:45 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 03:05:45 2023 ] Eval epoch: 36
[ Tue Jun 20 03:05:45 2023 ] 	Mean test loss of 625 batches: 2.317260.
[ Tue Jun 20 03:05:45 2023 ] 	Top1: 57.89%
[ Tue Jun 20 03:05:45 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:45 2023 ] Training epoch: 37
[ Tue Jun 20 03:05:46 2023 ] 	Training loss: 2.7021.  Training acc: 55.21%.
[ Tue Jun 20 03:05:46 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 03:05:46 2023 ] Eval epoch: 37
[ Tue Jun 20 03:05:46 2023 ] 	Mean test loss of 625 batches: 2.641415.
[ Tue Jun 20 03:05:46 2023 ] 	Top1: 47.37%
[ Tue Jun 20 03:05:46 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:46 2023 ] Training epoch: 38
[ Tue Jun 20 03:05:47 2023 ] 	Training loss: 2.4566.  Training acc: 58.33%.
[ Tue Jun 20 03:05:47 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 03:05:47 2023 ] Eval epoch: 38
[ Tue Jun 20 03:05:48 2023 ] 	Mean test loss of 625 batches: 4.400531.
[ Tue Jun 20 03:05:48 2023 ] 	Top1: 38.60%
[ Tue Jun 20 03:05:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:48 2023 ] Training epoch: 39
[ Tue Jun 20 03:05:48 2023 ] 	Training loss: 2.6305.  Training acc: 56.77%.
[ Tue Jun 20 03:05:48 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 03:05:48 2023 ] Eval epoch: 39
[ Tue Jun 20 03:05:49 2023 ] 	Mean test loss of 625 batches: 4.082069.
[ Tue Jun 20 03:05:49 2023 ] 	Top1: 43.86%
[ Tue Jun 20 03:05:49 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:49 2023 ] Training epoch: 40
[ Tue Jun 20 03:05:50 2023 ] 	Training loss: 2.6256.  Training acc: 54.69%.
[ Tue Jun 20 03:05:50 2023 ] 	Time consumption: [Data]24%, [Network]76%
[ Tue Jun 20 03:05:50 2023 ] Eval epoch: 40
[ Tue Jun 20 03:05:50 2023 ] 	Mean test loss of 625 batches: 2.173886.
[ Tue Jun 20 03:05:50 2023 ] 	Top1: 59.65%
[ Tue Jun 20 03:05:50 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:50 2023 ] Training epoch: 41
[ Tue Jun 20 03:05:51 2023 ] 	Training loss: 2.2929.  Training acc: 63.02%.
[ Tue Jun 20 03:05:51 2023 ] 	Time consumption: [Data]31%, [Network]69%
[ Tue Jun 20 03:05:51 2023 ] Eval epoch: 41
[ Tue Jun 20 03:05:51 2023 ] 	Mean test loss of 625 batches: 2.127048.
[ Tue Jun 20 03:05:51 2023 ] 	Top1: 64.91%
[ Tue Jun 20 03:05:51 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:51 2023 ] Training epoch: 42
[ Tue Jun 20 03:05:52 2023 ] 	Training loss: 2.4858.  Training acc: 60.94%.
[ Tue Jun 20 03:05:52 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Tue Jun 20 03:05:52 2023 ] Eval epoch: 42
[ Tue Jun 20 03:05:52 2023 ] 	Mean test loss of 625 batches: 2.061115.
[ Tue Jun 20 03:05:52 2023 ] 	Top1: 68.42%
[ Tue Jun 20 03:05:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:52 2023 ] Training epoch: 43
[ Tue Jun 20 03:05:53 2023 ] 	Training loss: 2.3561.  Training acc: 60.42%.
[ Tue Jun 20 03:05:53 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Tue Jun 20 03:05:53 2023 ] Eval epoch: 43
[ Tue Jun 20 03:05:54 2023 ] 	Mean test loss of 625 batches: 1.478209.
[ Tue Jun 20 03:05:54 2023 ] 	Top1: 68.42%
[ Tue Jun 20 03:05:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:54 2023 ] Training epoch: 44
[ Tue Jun 20 03:05:54 2023 ] 	Training loss: 2.2276.  Training acc: 59.90%.
[ Tue Jun 20 03:05:54 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 03:05:54 2023 ] Eval epoch: 44
[ Tue Jun 20 03:05:55 2023 ] 	Mean test loss of 625 batches: 1.974234.
[ Tue Jun 20 03:05:55 2023 ] 	Top1: 68.42%
[ Tue Jun 20 03:05:55 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:55 2023 ] Training epoch: 45
[ Tue Jun 20 03:05:55 2023 ] 	Training loss: 2.2619.  Training acc: 68.23%.
[ Tue Jun 20 03:05:55 2023 ] 	Time consumption: [Data]31%, [Network]69%
[ Tue Jun 20 03:05:55 2023 ] Eval epoch: 45
[ Tue Jun 20 03:05:56 2023 ] 	Mean test loss of 625 batches: 1.379880.
[ Tue Jun 20 03:05:56 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:05:56 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:56 2023 ] Training epoch: 46
[ Tue Jun 20 03:05:57 2023 ] 	Training loss: 2.2261.  Training acc: 55.21%.
[ Tue Jun 20 03:05:57 2023 ] 	Time consumption: [Data]24%, [Network]76%
[ Tue Jun 20 03:05:57 2023 ] Eval epoch: 46
[ Tue Jun 20 03:05:57 2023 ] 	Mean test loss of 625 batches: 1.414618.
[ Tue Jun 20 03:05:57 2023 ] 	Top1: 68.42%
[ Tue Jun 20 03:05:57 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:57 2023 ] Training epoch: 47
[ Tue Jun 20 03:05:58 2023 ] 	Training loss: 1.8468.  Training acc: 72.92%.
[ Tue Jun 20 03:05:58 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Tue Jun 20 03:05:58 2023 ] Eval epoch: 47
[ Tue Jun 20 03:05:58 2023 ] 	Mean test loss of 625 batches: 1.743288.
[ Tue Jun 20 03:05:58 2023 ] 	Top1: 68.42%
[ Tue Jun 20 03:05:58 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:58 2023 ] Training epoch: 48
[ Tue Jun 20 03:05:59 2023 ] 	Training loss: 1.9938.  Training acc: 65.62%.
[ Tue Jun 20 03:05:59 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 03:05:59 2023 ] Eval epoch: 48
[ Tue Jun 20 03:05:59 2023 ] 	Mean test loss of 625 batches: 1.374630.
[ Tue Jun 20 03:05:59 2023 ] 	Top1: 68.42%
[ Tue Jun 20 03:05:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:05:59 2023 ] Training epoch: 49
[ Tue Jun 20 03:06:00 2023 ] 	Training loss: 1.7717.  Training acc: 68.75%.
[ Tue Jun 20 03:06:00 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 03:06:00 2023 ] Eval epoch: 49
[ Tue Jun 20 03:06:01 2023 ] 	Mean test loss of 625 batches: 1.683488.
[ Tue Jun 20 03:06:01 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:06:01 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:01 2023 ] Training epoch: 50
[ Tue Jun 20 03:06:01 2023 ] 	Training loss: 1.9535.  Training acc: 64.58%.
[ Tue Jun 20 03:06:01 2023 ] 	Time consumption: [Data]33%, [Network]67%
[ Tue Jun 20 03:06:01 2023 ] Eval epoch: 50
[ Tue Jun 20 03:06:02 2023 ] 	Mean test loss of 625 batches: 1.309568.
[ Tue Jun 20 03:06:02 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:06:02 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:02 2023 ] Training epoch: 51
[ Tue Jun 20 03:06:03 2023 ] 	Training loss: 1.8264.  Training acc: 65.10%.
[ Tue Jun 20 03:06:03 2023 ] 	Time consumption: [Data]24%, [Network]75%
[ Tue Jun 20 03:06:03 2023 ] Eval epoch: 51
[ Tue Jun 20 03:06:03 2023 ] 	Mean test loss of 625 batches: 1.443730.
[ Tue Jun 20 03:06:03 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:06:03 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:03 2023 ] Training epoch: 52
[ Tue Jun 20 03:06:04 2023 ] 	Training loss: 2.0887.  Training acc: 63.54%.
[ Tue Jun 20 03:06:04 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Tue Jun 20 03:06:04 2023 ] Eval epoch: 52
[ Tue Jun 20 03:06:04 2023 ] 	Mean test loss of 625 batches: 1.337309.
[ Tue Jun 20 03:06:04 2023 ] 	Top1: 68.42%
[ Tue Jun 20 03:06:04 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:04 2023 ] Training epoch: 53
[ Tue Jun 20 03:06:05 2023 ] 	Training loss: 1.9371.  Training acc: 63.54%.
[ Tue Jun 20 03:06:05 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 03:06:05 2023 ] Eval epoch: 53
[ Tue Jun 20 03:06:05 2023 ] 	Mean test loss of 625 batches: 1.440167.
[ Tue Jun 20 03:06:05 2023 ] 	Top1: 68.42%
[ Tue Jun 20 03:06:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:05 2023 ] Training epoch: 54
[ Tue Jun 20 03:06:06 2023 ] 	Training loss: 1.9932.  Training acc: 61.46%.
[ Tue Jun 20 03:06:06 2023 ] 	Time consumption: [Data]31%, [Network]69%
[ Tue Jun 20 03:06:06 2023 ] Eval epoch: 54
[ Tue Jun 20 03:06:06 2023 ] 	Mean test loss of 625 batches: 1.400825.
[ Tue Jun 20 03:06:06 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:06:06 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:06 2023 ] Training epoch: 55
[ Tue Jun 20 03:06:07 2023 ] 	Training loss: 1.7013.  Training acc: 68.75%.
[ Tue Jun 20 03:06:07 2023 ] 	Time consumption: [Data]22%, [Network]77%
[ Tue Jun 20 03:06:07 2023 ] Eval epoch: 55
[ Tue Jun 20 03:06:08 2023 ] 	Mean test loss of 625 batches: 1.308681.
[ Tue Jun 20 03:06:08 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:06:08 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:08 2023 ] Training epoch: 56
[ Tue Jun 20 03:06:09 2023 ] 	Training loss: 1.8211.  Training acc: 68.75%.
[ Tue Jun 20 03:06:09 2023 ] 	Time consumption: [Data]20%, [Network]80%
[ Tue Jun 20 03:06:09 2023 ] Eval epoch: 56
[ Tue Jun 20 03:06:09 2023 ] 	Mean test loss of 625 batches: 1.173913.
[ Tue Jun 20 03:06:09 2023 ] 	Top1: 85.96%
[ Tue Jun 20 03:06:09 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:09 2023 ] Training epoch: 57
[ Tue Jun 20 03:06:10 2023 ] 	Training loss: 1.7002.  Training acc: 66.15%.
[ Tue Jun 20 03:06:10 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 20 03:06:10 2023 ] Eval epoch: 57
[ Tue Jun 20 03:06:11 2023 ] 	Mean test loss of 625 batches: 1.406317.
[ Tue Jun 20 03:06:11 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:06:11 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:11 2023 ] Training epoch: 58
[ Tue Jun 20 03:06:12 2023 ] 	Training loss: 2.0132.  Training acc: 65.62%.
[ Tue Jun 20 03:06:12 2023 ] 	Time consumption: [Data]21%, [Network]79%
[ Tue Jun 20 03:06:12 2023 ] Eval epoch: 58
[ Tue Jun 20 03:06:12 2023 ] 	Mean test loss of 625 batches: 1.184710.
[ Tue Jun 20 03:06:12 2023 ] 	Top1: 80.70%
[ Tue Jun 20 03:06:12 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:12 2023 ] Training epoch: 59
[ Tue Jun 20 03:06:13 2023 ] 	Training loss: 1.6792.  Training acc: 73.96%.
[ Tue Jun 20 03:06:13 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Tue Jun 20 03:06:13 2023 ] Eval epoch: 59
[ Tue Jun 20 03:06:14 2023 ] 	Mean test loss of 625 batches: 1.573380.
[ Tue Jun 20 03:06:14 2023 ] 	Top1: 73.68%
[ Tue Jun 20 03:06:14 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:14 2023 ] Training epoch: 60
[ Tue Jun 20 03:06:14 2023 ] 	Training loss: 1.6474.  Training acc: 77.08%.
[ Tue Jun 20 03:06:14 2023 ] 	Time consumption: [Data]24%, [Network]76%
[ Tue Jun 20 03:06:14 2023 ] Eval epoch: 60
[ Tue Jun 20 03:06:15 2023 ] 	Mean test loss of 625 batches: 1.479604.
[ Tue Jun 20 03:06:15 2023 ] 	Top1: 71.93%
[ Tue Jun 20 03:06:15 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:15 2023 ] Training epoch: 61
[ Tue Jun 20 03:06:16 2023 ] 	Training loss: 1.5922.  Training acc: 75.00%.
[ Tue Jun 20 03:06:16 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Tue Jun 20 03:06:16 2023 ] Eval epoch: 61
[ Tue Jun 20 03:06:16 2023 ] 	Mean test loss of 625 batches: 1.399079.
[ Tue Jun 20 03:06:16 2023 ] 	Top1: 71.93%
[ Tue Jun 20 03:06:16 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:16 2023 ] Training epoch: 62
[ Tue Jun 20 03:06:17 2023 ] 	Training loss: 1.5615.  Training acc: 76.04%.
[ Tue Jun 20 03:06:17 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Tue Jun 20 03:06:17 2023 ] Eval epoch: 62
[ Tue Jun 20 03:06:18 2023 ] 	Mean test loss of 625 batches: 1.639421.
[ Tue Jun 20 03:06:18 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:06:18 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:18 2023 ] Training epoch: 63
[ Tue Jun 20 03:06:18 2023 ] 	Training loss: 1.4624.  Training acc: 79.69%.
[ Tue Jun 20 03:06:18 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Tue Jun 20 03:06:18 2023 ] Eval epoch: 63
[ Tue Jun 20 03:06:19 2023 ] 	Mean test loss of 625 batches: 1.087042.
[ Tue Jun 20 03:06:19 2023 ] 	Top1: 92.98%
[ Tue Jun 20 03:06:19 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:19 2023 ] Training epoch: 64
[ Tue Jun 20 03:06:20 2023 ] 	Training loss: 1.4475.  Training acc: 83.33%.
[ Tue Jun 20 03:06:20 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 03:06:20 2023 ] Eval epoch: 64
[ Tue Jun 20 03:06:20 2023 ] 	Mean test loss of 625 batches: 1.109530.
[ Tue Jun 20 03:06:20 2023 ] 	Top1: 91.23%
[ Tue Jun 20 03:06:20 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:20 2023 ] Training epoch: 65
[ Tue Jun 20 03:06:21 2023 ] 	Training loss: 1.4730.  Training acc: 85.42%.
[ Tue Jun 20 03:06:21 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 03:06:21 2023 ] Eval epoch: 65
[ Tue Jun 20 03:06:21 2023 ] 	Mean test loss of 625 batches: 1.207454.
[ Tue Jun 20 03:06:21 2023 ] 	Top1: 82.46%
[ Tue Jun 20 03:06:21 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:21 2023 ] Training epoch: 66
[ Tue Jun 20 03:06:22 2023 ] 	Training loss: 1.4443.  Training acc: 82.29%.
[ Tue Jun 20 03:06:22 2023 ] 	Time consumption: [Data]25%, [Network]74%
[ Tue Jun 20 03:06:22 2023 ] Eval epoch: 66
[ Tue Jun 20 03:06:22 2023 ] 	Mean test loss of 625 batches: 1.028616.
[ Tue Jun 20 03:06:22 2023 ] 	Top1: 96.49%
[ Tue Jun 20 03:06:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:22 2023 ] Training epoch: 67
[ Tue Jun 20 03:06:23 2023 ] 	Training loss: 1.6187.  Training acc: 76.56%.
[ Tue Jun 20 03:06:23 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 03:06:23 2023 ] Eval epoch: 67
[ Tue Jun 20 03:06:24 2023 ] 	Mean test loss of 625 batches: 1.379863.
[ Tue Jun 20 03:06:24 2023 ] 	Top1: 75.44%
[ Tue Jun 20 03:06:24 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:24 2023 ] Training epoch: 68
[ Tue Jun 20 03:06:24 2023 ] 	Training loss: 1.2788.  Training acc: 86.98%.
[ Tue Jun 20 03:06:24 2023 ] 	Time consumption: [Data]25%, [Network]74%
[ Tue Jun 20 03:06:24 2023 ] Eval epoch: 68
[ Tue Jun 20 03:06:25 2023 ] 	Mean test loss of 625 batches: 0.979054.
[ Tue Jun 20 03:06:25 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:06:25 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:25 2023 ] Training epoch: 69
[ Tue Jun 20 03:06:26 2023 ] 	Training loss: 1.3816.  Training acc: 84.38%.
[ Tue Jun 20 03:06:26 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 03:06:26 2023 ] Eval epoch: 69
[ Tue Jun 20 03:06:26 2023 ] 	Mean test loss of 625 batches: 1.015607.
[ Tue Jun 20 03:06:26 2023 ] 	Top1: 98.25%
[ Tue Jun 20 03:06:26 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:26 2023 ] Training epoch: 70
[ Tue Jun 20 03:06:27 2023 ] 	Training loss: 1.3397.  Training acc: 87.50%.
[ Tue Jun 20 03:06:27 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 03:06:27 2023 ] Eval epoch: 70
[ Tue Jun 20 03:06:27 2023 ] 	Mean test loss of 625 batches: 1.019620.
[ Tue Jun 20 03:06:27 2023 ] 	Top1: 94.74%
[ Tue Jun 20 03:06:27 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:27 2023 ] Training epoch: 71
[ Tue Jun 20 03:06:28 2023 ] 	Training loss: 1.1874.  Training acc: 94.27%.
[ Tue Jun 20 03:06:28 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 03:06:28 2023 ] Eval epoch: 71
[ Tue Jun 20 03:06:28 2023 ] 	Mean test loss of 625 batches: 0.994985.
[ Tue Jun 20 03:06:28 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:06:28 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:28 2023 ] Training epoch: 72
[ Tue Jun 20 03:06:29 2023 ] 	Training loss: 1.4013.  Training acc: 84.90%.
[ Tue Jun 20 03:06:29 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Tue Jun 20 03:06:29 2023 ] Eval epoch: 72
[ Tue Jun 20 03:06:30 2023 ] 	Mean test loss of 625 batches: 1.526435.
[ Tue Jun 20 03:06:30 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:06:30 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:30 2023 ] Training epoch: 73
[ Tue Jun 20 03:06:30 2023 ] 	Training loss: 1.3436.  Training acc: 85.94%.
[ Tue Jun 20 03:06:31 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Tue Jun 20 03:06:31 2023 ] Eval epoch: 73
[ Tue Jun 20 03:06:31 2023 ] 	Mean test loss of 625 batches: 1.193193.
[ Tue Jun 20 03:06:31 2023 ] 	Top1: 73.68%
[ Tue Jun 20 03:06:31 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:31 2023 ] Training epoch: 74
[ Tue Jun 20 03:06:32 2023 ] 	Training loss: 1.3608.  Training acc: 82.81%.
[ Tue Jun 20 03:06:32 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 03:06:32 2023 ] Eval epoch: 74
[ Tue Jun 20 03:06:32 2023 ] 	Mean test loss of 625 batches: 1.465580.
[ Tue Jun 20 03:06:32 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:06:32 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:32 2023 ] Training epoch: 75
[ Tue Jun 20 03:06:33 2023 ] 	Training loss: 1.2388.  Training acc: 92.19%.
[ Tue Jun 20 03:06:33 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 03:06:33 2023 ] Eval epoch: 75
[ Tue Jun 20 03:06:33 2023 ] 	Mean test loss of 625 batches: 1.070325.
[ Tue Jun 20 03:06:33 2023 ] 	Top1: 91.23%
[ Tue Jun 20 03:06:33 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:33 2023 ] Training epoch: 76
[ Tue Jun 20 03:06:34 2023 ] 	Training loss: 1.2968.  Training acc: 86.46%.
[ Tue Jun 20 03:06:34 2023 ] 	Time consumption: [Data]31%, [Network]69%
[ Tue Jun 20 03:06:34 2023 ] Eval epoch: 76
[ Tue Jun 20 03:06:34 2023 ] 	Mean test loss of 625 batches: 1.232077.
[ Tue Jun 20 03:06:34 2023 ] 	Top1: 75.44%
[ Tue Jun 20 03:06:34 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:34 2023 ] Training epoch: 77
[ Tue Jun 20 03:06:35 2023 ] 	Training loss: 1.2028.  Training acc: 91.15%.
[ Tue Jun 20 03:06:35 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 03:06:35 2023 ] Eval epoch: 77
[ Tue Jun 20 03:06:35 2023 ] 	Mean test loss of 625 batches: 1.493784.
[ Tue Jun 20 03:06:35 2023 ] 	Top1: 68.42%
[ Tue Jun 20 03:06:35 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:35 2023 ] Training epoch: 78
[ Tue Jun 20 03:06:36 2023 ] 	Training loss: 1.7169.  Training acc: 76.56%.
[ Tue Jun 20 03:06:36 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 03:06:36 2023 ] Eval epoch: 78
[ Tue Jun 20 03:06:37 2023 ] 	Mean test loss of 625 batches: 1.126188.
[ Tue Jun 20 03:06:37 2023 ] 	Top1: 85.96%
[ Tue Jun 20 03:06:37 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:37 2023 ] Training epoch: 79
[ Tue Jun 20 03:06:37 2023 ] 	Training loss: 1.4473.  Training acc: 74.48%.
[ Tue Jun 20 03:06:37 2023 ] 	Time consumption: [Data]29%, [Network]70%
[ Tue Jun 20 03:06:37 2023 ] Eval epoch: 79
[ Tue Jun 20 03:06:38 2023 ] 	Mean test loss of 625 batches: 1.147740.
[ Tue Jun 20 03:06:38 2023 ] 	Top1: 78.95%
[ Tue Jun 20 03:06:38 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:38 2023 ] Training epoch: 80
[ Tue Jun 20 03:06:38 2023 ] 	Training loss: 1.2125.  Training acc: 90.10%.
[ Tue Jun 20 03:06:38 2023 ] 	Time consumption: [Data]33%, [Network]67%
[ Tue Jun 20 03:06:38 2023 ] Eval epoch: 80
[ Tue Jun 20 03:06:39 2023 ] 	Mean test loss of 625 batches: 0.981618.
[ Tue Jun 20 03:06:39 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:06:39 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:39 2023 ] Training epoch: 81
[ Tue Jun 20 03:06:40 2023 ] 	Training loss: 1.1968.  Training acc: 92.71%.
[ Tue Jun 20 03:06:40 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 03:06:40 2023 ] Eval epoch: 81
[ Tue Jun 20 03:06:40 2023 ] 	Mean test loss of 625 batches: 0.997575.
[ Tue Jun 20 03:06:40 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:06:40 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:40 2023 ] Training epoch: 82
[ Tue Jun 20 03:06:41 2023 ] 	Training loss: 1.3911.  Training acc: 88.54%.
[ Tue Jun 20 03:06:41 2023 ] 	Time consumption: [Data]32%, [Network]68%
[ Tue Jun 20 03:06:41 2023 ] Eval epoch: 82
[ Tue Jun 20 03:06:41 2023 ] 	Mean test loss of 625 batches: 1.281086.
[ Tue Jun 20 03:06:41 2023 ] 	Top1: 78.95%
[ Tue Jun 20 03:06:41 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:41 2023 ] Training epoch: 83
[ Tue Jun 20 03:06:42 2023 ] 	Training loss: 1.1962.  Training acc: 91.67%.
[ Tue Jun 20 03:06:42 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 03:06:42 2023 ] Eval epoch: 83
[ Tue Jun 20 03:06:42 2023 ] 	Mean test loss of 625 batches: 2.022526.
[ Tue Jun 20 03:06:42 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:06:42 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:42 2023 ] Training epoch: 84
[ Tue Jun 20 03:06:43 2023 ] 	Training loss: 1.1286.  Training acc: 93.23%.
[ Tue Jun 20 03:06:43 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 03:06:43 2023 ] Eval epoch: 84
[ Tue Jun 20 03:06:43 2023 ] 	Mean test loss of 625 batches: 2.128355.
[ Tue Jun 20 03:06:43 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:06:43 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:43 2023 ] Training epoch: 85
[ Tue Jun 20 03:06:44 2023 ] 	Training loss: 1.1450.  Training acc: 95.31%.
[ Tue Jun 20 03:06:44 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Tue Jun 20 03:06:44 2023 ] Eval epoch: 85
[ Tue Jun 20 03:06:45 2023 ] 	Mean test loss of 625 batches: 2.463441.
[ Tue Jun 20 03:06:45 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:06:45 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:45 2023 ] Training epoch: 86
[ Tue Jun 20 03:06:45 2023 ] 	Training loss: 1.1072.  Training acc: 97.92%.
[ Tue Jun 20 03:06:45 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 03:06:45 2023 ] Eval epoch: 86
[ Tue Jun 20 03:06:46 2023 ] 	Mean test loss of 625 batches: 1.855219.
[ Tue Jun 20 03:06:46 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:06:46 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:46 2023 ] Training epoch: 87
[ Tue Jun 20 03:06:47 2023 ] 	Training loss: 1.1079.  Training acc: 97.40%.
[ Tue Jun 20 03:06:47 2023 ] 	Time consumption: [Data]30%, [Network]69%
[ Tue Jun 20 03:06:47 2023 ] Eval epoch: 87
[ Tue Jun 20 03:06:47 2023 ] 	Mean test loss of 625 batches: 1.676164.
[ Tue Jun 20 03:06:47 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:06:47 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:47 2023 ] Training epoch: 88
[ Tue Jun 20 03:06:48 2023 ] 	Training loss: 1.0811.  Training acc: 96.35%.
[ Tue Jun 20 03:06:48 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Tue Jun 20 03:06:48 2023 ] Eval epoch: 88
[ Tue Jun 20 03:06:48 2023 ] 	Mean test loss of 625 batches: 1.209082.
[ Tue Jun 20 03:06:48 2023 ] 	Top1: 75.44%
[ Tue Jun 20 03:06:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:48 2023 ] Training epoch: 89
[ Tue Jun 20 03:06:49 2023 ] 	Training loss: 1.1617.  Training acc: 91.15%.
[ Tue Jun 20 03:06:49 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 03:06:49 2023 ] Eval epoch: 89
[ Tue Jun 20 03:06:49 2023 ] 	Mean test loss of 625 batches: 1.034271.
[ Tue Jun 20 03:06:49 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:06:49 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:49 2023 ] Training epoch: 90
[ Tue Jun 20 03:06:50 2023 ] 	Training loss: 1.0720.  Training acc: 96.35%.
[ Tue Jun 20 03:06:50 2023 ] 	Time consumption: [Data]32%, [Network]67%
[ Tue Jun 20 03:06:50 2023 ] Eval epoch: 90
[ Tue Jun 20 03:06:50 2023 ] 	Mean test loss of 625 batches: 1.019057.
[ Tue Jun 20 03:06:50 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:06:50 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:50 2023 ] Training epoch: 91
[ Tue Jun 20 03:06:51 2023 ] 	Training loss: 1.0993.  Training acc: 95.83%.
[ Tue Jun 20 03:06:51 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 03:06:51 2023 ] Eval epoch: 91
[ Tue Jun 20 03:06:52 2023 ] 	Mean test loss of 625 batches: 0.982345.
[ Tue Jun 20 03:06:52 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:06:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:52 2023 ] Training epoch: 92
[ Tue Jun 20 03:06:52 2023 ] 	Training loss: 1.0805.  Training acc: 96.88%.
[ Tue Jun 20 03:06:52 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 03:06:52 2023 ] Eval epoch: 92
[ Tue Jun 20 03:06:53 2023 ] 	Mean test loss of 625 batches: 0.958917.
[ Tue Jun 20 03:06:53 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:06:53 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:53 2023 ] Training epoch: 93
[ Tue Jun 20 03:06:53 2023 ] 	Training loss: 1.0734.  Training acc: 98.44%.
[ Tue Jun 20 03:06:53 2023 ] 	Time consumption: [Data]28%, [Network]71%
[ Tue Jun 20 03:06:53 2023 ] Eval epoch: 93
[ Tue Jun 20 03:06:54 2023 ] 	Mean test loss of 625 batches: 0.943669.
[ Tue Jun 20 03:06:54 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:06:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:54 2023 ] Training epoch: 94
[ Tue Jun 20 03:06:55 2023 ] 	Training loss: 1.1980.  Training acc: 94.27%.
[ Tue Jun 20 03:06:55 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 03:06:55 2023 ] Eval epoch: 94
[ Tue Jun 20 03:06:55 2023 ] 	Mean test loss of 625 batches: 0.936795.
[ Tue Jun 20 03:06:55 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:06:55 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:55 2023 ] Training epoch: 95
[ Tue Jun 20 03:06:56 2023 ] 	Training loss: 1.0837.  Training acc: 97.92%.
[ Tue Jun 20 03:06:56 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 03:06:56 2023 ] Eval epoch: 95
[ Tue Jun 20 03:06:56 2023 ] 	Mean test loss of 625 batches: 0.936297.
[ Tue Jun 20 03:06:56 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:06:56 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:56 2023 ] Training epoch: 96
[ Tue Jun 20 03:06:57 2023 ] 	Training loss: 1.0348.  Training acc: 97.40%.
[ Tue Jun 20 03:06:57 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 03:06:57 2023 ] Eval epoch: 96
[ Tue Jun 20 03:06:57 2023 ] 	Mean test loss of 625 batches: 0.935906.
[ Tue Jun 20 03:06:57 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:06:57 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:57 2023 ] Training epoch: 97
[ Tue Jun 20 03:06:58 2023 ] 	Training loss: 1.1413.  Training acc: 94.27%.
[ Tue Jun 20 03:06:58 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 03:06:58 2023 ] Eval epoch: 97
[ Tue Jun 20 03:06:59 2023 ] 	Mean test loss of 625 batches: 0.942917.
[ Tue Jun 20 03:06:59 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:06:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:06:59 2023 ] Training epoch: 98
[ Tue Jun 20 03:06:59 2023 ] 	Training loss: 1.0901.  Training acc: 96.35%.
[ Tue Jun 20 03:06:59 2023 ] 	Time consumption: [Data]27%, [Network]73%
[ Tue Jun 20 03:06:59 2023 ] Eval epoch: 98
[ Tue Jun 20 03:07:00 2023 ] 	Mean test loss of 625 batches: 0.940924.
[ Tue Jun 20 03:07:00 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:07:00 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:07:00 2023 ] Training epoch: 99
[ Tue Jun 20 03:07:01 2023 ] 	Training loss: 1.0216.  Training acc: 97.92%.
[ Tue Jun 20 03:07:01 2023 ] 	Time consumption: [Data]29%, [Network]71%
[ Tue Jun 20 03:07:01 2023 ] Eval epoch: 99
[ Tue Jun 20 03:07:01 2023 ] 	Mean test loss of 625 batches: 0.933420.
[ Tue Jun 20 03:07:01 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:07:01 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:07:01 2023 ] Training epoch: 100
[ Tue Jun 20 03:07:02 2023 ] 	Training loss: 1.0789.  Training acc: 97.40%.
[ Tue Jun 20 03:07:02 2023 ] 	Time consumption: [Data]25%, [Network]75%
[ Tue Jun 20 03:07:02 2023 ] Eval epoch: 100
[ Tue Jun 20 03:07:02 2023 ] 	Mean test loss of 625 batches: 0.928919.
[ Tue Jun 20 03:07:02 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:07:02 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:07:02 2023 ] Training epoch: 101
[ Tue Jun 20 03:07:03 2023 ] 	Training loss: 1.0433.  Training acc: 97.40%.
[ Tue Jun 20 03:07:03 2023 ] 	Time consumption: [Data]30%, [Network]70%
[ Tue Jun 20 03:07:03 2023 ] Eval epoch: 101
[ Tue Jun 20 03:07:04 2023 ] 	Mean test loss of 625 batches: 0.928998.
[ Tue Jun 20 03:07:04 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:07:04 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:07:04 2023 ] Training epoch: 102
[ Tue Jun 20 03:07:05 2023 ] 	Training loss: 1.0171.  Training acc: 98.44%.
[ Tue Jun 20 03:07:05 2023 ] 	Time consumption: [Data]24%, [Network]76%
[ Tue Jun 20 03:07:05 2023 ] Eval epoch: 102
[ Tue Jun 20 03:07:05 2023 ] 	Mean test loss of 625 batches: 0.932989.
[ Tue Jun 20 03:07:05 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:07:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:07:05 2023 ] Training epoch: 103
[ Tue Jun 20 03:07:06 2023 ] 	Training loss: 1.0455.  Training acc: 98.44%.
[ Tue Jun 20 03:07:06 2023 ] 	Time consumption: [Data]26%, [Network]74%
[ Tue Jun 20 03:07:06 2023 ] Eval epoch: 103
[ Tue Jun 20 03:07:06 2023 ] 	Mean test loss of 625 batches: 0.930987.
[ Tue Jun 20 03:07:06 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:07:06 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:07:06 2023 ] Training epoch: 104
[ Tue Jun 20 03:07:07 2023 ] 	Training loss: 1.0703.  Training acc: 95.31%.
[ Tue Jun 20 03:07:07 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Tue Jun 20 03:07:07 2023 ] Eval epoch: 104
[ Tue Jun 20 03:07:08 2023 ] 	Mean test loss of 625 batches: 0.933690.
[ Tue Jun 20 03:07:08 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:07:08 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:07:08 2023 ] Training epoch: 105
[ Tue Jun 20 03:07:09 2023 ] 	Training loss: 1.0516.  Training acc: 97.92%.
[ Tue Jun 20 03:07:09 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Tue Jun 20 03:07:09 2023 ] Eval epoch: 105
[ Tue Jun 20 03:07:09 2023 ] 	Mean test loss of 625 batches: 0.932568.
[ Tue Jun 20 03:07:09 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:07:09 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:07:09 2023 ] Training epoch: 106
[ Tue Jun 20 03:07:10 2023 ] 	Training loss: 1.0476.  Training acc: 97.40%.
[ Tue Jun 20 03:07:10 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Tue Jun 20 03:07:10 2023 ] Eval epoch: 106
[ Tue Jun 20 03:07:10 2023 ] 	Mean test loss of 625 batches: 0.934870.
[ Tue Jun 20 03:07:10 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:07:10 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:07:10 2023 ] Training epoch: 107
[ Tue Jun 20 03:07:11 2023 ] 	Training loss: 1.0553.  Training acc: 96.35%.
[ Tue Jun 20 03:07:11 2023 ] 	Time consumption: [Data]23%, [Network]77%
[ Tue Jun 20 03:07:11 2023 ] Eval epoch: 107
[ Tue Jun 20 03:07:12 2023 ] 	Mean test loss of 625 batches: 0.934738.
[ Tue Jun 20 03:07:12 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:07:12 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:07:12 2023 ] Training epoch: 108
[ Tue Jun 20 03:07:13 2023 ] 	Training loss: 1.0708.  Training acc: 95.83%.
[ Tue Jun 20 03:07:13 2023 ] 	Time consumption: [Data]25%, [Network]75%
[ Tue Jun 20 03:07:13 2023 ] Eval epoch: 108
[ Tue Jun 20 03:07:13 2023 ] 	Mean test loss of 625 batches: 0.934147.
[ Tue Jun 20 03:07:13 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:07:13 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:07:13 2023 ] Training epoch: 109
[ Tue Jun 20 03:07:14 2023 ] 	Training loss: 1.0681.  Training acc: 94.79%.
[ Tue Jun 20 03:07:14 2023 ] 	Time consumption: [Data]22%, [Network]78%
[ Tue Jun 20 03:07:14 2023 ] Eval epoch: 109
[ Tue Jun 20 03:07:15 2023 ] 	Mean test loss of 625 batches: 0.935267.
[ Tue Jun 20 03:07:15 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:07:15 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:07:15 2023 ] Training epoch: 110
[ Tue Jun 20 03:07:15 2023 ] 	Training loss: 1.0524.  Training acc: 99.48%.
[ Tue Jun 20 03:07:15 2023 ] 	Time consumption: [Data]28%, [Network]72%
[ Tue Jun 20 03:07:15 2023 ] Eval epoch: 110
[ Tue Jun 20 03:07:16 2023 ] 	Mean test loss of 625 batches: 0.935956.
[ Tue Jun 20 03:07:16 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:07:16 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:08:39 2023 ] using warm up, epoch: 5
[ Tue Jun 20 03:08:41 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 03:08:41 2023 ] # Parameters: 1538958
[ Tue Jun 20 03:08:41 2023 ] Training epoch: 1
[ Tue Jun 20 03:08:44 2023 ] 	Training loss: 716.1988.  Training acc: 33.33%.
[ Tue Jun 20 03:08:44 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 20 03:08:44 2023 ] Eval epoch: 1
[ Tue Jun 20 03:08:45 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:08:45 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:08:45 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:08:45 2023 ] Training epoch: 2
[ Tue Jun 20 03:08:45 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:08:45 2023 ] 	Time consumption: [Data]40%, [Network]60%
[ Tue Jun 20 03:08:45 2023 ] Eval epoch: 2
[ Tue Jun 20 03:08:46 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:08:46 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:08:46 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:08:46 2023 ] Training epoch: 3
[ Tue Jun 20 03:08:46 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:08:46 2023 ] 	Time consumption: [Data]43%, [Network]57%
[ Tue Jun 20 03:08:46 2023 ] Eval epoch: 3
[ Tue Jun 20 03:08:47 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:08:47 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:08:47 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:08:47 2023 ] Training epoch: 4
[ Tue Jun 20 03:08:47 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:08:47 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:08:47 2023 ] Eval epoch: 4
[ Tue Jun 20 03:08:48 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:08:48 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:08:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:08:48 2023 ] Training epoch: 5
[ Tue Jun 20 03:08:48 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:08:48 2023 ] 	Time consumption: [Data]43%, [Network]56%
[ Tue Jun 20 03:08:48 2023 ] Eval epoch: 5
[ Tue Jun 20 03:08:48 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:08:48 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:08:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:08:48 2023 ] Training epoch: 6
[ Tue Jun 20 03:08:49 2023 ] 	Training loss: nan.  Training acc: 42.71%.
[ Tue Jun 20 03:08:49 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:08:49 2023 ] Eval epoch: 6
[ Tue Jun 20 03:08:49 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:08:49 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:08:49 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:08:49 2023 ] Training epoch: 7
[ Tue Jun 20 03:08:50 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:08:50 2023 ] 	Time consumption: [Data]44%, [Network]56%
[ Tue Jun 20 03:08:50 2023 ] Eval epoch: 7
[ Tue Jun 20 03:08:50 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:08:50 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:08:50 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:08:50 2023 ] Training epoch: 8
[ Tue Jun 20 03:08:51 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:08:51 2023 ] 	Time consumption: [Data]42%, [Network]57%
[ Tue Jun 20 03:08:51 2023 ] Eval epoch: 8
[ Tue Jun 20 03:08:51 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:08:51 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:08:51 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:08:51 2023 ] Training epoch: 9
[ Tue Jun 20 03:08:52 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:08:52 2023 ] 	Time consumption: [Data]41%, [Network]58%
[ Tue Jun 20 03:08:52 2023 ] Eval epoch: 9
[ Tue Jun 20 03:08:52 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:08:52 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:08:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:08:52 2023 ] Training epoch: 10
[ Tue Jun 20 03:08:53 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:08:53 2023 ] 	Time consumption: [Data]41%, [Network]59%
[ Tue Jun 20 03:08:53 2023 ] Eval epoch: 10
[ Tue Jun 20 03:08:53 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:08:53 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:08:53 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:08:53 2023 ] Training epoch: 11
[ Tue Jun 20 03:08:53 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:08:53 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:08:53 2023 ] Eval epoch: 11
[ Tue Jun 20 03:08:54 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:08:54 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:08:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:08:54 2023 ] Training epoch: 12
[ Tue Jun 20 03:08:54 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:08:54 2023 ] 	Time consumption: [Data]40%, [Network]60%
[ Tue Jun 20 03:08:54 2023 ] Eval epoch: 12
[ Tue Jun 20 03:08:55 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:08:55 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:08:55 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:08:55 2023 ] Training epoch: 13
[ Tue Jun 20 03:08:55 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:08:55 2023 ] 	Time consumption: [Data]41%, [Network]59%
[ Tue Jun 20 03:08:55 2023 ] Eval epoch: 13
[ Tue Jun 20 03:08:55 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:08:55 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:08:55 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:08:55 2023 ] Training epoch: 14
[ Tue Jun 20 03:08:56 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:08:56 2023 ] 	Time consumption: [Data]43%, [Network]57%
[ Tue Jun 20 03:08:56 2023 ] Eval epoch: 14
[ Tue Jun 20 03:08:56 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:08:56 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:08:56 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:08:56 2023 ] Training epoch: 15
[ Tue Jun 20 03:08:57 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:08:57 2023 ] 	Time consumption: [Data]45%, [Network]55%
[ Tue Jun 20 03:08:57 2023 ] Eval epoch: 15
[ Tue Jun 20 03:08:57 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:08:57 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:08:57 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:08:57 2023 ] Training epoch: 16
[ Tue Jun 20 03:08:58 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:08:58 2023 ] 	Time consumption: [Data]41%, [Network]58%
[ Tue Jun 20 03:08:58 2023 ] Eval epoch: 16
[ Tue Jun 20 03:08:58 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:08:58 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:08:58 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:08:58 2023 ] Training epoch: 17
[ Tue Jun 20 03:08:59 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:08:59 2023 ] 	Time consumption: [Data]43%, [Network]56%
[ Tue Jun 20 03:08:59 2023 ] Eval epoch: 17
[ Tue Jun 20 03:08:59 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:08:59 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:08:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:08:59 2023 ] Training epoch: 18
[ Tue Jun 20 03:09:00 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:09:00 2023 ] 	Time consumption: [Data]36%, [Network]64%
[ Tue Jun 20 03:09:00 2023 ] Eval epoch: 18
[ Tue Jun 20 03:09:00 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:00 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:00 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:00 2023 ] Training epoch: 19
[ Tue Jun 20 03:09:01 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:09:01 2023 ] 	Time consumption: [Data]32%, [Network]67%
[ Tue Jun 20 03:09:01 2023 ] Eval epoch: 19
[ Tue Jun 20 03:09:01 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:01 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:01 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:01 2023 ] Training epoch: 20
[ Tue Jun 20 03:09:02 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:09:02 2023 ] 	Time consumption: [Data]33%, [Network]67%
[ Tue Jun 20 03:09:02 2023 ] Eval epoch: 20
[ Tue Jun 20 03:09:02 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:02 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:02 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:02 2023 ] Training epoch: 21
[ Tue Jun 20 03:09:03 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:09:03 2023 ] 	Time consumption: [Data]32%, [Network]68%
[ Tue Jun 20 03:09:03 2023 ] Eval epoch: 21
[ Tue Jun 20 03:09:03 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:03 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:03 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:03 2023 ] Training epoch: 22
[ Tue Jun 20 03:09:04 2023 ] 	Training loss: nan.  Training acc: 38.54%.
[ Tue Jun 20 03:09:04 2023 ] 	Time consumption: [Data]33%, [Network]66%
[ Tue Jun 20 03:09:04 2023 ] Eval epoch: 22
[ Tue Jun 20 03:09:04 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:04 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:04 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:04 2023 ] Training epoch: 23
[ Tue Jun 20 03:09:05 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:09:05 2023 ] 	Time consumption: [Data]33%, [Network]67%
[ Tue Jun 20 03:09:05 2023 ] Eval epoch: 23
[ Tue Jun 20 03:09:05 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:05 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:05 2023 ] Training epoch: 24
[ Tue Jun 20 03:09:06 2023 ] 	Training loss: nan.  Training acc: 42.71%.
[ Tue Jun 20 03:09:06 2023 ] 	Time consumption: [Data]34%, [Network]65%
[ Tue Jun 20 03:09:06 2023 ] Eval epoch: 24
[ Tue Jun 20 03:09:06 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:06 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:06 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:06 2023 ] Training epoch: 25
[ Tue Jun 20 03:09:07 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:09:07 2023 ] 	Time consumption: [Data]34%, [Network]65%
[ Tue Jun 20 03:09:07 2023 ] Eval epoch: 25
[ Tue Jun 20 03:09:08 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:08 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:08 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:08 2023 ] Training epoch: 26
[ Tue Jun 20 03:09:08 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:09:08 2023 ] 	Time consumption: [Data]33%, [Network]66%
[ Tue Jun 20 03:09:08 2023 ] Eval epoch: 26
[ Tue Jun 20 03:09:09 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:09 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:09 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:09 2023 ] Training epoch: 27
[ Tue Jun 20 03:09:09 2023 ] 	Training loss: nan.  Training acc: 42.71%.
[ Tue Jun 20 03:09:09 2023 ] 	Time consumption: [Data]34%, [Network]66%
[ Tue Jun 20 03:09:09 2023 ] Eval epoch: 27
[ Tue Jun 20 03:09:10 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:10 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:10 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:10 2023 ] Training epoch: 28
[ Tue Jun 20 03:09:10 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:09:10 2023 ] 	Time consumption: [Data]38%, [Network]62%
[ Tue Jun 20 03:09:10 2023 ] Eval epoch: 28
[ Tue Jun 20 03:09:11 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:11 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:11 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:11 2023 ] Training epoch: 29
[ Tue Jun 20 03:09:11 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:09:11 2023 ] 	Time consumption: [Data]44%, [Network]55%
[ Tue Jun 20 03:09:11 2023 ] Eval epoch: 29
[ Tue Jun 20 03:09:12 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:12 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:12 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:12 2023 ] Training epoch: 30
[ Tue Jun 20 03:09:12 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:09:12 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:09:12 2023 ] Eval epoch: 30
[ Tue Jun 20 03:09:12 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:12 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:12 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:12 2023 ] Training epoch: 31
[ Tue Jun 20 03:09:13 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:09:13 2023 ] 	Time consumption: [Data]44%, [Network]56%
[ Tue Jun 20 03:09:13 2023 ] Eval epoch: 31
[ Tue Jun 20 03:09:13 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:13 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:13 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:13 2023 ] Training epoch: 32
[ Tue Jun 20 03:09:14 2023 ] 	Training loss: nan.  Training acc: 44.79%.
[ Tue Jun 20 03:09:14 2023 ] 	Time consumption: [Data]44%, [Network]55%
[ Tue Jun 20 03:09:14 2023 ] Eval epoch: 32
[ Tue Jun 20 03:09:14 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:14 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:14 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:14 2023 ] Training epoch: 33
[ Tue Jun 20 03:09:15 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:09:15 2023 ] 	Time consumption: [Data]43%, [Network]57%
[ Tue Jun 20 03:09:15 2023 ] Eval epoch: 33
[ Tue Jun 20 03:09:15 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:15 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:15 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:15 2023 ] Training epoch: 34
[ Tue Jun 20 03:09:16 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:09:16 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:09:16 2023 ] Eval epoch: 34
[ Tue Jun 20 03:09:16 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:16 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:16 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:16 2023 ] Training epoch: 35
[ Tue Jun 20 03:09:17 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:09:17 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:09:17 2023 ] Eval epoch: 35
[ Tue Jun 20 03:09:17 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:17 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:17 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:17 2023 ] Training epoch: 36
[ Tue Jun 20 03:09:17 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:09:17 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:09:17 2023 ] Eval epoch: 36
[ Tue Jun 20 03:09:18 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:18 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:18 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:18 2023 ] Training epoch: 37
[ Tue Jun 20 03:09:18 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:09:18 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:09:18 2023 ] Eval epoch: 37
[ Tue Jun 20 03:09:19 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:19 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:19 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:19 2023 ] Training epoch: 38
[ Tue Jun 20 03:09:19 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:09:19 2023 ] 	Time consumption: [Data]41%, [Network]59%
[ Tue Jun 20 03:09:19 2023 ] Eval epoch: 38
[ Tue Jun 20 03:09:19 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:19 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:19 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:19 2023 ] Training epoch: 39
[ Tue Jun 20 03:09:20 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:09:20 2023 ] 	Time consumption: [Data]41%, [Network]59%
[ Tue Jun 20 03:09:20 2023 ] Eval epoch: 39
[ Tue Jun 20 03:09:20 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:20 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:20 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:20 2023 ] Training epoch: 40
[ Tue Jun 20 03:09:21 2023 ] 	Training loss: nan.  Training acc: 42.71%.
[ Tue Jun 20 03:09:21 2023 ] 	Time consumption: [Data]44%, [Network]56%
[ Tue Jun 20 03:09:21 2023 ] Eval epoch: 40
[ Tue Jun 20 03:09:21 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:21 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:21 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:21 2023 ] Training epoch: 41
[ Tue Jun 20 03:09:22 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:09:22 2023 ] 	Time consumption: [Data]41%, [Network]59%
[ Tue Jun 20 03:09:22 2023 ] Eval epoch: 41
[ Tue Jun 20 03:09:22 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:22 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:22 2023 ] Training epoch: 42
[ Tue Jun 20 03:09:23 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:09:23 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:09:23 2023 ] Eval epoch: 42
[ Tue Jun 20 03:09:23 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:23 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:23 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:23 2023 ] Training epoch: 43
[ Tue Jun 20 03:09:24 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:09:24 2023 ] 	Time consumption: [Data]44%, [Network]56%
[ Tue Jun 20 03:09:24 2023 ] Eval epoch: 43
[ Tue Jun 20 03:09:24 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:24 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:24 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:24 2023 ] Training epoch: 44
[ Tue Jun 20 03:09:25 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:09:25 2023 ] 	Time consumption: [Data]41%, [Network]59%
[ Tue Jun 20 03:09:25 2023 ] Eval epoch: 44
[ Tue Jun 20 03:09:25 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:25 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:25 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:25 2023 ] Training epoch: 45
[ Tue Jun 20 03:09:25 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:09:25 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:09:25 2023 ] Eval epoch: 45
[ Tue Jun 20 03:09:26 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:26 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:26 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:26 2023 ] Training epoch: 46
[ Tue Jun 20 03:09:26 2023 ] 	Training loss: nan.  Training acc: 42.71%.
[ Tue Jun 20 03:09:26 2023 ] 	Time consumption: [Data]43%, [Network]57%
[ Tue Jun 20 03:09:26 2023 ] Eval epoch: 46
[ Tue Jun 20 03:09:27 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:27 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:27 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:27 2023 ] Training epoch: 47
[ Tue Jun 20 03:09:27 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:09:27 2023 ] 	Time consumption: [Data]40%, [Network]60%
[ Tue Jun 20 03:09:27 2023 ] Eval epoch: 47
[ Tue Jun 20 03:09:27 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:27 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:27 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:27 2023 ] Training epoch: 48
[ Tue Jun 20 03:09:28 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:09:28 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:09:28 2023 ] Eval epoch: 48
[ Tue Jun 20 03:09:28 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:28 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:28 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:28 2023 ] Training epoch: 49
[ Tue Jun 20 03:09:29 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:09:29 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:09:29 2023 ] Eval epoch: 49
[ Tue Jun 20 03:09:29 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:29 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:29 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:29 2023 ] Training epoch: 50
[ Tue Jun 20 03:09:30 2023 ] 	Training loss: nan.  Training acc: 38.54%.
[ Tue Jun 20 03:09:30 2023 ] 	Time consumption: [Data]46%, [Network]54%
[ Tue Jun 20 03:09:30 2023 ] Eval epoch: 50
[ Tue Jun 20 03:09:30 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:30 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:30 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:30 2023 ] Training epoch: 51
[ Tue Jun 20 03:09:31 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:09:31 2023 ] 	Time consumption: [Data]41%, [Network]58%
[ Tue Jun 20 03:09:31 2023 ] Eval epoch: 51
[ Tue Jun 20 03:09:31 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:31 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:31 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:31 2023 ] Training epoch: 52
[ Tue Jun 20 03:09:32 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:09:32 2023 ] 	Time consumption: [Data]42%, [Network]57%
[ Tue Jun 20 03:09:32 2023 ] Eval epoch: 52
[ Tue Jun 20 03:09:32 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:32 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:32 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:32 2023 ] Training epoch: 53
[ Tue Jun 20 03:09:33 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:09:33 2023 ] 	Time consumption: [Data]39%, [Network]60%
[ Tue Jun 20 03:09:33 2023 ] Eval epoch: 53
[ Tue Jun 20 03:09:33 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:33 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:33 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:33 2023 ] Training epoch: 54
[ Tue Jun 20 03:09:33 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:09:33 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:09:33 2023 ] Eval epoch: 54
[ Tue Jun 20 03:09:34 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:34 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:34 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:34 2023 ] Training epoch: 55
[ Tue Jun 20 03:09:34 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:09:34 2023 ] 	Time consumption: [Data]43%, [Network]56%
[ Tue Jun 20 03:09:34 2023 ] Eval epoch: 55
[ Tue Jun 20 03:09:35 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:35 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:35 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:35 2023 ] Training epoch: 56
[ Tue Jun 20 03:09:35 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:09:35 2023 ] 	Time consumption: [Data]43%, [Network]57%
[ Tue Jun 20 03:09:35 2023 ] Eval epoch: 56
[ Tue Jun 20 03:09:36 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:36 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:36 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:36 2023 ] Training epoch: 57
[ Tue Jun 20 03:09:36 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:09:36 2023 ] 	Time consumption: [Data]40%, [Network]59%
[ Tue Jun 20 03:09:36 2023 ] Eval epoch: 57
[ Tue Jun 20 03:09:36 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:36 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:36 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:36 2023 ] Training epoch: 58
[ Tue Jun 20 03:09:37 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:09:37 2023 ] 	Time consumption: [Data]44%, [Network]56%
[ Tue Jun 20 03:09:37 2023 ] Eval epoch: 58
[ Tue Jun 20 03:09:37 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:37 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:37 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:37 2023 ] Training epoch: 59
[ Tue Jun 20 03:09:38 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:09:38 2023 ] 	Time consumption: [Data]41%, [Network]58%
[ Tue Jun 20 03:09:38 2023 ] Eval epoch: 59
[ Tue Jun 20 03:09:38 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:38 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:38 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:38 2023 ] Training epoch: 60
[ Tue Jun 20 03:09:39 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:09:39 2023 ] 	Time consumption: [Data]40%, [Network]60%
[ Tue Jun 20 03:09:39 2023 ] Eval epoch: 60
[ Tue Jun 20 03:09:39 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:39 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:39 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:39 2023 ] Training epoch: 61
[ Tue Jun 20 03:09:40 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:09:40 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:09:40 2023 ] Eval epoch: 61
[ Tue Jun 20 03:09:40 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:40 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:40 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:40 2023 ] Training epoch: 62
[ Tue Jun 20 03:09:41 2023 ] 	Training loss: nan.  Training acc: 38.02%.
[ Tue Jun 20 03:09:41 2023 ] 	Time consumption: [Data]39%, [Network]60%
[ Tue Jun 20 03:09:41 2023 ] Eval epoch: 62
[ Tue Jun 20 03:09:41 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:41 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:41 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:41 2023 ] Training epoch: 63
[ Tue Jun 20 03:09:41 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:09:41 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:09:41 2023 ] Eval epoch: 63
[ Tue Jun 20 03:09:42 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:42 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:42 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:42 2023 ] Training epoch: 64
[ Tue Jun 20 03:09:42 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:09:42 2023 ] 	Time consumption: [Data]43%, [Network]57%
[ Tue Jun 20 03:09:42 2023 ] Eval epoch: 64
[ Tue Jun 20 03:09:43 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:43 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:43 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:43 2023 ] Training epoch: 65
[ Tue Jun 20 03:09:43 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:09:43 2023 ] 	Time consumption: [Data]41%, [Network]58%
[ Tue Jun 20 03:09:43 2023 ] Eval epoch: 65
[ Tue Jun 20 03:09:43 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:43 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:43 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:43 2023 ] Training epoch: 66
[ Tue Jun 20 03:09:44 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:09:44 2023 ] 	Time consumption: [Data]46%, [Network]54%
[ Tue Jun 20 03:09:44 2023 ] Eval epoch: 66
[ Tue Jun 20 03:09:44 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:44 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:44 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:44 2023 ] Training epoch: 67
[ Tue Jun 20 03:09:45 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:09:45 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:09:45 2023 ] Eval epoch: 67
[ Tue Jun 20 03:09:45 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:45 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:45 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:45 2023 ] Training epoch: 68
[ Tue Jun 20 03:09:46 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:09:46 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:09:46 2023 ] Eval epoch: 68
[ Tue Jun 20 03:09:46 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:46 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:46 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:46 2023 ] Training epoch: 69
[ Tue Jun 20 03:09:47 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:09:47 2023 ] 	Time consumption: [Data]45%, [Network]55%
[ Tue Jun 20 03:09:47 2023 ] Eval epoch: 69
[ Tue Jun 20 03:09:47 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:47 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:47 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:47 2023 ] Training epoch: 70
[ Tue Jun 20 03:09:48 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:09:48 2023 ] 	Time consumption: [Data]41%, [Network]59%
[ Tue Jun 20 03:09:48 2023 ] Eval epoch: 70
[ Tue Jun 20 03:09:48 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:48 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:48 2023 ] Training epoch: 71
[ Tue Jun 20 03:09:49 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:09:49 2023 ] 	Time consumption: [Data]41%, [Network]59%
[ Tue Jun 20 03:09:49 2023 ] Eval epoch: 71
[ Tue Jun 20 03:09:49 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:49 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:49 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:49 2023 ] Training epoch: 72
[ Tue Jun 20 03:09:50 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:09:50 2023 ] 	Time consumption: [Data]42%, [Network]57%
[ Tue Jun 20 03:09:50 2023 ] Eval epoch: 72
[ Tue Jun 20 03:09:50 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:50 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:50 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:50 2023 ] Training epoch: 73
[ Tue Jun 20 03:09:50 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:09:50 2023 ] 	Time consumption: [Data]40%, [Network]60%
[ Tue Jun 20 03:09:50 2023 ] Eval epoch: 73
[ Tue Jun 20 03:09:51 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:51 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:51 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:51 2023 ] Training epoch: 74
[ Tue Jun 20 03:09:51 2023 ] 	Training loss: nan.  Training acc: 38.54%.
[ Tue Jun 20 03:09:51 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:09:51 2023 ] Eval epoch: 74
[ Tue Jun 20 03:09:52 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:52 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:52 2023 ] Training epoch: 75
[ Tue Jun 20 03:09:52 2023 ] 	Training loss: nan.  Training acc: 38.02%.
[ Tue Jun 20 03:09:52 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:09:52 2023 ] Eval epoch: 75
[ Tue Jun 20 03:09:53 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:53 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:53 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:53 2023 ] Training epoch: 76
[ Tue Jun 20 03:09:53 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:09:53 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:09:53 2023 ] Eval epoch: 76
[ Tue Jun 20 03:09:53 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:53 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:53 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:53 2023 ] Training epoch: 77
[ Tue Jun 20 03:09:54 2023 ] 	Training loss: nan.  Training acc: 44.79%.
[ Tue Jun 20 03:09:54 2023 ] 	Time consumption: [Data]45%, [Network]54%
[ Tue Jun 20 03:09:54 2023 ] Eval epoch: 77
[ Tue Jun 20 03:09:54 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:54 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:54 2023 ] Training epoch: 78
[ Tue Jun 20 03:09:55 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:09:55 2023 ] 	Time consumption: [Data]41%, [Network]59%
[ Tue Jun 20 03:09:55 2023 ] Eval epoch: 78
[ Tue Jun 20 03:09:55 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:55 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:55 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:55 2023 ] Training epoch: 79
[ Tue Jun 20 03:09:56 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:09:56 2023 ] 	Time consumption: [Data]41%, [Network]59%
[ Tue Jun 20 03:09:56 2023 ] Eval epoch: 79
[ Tue Jun 20 03:09:56 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:56 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:56 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:56 2023 ] Training epoch: 80
[ Tue Jun 20 03:09:57 2023 ] 	Training loss: nan.  Training acc: 38.54%.
[ Tue Jun 20 03:09:57 2023 ] 	Time consumption: [Data]43%, [Network]56%
[ Tue Jun 20 03:09:57 2023 ] Eval epoch: 80
[ Tue Jun 20 03:09:57 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:57 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:57 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:57 2023 ] Training epoch: 81
[ Tue Jun 20 03:09:57 2023 ] 	Training loss: nan.  Training acc: 37.50%.
[ Tue Jun 20 03:09:58 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:09:58 2023 ] Eval epoch: 81
[ Tue Jun 20 03:09:58 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:58 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:58 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:58 2023 ] Training epoch: 82
[ Tue Jun 20 03:09:59 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:09:59 2023 ] 	Time consumption: [Data]33%, [Network]66%
[ Tue Jun 20 03:09:59 2023 ] Eval epoch: 82
[ Tue Jun 20 03:09:59 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:09:59 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:09:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:09:59 2023 ] Training epoch: 83
[ Tue Jun 20 03:10:00 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:10:00 2023 ] 	Time consumption: [Data]32%, [Network]68%
[ Tue Jun 20 03:10:00 2023 ] Eval epoch: 83
[ Tue Jun 20 03:10:00 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:00 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:00 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:00 2023 ] Training epoch: 84
[ Tue Jun 20 03:10:01 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:10:01 2023 ] 	Time consumption: [Data]34%, [Network]65%
[ Tue Jun 20 03:10:01 2023 ] Eval epoch: 84
[ Tue Jun 20 03:10:01 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:01 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:01 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:01 2023 ] Training epoch: 85
[ Tue Jun 20 03:10:02 2023 ] 	Training loss: nan.  Training acc: 42.71%.
[ Tue Jun 20 03:10:02 2023 ] 	Time consumption: [Data]35%, [Network]65%
[ Tue Jun 20 03:10:02 2023 ] Eval epoch: 85
[ Tue Jun 20 03:10:02 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:02 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:02 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:02 2023 ] Training epoch: 86
[ Tue Jun 20 03:10:03 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:10:03 2023 ] 	Time consumption: [Data]33%, [Network]67%
[ Tue Jun 20 03:10:03 2023 ] Eval epoch: 86
[ Tue Jun 20 03:10:03 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:03 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:03 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:03 2023 ] Training epoch: 87
[ Tue Jun 20 03:10:04 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:10:04 2023 ] 	Time consumption: [Data]32%, [Network]67%
[ Tue Jun 20 03:10:04 2023 ] Eval epoch: 87
[ Tue Jun 20 03:10:04 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:04 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:04 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:04 2023 ] Training epoch: 88
[ Tue Jun 20 03:10:05 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:10:05 2023 ] 	Time consumption: [Data]32%, [Network]67%
[ Tue Jun 20 03:10:05 2023 ] Eval epoch: 88
[ Tue Jun 20 03:10:05 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:05 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:05 2023 ] Training epoch: 89
[ Tue Jun 20 03:10:06 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:10:06 2023 ] 	Time consumption: [Data]33%, [Network]67%
[ Tue Jun 20 03:10:06 2023 ] Eval epoch: 89
[ Tue Jun 20 03:10:06 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:06 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:06 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:06 2023 ] Training epoch: 90
[ Tue Jun 20 03:10:07 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:10:07 2023 ] 	Time consumption: [Data]34%, [Network]65%
[ Tue Jun 20 03:10:07 2023 ] Eval epoch: 90
[ Tue Jun 20 03:10:07 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:07 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:07 2023 ] Training epoch: 91
[ Tue Jun 20 03:10:08 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:10:08 2023 ] 	Time consumption: [Data]32%, [Network]67%
[ Tue Jun 20 03:10:08 2023 ] Eval epoch: 91
[ Tue Jun 20 03:10:08 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:08 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:08 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:08 2023 ] Training epoch: 92
[ Tue Jun 20 03:10:09 2023 ] 	Training loss: nan.  Training acc: 40.10%.
[ Tue Jun 20 03:10:09 2023 ] 	Time consumption: [Data]33%, [Network]66%
[ Tue Jun 20 03:10:09 2023 ] Eval epoch: 92
[ Tue Jun 20 03:10:09 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:09 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:09 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:09 2023 ] Training epoch: 93
[ Tue Jun 20 03:10:09 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:10:09 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:10:09 2023 ] Eval epoch: 93
[ Tue Jun 20 03:10:10 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:10 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:10 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:10 2023 ] Training epoch: 94
[ Tue Jun 20 03:10:10 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:10:10 2023 ] 	Time consumption: [Data]40%, [Network]59%
[ Tue Jun 20 03:10:10 2023 ] Eval epoch: 94
[ Tue Jun 20 03:10:11 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:11 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:11 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:11 2023 ] Training epoch: 95
[ Tue Jun 20 03:10:11 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:10:11 2023 ] 	Time consumption: [Data]41%, [Network]58%
[ Tue Jun 20 03:10:11 2023 ] Eval epoch: 95
[ Tue Jun 20 03:10:11 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:11 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:11 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:11 2023 ] Training epoch: 96
[ Tue Jun 20 03:10:12 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:10:12 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:10:12 2023 ] Eval epoch: 96
[ Tue Jun 20 03:10:12 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:12 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:12 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:12 2023 ] Training epoch: 97
[ Tue Jun 20 03:10:13 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:10:13 2023 ] 	Time consumption: [Data]41%, [Network]59%
[ Tue Jun 20 03:10:13 2023 ] Eval epoch: 97
[ Tue Jun 20 03:10:13 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:13 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:13 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:13 2023 ] Training epoch: 98
[ Tue Jun 20 03:10:14 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:10:14 2023 ] 	Time consumption: [Data]41%, [Network]59%
[ Tue Jun 20 03:10:14 2023 ] Eval epoch: 98
[ Tue Jun 20 03:10:14 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:14 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:14 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:14 2023 ] Training epoch: 99
[ Tue Jun 20 03:10:15 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:10:15 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:10:15 2023 ] Eval epoch: 99
[ Tue Jun 20 03:10:15 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:15 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:15 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:15 2023 ] Training epoch: 100
[ Tue Jun 20 03:10:16 2023 ] 	Training loss: nan.  Training acc: 38.54%.
[ Tue Jun 20 03:10:16 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:10:16 2023 ] Eval epoch: 100
[ Tue Jun 20 03:10:16 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:16 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:16 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:16 2023 ] Training epoch: 101
[ Tue Jun 20 03:10:16 2023 ] 	Training loss: nan.  Training acc: 43.23%.
[ Tue Jun 20 03:10:16 2023 ] 	Time consumption: [Data]44%, [Network]56%
[ Tue Jun 20 03:10:16 2023 ] Eval epoch: 101
[ Tue Jun 20 03:10:17 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:17 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:17 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:17 2023 ] Training epoch: 102
[ Tue Jun 20 03:10:17 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:10:17 2023 ] 	Time consumption: [Data]42%, [Network]57%
[ Tue Jun 20 03:10:17 2023 ] Eval epoch: 102
[ Tue Jun 20 03:10:18 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:18 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:18 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:18 2023 ] Training epoch: 103
[ Tue Jun 20 03:10:18 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:10:18 2023 ] 	Time consumption: [Data]43%, [Network]57%
[ Tue Jun 20 03:10:18 2023 ] Eval epoch: 103
[ Tue Jun 20 03:10:18 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:18 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:18 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:18 2023 ] Training epoch: 104
[ Tue Jun 20 03:10:19 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:10:19 2023 ] 	Time consumption: [Data]43%, [Network]57%
[ Tue Jun 20 03:10:19 2023 ] Eval epoch: 104
[ Tue Jun 20 03:10:19 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:19 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:19 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:19 2023 ] Training epoch: 105
[ Tue Jun 20 03:10:20 2023 ] 	Training loss: nan.  Training acc: 41.67%.
[ Tue Jun 20 03:10:20 2023 ] 	Time consumption: [Data]43%, [Network]57%
[ Tue Jun 20 03:10:20 2023 ] Eval epoch: 105
[ Tue Jun 20 03:10:20 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:20 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:20 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:20 2023 ] Training epoch: 106
[ Tue Jun 20 03:10:21 2023 ] 	Training loss: nan.  Training acc: 39.06%.
[ Tue Jun 20 03:10:21 2023 ] 	Time consumption: [Data]43%, [Network]57%
[ Tue Jun 20 03:10:21 2023 ] Eval epoch: 106
[ Tue Jun 20 03:10:21 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:21 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:21 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:21 2023 ] Training epoch: 107
[ Tue Jun 20 03:10:22 2023 ] 	Training loss: nan.  Training acc: 41.15%.
[ Tue Jun 20 03:10:22 2023 ] 	Time consumption: [Data]41%, [Network]58%
[ Tue Jun 20 03:10:22 2023 ] Eval epoch: 107
[ Tue Jun 20 03:10:22 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:22 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:22 2023 ] Training epoch: 108
[ Tue Jun 20 03:10:23 2023 ] 	Training loss: nan.  Training acc: 39.58%.
[ Tue Jun 20 03:10:23 2023 ] 	Time consumption: [Data]42%, [Network]58%
[ Tue Jun 20 03:10:23 2023 ] Eval epoch: 108
[ Tue Jun 20 03:10:23 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:23 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:23 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:23 2023 ] Training epoch: 109
[ Tue Jun 20 03:10:24 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:10:24 2023 ] 	Time consumption: [Data]44%, [Network]55%
[ Tue Jun 20 03:10:24 2023 ] Eval epoch: 109
[ Tue Jun 20 03:10:24 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:24 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:24 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:24 2023 ] Training epoch: 110
[ Tue Jun 20 03:10:24 2023 ] 	Training loss: nan.  Training acc: 42.19%.
[ Tue Jun 20 03:10:24 2023 ] 	Time consumption: [Data]42%, [Network]57%
[ Tue Jun 20 03:10:25 2023 ] Eval epoch: 110
[ Tue Jun 20 03:10:25 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:10:25 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:10:25 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:10:25 2023 ] Best accuracy: 0.2982456140350877
[ Tue Jun 20 03:10:25 2023 ] Epoch number: 1
[ Tue Jun 20 03:10:25 2023 ] Model name: results/ec3d_NTU60_CS
[ Tue Jun 20 03:10:25 2023 ] Model total number of params: 1538958
[ Tue Jun 20 03:10:25 2023 ] Weight decay: 0.0005
[ Tue Jun 20 03:10:25 2023 ] Base LR: 0.1
[ Tue Jun 20 03:10:25 2023 ] Batch Size: 64
[ Tue Jun 20 03:10:25 2023 ] Test Batch Size: 64
[ Tue Jun 20 03:10:25 2023 ] seed: 1
[ Tue Jun 20 03:17:02 2023 ] using warm up, epoch: 5
[ Tue Jun 20 03:17:29 2023 ] using warm up, epoch: 5
[ Tue Jun 20 03:17:31 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 03:17:31 2023 ] # Parameters: 1538958
[ Tue Jun 20 03:17:31 2023 ] Training epoch: 1
[ Tue Jun 20 03:17:35 2023 ] 	Training loss: nan.  Training acc: 39.25%.
[ Tue Jun 20 03:17:35 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 20 03:17:35 2023 ] Eval epoch: 1
[ Tue Jun 20 03:17:36 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:17:36 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:17:36 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:17:36 2023 ] Training epoch: 2
[ Tue Jun 20 03:17:38 2023 ] 	Training loss: nan.  Training acc: 41.08%.
[ Tue Jun 20 03:17:38 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 03:17:38 2023 ] Eval epoch: 2
[ Tue Jun 20 03:17:39 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:17:39 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:17:39 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:17:39 2023 ] Training epoch: 3
[ Tue Jun 20 03:17:41 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:17:41 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:17:41 2023 ] Eval epoch: 3
[ Tue Jun 20 03:17:41 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:17:41 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:17:41 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:17:41 2023 ] Training epoch: 4
[ Tue Jun 20 03:17:43 2023 ] 	Training loss: nan.  Training acc: 40.17%.
[ Tue Jun 20 03:17:43 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 20 03:17:43 2023 ] Eval epoch: 4
[ Tue Jun 20 03:17:44 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:17:44 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:17:44 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:17:44 2023 ] Training epoch: 5
[ Tue Jun 20 03:17:46 2023 ] 	Training loss: nan.  Training acc: 40.81%.
[ Tue Jun 20 03:17:46 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 20 03:17:46 2023 ] Eval epoch: 5
[ Tue Jun 20 03:17:46 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:17:46 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:17:46 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:17:46 2023 ] Training epoch: 6
[ Tue Jun 20 03:17:48 2023 ] 	Training loss: nan.  Training acc: 40.99%.
[ Tue Jun 20 03:17:48 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 03:17:48 2023 ] Eval epoch: 6
[ Tue Jun 20 03:17:49 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:17:49 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:17:49 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:17:49 2023 ] Training epoch: 7
[ Tue Jun 20 03:17:52 2023 ] 	Training loss: nan.  Training acc: 40.99%.
[ Tue Jun 20 03:17:52 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 20 03:17:52 2023 ] Eval epoch: 7
[ Tue Jun 20 03:17:52 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:17:52 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:17:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:17:52 2023 ] Training epoch: 8
[ Tue Jun 20 03:17:55 2023 ] 	Training loss: nan.  Training acc: 41.18%.
[ Tue Jun 20 03:17:55 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 20 03:17:55 2023 ] Eval epoch: 8
[ Tue Jun 20 03:17:56 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:17:56 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:17:56 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:17:56 2023 ] Training epoch: 9
[ Tue Jun 20 03:17:59 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:17:59 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Tue Jun 20 03:17:59 2023 ] Eval epoch: 9
[ Tue Jun 20 03:17:59 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:17:59 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:17:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:17:59 2023 ] Training epoch: 10
[ Tue Jun 20 03:18:01 2023 ] 	Training loss: nan.  Training acc: 41.36%.
[ Tue Jun 20 03:18:01 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 20 03:18:01 2023 ] Eval epoch: 10
[ Tue Jun 20 03:18:02 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:18:02 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:18:02 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:18:02 2023 ] Training epoch: 11
[ Tue Jun 20 03:18:04 2023 ] 	Training loss: nan.  Training acc: 40.72%.
[ Tue Jun 20 03:18:04 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:18:04 2023 ] Eval epoch: 11
[ Tue Jun 20 03:18:04 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:18:04 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:18:04 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:18:04 2023 ] Training epoch: 12
[ Tue Jun 20 03:18:07 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:18:07 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:18:07 2023 ] Eval epoch: 12
[ Tue Jun 20 03:18:07 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:18:07 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:18:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:18:07 2023 ] Training epoch: 13
[ Tue Jun 20 03:18:09 2023 ] 	Training loss: nan.  Training acc: 40.35%.
[ Tue Jun 20 03:18:09 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 20 03:18:09 2023 ] Eval epoch: 13
[ Tue Jun 20 03:18:10 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:18:10 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:18:10 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:18:10 2023 ] Training epoch: 14
[ Tue Jun 20 03:18:12 2023 ] 	Training loss: nan.  Training acc: 40.99%.
[ Tue Jun 20 03:18:12 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:18:12 2023 ] Eval epoch: 14
[ Tue Jun 20 03:18:12 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:18:12 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:18:12 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:18:12 2023 ] Training epoch: 15
[ Tue Jun 20 03:18:14 2023 ] 	Training loss: nan.  Training acc: 40.72%.
[ Tue Jun 20 03:18:14 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 20 03:18:14 2023 ] Eval epoch: 15
[ Tue Jun 20 03:18:15 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:18:15 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:18:15 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:18:15 2023 ] Training epoch: 16
[ Tue Jun 20 03:18:17 2023 ] 	Training loss: nan.  Training acc: 40.72%.
[ Tue Jun 20 03:18:17 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:18:17 2023 ] Eval epoch: 16
[ Tue Jun 20 03:18:17 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:18:17 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:18:17 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:18:17 2023 ] Training epoch: 17
[ Tue Jun 20 03:18:19 2023 ] 	Training loss: nan.  Training acc: 40.26%.
[ Tue Jun 20 03:18:19 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:18:19 2023 ] Eval epoch: 17
[ Tue Jun 20 03:18:20 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:18:20 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:18:20 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:18:20 2023 ] Training epoch: 18
[ Tue Jun 20 03:18:22 2023 ] 	Training loss: nan.  Training acc: 40.99%.
[ Tue Jun 20 03:18:22 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:18:22 2023 ] Eval epoch: 18
[ Tue Jun 20 03:18:22 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:18:22 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:18:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:18:22 2023 ] Training epoch: 19
[ Tue Jun 20 03:18:24 2023 ] 	Training loss: nan.  Training acc: 40.35%.
[ Tue Jun 20 03:18:24 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:18:24 2023 ] Eval epoch: 19
[ Tue Jun 20 03:18:25 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:18:25 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:18:25 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:18:25 2023 ] Training epoch: 20
[ Tue Jun 20 03:18:27 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:18:27 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:18:27 2023 ] Eval epoch: 20
[ Tue Jun 20 03:18:27 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:18:27 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:18:27 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:18:27 2023 ] Training epoch: 21
[ Tue Jun 20 03:18:30 2023 ] 	Training loss: nan.  Training acc: 40.35%.
[ Tue Jun 20 03:18:30 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:18:30 2023 ] Eval epoch: 21
[ Tue Jun 20 03:18:30 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:18:30 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:18:30 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:18:30 2023 ] Training epoch: 22
[ Tue Jun 20 03:18:32 2023 ] 	Training loss: nan.  Training acc: 40.72%.
[ Tue Jun 20 03:18:32 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:18:32 2023 ] Eval epoch: 22
[ Tue Jun 20 03:18:33 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:18:33 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:18:33 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:18:33 2023 ] Training epoch: 23
[ Tue Jun 20 03:18:35 2023 ] 	Training loss: nan.  Training acc: 40.44%.
[ Tue Jun 20 03:18:35 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:18:35 2023 ] Eval epoch: 23
[ Tue Jun 20 03:18:35 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:18:35 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:18:35 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:18:35 2023 ] Training epoch: 24
[ Tue Jun 20 03:18:37 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:18:37 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:18:37 2023 ] Eval epoch: 24
[ Tue Jun 20 03:18:38 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:18:38 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:18:38 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:18:38 2023 ] Training epoch: 25
[ Tue Jun 20 03:18:40 2023 ] 	Training loss: nan.  Training acc: 40.44%.
[ Tue Jun 20 03:18:40 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 20 03:18:40 2023 ] Eval epoch: 25
[ Tue Jun 20 03:18:40 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:18:40 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:18:40 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:18:40 2023 ] Training epoch: 26
[ Tue Jun 20 03:18:43 2023 ] 	Training loss: nan.  Training acc: 39.98%.
[ Tue Jun 20 03:18:43 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:18:43 2023 ] Eval epoch: 26
[ Tue Jun 20 03:18:43 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:18:43 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:18:43 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:18:43 2023 ] Training epoch: 27
[ Tue Jun 20 03:18:45 2023 ] 	Training loss: nan.  Training acc: 40.99%.
[ Tue Jun 20 03:18:45 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:18:45 2023 ] Eval epoch: 27
[ Tue Jun 20 03:18:46 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:18:46 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:18:46 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:18:46 2023 ] Training epoch: 28
[ Tue Jun 20 03:18:48 2023 ] 	Training loss: nan.  Training acc: 40.53%.
[ Tue Jun 20 03:18:48 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:18:48 2023 ] Eval epoch: 28
[ Tue Jun 20 03:18:48 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:18:48 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:18:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:18:48 2023 ] Training epoch: 29
[ Tue Jun 20 03:18:51 2023 ] 	Training loss: nan.  Training acc: 40.90%.
[ Tue Jun 20 03:18:51 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 20 03:18:51 2023 ] Eval epoch: 29
[ Tue Jun 20 03:18:52 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:18:52 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:18:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:18:52 2023 ] Training epoch: 30
[ Tue Jun 20 03:18:54 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:18:54 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 20 03:18:54 2023 ] Eval epoch: 30
[ Tue Jun 20 03:18:55 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:18:55 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:18:55 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:18:55 2023 ] Training epoch: 31
[ Tue Jun 20 03:19:30 2023 ] using warm up, epoch: 5
[ Tue Jun 20 03:19:32 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 03:19:32 2023 ] # Parameters: 1538958
[ Tue Jun 20 03:19:32 2023 ] Training epoch: 1
[ Tue Jun 20 03:19:48 2023 ] using warm up, epoch: 5
[ Tue Jun 20 03:19:50 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 03:19:50 2023 ] # Parameters: 1538958
[ Tue Jun 20 03:19:50 2023 ] Training epoch: 1
[ Tue Jun 20 03:20:18 2023 ] using warm up, epoch: 5
[ Tue Jun 20 03:20:20 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 03:20:20 2023 ] # Parameters: 1538958
[ Tue Jun 20 03:20:20 2023 ] Training epoch: 1
[ Tue Jun 20 03:20:25 2023 ] 	Training loss: nan.  Training acc: 39.43%.
[ Tue Jun 20 03:20:25 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Tue Jun 20 03:20:25 2023 ] Eval epoch: 1
[ Tue Jun 20 03:20:25 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:20:25 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:20:25 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:20:25 2023 ] Training epoch: 2
[ Tue Jun 20 03:20:28 2023 ] 	Training loss: nan.  Training acc: 41.08%.
[ Tue Jun 20 03:20:28 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:20:28 2023 ] Eval epoch: 2
[ Tue Jun 20 03:20:28 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:20:28 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:20:28 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:20:28 2023 ] Training epoch: 3
[ Tue Jun 20 03:20:30 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:20:30 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 03:20:30 2023 ] Eval epoch: 3
[ Tue Jun 20 03:20:31 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:20:31 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:20:31 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:20:31 2023 ] Training epoch: 4
[ Tue Jun 20 03:20:33 2023 ] 	Training loss: nan.  Training acc: 40.17%.
[ Tue Jun 20 03:20:33 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:20:33 2023 ] Eval epoch: 4
[ Tue Jun 20 03:20:33 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:20:33 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:20:33 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:20:33 2023 ] Training epoch: 5
[ Tue Jun 20 03:20:35 2023 ] 	Training loss: nan.  Training acc: 40.81%.
[ Tue Jun 20 03:20:35 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 20 03:20:35 2023 ] Eval epoch: 5
[ Tue Jun 20 03:20:36 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:20:36 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:20:36 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:20:36 2023 ] Training epoch: 6
[ Tue Jun 20 03:20:38 2023 ] 	Training loss: nan.  Training acc: 40.99%.
[ Tue Jun 20 03:20:38 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 20 03:20:38 2023 ] Eval epoch: 6
[ Tue Jun 20 03:20:39 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:20:39 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:20:39 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:20:39 2023 ] Training epoch: 7
[ Tue Jun 20 03:20:41 2023 ] 	Training loss: nan.  Training acc: 40.99%.
[ Tue Jun 20 03:20:41 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:20:41 2023 ] Eval epoch: 7
[ Tue Jun 20 03:20:41 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:20:41 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:20:41 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:20:41 2023 ] Training epoch: 8
[ Tue Jun 20 03:20:43 2023 ] 	Training loss: nan.  Training acc: 41.18%.
[ Tue Jun 20 03:20:43 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:20:43 2023 ] Eval epoch: 8
[ Tue Jun 20 03:20:44 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:20:44 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:20:44 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:20:44 2023 ] Training epoch: 9
[ Tue Jun 20 03:20:46 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:20:46 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:20:46 2023 ] Eval epoch: 9
[ Tue Jun 20 03:20:46 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:20:46 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:20:46 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:20:46 2023 ] Training epoch: 10
[ Tue Jun 20 03:20:48 2023 ] 	Training loss: nan.  Training acc: 41.36%.
[ Tue Jun 20 03:20:48 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:20:48 2023 ] Eval epoch: 10
[ Tue Jun 20 03:20:49 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:20:49 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:20:49 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:20:49 2023 ] Training epoch: 11
[ Tue Jun 20 03:20:51 2023 ] 	Training loss: nan.  Training acc: 40.72%.
[ Tue Jun 20 03:20:51 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 20 03:20:51 2023 ] Eval epoch: 11
[ Tue Jun 20 03:20:51 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:20:51 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:20:51 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:20:51 2023 ] Training epoch: 12
[ Tue Jun 20 03:20:53 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:20:53 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 20 03:20:53 2023 ] Eval epoch: 12
[ Tue Jun 20 03:20:54 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:20:54 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:20:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:20:54 2023 ] Training epoch: 13
[ Tue Jun 20 03:20:56 2023 ] 	Training loss: nan.  Training acc: 40.35%.
[ Tue Jun 20 03:20:56 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:20:56 2023 ] Eval epoch: 13
[ Tue Jun 20 03:20:57 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:20:57 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:20:57 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:20:57 2023 ] Training epoch: 14
[ Tue Jun 20 03:24:47 2023 ] using warm up, epoch: 5
[ Tue Jun 20 03:24:49 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 03:24:49 2023 ] # Parameters: 1538958
[ Tue Jun 20 03:24:49 2023 ] Training epoch: 1
[ Tue Jun 20 03:24:54 2023 ] 	Training loss: 90.8452.  Training acc: 35.29%.
[ Tue Jun 20 03:24:54 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 20 03:24:54 2023 ] Eval epoch: 1
[ Tue Jun 20 03:24:55 2023 ] 	Mean test loss of 625 batches: 596.963617.
[ Tue Jun 20 03:24:55 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:24:55 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:24:55 2023 ] Training epoch: 2
[ Tue Jun 20 03:24:57 2023 ] 	Training loss: 8.4328.  Training acc: 35.75%.
[ Tue Jun 20 03:24:57 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:24:57 2023 ] Eval epoch: 2
[ Tue Jun 20 03:24:57 2023 ] 	Mean test loss of 625 batches: 3.396972.
[ Tue Jun 20 03:24:57 2023 ] 	Top1: 31.58%
[ Tue Jun 20 03:24:57 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:24:57 2023 ] Training epoch: 3
[ Tue Jun 20 03:24:59 2023 ] 	Training loss: 6.4444.  Training acc: 47.06%.
[ Tue Jun 20 03:24:59 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Tue Jun 20 03:24:59 2023 ] Eval epoch: 3
[ Tue Jun 20 03:25:00 2023 ] 	Mean test loss of 625 batches: 4.547943.
[ Tue Jun 20 03:25:00 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:25:00 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:00 2023 ] Training epoch: 4
[ Tue Jun 20 03:25:02 2023 ] 	Training loss: 4.3917.  Training acc: 56.25%.
[ Tue Jun 20 03:25:02 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:25:02 2023 ] Eval epoch: 4
[ Tue Jun 20 03:25:02 2023 ] 	Mean test loss of 625 batches: 3.329051.
[ Tue Jun 20 03:25:02 2023 ] 	Top1: 63.16%
[ Tue Jun 20 03:25:02 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:02 2023 ] Training epoch: 5
[ Tue Jun 20 03:25:04 2023 ] 	Training loss: 3.5840.  Training acc: 56.99%.
[ Tue Jun 20 03:25:04 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:25:04 2023 ] Eval epoch: 5
[ Tue Jun 20 03:25:04 2023 ] 	Mean test loss of 625 batches: 6.341265.
[ Tue Jun 20 03:25:04 2023 ] 	Top1: 31.58%
[ Tue Jun 20 03:25:04 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:04 2023 ] Training epoch: 6
[ Tue Jun 20 03:25:06 2023 ] 	Training loss: 2.8041.  Training acc: 54.41%.
[ Tue Jun 20 03:25:06 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 20 03:25:06 2023 ] Eval epoch: 6
[ Tue Jun 20 03:25:07 2023 ] 	Mean test loss of 625 batches: 3.929557.
[ Tue Jun 20 03:25:07 2023 ] 	Top1: 31.58%
[ Tue Jun 20 03:25:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:07 2023 ] Training epoch: 7
[ Tue Jun 20 03:25:09 2023 ] 	Training loss: 2.4112.  Training acc: 53.31%.
[ Tue Jun 20 03:25:09 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 20 03:25:09 2023 ] Eval epoch: 7
[ Tue Jun 20 03:25:09 2023 ] 	Mean test loss of 625 batches: 6.575396.
[ Tue Jun 20 03:25:09 2023 ] 	Top1: 47.37%
[ Tue Jun 20 03:25:09 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:09 2023 ] Training epoch: 8
[ Tue Jun 20 03:25:11 2023 ] 	Training loss: 1.4084.  Training acc: 61.49%.
[ Tue Jun 20 03:25:11 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:25:11 2023 ] Eval epoch: 8
[ Tue Jun 20 03:25:12 2023 ] 	Mean test loss of 625 batches: 3.897252.
[ Tue Jun 20 03:25:12 2023 ] 	Top1: 38.60%
[ Tue Jun 20 03:25:12 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:12 2023 ] Training epoch: 9
[ Tue Jun 20 03:25:14 2023 ] 	Training loss: 1.4368.  Training acc: 61.31%.
[ Tue Jun 20 03:25:14 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:25:14 2023 ] Eval epoch: 9
[ Tue Jun 20 03:25:14 2023 ] 	Mean test loss of 625 batches: 1.519683.
[ Tue Jun 20 03:25:14 2023 ] 	Top1: 35.09%
[ Tue Jun 20 03:25:14 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:14 2023 ] Training epoch: 10
[ Tue Jun 20 03:25:16 2023 ] 	Training loss: 1.3398.  Training acc: 59.74%.
[ Tue Jun 20 03:25:16 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:25:16 2023 ] Eval epoch: 10
[ Tue Jun 20 03:25:17 2023 ] 	Mean test loss of 625 batches: 0.901070.
[ Tue Jun 20 03:25:17 2023 ] 	Top1: 64.91%
[ Tue Jun 20 03:25:17 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:17 2023 ] Training epoch: 11
[ Tue Jun 20 03:25:19 2023 ] 	Training loss: 1.0634.  Training acc: 63.69%.
[ Tue Jun 20 03:25:19 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:25:19 2023 ] Eval epoch: 11
[ Tue Jun 20 03:25:19 2023 ] 	Mean test loss of 625 batches: 0.787517.
[ Tue Jun 20 03:25:19 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:25:19 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:19 2023 ] Training epoch: 12
[ Tue Jun 20 03:25:21 2023 ] 	Training loss: 0.9282.  Training acc: 63.33%.
[ Tue Jun 20 03:25:21 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:25:21 2023 ] Eval epoch: 12
[ Tue Jun 20 03:25:22 2023 ] 	Mean test loss of 625 batches: 0.900639.
[ Tue Jun 20 03:25:22 2023 ] 	Top1: 68.42%
[ Tue Jun 20 03:25:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:22 2023 ] Training epoch: 13
[ Tue Jun 20 03:25:24 2023 ] 	Training loss: 1.4173.  Training acc: 58.82%.
[ Tue Jun 20 03:25:24 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 20 03:25:24 2023 ] Eval epoch: 13
[ Tue Jun 20 03:25:24 2023 ] 	Mean test loss of 625 batches: 5.001264.
[ Tue Jun 20 03:25:24 2023 ] 	Top1: 49.12%
[ Tue Jun 20 03:25:24 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:24 2023 ] Training epoch: 14
[ Tue Jun 20 03:25:26 2023 ] 	Training loss: 0.8677.  Training acc: 67.83%.
[ Tue Jun 20 03:25:26 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:25:26 2023 ] Eval epoch: 14
[ Tue Jun 20 03:25:27 2023 ] 	Mean test loss of 625 batches: 0.835614.
[ Tue Jun 20 03:25:27 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:25:27 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:27 2023 ] Training epoch: 15
[ Tue Jun 20 03:25:29 2023 ] 	Training loss: 0.6734.  Training acc: 78.68%.
[ Tue Jun 20 03:25:29 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:25:29 2023 ] Eval epoch: 15
[ Tue Jun 20 03:25:29 2023 ] 	Mean test loss of 625 batches: 0.756182.
[ Tue Jun 20 03:25:29 2023 ] 	Top1: 85.96%
[ Tue Jun 20 03:25:29 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:29 2023 ] Training epoch: 16
[ Tue Jun 20 03:25:31 2023 ] 	Training loss: 0.6258.  Training acc: 87.96%.
[ Tue Jun 20 03:25:31 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:25:31 2023 ] Eval epoch: 16
[ Tue Jun 20 03:25:32 2023 ] 	Mean test loss of 625 batches: 1.574020.
[ Tue Jun 20 03:25:32 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:25:32 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:32 2023 ] Training epoch: 17
[ Tue Jun 20 03:25:34 2023 ] 	Training loss: 0.4896.  Training acc: 93.84%.
[ Tue Jun 20 03:25:34 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:25:34 2023 ] Eval epoch: 17
[ Tue Jun 20 03:25:34 2023 ] 	Mean test loss of 625 batches: 0.780990.
[ Tue Jun 20 03:25:34 2023 ] 	Top1: 68.42%
[ Tue Jun 20 03:25:34 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:34 2023 ] Training epoch: 18
[ Tue Jun 20 03:25:36 2023 ] 	Training loss: 0.4277.  Training acc: 95.68%.
[ Tue Jun 20 03:25:36 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:25:36 2023 ] Eval epoch: 18
[ Tue Jun 20 03:25:37 2023 ] 	Mean test loss of 625 batches: 0.815292.
[ Tue Jun 20 03:25:37 2023 ] 	Top1: 66.67%
[ Tue Jun 20 03:25:37 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:37 2023 ] Training epoch: 19
[ Tue Jun 20 03:25:39 2023 ] 	Training loss: 0.3975.  Training acc: 96.60%.
[ Tue Jun 20 03:25:39 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 20 03:25:39 2023 ] Eval epoch: 19
[ Tue Jun 20 03:25:39 2023 ] 	Mean test loss of 625 batches: 0.768795.
[ Tue Jun 20 03:25:39 2023 ] 	Top1: 66.67%
[ Tue Jun 20 03:25:39 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:39 2023 ] Training epoch: 20
[ Tue Jun 20 03:25:41 2023 ] 	Training loss: 0.3878.  Training acc: 97.89%.
[ Tue Jun 20 03:25:41 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 20 03:25:41 2023 ] Eval epoch: 20
[ Tue Jun 20 03:25:42 2023 ] 	Mean test loss of 625 batches: 0.380908.
[ Tue Jun 20 03:25:42 2023 ] 	Top1: 98.25%
[ Tue Jun 20 03:25:42 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:42 2023 ] Training epoch: 21
[ Tue Jun 20 03:25:44 2023 ] 	Training loss: 0.3651.  Training acc: 98.99%.
[ Tue Jun 20 03:25:44 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:25:44 2023 ] Eval epoch: 21
[ Tue Jun 20 03:25:44 2023 ] 	Mean test loss of 625 batches: 0.472433.
[ Tue Jun 20 03:25:44 2023 ] 	Top1: 94.74%
[ Tue Jun 20 03:25:44 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:44 2023 ] Training epoch: 22
[ Tue Jun 20 03:25:46 2023 ] 	Training loss: 0.3927.  Training acc: 98.35%.
[ Tue Jun 20 03:25:46 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:25:46 2023 ] Eval epoch: 22
[ Tue Jun 20 03:25:47 2023 ] 	Mean test loss of 625 batches: 0.951761.
[ Tue Jun 20 03:25:47 2023 ] 	Top1: 52.63%
[ Tue Jun 20 03:25:47 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:47 2023 ] Training epoch: 23
[ Tue Jun 20 03:25:49 2023 ] 	Training loss: 0.6259.  Training acc: 92.56%.
[ Tue Jun 20 03:25:49 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:25:49 2023 ] Eval epoch: 23
[ Tue Jun 20 03:25:49 2023 ] 	Mean test loss of 625 batches: 1.724724.
[ Tue Jun 20 03:25:49 2023 ] 	Top1: 68.42%
[ Tue Jun 20 03:25:49 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:49 2023 ] Training epoch: 24
[ Tue Jun 20 03:25:51 2023 ] 	Training loss: 0.7380.  Training acc: 86.95%.
[ Tue Jun 20 03:25:51 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 20 03:25:51 2023 ] Eval epoch: 24
[ Tue Jun 20 03:25:52 2023 ] 	Mean test loss of 625 batches: 0.413545.
[ Tue Jun 20 03:25:52 2023 ] 	Top1: 98.25%
[ Tue Jun 20 03:25:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:52 2023 ] Training epoch: 25
[ Tue Jun 20 03:25:54 2023 ] 	Training loss: 0.4555.  Training acc: 94.94%.
[ Tue Jun 20 03:25:54 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:25:54 2023 ] Eval epoch: 25
[ Tue Jun 20 03:25:54 2023 ] 	Mean test loss of 625 batches: 0.416549.
[ Tue Jun 20 03:25:54 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:25:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:54 2023 ] Training epoch: 26
[ Tue Jun 20 03:25:56 2023 ] 	Training loss: 0.4013.  Training acc: 96.42%.
[ Tue Jun 20 03:25:56 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:25:56 2023 ] Eval epoch: 26
[ Tue Jun 20 03:25:57 2023 ] 	Mean test loss of 625 batches: 0.317841.
[ Tue Jun 20 03:25:57 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:25:57 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:57 2023 ] Training epoch: 27
[ Tue Jun 20 03:25:59 2023 ] 	Training loss: 0.3699.  Training acc: 98.25%.
[ Tue Jun 20 03:25:59 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:25:59 2023 ] Eval epoch: 27
[ Tue Jun 20 03:25:59 2023 ] 	Mean test loss of 625 batches: 0.378524.
[ Tue Jun 20 03:25:59 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:25:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:25:59 2023 ] Training epoch: 28
[ Tue Jun 20 03:26:02 2023 ] 	Training loss: 0.3722.  Training acc: 98.35%.
[ Tue Jun 20 03:26:02 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:26:02 2023 ] Eval epoch: 28
[ Tue Jun 20 03:26:02 2023 ] 	Mean test loss of 625 batches: 0.419011.
[ Tue Jun 20 03:26:02 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:26:02 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:02 2023 ] Training epoch: 29
[ Tue Jun 20 03:26:04 2023 ] 	Training loss: 0.3674.  Training acc: 97.61%.
[ Tue Jun 20 03:26:04 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:26:04 2023 ] Eval epoch: 29
[ Tue Jun 20 03:26:05 2023 ] 	Mean test loss of 625 batches: 0.353699.
[ Tue Jun 20 03:26:05 2023 ] 	Top1: 98.25%
[ Tue Jun 20 03:26:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:05 2023 ] Training epoch: 30
[ Tue Jun 20 03:26:07 2023 ] 	Training loss: 0.3548.  Training acc: 98.81%.
[ Tue Jun 20 03:26:07 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:26:07 2023 ] Eval epoch: 30
[ Tue Jun 20 03:26:07 2023 ] 	Mean test loss of 625 batches: 0.447781.
[ Tue Jun 20 03:26:07 2023 ] 	Top1: 98.25%
[ Tue Jun 20 03:26:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:07 2023 ] Training epoch: 31
[ Tue Jun 20 03:26:09 2023 ] 	Training loss: 0.3277.  Training acc: 99.72%.
[ Tue Jun 20 03:26:09 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 20 03:26:09 2023 ] Eval epoch: 31
[ Tue Jun 20 03:26:09 2023 ] 	Mean test loss of 625 batches: 0.427236.
[ Tue Jun 20 03:26:09 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:26:09 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:09 2023 ] Training epoch: 32
[ Tue Jun 20 03:26:12 2023 ] 	Training loss: 0.3293.  Training acc: 99.63%.
[ Tue Jun 20 03:26:12 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Tue Jun 20 03:26:12 2023 ] Eval epoch: 32
[ Tue Jun 20 03:26:12 2023 ] 	Mean test loss of 625 batches: 0.479142.
[ Tue Jun 20 03:26:12 2023 ] 	Top1: 98.25%
[ Tue Jun 20 03:26:12 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:12 2023 ] Training epoch: 33
[ Tue Jun 20 03:26:14 2023 ] 	Training loss: 0.3271.  Training acc: 99.45%.
[ Tue Jun 20 03:26:14 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:26:14 2023 ] Eval epoch: 33
[ Tue Jun 20 03:26:15 2023 ] 	Mean test loss of 625 batches: 0.517457.
[ Tue Jun 20 03:26:15 2023 ] 	Top1: 91.23%
[ Tue Jun 20 03:26:15 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:15 2023 ] Training epoch: 34
[ Tue Jun 20 03:26:17 2023 ] 	Training loss: 0.3336.  Training acc: 99.45%.
[ Tue Jun 20 03:26:17 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:26:17 2023 ] Eval epoch: 34
[ Tue Jun 20 03:26:17 2023 ] 	Mean test loss of 625 batches: 0.399620.
[ Tue Jun 20 03:26:17 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:26:17 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:17 2023 ] Training epoch: 35
[ Tue Jun 20 03:26:19 2023 ] 	Training loss: 0.3457.  Training acc: 99.54%.
[ Tue Jun 20 03:26:19 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:26:19 2023 ] Eval epoch: 35
[ Tue Jun 20 03:26:20 2023 ] 	Mean test loss of 625 batches: 0.344510.
[ Tue Jun 20 03:26:20 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:26:20 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:20 2023 ] Training epoch: 36
[ Tue Jun 20 03:26:22 2023 ] 	Training loss: 0.3278.  Training acc: 99.45%.
[ Tue Jun 20 03:26:22 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:26:22 2023 ] Eval epoch: 36
[ Tue Jun 20 03:26:22 2023 ] 	Mean test loss of 625 batches: 0.695435.
[ Tue Jun 20 03:26:22 2023 ] 	Top1: 61.40%
[ Tue Jun 20 03:26:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:22 2023 ] Training epoch: 37
[ Tue Jun 20 03:26:25 2023 ] 	Training loss: 0.3327.  Training acc: 99.63%.
[ Tue Jun 20 03:26:25 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:26:25 2023 ] Eval epoch: 37
[ Tue Jun 20 03:26:25 2023 ] 	Mean test loss of 625 batches: 0.367616.
[ Tue Jun 20 03:26:25 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:26:25 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:25 2023 ] Training epoch: 38
[ Tue Jun 20 03:26:27 2023 ] 	Training loss: 0.3240.  Training acc: 99.82%.
[ Tue Jun 20 03:26:27 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:26:27 2023 ] Eval epoch: 38
[ Tue Jun 20 03:26:28 2023 ] 	Mean test loss of 625 batches: 0.730429.
[ Tue Jun 20 03:26:28 2023 ] 	Top1: 61.40%
[ Tue Jun 20 03:26:28 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:28 2023 ] Training epoch: 39
[ Tue Jun 20 03:26:30 2023 ] 	Training loss: 0.3272.  Training acc: 99.82%.
[ Tue Jun 20 03:26:30 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:26:30 2023 ] Eval epoch: 39
[ Tue Jun 20 03:26:30 2023 ] 	Mean test loss of 625 batches: 0.384737.
[ Tue Jun 20 03:26:30 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:26:30 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:30 2023 ] Training epoch: 40
[ Tue Jun 20 03:26:32 2023 ] 	Training loss: 0.3269.  Training acc: 99.63%.
[ Tue Jun 20 03:26:32 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:26:32 2023 ] Eval epoch: 40
[ Tue Jun 20 03:26:33 2023 ] 	Mean test loss of 625 batches: 0.334659.
[ Tue Jun 20 03:26:33 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:26:33 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:33 2023 ] Training epoch: 41
[ Tue Jun 20 03:26:35 2023 ] 	Training loss: 0.3296.  Training acc: 99.72%.
[ Tue Jun 20 03:26:35 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:26:35 2023 ] Eval epoch: 41
[ Tue Jun 20 03:26:35 2023 ] 	Mean test loss of 625 batches: 0.593547.
[ Tue Jun 20 03:26:35 2023 ] 	Top1: 68.42%
[ Tue Jun 20 03:26:35 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:35 2023 ] Training epoch: 42
[ Tue Jun 20 03:26:37 2023 ] 	Training loss: 0.3300.  Training acc: 99.45%.
[ Tue Jun 20 03:26:37 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:26:37 2023 ] Eval epoch: 42
[ Tue Jun 20 03:26:38 2023 ] 	Mean test loss of 625 batches: 0.376362.
[ Tue Jun 20 03:26:38 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:26:38 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:38 2023 ] Training epoch: 43
[ Tue Jun 20 03:26:40 2023 ] 	Training loss: 0.3434.  Training acc: 99.17%.
[ Tue Jun 20 03:26:40 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:26:40 2023 ] Eval epoch: 43
[ Tue Jun 20 03:26:40 2023 ] 	Mean test loss of 625 batches: 0.321526.
[ Tue Jun 20 03:26:40 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:26:40 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:40 2023 ] Training epoch: 44
[ Tue Jun 20 03:26:42 2023 ] 	Training loss: 0.3428.  Training acc: 99.82%.
[ Tue Jun 20 03:26:42 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:26:42 2023 ] Eval epoch: 44
[ Tue Jun 20 03:26:43 2023 ] 	Mean test loss of 625 batches: 0.346423.
[ Tue Jun 20 03:26:43 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:26:43 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:43 2023 ] Training epoch: 45
[ Tue Jun 20 03:26:45 2023 ] 	Training loss: 0.3399.  Training acc: 99.54%.
[ Tue Jun 20 03:26:45 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:26:45 2023 ] Eval epoch: 45
[ Tue Jun 20 03:26:45 2023 ] 	Mean test loss of 625 batches: 0.299597.
[ Tue Jun 20 03:26:45 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:26:45 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:45 2023 ] Training epoch: 46
[ Tue Jun 20 03:26:47 2023 ] 	Training loss: 0.3208.  Training acc: 99.82%.
[ Tue Jun 20 03:26:47 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:26:47 2023 ] Eval epoch: 46
[ Tue Jun 20 03:26:48 2023 ] 	Mean test loss of 625 batches: 0.499642.
[ Tue Jun 20 03:26:48 2023 ] 	Top1: 96.49%
[ Tue Jun 20 03:26:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:48 2023 ] Training epoch: 47
[ Tue Jun 20 03:26:50 2023 ] 	Training loss: 0.3152.  Training acc: 99.82%.
[ Tue Jun 20 03:26:50 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:26:50 2023 ] Eval epoch: 47
[ Tue Jun 20 03:26:50 2023 ] 	Mean test loss of 625 batches: 0.317237.
[ Tue Jun 20 03:26:50 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:26:50 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:50 2023 ] Training epoch: 48
[ Tue Jun 20 03:26:52 2023 ] 	Training loss: 0.3213.  Training acc: 99.45%.
[ Tue Jun 20 03:26:52 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:26:52 2023 ] Eval epoch: 48
[ Tue Jun 20 03:26:53 2023 ] 	Mean test loss of 625 batches: 0.406442.
[ Tue Jun 20 03:26:53 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:26:53 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:53 2023 ] Training epoch: 49
[ Tue Jun 20 03:26:55 2023 ] 	Training loss: 0.3336.  Training acc: 99.17%.
[ Tue Jun 20 03:26:55 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:26:55 2023 ] Eval epoch: 49
[ Tue Jun 20 03:26:55 2023 ] 	Mean test loss of 625 batches: 0.311758.
[ Tue Jun 20 03:26:55 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:26:55 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:55 2023 ] Training epoch: 50
[ Tue Jun 20 03:26:57 2023 ] 	Training loss: 0.3344.  Training acc: 99.63%.
[ Tue Jun 20 03:26:57 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 20 03:26:57 2023 ] Eval epoch: 50
[ Tue Jun 20 03:26:58 2023 ] 	Mean test loss of 625 batches: 0.306764.
[ Tue Jun 20 03:26:58 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:26:58 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:26:58 2023 ] Training epoch: 51
[ Tue Jun 20 03:27:00 2023 ] 	Training loss: 0.3407.  Training acc: 98.90%.
[ Tue Jun 20 03:27:00 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:27:00 2023 ] Eval epoch: 51
[ Tue Jun 20 03:27:00 2023 ] 	Mean test loss of 625 batches: 0.583873.
[ Tue Jun 20 03:27:00 2023 ] 	Top1: 87.72%
[ Tue Jun 20 03:27:00 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:00 2023 ] Training epoch: 52
[ Tue Jun 20 03:27:02 2023 ] 	Training loss: 0.3310.  Training acc: 99.08%.
[ Tue Jun 20 03:27:02 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 20 03:27:02 2023 ] Eval epoch: 52
[ Tue Jun 20 03:27:03 2023 ] 	Mean test loss of 625 batches: 0.302164.
[ Tue Jun 20 03:27:03 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:27:03 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:03 2023 ] Training epoch: 53
[ Tue Jun 20 03:27:05 2023 ] 	Training loss: 0.3372.  Training acc: 99.54%.
[ Tue Jun 20 03:27:05 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:27:05 2023 ] Eval epoch: 53
[ Tue Jun 20 03:27:05 2023 ] 	Mean test loss of 625 batches: 0.305226.
[ Tue Jun 20 03:27:05 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:27:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:05 2023 ] Training epoch: 54
[ Tue Jun 20 03:27:07 2023 ] 	Training loss: 0.3363.  Training acc: 99.17%.
[ Tue Jun 20 03:27:07 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:27:07 2023 ] Eval epoch: 54
[ Tue Jun 20 03:27:08 2023 ] 	Mean test loss of 625 batches: 0.370877.
[ Tue Jun 20 03:27:08 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:27:08 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:08 2023 ] Training epoch: 55
[ Tue Jun 20 03:27:10 2023 ] 	Training loss: 0.3165.  Training acc: 99.91%.
[ Tue Jun 20 03:27:10 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:27:10 2023 ] Eval epoch: 55
[ Tue Jun 20 03:27:10 2023 ] 	Mean test loss of 625 batches: 0.373124.
[ Tue Jun 20 03:27:10 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:27:10 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:10 2023 ] Training epoch: 56
[ Tue Jun 20 03:27:12 2023 ] 	Training loss: 0.3129.  Training acc: 99.82%.
[ Tue Jun 20 03:27:12 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:27:12 2023 ] Eval epoch: 56
[ Tue Jun 20 03:27:13 2023 ] 	Mean test loss of 625 batches: 0.666718.
[ Tue Jun 20 03:27:13 2023 ] 	Top1: 61.40%
[ Tue Jun 20 03:27:13 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:13 2023 ] Training epoch: 57
[ Tue Jun 20 03:27:15 2023 ] 	Training loss: 0.3193.  Training acc: 99.82%.
[ Tue Jun 20 03:27:15 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 20 03:27:15 2023 ] Eval epoch: 57
[ Tue Jun 20 03:27:15 2023 ] 	Mean test loss of 625 batches: 0.360341.
[ Tue Jun 20 03:27:15 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:27:15 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:15 2023 ] Training epoch: 58
[ Tue Jun 20 03:27:17 2023 ] 	Training loss: 0.3242.  Training acc: 99.82%.
[ Tue Jun 20 03:27:17 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:27:17 2023 ] Eval epoch: 58
[ Tue Jun 20 03:27:18 2023 ] 	Mean test loss of 625 batches: 0.413698.
[ Tue Jun 20 03:27:18 2023 ] 	Top1: 98.25%
[ Tue Jun 20 03:27:18 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:18 2023 ] Training epoch: 59
[ Tue Jun 20 03:27:20 2023 ] 	Training loss: 0.3302.  Training acc: 99.72%.
[ Tue Jun 20 03:27:20 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:27:20 2023 ] Eval epoch: 59
[ Tue Jun 20 03:27:20 2023 ] 	Mean test loss of 625 batches: 0.450296.
[ Tue Jun 20 03:27:20 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:27:20 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:20 2023 ] Training epoch: 60
[ Tue Jun 20 03:27:22 2023 ] 	Training loss: 0.3402.  Training acc: 99.08%.
[ Tue Jun 20 03:27:22 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:27:22 2023 ] Eval epoch: 60
[ Tue Jun 20 03:27:23 2023 ] 	Mean test loss of 625 batches: 0.367648.
[ Tue Jun 20 03:27:23 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:27:23 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:23 2023 ] Training epoch: 61
[ Tue Jun 20 03:27:25 2023 ] 	Training loss: 0.3324.  Training acc: 99.63%.
[ Tue Jun 20 03:27:25 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 20 03:27:25 2023 ] Eval epoch: 61
[ Tue Jun 20 03:27:25 2023 ] 	Mean test loss of 625 batches: 0.611640.
[ Tue Jun 20 03:27:25 2023 ] 	Top1: 89.47%
[ Tue Jun 20 03:27:25 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:25 2023 ] Training epoch: 62
[ Tue Jun 20 03:27:27 2023 ] 	Training loss: 0.3206.  Training acc: 99.63%.
[ Tue Jun 20 03:27:27 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:27:27 2023 ] Eval epoch: 62
[ Tue Jun 20 03:27:28 2023 ] 	Mean test loss of 625 batches: 0.369041.
[ Tue Jun 20 03:27:28 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:27:28 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:28 2023 ] Training epoch: 63
[ Tue Jun 20 03:27:30 2023 ] 	Training loss: 0.3319.  Training acc: 99.17%.
[ Tue Jun 20 03:27:30 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:27:30 2023 ] Eval epoch: 63
[ Tue Jun 20 03:27:30 2023 ] 	Mean test loss of 625 batches: 0.301852.
[ Tue Jun 20 03:27:30 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:27:30 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:30 2023 ] Training epoch: 64
[ Tue Jun 20 03:27:32 2023 ] 	Training loss: 0.3208.  Training acc: 99.63%.
[ Tue Jun 20 03:27:32 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 20 03:27:32 2023 ] Eval epoch: 64
[ Tue Jun 20 03:27:32 2023 ] 	Mean test loss of 625 batches: 0.407701.
[ Tue Jun 20 03:27:32 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:27:32 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:32 2023 ] Training epoch: 65
[ Tue Jun 20 03:27:34 2023 ] 	Training loss: 0.3217.  Training acc: 99.63%.
[ Tue Jun 20 03:27:34 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:27:34 2023 ] Eval epoch: 65
[ Tue Jun 20 03:27:35 2023 ] 	Mean test loss of 625 batches: 0.756577.
[ Tue Jun 20 03:27:35 2023 ] 	Top1: 61.40%
[ Tue Jun 20 03:27:35 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:35 2023 ] Training epoch: 66
[ Tue Jun 20 03:27:37 2023 ] 	Training loss: 0.3448.  Training acc: 98.99%.
[ Tue Jun 20 03:27:37 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:27:37 2023 ] Eval epoch: 66
[ Tue Jun 20 03:27:37 2023 ] 	Mean test loss of 625 batches: 0.330738.
[ Tue Jun 20 03:27:37 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:27:37 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:37 2023 ] Training epoch: 67
[ Tue Jun 20 03:27:39 2023 ] 	Training loss: 0.3380.  Training acc: 99.72%.
[ Tue Jun 20 03:27:39 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:27:39 2023 ] Eval epoch: 67
[ Tue Jun 20 03:27:40 2023 ] 	Mean test loss of 625 batches: 0.375969.
[ Tue Jun 20 03:27:40 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:27:40 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:40 2023 ] Training epoch: 68
[ Tue Jun 20 03:27:42 2023 ] 	Training loss: 0.3214.  Training acc: 99.72%.
[ Tue Jun 20 03:27:42 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:27:42 2023 ] Eval epoch: 68
[ Tue Jun 20 03:27:42 2023 ] 	Mean test loss of 625 batches: 0.342996.
[ Tue Jun 20 03:27:42 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:27:42 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:42 2023 ] Training epoch: 69
[ Tue Jun 20 03:27:44 2023 ] 	Training loss: 0.3442.  Training acc: 99.08%.
[ Tue Jun 20 03:27:44 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:27:44 2023 ] Eval epoch: 69
[ Tue Jun 20 03:27:45 2023 ] 	Mean test loss of 625 batches: 0.466607.
[ Tue Jun 20 03:27:45 2023 ] 	Top1: 98.25%
[ Tue Jun 20 03:27:45 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:45 2023 ] Training epoch: 70
[ Tue Jun 20 03:27:47 2023 ] 	Training loss: 0.3322.  Training acc: 99.17%.
[ Tue Jun 20 03:27:47 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:27:47 2023 ] Eval epoch: 70
[ Tue Jun 20 03:27:47 2023 ] 	Mean test loss of 625 batches: 0.314657.
[ Tue Jun 20 03:27:47 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:27:47 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:47 2023 ] Training epoch: 71
[ Tue Jun 20 03:27:50 2023 ] 	Training loss: 0.3386.  Training acc: 98.99%.
[ Tue Jun 20 03:27:50 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 20 03:27:50 2023 ] Eval epoch: 71
[ Tue Jun 20 03:27:50 2023 ] 	Mean test loss of 625 batches: 0.331666.
[ Tue Jun 20 03:27:50 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:27:50 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:50 2023 ] Training epoch: 72
[ Tue Jun 20 03:27:52 2023 ] 	Training loss: 0.3857.  Training acc: 98.07%.
[ Tue Jun 20 03:27:52 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:27:52 2023 ] Eval epoch: 72
[ Tue Jun 20 03:27:52 2023 ] 	Mean test loss of 625 batches: 0.500150.
[ Tue Jun 20 03:27:52 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:27:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:52 2023 ] Training epoch: 73
[ Tue Jun 20 03:27:54 2023 ] 	Training loss: 0.3538.  Training acc: 99.08%.
[ Tue Jun 20 03:27:54 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:27:55 2023 ] Eval epoch: 73
[ Tue Jun 20 03:27:55 2023 ] 	Mean test loss of 625 batches: 0.300999.
[ Tue Jun 20 03:27:55 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:27:55 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:55 2023 ] Training epoch: 74
[ Tue Jun 20 03:27:57 2023 ] 	Training loss: 0.3323.  Training acc: 99.26%.
[ Tue Jun 20 03:27:57 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:27:57 2023 ] Eval epoch: 74
[ Tue Jun 20 03:27:57 2023 ] 	Mean test loss of 625 batches: 0.344889.
[ Tue Jun 20 03:27:57 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:27:57 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:27:57 2023 ] Training epoch: 75
[ Tue Jun 20 03:27:59 2023 ] 	Training loss: 0.3386.  Training acc: 99.08%.
[ Tue Jun 20 03:27:59 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:27:59 2023 ] Eval epoch: 75
[ Tue Jun 20 03:28:00 2023 ] 	Mean test loss of 625 batches: 0.410811.
[ Tue Jun 20 03:28:00 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:28:00 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:00 2023 ] Training epoch: 76
[ Tue Jun 20 03:28:02 2023 ] 	Training loss: 0.3500.  Training acc: 98.35%.
[ Tue Jun 20 03:28:02 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 20 03:28:02 2023 ] Eval epoch: 76
[ Tue Jun 20 03:28:02 2023 ] 	Mean test loss of 625 batches: 0.308987.
[ Tue Jun 20 03:28:02 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:28:02 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:02 2023 ] Training epoch: 77
[ Tue Jun 20 03:28:04 2023 ] 	Training loss: 0.3557.  Training acc: 97.98%.
[ Tue Jun 20 03:28:04 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 20 03:28:04 2023 ] Eval epoch: 77
[ Tue Jun 20 03:28:05 2023 ] 	Mean test loss of 625 batches: 2.100184.
[ Tue Jun 20 03:28:05 2023 ] 	Top1: 42.11%
[ Tue Jun 20 03:28:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:05 2023 ] Training epoch: 78
[ Tue Jun 20 03:28:07 2023 ] 	Training loss: 0.3446.  Training acc: 98.81%.
[ Tue Jun 20 03:28:07 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:28:07 2023 ] Eval epoch: 78
[ Tue Jun 20 03:28:07 2023 ] 	Mean test loss of 625 batches: 0.369962.
[ Tue Jun 20 03:28:07 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:28:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:07 2023 ] Training epoch: 79
[ Tue Jun 20 03:28:09 2023 ] 	Training loss: 0.3324.  Training acc: 98.07%.
[ Tue Jun 20 03:28:09 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 20 03:28:09 2023 ] Eval epoch: 79
[ Tue Jun 20 03:28:10 2023 ] 	Mean test loss of 625 batches: 0.328259.
[ Tue Jun 20 03:28:10 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:28:10 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:10 2023 ] Training epoch: 80
[ Tue Jun 20 03:28:12 2023 ] 	Training loss: 0.3512.  Training acc: 99.45%.
[ Tue Jun 20 03:28:12 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 20 03:28:12 2023 ] Eval epoch: 80
[ Tue Jun 20 03:28:12 2023 ] 	Mean test loss of 625 batches: 0.476547.
[ Tue Jun 20 03:28:12 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:28:12 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:12 2023 ] Training epoch: 81
[ Tue Jun 20 03:28:14 2023 ] 	Training loss: 0.3418.  Training acc: 99.17%.
[ Tue Jun 20 03:28:14 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 20 03:28:14 2023 ] Eval epoch: 81
[ Tue Jun 20 03:28:15 2023 ] 	Mean test loss of 625 batches: 0.337920.
[ Tue Jun 20 03:28:15 2023 ] 	Top1: 98.25%
[ Tue Jun 20 03:28:15 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:15 2023 ] Training epoch: 82
[ Tue Jun 20 03:28:17 2023 ] 	Training loss: 0.3280.  Training acc: 99.91%.
[ Tue Jun 20 03:28:17 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:28:17 2023 ] Eval epoch: 82
[ Tue Jun 20 03:28:17 2023 ] 	Mean test loss of 625 batches: 0.538681.
[ Tue Jun 20 03:28:17 2023 ] 	Top1: 89.47%
[ Tue Jun 20 03:28:17 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:17 2023 ] Training epoch: 83
[ Tue Jun 20 03:28:19 2023 ] 	Training loss: 0.3270.  Training acc: 99.45%.
[ Tue Jun 20 03:28:19 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:28:19 2023 ] Eval epoch: 83
[ Tue Jun 20 03:28:20 2023 ] 	Mean test loss of 625 batches: 0.314336.
[ Tue Jun 20 03:28:20 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:28:20 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:20 2023 ] Training epoch: 84
[ Tue Jun 20 03:28:22 2023 ] 	Training loss: 0.3348.  Training acc: 99.63%.
[ Tue Jun 20 03:28:22 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:28:22 2023 ] Eval epoch: 84
[ Tue Jun 20 03:28:22 2023 ] 	Mean test loss of 625 batches: 0.536373.
[ Tue Jun 20 03:28:22 2023 ] 	Top1: 94.74%
[ Tue Jun 20 03:28:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:22 2023 ] Training epoch: 85
[ Tue Jun 20 03:28:24 2023 ] 	Training loss: 0.3257.  Training acc: 99.45%.
[ Tue Jun 20 03:28:24 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:28:24 2023 ] Eval epoch: 85
[ Tue Jun 20 03:28:25 2023 ] 	Mean test loss of 625 batches: 0.325147.
[ Tue Jun 20 03:28:25 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:28:25 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:25 2023 ] Training epoch: 86
[ Tue Jun 20 03:28:27 2023 ] 	Training loss: 0.3246.  Training acc: 99.36%.
[ Tue Jun 20 03:28:27 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:28:27 2023 ] Eval epoch: 86
[ Tue Jun 20 03:28:27 2023 ] 	Mean test loss of 625 batches: 0.555889.
[ Tue Jun 20 03:28:27 2023 ] 	Top1: 75.44%
[ Tue Jun 20 03:28:27 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:27 2023 ] Training epoch: 87
[ Tue Jun 20 03:28:29 2023 ] 	Training loss: 0.3596.  Training acc: 97.79%.
[ Tue Jun 20 03:28:29 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 20 03:28:29 2023 ] Eval epoch: 87
[ Tue Jun 20 03:28:30 2023 ] 	Mean test loss of 625 batches: 0.559248.
[ Tue Jun 20 03:28:30 2023 ] 	Top1: 94.74%
[ Tue Jun 20 03:28:30 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:30 2023 ] Training epoch: 88
[ Tue Jun 20 03:28:32 2023 ] 	Training loss: 0.3612.  Training acc: 98.44%.
[ Tue Jun 20 03:28:32 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:28:32 2023 ] Eval epoch: 88
[ Tue Jun 20 03:28:32 2023 ] 	Mean test loss of 625 batches: 0.343673.
[ Tue Jun 20 03:28:32 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:28:32 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:32 2023 ] Training epoch: 89
[ Tue Jun 20 03:28:34 2023 ] 	Training loss: 0.3416.  Training acc: 98.99%.
[ Tue Jun 20 03:28:34 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:28:34 2023 ] Eval epoch: 89
[ Tue Jun 20 03:28:34 2023 ] 	Mean test loss of 625 batches: 0.459442.
[ Tue Jun 20 03:28:34 2023 ] 	Top1: 96.49%
[ Tue Jun 20 03:28:34 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:34 2023 ] Training epoch: 90
[ Tue Jun 20 03:28:36 2023 ] 	Training loss: 0.3414.  Training acc: 99.63%.
[ Tue Jun 20 03:28:36 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:28:36 2023 ] Eval epoch: 90
[ Tue Jun 20 03:28:37 2023 ] 	Mean test loss of 625 batches: 0.371743.
[ Tue Jun 20 03:28:37 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:28:37 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:37 2023 ] Training epoch: 91
[ Tue Jun 20 03:28:39 2023 ] 	Training loss: 0.3458.  Training acc: 99.08%.
[ Tue Jun 20 03:28:39 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 20 03:28:39 2023 ] Eval epoch: 91
[ Tue Jun 20 03:28:40 2023 ] 	Mean test loss of 625 batches: 0.294792.
[ Tue Jun 20 03:28:40 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:28:40 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:40 2023 ] Training epoch: 92
[ Tue Jun 20 03:28:42 2023 ] 	Training loss: 0.3073.  Training acc: 100.00%.
[ Tue Jun 20 03:28:42 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:28:42 2023 ] Eval epoch: 92
[ Tue Jun 20 03:28:42 2023 ] 	Mean test loss of 625 batches: 0.293727.
[ Tue Jun 20 03:28:42 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:28:42 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:42 2023 ] Training epoch: 93
[ Tue Jun 20 03:28:44 2023 ] 	Training loss: 0.3056.  Training acc: 100.00%.
[ Tue Jun 20 03:28:44 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:28:44 2023 ] Eval epoch: 93
[ Tue Jun 20 03:28:45 2023 ] 	Mean test loss of 625 batches: 0.293434.
[ Tue Jun 20 03:28:45 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:28:45 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:45 2023 ] Training epoch: 94
[ Tue Jun 20 03:28:47 2023 ] 	Training loss: 0.3023.  Training acc: 100.00%.
[ Tue Jun 20 03:28:47 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:28:47 2023 ] Eval epoch: 94
[ Tue Jun 20 03:28:47 2023 ] 	Mean test loss of 625 batches: 0.295762.
[ Tue Jun 20 03:28:47 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:28:47 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:47 2023 ] Training epoch: 95
[ Tue Jun 20 03:28:49 2023 ] 	Training loss: 0.3039.  Training acc: 99.91%.
[ Tue Jun 20 03:28:49 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 20 03:28:49 2023 ] Eval epoch: 95
[ Tue Jun 20 03:28:50 2023 ] 	Mean test loss of 625 batches: 0.295014.
[ Tue Jun 20 03:28:50 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:28:50 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:50 2023 ] Training epoch: 96
[ Tue Jun 20 03:28:52 2023 ] 	Training loss: 0.3044.  Training acc: 99.91%.
[ Tue Jun 20 03:28:52 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:28:52 2023 ] Eval epoch: 96
[ Tue Jun 20 03:28:52 2023 ] 	Mean test loss of 625 batches: 0.294743.
[ Tue Jun 20 03:28:52 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:28:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:52 2023 ] Training epoch: 97
[ Tue Jun 20 03:28:54 2023 ] 	Training loss: 0.3025.  Training acc: 100.00%.
[ Tue Jun 20 03:28:54 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:28:54 2023 ] Eval epoch: 97
[ Tue Jun 20 03:28:55 2023 ] 	Mean test loss of 625 batches: 0.294212.
[ Tue Jun 20 03:28:55 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:28:55 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:55 2023 ] Training epoch: 98
[ Tue Jun 20 03:28:57 2023 ] 	Training loss: 0.3045.  Training acc: 99.91%.
[ Tue Jun 20 03:28:57 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:28:57 2023 ] Eval epoch: 98
[ Tue Jun 20 03:28:57 2023 ] 	Mean test loss of 625 batches: 0.293451.
[ Tue Jun 20 03:28:57 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:28:57 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:28:57 2023 ] Training epoch: 99
[ Tue Jun 20 03:28:59 2023 ] 	Training loss: 0.3010.  Training acc: 100.00%.
[ Tue Jun 20 03:28:59 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 20 03:28:59 2023 ] Eval epoch: 99
[ Tue Jun 20 03:29:00 2023 ] 	Mean test loss of 625 batches: 0.299994.
[ Tue Jun 20 03:29:00 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:29:00 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:29:00 2023 ] Training epoch: 100
[ Tue Jun 20 03:29:02 2023 ] 	Training loss: 0.3017.  Training acc: 100.00%.
[ Tue Jun 20 03:29:02 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:29:02 2023 ] Eval epoch: 100
[ Tue Jun 20 03:29:02 2023 ] 	Mean test loss of 625 batches: 0.292954.
[ Tue Jun 20 03:29:02 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:29:02 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:29:02 2023 ] Training epoch: 101
[ Tue Jun 20 03:29:04 2023 ] 	Training loss: 0.3028.  Training acc: 99.91%.
[ Tue Jun 20 03:29:04 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:29:04 2023 ] Eval epoch: 101
[ Tue Jun 20 03:29:05 2023 ] 	Mean test loss of 625 batches: 0.293004.
[ Tue Jun 20 03:29:05 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:29:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:29:05 2023 ] Training epoch: 102
[ Tue Jun 20 03:29:07 2023 ] 	Training loss: 0.2992.  Training acc: 100.00%.
[ Tue Jun 20 03:29:07 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:29:07 2023 ] Eval epoch: 102
[ Tue Jun 20 03:29:07 2023 ] 	Mean test loss of 625 batches: 0.293300.
[ Tue Jun 20 03:29:07 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:29:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:29:07 2023 ] Training epoch: 103
[ Tue Jun 20 03:29:09 2023 ] 	Training loss: 0.2983.  Training acc: 100.00%.
[ Tue Jun 20 03:29:09 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:29:09 2023 ] Eval epoch: 103
[ Tue Jun 20 03:29:10 2023 ] 	Mean test loss of 625 batches: 0.292803.
[ Tue Jun 20 03:29:10 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:29:10 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:29:10 2023 ] Training epoch: 104
[ Tue Jun 20 03:29:12 2023 ] 	Training loss: 0.3014.  Training acc: 99.82%.
[ Tue Jun 20 03:29:12 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 03:29:12 2023 ] Eval epoch: 104
[ Tue Jun 20 03:29:12 2023 ] 	Mean test loss of 625 batches: 0.292822.
[ Tue Jun 20 03:29:12 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:29:12 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:29:12 2023 ] Training epoch: 105
[ Tue Jun 20 03:29:14 2023 ] 	Training loss: 0.3018.  Training acc: 99.91%.
[ Tue Jun 20 03:29:14 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:29:14 2023 ] Eval epoch: 105
[ Tue Jun 20 03:29:15 2023 ] 	Mean test loss of 625 batches: 0.292609.
[ Tue Jun 20 03:29:15 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:29:15 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:29:15 2023 ] Training epoch: 106
[ Tue Jun 20 03:29:17 2023 ] 	Training loss: 0.2996.  Training acc: 100.00%.
[ Tue Jun 20 03:29:17 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:29:17 2023 ] Eval epoch: 106
[ Tue Jun 20 03:29:17 2023 ] 	Mean test loss of 625 batches: 0.293026.
[ Tue Jun 20 03:29:17 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:29:17 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:29:17 2023 ] Training epoch: 107
[ Tue Jun 20 03:29:19 2023 ] 	Training loss: 0.2999.  Training acc: 100.00%.
[ Tue Jun 20 03:29:19 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:29:19 2023 ] Eval epoch: 107
[ Tue Jun 20 03:29:20 2023 ] 	Mean test loss of 625 batches: 0.293036.
[ Tue Jun 20 03:29:20 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:29:20 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:29:20 2023 ] Training epoch: 108
[ Tue Jun 20 03:29:22 2023 ] 	Training loss: 0.3010.  Training acc: 100.00%.
[ Tue Jun 20 03:29:22 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:29:22 2023 ] Eval epoch: 108
[ Tue Jun 20 03:29:22 2023 ] 	Mean test loss of 625 batches: 0.292442.
[ Tue Jun 20 03:29:22 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:29:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:29:22 2023 ] Training epoch: 109
[ Tue Jun 20 03:29:24 2023 ] 	Training loss: 0.3005.  Training acc: 99.91%.
[ Tue Jun 20 03:29:24 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:29:24 2023 ] Eval epoch: 109
[ Tue Jun 20 03:29:25 2023 ] 	Mean test loss of 625 batches: 0.292662.
[ Tue Jun 20 03:29:25 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:29:25 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:29:25 2023 ] Training epoch: 110
[ Tue Jun 20 03:29:27 2023 ] 	Training loss: 0.3018.  Training acc: 99.91%.
[ Tue Jun 20 03:29:27 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 20 03:29:27 2023 ] Eval epoch: 110
[ Tue Jun 20 03:29:27 2023 ] 	Mean test loss of 625 batches: 0.292769.
[ Tue Jun 20 03:29:27 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:29:27 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:33:29 2023 ] using warm up, epoch: 5
[ Tue Jun 20 03:33:31 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 03:33:31 2023 ] # Parameters: 1538958
[ Tue Jun 20 03:33:31 2023 ] Training epoch: 1
[ Tue Jun 20 03:33:36 2023 ] 	Training loss: 87.4695.  Training acc: 35.11%.
[ Tue Jun 20 03:33:36 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 20 03:33:36 2023 ] Eval epoch: 1
[ Tue Jun 20 03:33:37 2023 ] 	Mean test loss of 625 batches: 1067.466895.
[ Tue Jun 20 03:33:37 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:33:37 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:33:37 2023 ] Training epoch: 2
[ Tue Jun 20 03:33:39 2023 ] 	Training loss: 9.3256.  Training acc: 33.82%.
[ Tue Jun 20 03:33:39 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 20 03:33:39 2023 ] Eval epoch: 2
[ Tue Jun 20 03:33:40 2023 ] 	Mean test loss of 625 batches: 1.204752.
[ Tue Jun 20 03:33:40 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:33:40 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:33:40 2023 ] Training epoch: 3
[ Tue Jun 20 03:33:42 2023 ] 	Training loss: 6.8658.  Training acc: 35.29%.
[ Tue Jun 20 03:33:42 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:33:42 2023 ] Eval epoch: 3
[ Tue Jun 20 03:33:42 2023 ] 	Mean test loss of 625 batches: 3.553686.
[ Tue Jun 20 03:33:42 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:33:42 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:33:42 2023 ] Training epoch: 4
[ Tue Jun 20 03:33:44 2023 ] 	Training loss: 4.5460.  Training acc: 46.05%.
[ Tue Jun 20 03:33:44 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:33:44 2023 ] Eval epoch: 4
[ Tue Jun 20 03:33:45 2023 ] 	Mean test loss of 625 batches: 3.574937.
[ Tue Jun 20 03:33:45 2023 ] 	Top1: 40.35%
[ Tue Jun 20 03:33:45 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:33:45 2023 ] Training epoch: 5
[ Tue Jun 20 03:33:47 2023 ] 	Training loss: 3.7894.  Training acc: 51.19%.
[ Tue Jun 20 03:33:47 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:33:47 2023 ] Eval epoch: 5
[ Tue Jun 20 03:33:47 2023 ] 	Mean test loss of 625 batches: 32.282062.
[ Tue Jun 20 03:33:47 2023 ] 	Top1: 40.35%
[ Tue Jun 20 03:33:47 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:33:47 2023 ] Training epoch: 6
[ Tue Jun 20 03:33:49 2023 ] 	Training loss: 2.7841.  Training acc: 43.93%.
[ Tue Jun 20 03:33:49 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 20 03:33:49 2023 ] Eval epoch: 6
[ Tue Jun 20 03:33:50 2023 ] 	Mean test loss of 625 batches: 41.759558.
[ Tue Jun 20 03:33:50 2023 ] 	Top1: 38.60%
[ Tue Jun 20 03:33:50 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:33:50 2023 ] Training epoch: 7
[ Tue Jun 20 03:33:52 2023 ] 	Training loss: 1.8696.  Training acc: 47.33%.
[ Tue Jun 20 03:33:52 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:33:52 2023 ] Eval epoch: 7
[ Tue Jun 20 03:33:55 2023 ] using warm up, epoch: 5
[ Tue Jun 20 03:33:57 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 03:33:57 2023 ] # Parameters: 1538958
[ Tue Jun 20 03:33:57 2023 ] Training epoch: 1
[ Tue Jun 20 03:34:02 2023 ] 	Training loss: 85.2974.  Training acc: 35.02%.
[ Tue Jun 20 03:34:02 2023 ] 	Time consumption: [Data]07%, [Network]92%
[ Tue Jun 20 03:34:02 2023 ] Eval epoch: 1
[ Tue Jun 20 03:34:03 2023 ] 	Mean test loss of 625 batches: 176.957574.
[ Tue Jun 20 03:34:03 2023 ] 	Top1: 38.60%
[ Tue Jun 20 03:34:03 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:34:03 2023 ] Training epoch: 2
[ Tue Jun 20 03:34:05 2023 ] 	Training loss: 7.7749.  Training acc: 36.03%.
[ Tue Jun 20 03:34:05 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:34:05 2023 ] Eval epoch: 2
[ Tue Jun 20 03:34:05 2023 ] 	Mean test loss of 625 batches: 3.523065.
[ Tue Jun 20 03:34:05 2023 ] 	Top1: 31.58%
[ Tue Jun 20 03:34:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:34:05 2023 ] Training epoch: 3
[ Tue Jun 20 03:34:18 2023 ] using warm up, epoch: 5
[ Tue Jun 20 03:34:20 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 03:34:20 2023 ] # Parameters: 1538958
[ Tue Jun 20 03:34:20 2023 ] Training epoch: 1
[ Tue Jun 20 03:34:25 2023 ] 	Training loss: 85.9958.  Training acc: 34.38%.
[ Tue Jun 20 03:34:25 2023 ] 	Time consumption: [Data]08%, [Network]92%
[ Tue Jun 20 03:34:25 2023 ] Eval epoch: 1
[ Tue Jun 20 03:34:26 2023 ] 	Mean test loss of 625 batches: 2226.689600.
[ Tue Jun 20 03:34:26 2023 ] 	Top1: 38.60%
[ Tue Jun 20 03:34:26 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:34:26 2023 ] Training epoch: 2
[ Tue Jun 20 03:34:28 2023 ] 	Training loss: 8.8385.  Training acc: 35.48%.
[ Tue Jun 20 03:34:28 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:34:28 2023 ] Eval epoch: 2
[ Tue Jun 20 03:34:29 2023 ] 	Mean test loss of 625 batches: 2.422022.
[ Tue Jun 20 03:34:29 2023 ] 	Top1: 36.84%
[ Tue Jun 20 03:34:29 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:34:29 2023 ] Training epoch: 3
[ Tue Jun 20 03:34:31 2023 ] 	Training loss: 6.4794.  Training acc: 39.06%.
[ Tue Jun 20 03:34:31 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:34:31 2023 ] Eval epoch: 3
[ Tue Jun 20 03:34:31 2023 ] 	Mean test loss of 625 batches: 1.732219.
[ Tue Jun 20 03:34:31 2023 ] 	Top1: 54.39%
[ Tue Jun 20 03:34:31 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:34:31 2023 ] Training epoch: 4
[ Tue Jun 20 03:34:33 2023 ] 	Training loss: 3.9587.  Training acc: 53.31%.
[ Tue Jun 20 03:34:33 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:34:33 2023 ] Eval epoch: 4
[ Tue Jun 20 03:34:34 2023 ] 	Mean test loss of 625 batches: 3.902806.
[ Tue Jun 20 03:34:34 2023 ] 	Top1: 38.60%
[ Tue Jun 20 03:34:34 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:34:34 2023 ] Training epoch: 5
[ Tue Jun 20 03:34:36 2023 ] 	Training loss: 4.1816.  Training acc: 53.77%.
[ Tue Jun 20 03:34:36 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:34:36 2023 ] Eval epoch: 5
[ Tue Jun 20 03:34:36 2023 ] 	Mean test loss of 625 batches: 3.763558.
[ Tue Jun 20 03:34:36 2023 ] 	Top1: 3.51%
[ Tue Jun 20 03:34:36 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:34:36 2023 ] Training epoch: 6
[ Tue Jun 20 03:34:38 2023 ] 	Training loss: 3.2626.  Training acc: 45.31%.
[ Tue Jun 20 03:34:38 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 03:34:38 2023 ] Eval epoch: 6
[ Tue Jun 20 03:34:39 2023 ] 	Mean test loss of 625 batches: 3.631437.
[ Tue Jun 20 03:34:39 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:34:39 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:34:39 2023 ] Training epoch: 7
[ Tue Jun 20 03:34:41 2023 ] 	Training loss: 2.1879.  Training acc: 51.65%.
[ Tue Jun 20 03:34:41 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:34:41 2023 ] Eval epoch: 7
[ Tue Jun 20 03:34:42 2023 ] 	Mean test loss of 625 batches: 3.667639.
[ Tue Jun 20 03:34:42 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:34:42 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:34:42 2023 ] Training epoch: 8
[ Tue Jun 20 03:34:44 2023 ] 	Training loss: 1.9170.  Training acc: 49.36%.
[ Tue Jun 20 03:34:44 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:34:44 2023 ] Eval epoch: 8
[ Tue Jun 20 03:34:44 2023 ] 	Mean test loss of 625 batches: 0.923989.
[ Tue Jun 20 03:34:44 2023 ] 	Top1: 50.88%
[ Tue Jun 20 03:34:44 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:34:44 2023 ] Training epoch: 9
[ Tue Jun 20 03:34:46 2023 ] 	Training loss: 1.8398.  Training acc: 52.76%.
[ Tue Jun 20 03:34:46 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 20 03:34:46 2023 ] Eval epoch: 9
[ Tue Jun 20 03:34:47 2023 ] 	Mean test loss of 625 batches: 2.359375.
[ Tue Jun 20 03:34:47 2023 ] 	Top1: 38.60%
[ Tue Jun 20 03:34:47 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:34:47 2023 ] Training epoch: 10
[ Tue Jun 20 03:34:49 2023 ] 	Training loss: 1.4024.  Training acc: 53.95%.
[ Tue Jun 20 03:34:49 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:34:49 2023 ] Eval epoch: 10
[ Tue Jun 20 03:34:49 2023 ] 	Mean test loss of 625 batches: 3.067084.
[ Tue Jun 20 03:34:49 2023 ] 	Top1: 54.39%
[ Tue Jun 20 03:34:49 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:34:49 2023 ] Training epoch: 11
[ Tue Jun 20 03:34:51 2023 ] 	Training loss: 1.2534.  Training acc: 55.15%.
[ Tue Jun 20 03:34:51 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 03:34:51 2023 ] Eval epoch: 11
[ Tue Jun 20 03:34:52 2023 ] 	Mean test loss of 625 batches: 1.270957.
[ Tue Jun 20 03:34:52 2023 ] 	Top1: 47.37%
[ Tue Jun 20 03:34:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:34:52 2023 ] Training epoch: 12
[ Tue Jun 20 03:34:54 2023 ] 	Training loss: 1.0647.  Training acc: 61.86%.
[ Tue Jun 20 03:34:54 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 20 03:34:54 2023 ] Eval epoch: 12
[ Tue Jun 20 03:34:54 2023 ] 	Mean test loss of 625 batches: 1.225929.
[ Tue Jun 20 03:34:54 2023 ] 	Top1: 47.37%
[ Tue Jun 20 03:34:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:34:54 2023 ] Training epoch: 13
[ Tue Jun 20 03:34:56 2023 ] 	Training loss: 1.2263.  Training acc: 56.16%.
[ Tue Jun 20 03:34:56 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 20 03:34:56 2023 ] Eval epoch: 13
[ Tue Jun 20 03:34:57 2023 ] 	Mean test loss of 625 batches: 0.808511.
[ Tue Jun 20 03:34:57 2023 ] 	Top1: 66.67%
[ Tue Jun 20 03:34:57 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:34:57 2023 ] Training epoch: 14
[ Tue Jun 20 03:34:59 2023 ] 	Training loss: 0.9598.  Training acc: 64.15%.
[ Tue Jun 20 03:34:59 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:34:59 2023 ] Eval epoch: 14
[ Tue Jun 20 03:35:00 2023 ] 	Mean test loss of 625 batches: 1.527449.
[ Tue Jun 20 03:35:00 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:35:00 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:00 2023 ] Training epoch: 15
[ Tue Jun 20 03:35:02 2023 ] 	Training loss: 0.8282.  Training acc: 64.34%.
[ Tue Jun 20 03:35:02 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 03:35:02 2023 ] Eval epoch: 15
[ Tue Jun 20 03:35:02 2023 ] 	Mean test loss of 625 batches: 0.933637.
[ Tue Jun 20 03:35:02 2023 ] 	Top1: 64.91%
[ Tue Jun 20 03:35:02 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:02 2023 ] Training epoch: 16
[ Tue Jun 20 03:35:04 2023 ] 	Training loss: 0.8060.  Training acc: 67.10%.
[ Tue Jun 20 03:35:04 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:35:04 2023 ] Eval epoch: 16
[ Tue Jun 20 03:35:05 2023 ] 	Mean test loss of 625 batches: 0.909717.
[ Tue Jun 20 03:35:05 2023 ] 	Top1: 56.14%
[ Tue Jun 20 03:35:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:05 2023 ] Training epoch: 17
[ Tue Jun 20 03:35:07 2023 ] 	Training loss: 0.6939.  Training acc: 77.57%.
[ Tue Jun 20 03:35:07 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:35:07 2023 ] Eval epoch: 17
[ Tue Jun 20 03:35:07 2023 ] 	Mean test loss of 625 batches: 1.034105.
[ Tue Jun 20 03:35:07 2023 ] 	Top1: 49.12%
[ Tue Jun 20 03:35:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:07 2023 ] Training epoch: 18
[ Tue Jun 20 03:35:10 2023 ] 	Training loss: 0.7787.  Training acc: 72.52%.
[ Tue Jun 20 03:35:10 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 20 03:35:10 2023 ] Eval epoch: 18
[ Tue Jun 20 03:35:10 2023 ] 	Mean test loss of 625 batches: 0.656403.
[ Tue Jun 20 03:35:10 2023 ] 	Top1: 82.46%
[ Tue Jun 20 03:35:10 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:10 2023 ] Training epoch: 19
[ Tue Jun 20 03:35:13 2023 ] 	Training loss: 0.6835.  Training acc: 79.14%.
[ Tue Jun 20 03:35:13 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:35:13 2023 ] Eval epoch: 19
[ Tue Jun 20 03:35:13 2023 ] 	Mean test loss of 625 batches: 0.719745.
[ Tue Jun 20 03:35:13 2023 ] 	Top1: 82.46%
[ Tue Jun 20 03:35:13 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:13 2023 ] Training epoch: 20
[ Tue Jun 20 03:35:15 2023 ] 	Training loss: 0.6527.  Training acc: 83.82%.
[ Tue Jun 20 03:35:15 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:35:15 2023 ] Eval epoch: 20
[ Tue Jun 20 03:35:16 2023 ] 	Mean test loss of 625 batches: 0.698200.
[ Tue Jun 20 03:35:16 2023 ] 	Top1: 71.93%
[ Tue Jun 20 03:35:16 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:16 2023 ] Training epoch: 21
[ Tue Jun 20 03:35:18 2023 ] 	Training loss: 0.5821.  Training acc: 88.97%.
[ Tue Jun 20 03:35:18 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:35:18 2023 ] Eval epoch: 21
[ Tue Jun 20 03:35:18 2023 ] 	Mean test loss of 625 batches: 0.919753.
[ Tue Jun 20 03:35:18 2023 ] 	Top1: 40.35%
[ Tue Jun 20 03:35:18 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:18 2023 ] Training epoch: 22
[ Tue Jun 20 03:35:20 2023 ] 	Training loss: 0.6350.  Training acc: 85.11%.
[ Tue Jun 20 03:35:20 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:35:20 2023 ] Eval epoch: 22
[ Tue Jun 20 03:35:21 2023 ] 	Mean test loss of 625 batches: 1.391098.
[ Tue Jun 20 03:35:21 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:35:21 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:21 2023 ] Training epoch: 23
[ Tue Jun 20 03:35:23 2023 ] 	Training loss: 0.6367.  Training acc: 86.12%.
[ Tue Jun 20 03:35:23 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 20 03:35:23 2023 ] Eval epoch: 23
[ Tue Jun 20 03:35:23 2023 ] 	Mean test loss of 625 batches: 0.836150.
[ Tue Jun 20 03:35:23 2023 ] 	Top1: 57.89%
[ Tue Jun 20 03:35:23 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:23 2023 ] Training epoch: 24
[ Tue Jun 20 03:35:25 2023 ] 	Training loss: 0.6261.  Training acc: 87.04%.
[ Tue Jun 20 03:35:25 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:35:25 2023 ] Eval epoch: 24
[ Tue Jun 20 03:35:26 2023 ] 	Mean test loss of 625 batches: 0.581106.
[ Tue Jun 20 03:35:26 2023 ] 	Top1: 96.49%
[ Tue Jun 20 03:35:26 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:26 2023 ] Training epoch: 25
[ Tue Jun 20 03:35:28 2023 ] 	Training loss: 0.5783.  Training acc: 90.62%.
[ Tue Jun 20 03:35:28 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:35:28 2023 ] Eval epoch: 25
[ Tue Jun 20 03:35:28 2023 ] 	Mean test loss of 625 batches: 1.281537.
[ Tue Jun 20 03:35:28 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:35:28 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:28 2023 ] Training epoch: 26
[ Tue Jun 20 03:35:31 2023 ] 	Training loss: 0.5716.  Training acc: 90.35%.
[ Tue Jun 20 03:35:31 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 03:35:31 2023 ] Eval epoch: 26
[ Tue Jun 20 03:35:31 2023 ] 	Mean test loss of 625 batches: 1.111527.
[ Tue Jun 20 03:35:31 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:35:31 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:31 2023 ] Training epoch: 27
[ Tue Jun 20 03:35:33 2023 ] 	Training loss: 0.5509.  Training acc: 93.20%.
[ Tue Jun 20 03:35:33 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:35:33 2023 ] Eval epoch: 27
[ Tue Jun 20 03:35:34 2023 ] 	Mean test loss of 625 batches: 1.316297.
[ Tue Jun 20 03:35:34 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:35:34 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:34 2023 ] Training epoch: 28
[ Tue Jun 20 03:35:36 2023 ] 	Training loss: 0.5727.  Training acc: 92.10%.
[ Tue Jun 20 03:35:36 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:35:36 2023 ] Eval epoch: 28
[ Tue Jun 20 03:35:36 2023 ] 	Mean test loss of 625 batches: 0.504418.
[ Tue Jun 20 03:35:36 2023 ] 	Top1: 94.74%
[ Tue Jun 20 03:35:36 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:36 2023 ] Training epoch: 29
[ Tue Jun 20 03:35:38 2023 ] 	Training loss: 0.5856.  Training acc: 89.89%.
[ Tue Jun 20 03:35:38 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:35:38 2023 ] Eval epoch: 29
[ Tue Jun 20 03:35:39 2023 ] 	Mean test loss of 625 batches: 0.638683.
[ Tue Jun 20 03:35:39 2023 ] 	Top1: 73.68%
[ Tue Jun 20 03:35:39 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:39 2023 ] Training epoch: 30
[ Tue Jun 20 03:35:41 2023 ] 	Training loss: 0.9661.  Training acc: 84.83%.
[ Tue Jun 20 03:35:41 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:35:41 2023 ] Eval epoch: 30
[ Tue Jun 20 03:35:41 2023 ] 	Mean test loss of 625 batches: 0.930569.
[ Tue Jun 20 03:35:41 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:35:41 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:41 2023 ] Training epoch: 31
[ Tue Jun 20 03:35:43 2023 ] 	Training loss: 0.9055.  Training acc: 67.56%.
[ Tue Jun 20 03:35:43 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:35:43 2023 ] Eval epoch: 31
[ Tue Jun 20 03:35:44 2023 ] 	Mean test loss of 625 batches: 1.056947.
[ Tue Jun 20 03:35:44 2023 ] 	Top1: 52.63%
[ Tue Jun 20 03:35:44 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:44 2023 ] Training epoch: 32
[ Tue Jun 20 03:35:46 2023 ] 	Training loss: 0.8214.  Training acc: 70.13%.
[ Tue Jun 20 03:35:46 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:35:46 2023 ] Eval epoch: 32
[ Tue Jun 20 03:35:46 2023 ] 	Mean test loss of 625 batches: 0.883423.
[ Tue Jun 20 03:35:46 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:35:46 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:46 2023 ] Training epoch: 33
[ Tue Jun 20 03:35:49 2023 ] 	Training loss: 0.6535.  Training acc: 84.56%.
[ Tue Jun 20 03:35:49 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:35:49 2023 ] Eval epoch: 33
[ Tue Jun 20 03:35:49 2023 ] 	Mean test loss of 625 batches: 0.526893.
[ Tue Jun 20 03:35:49 2023 ] 	Top1: 94.74%
[ Tue Jun 20 03:35:49 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:49 2023 ] Training epoch: 34
[ Tue Jun 20 03:35:51 2023 ] 	Training loss: 0.7530.  Training acc: 84.56%.
[ Tue Jun 20 03:35:51 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:35:51 2023 ] Eval epoch: 34
[ Tue Jun 20 03:35:52 2023 ] 	Mean test loss of 625 batches: 1.007310.
[ Tue Jun 20 03:35:52 2023 ] 	Top1: 36.84%
[ Tue Jun 20 03:35:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:52 2023 ] Training epoch: 35
[ Tue Jun 20 03:35:54 2023 ] 	Training loss: 0.7677.  Training acc: 78.03%.
[ Tue Jun 20 03:35:54 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:35:54 2023 ] Eval epoch: 35
[ Tue Jun 20 03:35:54 2023 ] 	Mean test loss of 625 batches: 0.613334.
[ Tue Jun 20 03:35:54 2023 ] 	Top1: 87.72%
[ Tue Jun 20 03:35:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:54 2023 ] Training epoch: 36
[ Tue Jun 20 03:35:56 2023 ] 	Training loss: 0.5813.  Training acc: 88.97%.
[ Tue Jun 20 03:35:56 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:35:56 2023 ] Eval epoch: 36
[ Tue Jun 20 03:35:57 2023 ] 	Mean test loss of 625 batches: 1.549735.
[ Tue Jun 20 03:35:57 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:35:57 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:35:57 2023 ] Training epoch: 37
[ Tue Jun 20 03:36:00 2023 ] 	Training loss: 0.5045.  Training acc: 90.62%.
[ Tue Jun 20 03:36:00 2023 ] 	Time consumption: [Data]12%, [Network]87%
[ Tue Jun 20 03:36:00 2023 ] Eval epoch: 37
[ Tue Jun 20 03:36:00 2023 ] 	Mean test loss of 625 batches: 0.534188.
[ Tue Jun 20 03:36:00 2023 ] 	Top1: 92.98%
[ Tue Jun 20 03:36:00 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:00 2023 ] Training epoch: 38
[ Tue Jun 20 03:36:02 2023 ] 	Training loss: 0.5692.  Training acc: 89.15%.
[ Tue Jun 20 03:36:02 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:36:02 2023 ] Eval epoch: 38
[ Tue Jun 20 03:36:03 2023 ] 	Mean test loss of 625 batches: 0.929784.
[ Tue Jun 20 03:36:03 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:36:03 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:03 2023 ] Training epoch: 39
[ Tue Jun 20 03:36:05 2023 ] 	Training loss: 0.4247.  Training acc: 95.40%.
[ Tue Jun 20 03:36:05 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:36:05 2023 ] Eval epoch: 39
[ Tue Jun 20 03:36:06 2023 ] 	Mean test loss of 625 batches: 0.938614.
[ Tue Jun 20 03:36:06 2023 ] 	Top1: 50.88%
[ Tue Jun 20 03:36:06 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:06 2023 ] Training epoch: 40
[ Tue Jun 20 03:36:08 2023 ] 	Training loss: 0.4054.  Training acc: 95.59%.
[ Tue Jun 20 03:36:08 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 20 03:36:08 2023 ] Eval epoch: 40
[ Tue Jun 20 03:36:08 2023 ] 	Mean test loss of 625 batches: 0.665050.
[ Tue Jun 20 03:36:08 2023 ] 	Top1: 61.40%
[ Tue Jun 20 03:36:08 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:08 2023 ] Training epoch: 41
[ Tue Jun 20 03:36:10 2023 ] 	Training loss: 0.3720.  Training acc: 97.33%.
[ Tue Jun 20 03:36:10 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:36:10 2023 ] Eval epoch: 41
[ Tue Jun 20 03:36:11 2023 ] 	Mean test loss of 625 batches: 1.035140.
[ Tue Jun 20 03:36:11 2023 ] 	Top1: 64.91%
[ Tue Jun 20 03:36:11 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:11 2023 ] Training epoch: 42
[ Tue Jun 20 03:36:13 2023 ] 	Training loss: 0.3496.  Training acc: 98.90%.
[ Tue Jun 20 03:36:13 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:36:13 2023 ] Eval epoch: 42
[ Tue Jun 20 03:36:13 2023 ] 	Mean test loss of 625 batches: 0.424824.
[ Tue Jun 20 03:36:13 2023 ] 	Top1: 96.49%
[ Tue Jun 20 03:36:13 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:13 2023 ] Training epoch: 43
[ Tue Jun 20 03:36:15 2023 ] 	Training loss: 0.3536.  Training acc: 98.44%.
[ Tue Jun 20 03:36:15 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:36:15 2023 ] Eval epoch: 43
[ Tue Jun 20 03:36:16 2023 ] 	Mean test loss of 625 batches: 0.394638.
[ Tue Jun 20 03:36:16 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:36:16 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:16 2023 ] Training epoch: 44
[ Tue Jun 20 03:36:18 2023 ] 	Training loss: 0.3461.  Training acc: 98.71%.
[ Tue Jun 20 03:36:18 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:36:18 2023 ] Eval epoch: 44
[ Tue Jun 20 03:36:19 2023 ] 	Mean test loss of 625 batches: 0.648819.
[ Tue Jun 20 03:36:19 2023 ] 	Top1: 63.16%
[ Tue Jun 20 03:36:19 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:19 2023 ] Training epoch: 45
[ Tue Jun 20 03:36:21 2023 ] 	Training loss: 0.3489.  Training acc: 98.99%.
[ Tue Jun 20 03:36:21 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:36:21 2023 ] Eval epoch: 45
[ Tue Jun 20 03:36:21 2023 ] 	Mean test loss of 625 batches: 0.386934.
[ Tue Jun 20 03:36:21 2023 ] 	Top1: 98.25%
[ Tue Jun 20 03:36:21 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:21 2023 ] Training epoch: 46
[ Tue Jun 20 03:36:23 2023 ] 	Training loss: 0.3381.  Training acc: 98.99%.
[ Tue Jun 20 03:36:23 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:36:23 2023 ] Eval epoch: 46
[ Tue Jun 20 03:36:24 2023 ] 	Mean test loss of 625 batches: 0.542423.
[ Tue Jun 20 03:36:24 2023 ] 	Top1: 94.74%
[ Tue Jun 20 03:36:24 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:24 2023 ] Training epoch: 47
[ Tue Jun 20 03:36:26 2023 ] 	Training loss: 0.3339.  Training acc: 99.54%.
[ Tue Jun 20 03:36:26 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:36:26 2023 ] Eval epoch: 47
[ Tue Jun 20 03:36:27 2023 ] 	Mean test loss of 625 batches: 0.314839.
[ Tue Jun 20 03:36:27 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:36:27 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:27 2023 ] Training epoch: 48
[ Tue Jun 20 03:36:29 2023 ] 	Training loss: 0.3362.  Training acc: 98.90%.
[ Tue Jun 20 03:36:29 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:36:29 2023 ] Eval epoch: 48
[ Tue Jun 20 03:36:29 2023 ] 	Mean test loss of 625 batches: 1.114610.
[ Tue Jun 20 03:36:29 2023 ] 	Top1: 64.91%
[ Tue Jun 20 03:36:29 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:29 2023 ] Training epoch: 49
[ Tue Jun 20 03:36:31 2023 ] 	Training loss: 0.3304.  Training acc: 99.54%.
[ Tue Jun 20 03:36:31 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:36:31 2023 ] Eval epoch: 49
[ Tue Jun 20 03:36:32 2023 ] 	Mean test loss of 625 batches: 0.450101.
[ Tue Jun 20 03:36:32 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:36:32 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:32 2023 ] Training epoch: 50
[ Tue Jun 20 03:36:34 2023 ] 	Training loss: 0.3494.  Training acc: 99.17%.
[ Tue Jun 20 03:36:34 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:36:34 2023 ] Eval epoch: 50
[ Tue Jun 20 03:36:34 2023 ] 	Mean test loss of 625 batches: 0.975049.
[ Tue Jun 20 03:36:34 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:36:34 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:34 2023 ] Training epoch: 51
[ Tue Jun 20 03:36:36 2023 ] 	Training loss: 0.3602.  Training acc: 98.44%.
[ Tue Jun 20 03:36:36 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:36:36 2023 ] Eval epoch: 51
[ Tue Jun 20 03:36:37 2023 ] 	Mean test loss of 625 batches: 0.562662.
[ Tue Jun 20 03:36:37 2023 ] 	Top1: 89.47%
[ Tue Jun 20 03:36:37 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:37 2023 ] Training epoch: 52
[ Tue Jun 20 03:36:39 2023 ] 	Training loss: 0.3299.  Training acc: 99.63%.
[ Tue Jun 20 03:36:39 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:36:39 2023 ] Eval epoch: 52
[ Tue Jun 20 03:36:39 2023 ] 	Mean test loss of 625 batches: 0.319834.
[ Tue Jun 20 03:36:39 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:36:39 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:39 2023 ] Training epoch: 53
[ Tue Jun 20 03:36:42 2023 ] 	Training loss: 0.3370.  Training acc: 99.08%.
[ Tue Jun 20 03:36:42 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 20 03:36:42 2023 ] Eval epoch: 53
[ Tue Jun 20 03:36:42 2023 ] 	Mean test loss of 625 batches: 0.360934.
[ Tue Jun 20 03:36:42 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:36:42 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:42 2023 ] Training epoch: 54
[ Tue Jun 20 03:36:44 2023 ] 	Training loss: 0.3539.  Training acc: 98.71%.
[ Tue Jun 20 03:36:44 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:36:44 2023 ] Eval epoch: 54
[ Tue Jun 20 03:36:45 2023 ] 	Mean test loss of 625 batches: 0.414928.
[ Tue Jun 20 03:36:45 2023 ] 	Top1: 91.23%
[ Tue Jun 20 03:36:45 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:45 2023 ] Training epoch: 55
[ Tue Jun 20 03:36:47 2023 ] 	Training loss: 0.3265.  Training acc: 99.63%.
[ Tue Jun 20 03:36:47 2023 ] 	Time consumption: [Data]13%, [Network]86%
[ Tue Jun 20 03:36:47 2023 ] Eval epoch: 55
[ Tue Jun 20 03:36:48 2023 ] 	Mean test loss of 625 batches: 0.314926.
[ Tue Jun 20 03:36:48 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:36:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:48 2023 ] Training epoch: 56
[ Tue Jun 20 03:36:50 2023 ] 	Training loss: 0.3222.  Training acc: 99.72%.
[ Tue Jun 20 03:36:50 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:36:50 2023 ] Eval epoch: 56
[ Tue Jun 20 03:36:51 2023 ] 	Mean test loss of 625 batches: 0.363527.
[ Tue Jun 20 03:36:51 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:36:51 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:51 2023 ] Training epoch: 57
[ Tue Jun 20 03:36:53 2023 ] 	Training loss: 0.3194.  Training acc: 99.54%.
[ Tue Jun 20 03:36:53 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:36:53 2023 ] Eval epoch: 57
[ Tue Jun 20 03:36:53 2023 ] 	Mean test loss of 625 batches: 0.361764.
[ Tue Jun 20 03:36:53 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:36:53 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:53 2023 ] Training epoch: 58
[ Tue Jun 20 03:36:55 2023 ] 	Training loss: 0.3275.  Training acc: 99.45%.
[ Tue Jun 20 03:36:55 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:36:55 2023 ] Eval epoch: 58
[ Tue Jun 20 03:36:56 2023 ] 	Mean test loss of 625 batches: 0.410052.
[ Tue Jun 20 03:36:56 2023 ] 	Top1: 98.25%
[ Tue Jun 20 03:36:56 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:56 2023 ] Training epoch: 59
[ Tue Jun 20 03:36:58 2023 ] 	Training loss: 0.3357.  Training acc: 99.45%.
[ Tue Jun 20 03:36:58 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:36:58 2023 ] Eval epoch: 59
[ Tue Jun 20 03:36:59 2023 ] 	Mean test loss of 625 batches: 0.407070.
[ Tue Jun 20 03:36:59 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:36:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:36:59 2023 ] Training epoch: 60
[ Tue Jun 20 03:37:01 2023 ] 	Training loss: 0.3461.  Training acc: 99.26%.
[ Tue Jun 20 03:37:01 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:37:01 2023 ] Eval epoch: 60
[ Tue Jun 20 03:37:01 2023 ] 	Mean test loss of 625 batches: 0.660104.
[ Tue Jun 20 03:37:01 2023 ] 	Top1: 82.46%
[ Tue Jun 20 03:37:01 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:01 2023 ] Training epoch: 61
[ Tue Jun 20 03:37:03 2023 ] 	Training loss: 0.3361.  Training acc: 99.08%.
[ Tue Jun 20 03:37:03 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:37:03 2023 ] Eval epoch: 61
[ Tue Jun 20 03:37:04 2023 ] 	Mean test loss of 625 batches: 0.422748.
[ Tue Jun 20 03:37:04 2023 ] 	Top1: 98.25%
[ Tue Jun 20 03:37:04 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:04 2023 ] Training epoch: 62
[ Tue Jun 20 03:37:06 2023 ] 	Training loss: 0.3217.  Training acc: 99.91%.
[ Tue Jun 20 03:37:06 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 03:37:06 2023 ] Eval epoch: 62
[ Tue Jun 20 03:37:06 2023 ] 	Mean test loss of 625 batches: 0.372871.
[ Tue Jun 20 03:37:06 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:37:06 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:06 2023 ] Training epoch: 63
[ Tue Jun 20 03:37:08 2023 ] 	Training loss: 0.3169.  Training acc: 99.72%.
[ Tue Jun 20 03:37:08 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:37:08 2023 ] Eval epoch: 63
[ Tue Jun 20 03:37:09 2023 ] 	Mean test loss of 625 batches: 0.479494.
[ Tue Jun 20 03:37:09 2023 ] 	Top1: 94.74%
[ Tue Jun 20 03:37:09 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:09 2023 ] Training epoch: 64
[ Tue Jun 20 03:37:11 2023 ] 	Training loss: 0.3179.  Training acc: 99.63%.
[ Tue Jun 20 03:37:11 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:37:11 2023 ] Eval epoch: 64
[ Tue Jun 20 03:37:12 2023 ] 	Mean test loss of 625 batches: 0.406475.
[ Tue Jun 20 03:37:12 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:37:12 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:12 2023 ] Training epoch: 65
[ Tue Jun 20 03:37:14 2023 ] 	Training loss: 0.3196.  Training acc: 99.82%.
[ Tue Jun 20 03:37:14 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 20 03:37:14 2023 ] Eval epoch: 65
[ Tue Jun 20 03:37:14 2023 ] 	Mean test loss of 625 batches: 0.321401.
[ Tue Jun 20 03:37:14 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:37:14 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:14 2023 ] Training epoch: 66
[ Tue Jun 20 03:37:16 2023 ] 	Training loss: 0.3234.  Training acc: 99.45%.
[ Tue Jun 20 03:37:16 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:37:16 2023 ] Eval epoch: 66
[ Tue Jun 20 03:37:17 2023 ] 	Mean test loss of 625 batches: 0.437516.
[ Tue Jun 20 03:37:17 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:37:17 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:17 2023 ] Training epoch: 67
[ Tue Jun 20 03:37:19 2023 ] 	Training loss: 0.3379.  Training acc: 99.36%.
[ Tue Jun 20 03:37:19 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 20 03:37:19 2023 ] Eval epoch: 67
[ Tue Jun 20 03:37:19 2023 ] 	Mean test loss of 625 batches: 0.359082.
[ Tue Jun 20 03:37:19 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:37:19 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:19 2023 ] Training epoch: 68
[ Tue Jun 20 03:37:21 2023 ] 	Training loss: 0.3350.  Training acc: 99.26%.
[ Tue Jun 20 03:37:21 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:37:21 2023 ] Eval epoch: 68
[ Tue Jun 20 03:37:22 2023 ] 	Mean test loss of 625 batches: 0.559124.
[ Tue Jun 20 03:37:22 2023 ] 	Top1: 87.72%
[ Tue Jun 20 03:37:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:22 2023 ] Training epoch: 69
[ Tue Jun 20 03:37:24 2023 ] 	Training loss: 0.3463.  Training acc: 98.99%.
[ Tue Jun 20 03:37:24 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:37:24 2023 ] Eval epoch: 69
[ Tue Jun 20 03:37:24 2023 ] 	Mean test loss of 625 batches: 4.394044.
[ Tue Jun 20 03:37:24 2023 ] 	Top1: 38.60%
[ Tue Jun 20 03:37:24 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:24 2023 ] Training epoch: 70
[ Tue Jun 20 03:37:27 2023 ] 	Training loss: 0.3396.  Training acc: 99.26%.
[ Tue Jun 20 03:37:27 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:37:27 2023 ] Eval epoch: 70
[ Tue Jun 20 03:37:27 2023 ] 	Mean test loss of 625 batches: 0.615047.
[ Tue Jun 20 03:37:27 2023 ] 	Top1: 87.72%
[ Tue Jun 20 03:37:27 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:27 2023 ] Training epoch: 71
[ Tue Jun 20 03:37:29 2023 ] 	Training loss: 0.3288.  Training acc: 99.82%.
[ Tue Jun 20 03:37:29 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:37:29 2023 ] Eval epoch: 71
[ Tue Jun 20 03:37:30 2023 ] 	Mean test loss of 625 batches: 1.200738.
[ Tue Jun 20 03:37:30 2023 ] 	Top1: 68.42%
[ Tue Jun 20 03:37:30 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:30 2023 ] Training epoch: 72
[ Tue Jun 20 03:37:32 2023 ] 	Training loss: 0.3652.  Training acc: 98.16%.
[ Tue Jun 20 03:37:32 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:37:32 2023 ] Eval epoch: 72
[ Tue Jun 20 03:37:32 2023 ] 	Mean test loss of 625 batches: 0.486795.
[ Tue Jun 20 03:37:32 2023 ] 	Top1: 92.98%
[ Tue Jun 20 03:37:32 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:32 2023 ] Training epoch: 73
[ Tue Jun 20 03:37:34 2023 ] 	Training loss: 0.3508.  Training acc: 98.35%.
[ Tue Jun 20 03:37:34 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:37:34 2023 ] Eval epoch: 73
[ Tue Jun 20 03:37:35 2023 ] 	Mean test loss of 625 batches: 0.346413.
[ Tue Jun 20 03:37:35 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:37:35 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:35 2023 ] Training epoch: 74
[ Tue Jun 20 03:37:37 2023 ] 	Training loss: 0.3294.  Training acc: 99.36%.
[ Tue Jun 20 03:37:37 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:37:37 2023 ] Eval epoch: 74
[ Tue Jun 20 03:37:37 2023 ] 	Mean test loss of 625 batches: 0.410371.
[ Tue Jun 20 03:37:37 2023 ] 	Top1: 98.25%
[ Tue Jun 20 03:37:37 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:37 2023 ] Training epoch: 75
[ Tue Jun 20 03:37:40 2023 ] 	Training loss: 0.3212.  Training acc: 99.63%.
[ Tue Jun 20 03:37:40 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 20 03:37:40 2023 ] Eval epoch: 75
[ Tue Jun 20 03:37:41 2023 ] 	Mean test loss of 625 batches: 0.444696.
[ Tue Jun 20 03:37:41 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:37:41 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:41 2023 ] Training epoch: 76
[ Tue Jun 20 03:37:43 2023 ] 	Training loss: 0.3148.  Training acc: 99.91%.
[ Tue Jun 20 03:37:43 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:37:43 2023 ] Eval epoch: 76
[ Tue Jun 20 03:37:43 2023 ] 	Mean test loss of 625 batches: 0.388660.
[ Tue Jun 20 03:37:43 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:37:43 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:43 2023 ] Training epoch: 77
[ Tue Jun 20 03:37:45 2023 ] 	Training loss: 0.3114.  Training acc: 100.00%.
[ Tue Jun 20 03:37:45 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 20 03:37:45 2023 ] Eval epoch: 77
[ Tue Jun 20 03:37:46 2023 ] 	Mean test loss of 625 batches: 0.723583.
[ Tue Jun 20 03:37:46 2023 ] 	Top1: 59.65%
[ Tue Jun 20 03:37:46 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:46 2023 ] Training epoch: 78
[ Tue Jun 20 03:37:48 2023 ] 	Training loss: 0.3193.  Training acc: 99.82%.
[ Tue Jun 20 03:37:48 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:37:48 2023 ] Eval epoch: 78
[ Tue Jun 20 03:37:48 2023 ] 	Mean test loss of 625 batches: 0.368048.
[ Tue Jun 20 03:37:48 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:37:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:48 2023 ] Training epoch: 79
[ Tue Jun 20 03:37:51 2023 ] 	Training loss: 0.3254.  Training acc: 99.54%.
[ Tue Jun 20 03:37:51 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 20 03:37:51 2023 ] Eval epoch: 79
[ Tue Jun 20 03:37:51 2023 ] 	Mean test loss of 625 batches: 0.302696.
[ Tue Jun 20 03:37:51 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:37:51 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:51 2023 ] Training epoch: 80
[ Tue Jun 20 03:37:53 2023 ] 	Training loss: 0.3184.  Training acc: 99.91%.
[ Tue Jun 20 03:37:53 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 03:37:53 2023 ] Eval epoch: 80
[ Tue Jun 20 03:37:54 2023 ] 	Mean test loss of 625 batches: 0.703982.
[ Tue Jun 20 03:37:54 2023 ] 	Top1: 70.18%
[ Tue Jun 20 03:37:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:54 2023 ] Training epoch: 81
[ Tue Jun 20 03:37:56 2023 ] 	Training loss: 0.3251.  Training acc: 99.72%.
[ Tue Jun 20 03:37:56 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:37:56 2023 ] Eval epoch: 81
[ Tue Jun 20 03:37:56 2023 ] 	Mean test loss of 625 batches: 0.408314.
[ Tue Jun 20 03:37:56 2023 ] 	Top1: 98.25%
[ Tue Jun 20 03:37:56 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:56 2023 ] Training epoch: 82
[ Tue Jun 20 03:37:58 2023 ] 	Training loss: 0.3114.  Training acc: 99.91%.
[ Tue Jun 20 03:37:58 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:37:58 2023 ] Eval epoch: 82
[ Tue Jun 20 03:37:59 2023 ] 	Mean test loss of 625 batches: 0.782459.
[ Tue Jun 20 03:37:59 2023 ] 	Top1: 50.88%
[ Tue Jun 20 03:37:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:37:59 2023 ] Training epoch: 83
[ Tue Jun 20 03:38:01 2023 ] 	Training loss: 0.3164.  Training acc: 99.82%.
[ Tue Jun 20 03:38:01 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:38:01 2023 ] Eval epoch: 83
[ Tue Jun 20 03:38:01 2023 ] 	Mean test loss of 625 batches: 0.446258.
[ Tue Jun 20 03:38:01 2023 ] 	Top1: 92.98%
[ Tue Jun 20 03:38:01 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:01 2023 ] Training epoch: 84
[ Tue Jun 20 03:38:04 2023 ] 	Training loss: 0.3104.  Training acc: 99.82%.
[ Tue Jun 20 03:38:04 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:38:04 2023 ] Eval epoch: 84
[ Tue Jun 20 03:38:04 2023 ] 	Mean test loss of 625 batches: 0.405240.
[ Tue Jun 20 03:38:04 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:38:04 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:04 2023 ] Training epoch: 85
[ Tue Jun 20 03:38:06 2023 ] 	Training loss: 0.3187.  Training acc: 99.45%.
[ Tue Jun 20 03:38:06 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:38:06 2023 ] Eval epoch: 85
[ Tue Jun 20 03:38:07 2023 ] 	Mean test loss of 625 batches: 0.445133.
[ Tue Jun 20 03:38:07 2023 ] 	Top1: 96.49%
[ Tue Jun 20 03:38:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:07 2023 ] Training epoch: 86
[ Tue Jun 20 03:38:09 2023 ] 	Training loss: 0.3161.  Training acc: 99.72%.
[ Tue Jun 20 03:38:09 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:38:09 2023 ] Eval epoch: 86
[ Tue Jun 20 03:38:09 2023 ] 	Mean test loss of 625 batches: 0.339975.
[ Tue Jun 20 03:38:09 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:38:09 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:09 2023 ] Training epoch: 87
[ Tue Jun 20 03:38:11 2023 ] 	Training loss: 0.3211.  Training acc: 99.63%.
[ Tue Jun 20 03:38:11 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 20 03:38:11 2023 ] Eval epoch: 87
[ Tue Jun 20 03:38:12 2023 ] 	Mean test loss of 625 batches: 0.367351.
[ Tue Jun 20 03:38:12 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:38:12 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:12 2023 ] Training epoch: 88
[ Tue Jun 20 03:38:14 2023 ] 	Training loss: 0.3220.  Training acc: 99.17%.
[ Tue Jun 20 03:38:14 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 20 03:38:14 2023 ] Eval epoch: 88
[ Tue Jun 20 03:38:15 2023 ] 	Mean test loss of 625 batches: 1.044899.
[ Tue Jun 20 03:38:15 2023 ] 	Top1: 68.42%
[ Tue Jun 20 03:38:15 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:15 2023 ] Training epoch: 89
[ Tue Jun 20 03:38:17 2023 ] 	Training loss: 0.3245.  Training acc: 99.63%.
[ Tue Jun 20 03:38:17 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 20 03:38:17 2023 ] Eval epoch: 89
[ Tue Jun 20 03:38:17 2023 ] 	Mean test loss of 625 batches: 0.337975.
[ Tue Jun 20 03:38:17 2023 ] 	Top1: 98.25%
[ Tue Jun 20 03:38:17 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:17 2023 ] Training epoch: 90
[ Tue Jun 20 03:38:19 2023 ] 	Training loss: 0.3366.  Training acc: 99.63%.
[ Tue Jun 20 03:38:19 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:38:19 2023 ] Eval epoch: 90
[ Tue Jun 20 03:38:20 2023 ] 	Mean test loss of 625 batches: 0.525132.
[ Tue Jun 20 03:38:20 2023 ] 	Top1: 78.95%
[ Tue Jun 20 03:38:20 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:20 2023 ] Training epoch: 91
[ Tue Jun 20 03:38:22 2023 ] 	Training loss: 0.3134.  Training acc: 99.91%.
[ Tue Jun 20 03:38:22 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 03:38:22 2023 ] Eval epoch: 91
[ Tue Jun 20 03:38:22 2023 ] 	Mean test loss of 625 batches: 0.298138.
[ Tue Jun 20 03:38:22 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:38:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:22 2023 ] Training epoch: 92
[ Tue Jun 20 03:38:24 2023 ] 	Training loss: 0.3068.  Training acc: 99.91%.
[ Tue Jun 20 03:38:24 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:38:24 2023 ] Eval epoch: 92
[ Tue Jun 20 03:38:25 2023 ] 	Mean test loss of 625 batches: 0.297100.
[ Tue Jun 20 03:38:25 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:38:25 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:25 2023 ] Training epoch: 93
[ Tue Jun 20 03:38:27 2023 ] 	Training loss: 0.3055.  Training acc: 99.82%.
[ Tue Jun 20 03:38:27 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:38:27 2023 ] Eval epoch: 93
[ Tue Jun 20 03:38:27 2023 ] 	Mean test loss of 625 batches: 0.297764.
[ Tue Jun 20 03:38:27 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:38:27 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:27 2023 ] Training epoch: 94
[ Tue Jun 20 03:38:30 2023 ] 	Training loss: 0.3009.  Training acc: 100.00%.
[ Tue Jun 20 03:38:30 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 20 03:38:30 2023 ] Eval epoch: 94
[ Tue Jun 20 03:38:31 2023 ] 	Mean test loss of 625 batches: 0.301524.
[ Tue Jun 20 03:38:31 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:38:31 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:31 2023 ] Training epoch: 95
[ Tue Jun 20 03:38:33 2023 ] 	Training loss: 0.3012.  Training acc: 100.00%.
[ Tue Jun 20 03:38:33 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:38:33 2023 ] Eval epoch: 95
[ Tue Jun 20 03:38:33 2023 ] 	Mean test loss of 625 batches: 0.296916.
[ Tue Jun 20 03:38:33 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:38:33 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:33 2023 ] Training epoch: 96
[ Tue Jun 20 03:38:35 2023 ] 	Training loss: 0.3056.  Training acc: 99.91%.
[ Tue Jun 20 03:38:35 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:38:35 2023 ] Eval epoch: 96
[ Tue Jun 20 03:38:36 2023 ] 	Mean test loss of 625 batches: 0.296850.
[ Tue Jun 20 03:38:36 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:38:36 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:36 2023 ] Training epoch: 97
[ Tue Jun 20 03:38:38 2023 ] 	Training loss: 0.3015.  Training acc: 100.00%.
[ Tue Jun 20 03:38:38 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:38:38 2023 ] Eval epoch: 97
[ Tue Jun 20 03:38:38 2023 ] 	Mean test loss of 625 batches: 0.293727.
[ Tue Jun 20 03:38:38 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:38:38 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:38 2023 ] Training epoch: 98
[ Tue Jun 20 03:38:40 2023 ] 	Training loss: 0.3038.  Training acc: 100.00%.
[ Tue Jun 20 03:38:40 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:38:40 2023 ] Eval epoch: 98
[ Tue Jun 20 03:38:41 2023 ] 	Mean test loss of 625 batches: 0.292659.
[ Tue Jun 20 03:38:41 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:38:41 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:41 2023 ] Training epoch: 99
[ Tue Jun 20 03:38:43 2023 ] 	Training loss: 0.2991.  Training acc: 100.00%.
[ Tue Jun 20 03:38:43 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 20 03:38:43 2023 ] Eval epoch: 99
[ Tue Jun 20 03:38:43 2023 ] 	Mean test loss of 625 batches: 0.297046.
[ Tue Jun 20 03:38:43 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:38:43 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:43 2023 ] Training epoch: 100
[ Tue Jun 20 03:38:45 2023 ] 	Training loss: 0.3025.  Training acc: 99.91%.
[ Tue Jun 20 03:38:45 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:38:45 2023 ] Eval epoch: 100
[ Tue Jun 20 03:38:46 2023 ] 	Mean test loss of 625 batches: 0.292405.
[ Tue Jun 20 03:38:46 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:38:46 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:46 2023 ] Training epoch: 101
[ Tue Jun 20 03:38:48 2023 ] 	Training loss: 0.3002.  Training acc: 100.00%.
[ Tue Jun 20 03:38:48 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:38:48 2023 ] Eval epoch: 101
[ Tue Jun 20 03:38:48 2023 ] 	Mean test loss of 625 batches: 0.292485.
[ Tue Jun 20 03:38:48 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:38:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:48 2023 ] Training epoch: 102
[ Tue Jun 20 03:38:50 2023 ] 	Training loss: 0.2983.  Training acc: 100.00%.
[ Tue Jun 20 03:38:50 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:38:50 2023 ] Eval epoch: 102
[ Tue Jun 20 03:38:51 2023 ] 	Mean test loss of 625 batches: 0.292649.
[ Tue Jun 20 03:38:51 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:38:51 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:51 2023 ] Training epoch: 103
[ Tue Jun 20 03:38:53 2023 ] 	Training loss: 0.2981.  Training acc: 99.91%.
[ Tue Jun 20 03:38:53 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:38:53 2023 ] Eval epoch: 103
[ Tue Jun 20 03:38:54 2023 ] 	Mean test loss of 625 batches: 0.292584.
[ Tue Jun 20 03:38:54 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:38:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:54 2023 ] Training epoch: 104
[ Tue Jun 20 03:38:56 2023 ] 	Training loss: 0.3000.  Training acc: 99.91%.
[ Tue Jun 20 03:38:56 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 20 03:38:56 2023 ] Eval epoch: 104
[ Tue Jun 20 03:38:56 2023 ] 	Mean test loss of 625 batches: 0.292471.
[ Tue Jun 20 03:38:56 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:38:56 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:56 2023 ] Training epoch: 105
[ Tue Jun 20 03:38:58 2023 ] 	Training loss: 0.3008.  Training acc: 100.00%.
[ Tue Jun 20 03:38:58 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:38:58 2023 ] Eval epoch: 105
[ Tue Jun 20 03:38:59 2023 ] 	Mean test loss of 625 batches: 0.292462.
[ Tue Jun 20 03:38:59 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:38:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:38:59 2023 ] Training epoch: 106
[ Tue Jun 20 03:39:01 2023 ] 	Training loss: 0.3000.  Training acc: 99.91%.
[ Tue Jun 20 03:39:01 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:39:01 2023 ] Eval epoch: 106
[ Tue Jun 20 03:39:01 2023 ] 	Mean test loss of 625 batches: 0.292681.
[ Tue Jun 20 03:39:01 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:39:01 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:39:01 2023 ] Training epoch: 107
[ Tue Jun 20 03:39:03 2023 ] 	Training loss: 0.2994.  Training acc: 100.00%.
[ Tue Jun 20 03:39:03 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:39:03 2023 ] Eval epoch: 107
[ Tue Jun 20 03:39:04 2023 ] 	Mean test loss of 625 batches: 0.292866.
[ Tue Jun 20 03:39:04 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:39:04 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:39:04 2023 ] Training epoch: 108
[ Tue Jun 20 03:39:06 2023 ] 	Training loss: 0.2988.  Training acc: 99.91%.
[ Tue Jun 20 03:39:06 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:39:06 2023 ] Eval epoch: 108
[ Tue Jun 20 03:39:07 2023 ] 	Mean test loss of 625 batches: 0.292589.
[ Tue Jun 20 03:39:07 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:39:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:39:07 2023 ] Training epoch: 109
[ Tue Jun 20 03:39:09 2023 ] 	Training loss: 0.2995.  Training acc: 99.91%.
[ Tue Jun 20 03:39:09 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:39:09 2023 ] Eval epoch: 109
[ Tue Jun 20 03:39:09 2023 ] 	Mean test loss of 625 batches: 0.292409.
[ Tue Jun 20 03:39:09 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:39:09 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:39:09 2023 ] Training epoch: 110
[ Tue Jun 20 03:39:11 2023 ] 	Training loss: 0.3005.  Training acc: 99.91%.
[ Tue Jun 20 03:39:11 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:39:11 2023 ] Eval epoch: 110
[ Tue Jun 20 03:39:12 2023 ] 	Mean test loss of 625 batches: 0.293004.
[ Tue Jun 20 03:39:12 2023 ] 	Top1: 100.00%
[ Tue Jun 20 03:39:12 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:40:41 2023 ] using warm up, epoch: 5
[ Tue Jun 20 03:40:43 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 03:40:43 2023 ] # Parameters: 1538958
[ Tue Jun 20 03:40:43 2023 ] Training epoch: 1
[ Tue Jun 20 03:40:48 2023 ] 	Training loss: nan.  Training acc: 39.25%.
[ Tue Jun 20 03:40:48 2023 ] 	Time consumption: [Data]09%, [Network]91%
[ Tue Jun 20 03:40:48 2023 ] Eval epoch: 1
[ Tue Jun 20 03:40:48 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:40:48 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:40:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:40:48 2023 ] Training epoch: 2
[ Tue Jun 20 03:40:50 2023 ] 	Training loss: nan.  Training acc: 41.08%.
[ Tue Jun 20 03:40:50 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:40:50 2023 ] Eval epoch: 2
[ Tue Jun 20 03:40:51 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:40:51 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:40:51 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:40:51 2023 ] Training epoch: 3
[ Tue Jun 20 03:40:53 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:40:53 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:40:53 2023 ] Eval epoch: 3
[ Tue Jun 20 03:40:53 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:40:53 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:40:53 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:40:53 2023 ] Training epoch: 4
[ Tue Jun 20 03:40:56 2023 ] 	Training loss: nan.  Training acc: 40.17%.
[ Tue Jun 20 03:40:56 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:40:56 2023 ] Eval epoch: 4
[ Tue Jun 20 03:40:56 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:40:56 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:40:56 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:40:56 2023 ] Training epoch: 5
[ Tue Jun 20 03:40:58 2023 ] 	Training loss: nan.  Training acc: 40.81%.
[ Tue Jun 20 03:40:58 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:40:58 2023 ] Eval epoch: 5
[ Tue Jun 20 03:40:59 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:40:59 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:40:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:40:59 2023 ] Training epoch: 6
[ Tue Jun 20 03:41:01 2023 ] 	Training loss: nan.  Training acc: 40.99%.
[ Tue Jun 20 03:41:01 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 20 03:41:01 2023 ] Eval epoch: 6
[ Tue Jun 20 03:41:02 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:02 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:02 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:02 2023 ] Training epoch: 7
[ Tue Jun 20 03:41:04 2023 ] 	Training loss: nan.  Training acc: 40.99%.
[ Tue Jun 20 03:41:04 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:41:04 2023 ] Eval epoch: 7
[ Tue Jun 20 03:41:04 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:04 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:04 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:04 2023 ] Training epoch: 8
[ Tue Jun 20 03:41:07 2023 ] 	Training loss: nan.  Training acc: 41.18%.
[ Tue Jun 20 03:41:07 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:41:07 2023 ] Eval epoch: 8
[ Tue Jun 20 03:41:07 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:07 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:07 2023 ] Training epoch: 9
[ Tue Jun 20 03:41:09 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:41:09 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:41:09 2023 ] Eval epoch: 9
[ Tue Jun 20 03:41:10 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:10 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:10 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:10 2023 ] Training epoch: 10
[ Tue Jun 20 03:41:12 2023 ] 	Training loss: nan.  Training acc: 41.36%.
[ Tue Jun 20 03:41:12 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:41:12 2023 ] Eval epoch: 10
[ Tue Jun 20 03:41:12 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:12 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:12 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:12 2023 ] Training epoch: 11
[ Tue Jun 20 03:41:14 2023 ] 	Training loss: nan.  Training acc: 40.72%.
[ Tue Jun 20 03:41:14 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:41:14 2023 ] Eval epoch: 11
[ Tue Jun 20 03:41:15 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:15 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:15 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:15 2023 ] Training epoch: 12
[ Tue Jun 20 03:41:17 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:41:17 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:41:17 2023 ] Eval epoch: 12
[ Tue Jun 20 03:41:17 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:17 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:17 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:17 2023 ] Training epoch: 13
[ Tue Jun 20 03:41:19 2023 ] 	Training loss: nan.  Training acc: 40.35%.
[ Tue Jun 20 03:41:19 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 03:41:19 2023 ] Eval epoch: 13
[ Tue Jun 20 03:41:20 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:20 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:20 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:20 2023 ] Training epoch: 14
[ Tue Jun 20 03:41:22 2023 ] 	Training loss: nan.  Training acc: 40.99%.
[ Tue Jun 20 03:41:22 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:41:22 2023 ] Eval epoch: 14
[ Tue Jun 20 03:41:22 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:22 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:22 2023 ] Training epoch: 15
[ Tue Jun 20 03:41:24 2023 ] 	Training loss: nan.  Training acc: 40.72%.
[ Tue Jun 20 03:41:24 2023 ] 	Time consumption: [Data]17%, [Network]82%
[ Tue Jun 20 03:41:24 2023 ] Eval epoch: 15
[ Tue Jun 20 03:41:25 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:25 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:25 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:25 2023 ] Training epoch: 16
[ Tue Jun 20 03:41:27 2023 ] 	Training loss: nan.  Training acc: 40.72%.
[ Tue Jun 20 03:41:27 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 03:41:27 2023 ] Eval epoch: 16
[ Tue Jun 20 03:41:27 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:27 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:27 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:27 2023 ] Training epoch: 17
[ Tue Jun 20 03:41:29 2023 ] 	Training loss: nan.  Training acc: 40.26%.
[ Tue Jun 20 03:41:29 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 20 03:41:29 2023 ] Eval epoch: 17
[ Tue Jun 20 03:41:30 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:30 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:30 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:30 2023 ] Training epoch: 18
[ Tue Jun 20 03:41:32 2023 ] 	Training loss: nan.  Training acc: 40.99%.
[ Tue Jun 20 03:41:32 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:41:32 2023 ] Eval epoch: 18
[ Tue Jun 20 03:41:32 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:32 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:32 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:32 2023 ] Training epoch: 19
[ Tue Jun 20 03:41:35 2023 ] 	Training loss: nan.  Training acc: 40.35%.
[ Tue Jun 20 03:41:35 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:41:35 2023 ] Eval epoch: 19
[ Tue Jun 20 03:41:35 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:35 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:35 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:35 2023 ] Training epoch: 20
[ Tue Jun 20 03:41:37 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:41:37 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:41:37 2023 ] Eval epoch: 20
[ Tue Jun 20 03:41:38 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:38 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:38 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:38 2023 ] Training epoch: 21
[ Tue Jun 20 03:41:40 2023 ] 	Training loss: nan.  Training acc: 40.35%.
[ Tue Jun 20 03:41:40 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 03:41:40 2023 ] Eval epoch: 21
[ Tue Jun 20 03:41:40 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:40 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:40 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:40 2023 ] Training epoch: 22
[ Tue Jun 20 03:41:42 2023 ] 	Training loss: nan.  Training acc: 40.72%.
[ Tue Jun 20 03:41:42 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 20 03:41:42 2023 ] Eval epoch: 22
[ Tue Jun 20 03:41:43 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:43 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:43 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:43 2023 ] Training epoch: 23
[ Tue Jun 20 03:41:45 2023 ] 	Training loss: nan.  Training acc: 40.44%.
[ Tue Jun 20 03:41:45 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:41:45 2023 ] Eval epoch: 23
[ Tue Jun 20 03:41:45 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:45 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:45 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:45 2023 ] Training epoch: 24
[ Tue Jun 20 03:41:48 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:41:48 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 20 03:41:48 2023 ] Eval epoch: 24
[ Tue Jun 20 03:41:49 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:49 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:49 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:49 2023 ] Training epoch: 25
[ Tue Jun 20 03:41:51 2023 ] 	Training loss: nan.  Training acc: 40.44%.
[ Tue Jun 20 03:41:51 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:41:51 2023 ] Eval epoch: 25
[ Tue Jun 20 03:41:51 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:51 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:51 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:51 2023 ] Training epoch: 26
[ Tue Jun 20 03:41:53 2023 ] 	Training loss: nan.  Training acc: 39.98%.
[ Tue Jun 20 03:41:53 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:41:53 2023 ] Eval epoch: 26
[ Tue Jun 20 03:41:54 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:54 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:54 2023 ] Training epoch: 27
[ Tue Jun 20 03:41:56 2023 ] 	Training loss: nan.  Training acc: 40.99%.
[ Tue Jun 20 03:41:56 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:41:56 2023 ] Eval epoch: 27
[ Tue Jun 20 03:41:56 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:56 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:56 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:56 2023 ] Training epoch: 28
[ Tue Jun 20 03:41:58 2023 ] 	Training loss: nan.  Training acc: 40.53%.
[ Tue Jun 20 03:41:58 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:41:58 2023 ] Eval epoch: 28
[ Tue Jun 20 03:41:59 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:41:59 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:41:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:41:59 2023 ] Training epoch: 29
[ Tue Jun 20 03:42:01 2023 ] 	Training loss: nan.  Training acc: 40.90%.
[ Tue Jun 20 03:42:01 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:42:01 2023 ] Eval epoch: 29
[ Tue Jun 20 03:42:01 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:01 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:01 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:01 2023 ] Training epoch: 30
[ Tue Jun 20 03:42:03 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:42:03 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:42:03 2023 ] Eval epoch: 30
[ Tue Jun 20 03:42:04 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:04 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:04 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:04 2023 ] Training epoch: 31
[ Tue Jun 20 03:42:06 2023 ] 	Training loss: nan.  Training acc: 40.99%.
[ Tue Jun 20 03:42:06 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:42:06 2023 ] Eval epoch: 31
[ Tue Jun 20 03:42:06 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:06 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:06 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:06 2023 ] Training epoch: 32
[ Tue Jun 20 03:42:08 2023 ] 	Training loss: nan.  Training acc: 40.90%.
[ Tue Jun 20 03:42:08 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:42:08 2023 ] Eval epoch: 32
[ Tue Jun 20 03:42:09 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:09 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:09 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:09 2023 ] Training epoch: 33
[ Tue Jun 20 03:42:11 2023 ] 	Training loss: nan.  Training acc: 40.35%.
[ Tue Jun 20 03:42:11 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 03:42:11 2023 ] Eval epoch: 33
[ Tue Jun 20 03:42:11 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:11 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:11 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:11 2023 ] Training epoch: 34
[ Tue Jun 20 03:42:13 2023 ] 	Training loss: nan.  Training acc: 40.99%.
[ Tue Jun 20 03:42:13 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:42:13 2023 ] Eval epoch: 34
[ Tue Jun 20 03:42:14 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:14 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:14 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:14 2023 ] Training epoch: 35
[ Tue Jun 20 03:42:16 2023 ] 	Training loss: nan.  Training acc: 41.45%.
[ Tue Jun 20 03:42:16 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:42:16 2023 ] Eval epoch: 35
[ Tue Jun 20 03:42:16 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:16 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:16 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:16 2023 ] Training epoch: 36
[ Tue Jun 20 03:42:19 2023 ] 	Training loss: nan.  Training acc: 41.27%.
[ Tue Jun 20 03:42:19 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:42:19 2023 ] Eval epoch: 36
[ Tue Jun 20 03:42:19 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:19 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:19 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:19 2023 ] Training epoch: 37
[ Tue Jun 20 03:42:21 2023 ] 	Training loss: nan.  Training acc: 40.44%.
[ Tue Jun 20 03:42:21 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:42:21 2023 ] Eval epoch: 37
[ Tue Jun 20 03:42:22 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:22 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:22 2023 ] Training epoch: 38
[ Tue Jun 20 03:42:24 2023 ] 	Training loss: nan.  Training acc: 41.08%.
[ Tue Jun 20 03:42:24 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 20 03:42:24 2023 ] Eval epoch: 38
[ Tue Jun 20 03:42:24 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:24 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:24 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:24 2023 ] Training epoch: 39
[ Tue Jun 20 03:42:26 2023 ] 	Training loss: nan.  Training acc: 40.26%.
[ Tue Jun 20 03:42:26 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:42:26 2023 ] Eval epoch: 39
[ Tue Jun 20 03:42:27 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:27 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:27 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:27 2023 ] Training epoch: 40
[ Tue Jun 20 03:42:29 2023 ] 	Training loss: nan.  Training acc: 40.26%.
[ Tue Jun 20 03:42:29 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:42:29 2023 ] Eval epoch: 40
[ Tue Jun 20 03:42:29 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:29 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:29 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:29 2023 ] Training epoch: 41
[ Tue Jun 20 03:42:31 2023 ] 	Training loss: nan.  Training acc: 40.72%.
[ Tue Jun 20 03:42:31 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:42:31 2023 ] Eval epoch: 41
[ Tue Jun 20 03:42:32 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:32 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:32 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:32 2023 ] Training epoch: 42
[ Tue Jun 20 03:42:34 2023 ] 	Training loss: nan.  Training acc: 40.35%.
[ Tue Jun 20 03:42:34 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:42:34 2023 ] Eval epoch: 42
[ Tue Jun 20 03:42:34 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:34 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:34 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:34 2023 ] Training epoch: 43
[ Tue Jun 20 03:42:36 2023 ] 	Training loss: nan.  Training acc: 40.53%.
[ Tue Jun 20 03:42:36 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:42:36 2023 ] Eval epoch: 43
[ Tue Jun 20 03:42:37 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:37 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:37 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:37 2023 ] Training epoch: 44
[ Tue Jun 20 03:42:40 2023 ] 	Training loss: nan.  Training acc: 40.53%.
[ Tue Jun 20 03:42:40 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 20 03:42:40 2023 ] Eval epoch: 44
[ Tue Jun 20 03:42:40 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:40 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:40 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:40 2023 ] Training epoch: 45
[ Tue Jun 20 03:42:42 2023 ] 	Training loss: nan.  Training acc: 40.53%.
[ Tue Jun 20 03:42:42 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:42:42 2023 ] Eval epoch: 45
[ Tue Jun 20 03:42:43 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:43 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:43 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:43 2023 ] Training epoch: 46
[ Tue Jun 20 03:42:45 2023 ] 	Training loss: nan.  Training acc: 40.81%.
[ Tue Jun 20 03:42:45 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:42:45 2023 ] Eval epoch: 46
[ Tue Jun 20 03:42:45 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:45 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:45 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:45 2023 ] Training epoch: 47
[ Tue Jun 20 03:42:47 2023 ] 	Training loss: nan.  Training acc: 40.81%.
[ Tue Jun 20 03:42:47 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:42:47 2023 ] Eval epoch: 47
[ Tue Jun 20 03:42:48 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:48 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:48 2023 ] Training epoch: 48
[ Tue Jun 20 03:42:50 2023 ] 	Training loss: nan.  Training acc: 40.26%.
[ Tue Jun 20 03:42:50 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:42:50 2023 ] Eval epoch: 48
[ Tue Jun 20 03:42:50 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:50 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:50 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:50 2023 ] Training epoch: 49
[ Tue Jun 20 03:42:52 2023 ] 	Training loss: nan.  Training acc: 40.81%.
[ Tue Jun 20 03:42:52 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 03:42:52 2023 ] Eval epoch: 49
[ Tue Jun 20 03:42:53 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:53 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:53 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:53 2023 ] Training epoch: 50
[ Tue Jun 20 03:42:55 2023 ] 	Training loss: nan.  Training acc: 40.90%.
[ Tue Jun 20 03:42:55 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:42:55 2023 ] Eval epoch: 50
[ Tue Jun 20 03:42:55 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:55 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:55 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:55 2023 ] Training epoch: 51
[ Tue Jun 20 03:42:57 2023 ] 	Training loss: nan.  Training acc: 40.81%.
[ Tue Jun 20 03:42:57 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:42:57 2023 ] Eval epoch: 51
[ Tue Jun 20 03:42:58 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:42:58 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:42:58 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:42:58 2023 ] Training epoch: 52
[ Tue Jun 20 03:43:00 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:43:00 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:43:00 2023 ] Eval epoch: 52
[ Tue Jun 20 03:43:00 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:00 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:00 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:00 2023 ] Training epoch: 53
[ Tue Jun 20 03:43:02 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:43:02 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:43:02 2023 ] Eval epoch: 53
[ Tue Jun 20 03:43:03 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:03 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:03 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:03 2023 ] Training epoch: 54
[ Tue Jun 20 03:43:05 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:43:05 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 20 03:43:05 2023 ] Eval epoch: 54
[ Tue Jun 20 03:43:05 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:05 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:05 2023 ] Training epoch: 55
[ Tue Jun 20 03:43:07 2023 ] 	Training loss: nan.  Training acc: 40.90%.
[ Tue Jun 20 03:43:07 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:43:07 2023 ] Eval epoch: 55
[ Tue Jun 20 03:43:08 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:08 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:08 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:08 2023 ] Training epoch: 56
[ Tue Jun 20 03:43:10 2023 ] 	Training loss: nan.  Training acc: 40.35%.
[ Tue Jun 20 03:43:10 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:43:10 2023 ] Eval epoch: 56
[ Tue Jun 20 03:43:10 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:10 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:10 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:10 2023 ] Training epoch: 57
[ Tue Jun 20 03:43:13 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:43:13 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:43:13 2023 ] Eval epoch: 57
[ Tue Jun 20 03:43:13 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:13 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:13 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:13 2023 ] Training epoch: 58
[ Tue Jun 20 03:43:15 2023 ] 	Training loss: nan.  Training acc: 41.08%.
[ Tue Jun 20 03:43:15 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:43:15 2023 ] Eval epoch: 58
[ Tue Jun 20 03:43:16 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:16 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:16 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:16 2023 ] Training epoch: 59
[ Tue Jun 20 03:43:18 2023 ] 	Training loss: nan.  Training acc: 40.99%.
[ Tue Jun 20 03:43:18 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:43:18 2023 ] Eval epoch: 59
[ Tue Jun 20 03:43:18 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:18 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:18 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:18 2023 ] Training epoch: 60
[ Tue Jun 20 03:43:20 2023 ] 	Training loss: nan.  Training acc: 41.27%.
[ Tue Jun 20 03:43:20 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:43:20 2023 ] Eval epoch: 60
[ Tue Jun 20 03:43:21 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:21 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:21 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:21 2023 ] Training epoch: 61
[ Tue Jun 20 03:43:23 2023 ] 	Training loss: nan.  Training acc: 40.90%.
[ Tue Jun 20 03:43:23 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 03:43:23 2023 ] Eval epoch: 61
[ Tue Jun 20 03:43:23 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:23 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:23 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:23 2023 ] Training epoch: 62
[ Tue Jun 20 03:43:25 2023 ] 	Training loss: nan.  Training acc: 40.53%.
[ Tue Jun 20 03:43:25 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 03:43:25 2023 ] Eval epoch: 62
[ Tue Jun 20 03:43:26 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:26 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:26 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:26 2023 ] Training epoch: 63
[ Tue Jun 20 03:43:28 2023 ] 	Training loss: nan.  Training acc: 40.53%.
[ Tue Jun 20 03:43:28 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 20 03:43:28 2023 ] Eval epoch: 63
[ Tue Jun 20 03:43:29 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:29 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:29 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:29 2023 ] Training epoch: 64
[ Tue Jun 20 03:43:31 2023 ] 	Training loss: nan.  Training acc: 40.81%.
[ Tue Jun 20 03:43:31 2023 ] 	Time consumption: [Data]12%, [Network]87%
[ Tue Jun 20 03:43:31 2023 ] Eval epoch: 64
[ Tue Jun 20 03:43:32 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:32 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:32 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:32 2023 ] Training epoch: 65
[ Tue Jun 20 03:43:34 2023 ] 	Training loss: nan.  Training acc: 40.90%.
[ Tue Jun 20 03:43:34 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:43:34 2023 ] Eval epoch: 65
[ Tue Jun 20 03:43:34 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:34 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:34 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:34 2023 ] Training epoch: 66
[ Tue Jun 20 03:43:36 2023 ] 	Training loss: nan.  Training acc: 40.35%.
[ Tue Jun 20 03:43:36 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 20 03:43:36 2023 ] Eval epoch: 66
[ Tue Jun 20 03:43:37 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:37 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:37 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:37 2023 ] Training epoch: 67
[ Tue Jun 20 03:43:39 2023 ] 	Training loss: nan.  Training acc: 40.35%.
[ Tue Jun 20 03:43:39 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:43:39 2023 ] Eval epoch: 67
[ Tue Jun 20 03:43:39 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:39 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:39 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:39 2023 ] Training epoch: 68
[ Tue Jun 20 03:43:41 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:43:41 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 03:43:41 2023 ] Eval epoch: 68
[ Tue Jun 20 03:43:42 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:42 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:42 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:42 2023 ] Training epoch: 69
[ Tue Jun 20 03:43:44 2023 ] 	Training loss: nan.  Training acc: 41.08%.
[ Tue Jun 20 03:43:44 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:43:44 2023 ] Eval epoch: 69
[ Tue Jun 20 03:43:44 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:44 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:44 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:44 2023 ] Training epoch: 70
[ Tue Jun 20 03:43:46 2023 ] 	Training loss: nan.  Training acc: 40.81%.
[ Tue Jun 20 03:43:46 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:43:46 2023 ] Eval epoch: 70
[ Tue Jun 20 03:43:47 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:47 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:47 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:47 2023 ] Training epoch: 71
[ Tue Jun 20 03:43:49 2023 ] 	Training loss: nan.  Training acc: 40.90%.
[ Tue Jun 20 03:43:49 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:43:49 2023 ] Eval epoch: 71
[ Tue Jun 20 03:43:49 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:49 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:49 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:49 2023 ] Training epoch: 72
[ Tue Jun 20 03:43:51 2023 ] 	Training loss: nan.  Training acc: 40.99%.
[ Tue Jun 20 03:43:51 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:43:51 2023 ] Eval epoch: 72
[ Tue Jun 20 03:43:52 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:52 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:52 2023 ] Training epoch: 73
[ Tue Jun 20 03:43:54 2023 ] 	Training loss: nan.  Training acc: 40.26%.
[ Tue Jun 20 03:43:54 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:43:54 2023 ] Eval epoch: 73
[ Tue Jun 20 03:43:54 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:54 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:54 2023 ] Training epoch: 74
[ Tue Jun 20 03:43:56 2023 ] 	Training loss: nan.  Training acc: 40.44%.
[ Tue Jun 20 03:43:56 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:43:56 2023 ] Eval epoch: 74
[ Tue Jun 20 03:43:57 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:57 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:57 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:57 2023 ] Training epoch: 75
[ Tue Jun 20 03:43:59 2023 ] 	Training loss: nan.  Training acc: 39.98%.
[ Tue Jun 20 03:43:59 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:43:59 2023 ] Eval epoch: 75
[ Tue Jun 20 03:43:59 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:43:59 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:43:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:43:59 2023 ] Training epoch: 76
[ Tue Jun 20 03:44:01 2023 ] 	Training loss: nan.  Training acc: 40.99%.
[ Tue Jun 20 03:44:01 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:44:01 2023 ] Eval epoch: 76
[ Tue Jun 20 03:44:02 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:02 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:02 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:02 2023 ] Training epoch: 77
[ Tue Jun 20 03:44:04 2023 ] 	Training loss: nan.  Training acc: 40.53%.
[ Tue Jun 20 03:44:04 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 03:44:04 2023 ] Eval epoch: 77
[ Tue Jun 20 03:44:04 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:04 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:04 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:04 2023 ] Training epoch: 78
[ Tue Jun 20 03:44:07 2023 ] 	Training loss: nan.  Training acc: 40.44%.
[ Tue Jun 20 03:44:07 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 20 03:44:07 2023 ] Eval epoch: 78
[ Tue Jun 20 03:44:07 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:07 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:07 2023 ] Training epoch: 79
[ Tue Jun 20 03:44:09 2023 ] 	Training loss: nan.  Training acc: 40.72%.
[ Tue Jun 20 03:44:09 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 20 03:44:09 2023 ] Eval epoch: 79
[ Tue Jun 20 03:44:10 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:10 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:10 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:10 2023 ] Training epoch: 80
[ Tue Jun 20 03:44:12 2023 ] 	Training loss: nan.  Training acc: 40.72%.
[ Tue Jun 20 03:44:12 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:44:12 2023 ] Eval epoch: 80
[ Tue Jun 20 03:44:12 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:12 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:12 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:12 2023 ] Training epoch: 81
[ Tue Jun 20 03:44:14 2023 ] 	Training loss: nan.  Training acc: 40.72%.
[ Tue Jun 20 03:44:14 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 20 03:44:14 2023 ] Eval epoch: 81
[ Tue Jun 20 03:44:15 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:15 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:15 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:15 2023 ] Training epoch: 82
[ Tue Jun 20 03:44:17 2023 ] 	Training loss: nan.  Training acc: 40.90%.
[ Tue Jun 20 03:44:17 2023 ] 	Time consumption: [Data]16%, [Network]83%
[ Tue Jun 20 03:44:17 2023 ] Eval epoch: 82
[ Tue Jun 20 03:44:17 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:17 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:17 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:17 2023 ] Training epoch: 83
[ Tue Jun 20 03:44:20 2023 ] 	Training loss: nan.  Training acc: 40.90%.
[ Tue Jun 20 03:44:20 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 03:44:20 2023 ] Eval epoch: 83
[ Tue Jun 20 03:44:20 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:20 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:20 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:20 2023 ] Training epoch: 84
[ Tue Jun 20 03:44:23 2023 ] 	Training loss: nan.  Training acc: 40.90%.
[ Tue Jun 20 03:44:23 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:44:23 2023 ] Eval epoch: 84
[ Tue Jun 20 03:44:23 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:23 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:23 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:23 2023 ] Training epoch: 85
[ Tue Jun 20 03:44:25 2023 ] 	Training loss: nan.  Training acc: 41.08%.
[ Tue Jun 20 03:44:25 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:44:25 2023 ] Eval epoch: 85
[ Tue Jun 20 03:44:26 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:26 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:26 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:26 2023 ] Training epoch: 86
[ Tue Jun 20 03:44:28 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:44:28 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:44:28 2023 ] Eval epoch: 86
[ Tue Jun 20 03:44:29 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:29 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:29 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:29 2023 ] Training epoch: 87
[ Tue Jun 20 03:44:31 2023 ] 	Training loss: nan.  Training acc: 40.44%.
[ Tue Jun 20 03:44:31 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:44:31 2023 ] Eval epoch: 87
[ Tue Jun 20 03:44:31 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:31 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:31 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:31 2023 ] Training epoch: 88
[ Tue Jun 20 03:44:33 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:44:33 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:44:33 2023 ] Eval epoch: 88
[ Tue Jun 20 03:44:34 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:34 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:34 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:34 2023 ] Training epoch: 89
[ Tue Jun 20 03:44:36 2023 ] 	Training loss: nan.  Training acc: 41.18%.
[ Tue Jun 20 03:44:36 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:44:36 2023 ] Eval epoch: 89
[ Tue Jun 20 03:44:36 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:36 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:36 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:36 2023 ] Training epoch: 90
[ Tue Jun 20 03:44:39 2023 ] 	Training loss: nan.  Training acc: 40.35%.
[ Tue Jun 20 03:44:39 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:44:39 2023 ] Eval epoch: 90
[ Tue Jun 20 03:44:39 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:39 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:39 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:39 2023 ] Training epoch: 91
[ Tue Jun 20 03:44:41 2023 ] 	Training loss: nan.  Training acc: 40.53%.
[ Tue Jun 20 03:44:41 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 20 03:44:41 2023 ] Eval epoch: 91
[ Tue Jun 20 03:44:42 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:42 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:42 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:42 2023 ] Training epoch: 92
[ Tue Jun 20 03:44:44 2023 ] 	Training loss: nan.  Training acc: 41.08%.
[ Tue Jun 20 03:44:44 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:44:44 2023 ] Eval epoch: 92
[ Tue Jun 20 03:44:44 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:44 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:44 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:44 2023 ] Training epoch: 93
[ Tue Jun 20 03:44:46 2023 ] 	Training loss: nan.  Training acc: 40.90%.
[ Tue Jun 20 03:44:46 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:44:46 2023 ] Eval epoch: 93
[ Tue Jun 20 03:44:47 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:47 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:47 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:47 2023 ] Training epoch: 94
[ Tue Jun 20 03:44:49 2023 ] 	Training loss: nan.  Training acc: 40.81%.
[ Tue Jun 20 03:44:49 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:44:49 2023 ] Eval epoch: 94
[ Tue Jun 20 03:44:49 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:49 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:49 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:49 2023 ] Training epoch: 95
[ Tue Jun 20 03:44:51 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:44:51 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:44:51 2023 ] Eval epoch: 95
[ Tue Jun 20 03:44:52 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:52 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:52 2023 ] Training epoch: 96
[ Tue Jun 20 03:44:54 2023 ] 	Training loss: nan.  Training acc: 40.90%.
[ Tue Jun 20 03:44:54 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:44:54 2023 ] Eval epoch: 96
[ Tue Jun 20 03:44:54 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:54 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:54 2023 ] Training epoch: 97
[ Tue Jun 20 03:44:56 2023 ] 	Training loss: nan.  Training acc: 40.90%.
[ Tue Jun 20 03:44:56 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:44:56 2023 ] Eval epoch: 97
[ Tue Jun 20 03:44:57 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:57 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:57 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:57 2023 ] Training epoch: 98
[ Tue Jun 20 03:44:59 2023 ] 	Training loss: nan.  Training acc: 41.27%.
[ Tue Jun 20 03:44:59 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 03:44:59 2023 ] Eval epoch: 98
[ Tue Jun 20 03:44:59 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:44:59 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:44:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:44:59 2023 ] Training epoch: 99
[ Tue Jun 20 03:45:01 2023 ] 	Training loss: nan.  Training acc: 40.53%.
[ Tue Jun 20 03:45:01 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:45:01 2023 ] Eval epoch: 99
[ Tue Jun 20 03:45:02 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:45:02 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:45:02 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:45:02 2023 ] Training epoch: 100
[ Tue Jun 20 03:45:04 2023 ] 	Training loss: nan.  Training acc: 40.81%.
[ Tue Jun 20 03:45:04 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:45:04 2023 ] Eval epoch: 100
[ Tue Jun 20 03:45:05 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:45:05 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:45:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:45:05 2023 ] Training epoch: 101
[ Tue Jun 20 03:45:07 2023 ] 	Training loss: nan.  Training acc: 40.72%.
[ Tue Jun 20 03:45:07 2023 ] 	Time consumption: [Data]19%, [Network]81%
[ Tue Jun 20 03:45:07 2023 ] Eval epoch: 101
[ Tue Jun 20 03:45:07 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:45:07 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:45:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:45:07 2023 ] Training epoch: 102
[ Tue Jun 20 03:45:09 2023 ] 	Training loss: nan.  Training acc: 40.26%.
[ Tue Jun 20 03:45:09 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 20 03:45:09 2023 ] Eval epoch: 102
[ Tue Jun 20 03:45:10 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:45:10 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:45:10 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:45:10 2023 ] Training epoch: 103
[ Tue Jun 20 03:45:13 2023 ] 	Training loss: nan.  Training acc: 40.99%.
[ Tue Jun 20 03:45:13 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 03:45:13 2023 ] Eval epoch: 103
[ Tue Jun 20 03:45:13 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:45:13 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:45:13 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:45:13 2023 ] Training epoch: 104
[ Tue Jun 20 03:45:15 2023 ] 	Training loss: nan.  Training acc: 40.62%.
[ Tue Jun 20 03:45:15 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:45:15 2023 ] Eval epoch: 104
[ Tue Jun 20 03:45:16 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:45:16 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:45:16 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:45:16 2023 ] Training epoch: 105
[ Tue Jun 20 03:45:18 2023 ] 	Training loss: nan.  Training acc: 41.08%.
[ Tue Jun 20 03:45:18 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:45:18 2023 ] Eval epoch: 105
[ Tue Jun 20 03:45:18 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:45:18 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:45:18 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:45:18 2023 ] Training epoch: 106
[ Tue Jun 20 03:45:20 2023 ] 	Training loss: nan.  Training acc: 41.27%.
[ Tue Jun 20 03:45:20 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:45:20 2023 ] Eval epoch: 106
[ Tue Jun 20 03:45:21 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:45:21 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:45:21 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:45:21 2023 ] Training epoch: 107
[ Tue Jun 20 03:45:23 2023 ] 	Training loss: nan.  Training acc: 40.81%.
[ Tue Jun 20 03:45:23 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 03:45:23 2023 ] Eval epoch: 107
[ Tue Jun 20 03:45:24 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:45:24 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:45:24 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:45:24 2023 ] Training epoch: 108
[ Tue Jun 20 03:45:26 2023 ] 	Training loss: nan.  Training acc: 41.08%.
[ Tue Jun 20 03:45:26 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:45:26 2023 ] Eval epoch: 108
[ Tue Jun 20 03:45:26 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:45:26 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:45:26 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:45:26 2023 ] Training epoch: 109
[ Tue Jun 20 03:45:28 2023 ] 	Training loss: nan.  Training acc: 39.89%.
[ Tue Jun 20 03:45:28 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:45:28 2023 ] Eval epoch: 109
[ Tue Jun 20 03:45:29 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:45:29 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:45:29 2023 ] 	Top5: 100.00%
[ Tue Jun 20 03:45:29 2023 ] Training epoch: 110
[ Tue Jun 20 03:45:31 2023 ] 	Training loss: nan.  Training acc: 40.81%.
[ Tue Jun 20 03:45:31 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 03:45:31 2023 ] Eval epoch: 110
[ Tue Jun 20 03:45:32 2023 ] 	Mean test loss of 625 batches:  nan.
[ Tue Jun 20 03:45:32 2023 ] 	Top1: 29.82%
[ Tue Jun 20 03:45:32 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:04:22 2023 ] using warm up, epoch: 5
[ Tue Jun 20 04:04:24 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 04:04:24 2023 ] # Parameters: 1538958
[ Tue Jun 20 04:04:24 2023 ] Training epoch: 1
[ Tue Jun 20 04:04:29 2023 ] 	Training loss: 86.4442.  Training acc: 33.92%.
[ Tue Jun 20 04:04:29 2023 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jun 20 04:04:29 2023 ] Eval epoch: 1
[ Tue Jun 20 04:04:30 2023 ] 	Mean test loss of 625 batches: 385.885071.
[ Tue Jun 20 04:04:30 2023 ] 	Top1: 38.60%
[ Tue Jun 20 04:04:30 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:04:30 2023 ] Training epoch: 2
[ Tue Jun 20 04:04:32 2023 ] 	Training loss: 7.3057.  Training acc: 45.68%.
[ Tue Jun 20 04:04:32 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:04:32 2023 ] Eval epoch: 2
[ Tue Jun 20 04:04:32 2023 ] 	Mean test loss of 625 batches: 61.084519.
[ Tue Jun 20 04:04:32 2023 ] 	Top1: 38.60%
[ Tue Jun 20 04:04:32 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:04:32 2023 ] Training epoch: 3
[ Tue Jun 20 04:04:34 2023 ] 	Training loss: 4.3350.  Training acc: 58.00%.
[ Tue Jun 20 04:04:34 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:04:34 2023 ] Eval epoch: 3
[ Tue Jun 20 04:04:34 2023 ] 	Mean test loss of 625 batches: 2.918621.
[ Tue Jun 20 04:04:34 2023 ] 	Top1: 68.42%
[ Tue Jun 20 04:04:34 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:04:34 2023 ] Training epoch: 4
[ Tue Jun 20 04:04:36 2023 ] 	Training loss: 2.6295.  Training acc: 69.85%.
[ Tue Jun 20 04:04:36 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:04:36 2023 ] Eval epoch: 4
[ Tue Jun 20 04:04:36 2023 ] 	Mean test loss of 625 batches: 0.815415.
[ Tue Jun 20 04:04:36 2023 ] 	Top1: 89.47%
[ Tue Jun 20 04:04:36 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:04:36 2023 ] Training epoch: 5
[ Tue Jun 20 04:04:38 2023 ] 	Training loss: 3.5846.  Training acc: 69.76%.
[ Tue Jun 20 04:04:38 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:04:38 2023 ] Eval epoch: 5
[ Tue Jun 20 04:04:39 2023 ] 	Mean test loss of 625 batches: 16.362006.
[ Tue Jun 20 04:04:39 2023 ] 	Top1: 29.82%
[ Tue Jun 20 04:04:39 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:04:39 2023 ] Training epoch: 6
[ Tue Jun 20 04:04:40 2023 ] 	Training loss: 1.9698.  Training acc: 71.32%.
[ Tue Jun 20 04:04:40 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Tue Jun 20 04:04:40 2023 ] Eval epoch: 6
[ Tue Jun 20 04:04:41 2023 ] 	Mean test loss of 625 batches: 3.732164.
[ Tue Jun 20 04:04:41 2023 ] 	Top1: 52.63%
[ Tue Jun 20 04:04:41 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:04:41 2023 ] Training epoch: 7
[ Tue Jun 20 04:04:43 2023 ] 	Training loss: 1.5406.  Training acc: 72.61%.
[ Tue Jun 20 04:04:43 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:04:43 2023 ] Eval epoch: 7
[ Tue Jun 20 04:04:43 2023 ] 	Mean test loss of 625 batches: 0.529710.
[ Tue Jun 20 04:04:43 2023 ] 	Top1: 92.98%
[ Tue Jun 20 04:04:43 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:04:43 2023 ] Training epoch: 8
[ Tue Jun 20 04:04:45 2023 ] 	Training loss: 1.0289.  Training acc: 85.02%.
[ Tue Jun 20 04:04:45 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:04:45 2023 ] Eval epoch: 8
[ Tue Jun 20 04:04:45 2023 ] 	Mean test loss of 625 batches: 2.069841.
[ Tue Jun 20 04:04:45 2023 ] 	Top1: 68.42%
[ Tue Jun 20 04:04:45 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:04:45 2023 ] Training epoch: 9
[ Tue Jun 20 04:04:47 2023 ] 	Training loss: 0.7284.  Training acc: 88.51%.
[ Tue Jun 20 04:04:47 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Tue Jun 20 04:04:47 2023 ] Eval epoch: 9
[ Tue Jun 20 04:04:47 2023 ] 	Mean test loss of 625 batches: 0.497185.
[ Tue Jun 20 04:04:47 2023 ] 	Top1: 89.47%
[ Tue Jun 20 04:04:47 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:04:47 2023 ] Training epoch: 10
[ Tue Jun 20 04:04:49 2023 ] 	Training loss: 0.8903.  Training acc: 83.73%.
[ Tue Jun 20 04:04:49 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:04:49 2023 ] Eval epoch: 10
[ Tue Jun 20 04:04:50 2023 ] 	Mean test loss of 625 batches: 1.191134.
[ Tue Jun 20 04:04:50 2023 ] 	Top1: 75.44%
[ Tue Jun 20 04:04:50 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:04:50 2023 ] Training epoch: 11
[ Tue Jun 20 04:04:51 2023 ] 	Training loss: 0.8469.  Training acc: 89.89%.
[ Tue Jun 20 04:04:51 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:04:51 2023 ] Eval epoch: 11
[ Tue Jun 20 04:04:52 2023 ] 	Mean test loss of 625 batches: 0.662342.
[ Tue Jun 20 04:04:52 2023 ] 	Top1: 89.47%
[ Tue Jun 20 04:04:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:04:52 2023 ] Training epoch: 12
[ Tue Jun 20 04:04:54 2023 ] 	Training loss: 0.6560.  Training acc: 91.82%.
[ Tue Jun 20 04:04:54 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:04:54 2023 ] Eval epoch: 12
[ Tue Jun 20 04:04:54 2023 ] 	Mean test loss of 625 batches: 0.506475.
[ Tue Jun 20 04:04:54 2023 ] 	Top1: 94.74%
[ Tue Jun 20 04:04:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:04:54 2023 ] Training epoch: 13
[ Tue Jun 20 04:04:56 2023 ] 	Training loss: 0.4635.  Training acc: 95.40%.
[ Tue Jun 20 04:04:56 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:04:56 2023 ] Eval epoch: 13
[ Tue Jun 20 04:04:56 2023 ] 	Mean test loss of 625 batches: 1.113424.
[ Tue Jun 20 04:04:56 2023 ] 	Top1: 50.88%
[ Tue Jun 20 04:04:56 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:04:56 2023 ] Training epoch: 14
[ Tue Jun 20 04:04:58 2023 ] 	Training loss: 0.3945.  Training acc: 98.16%.
[ Tue Jun 20 04:04:58 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:04:58 2023 ] Eval epoch: 14
[ Tue Jun 20 04:04:58 2023 ] 	Mean test loss of 625 batches: 0.737526.
[ Tue Jun 20 04:04:58 2023 ] 	Top1: 68.42%
[ Tue Jun 20 04:04:58 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:04:58 2023 ] Training epoch: 15
[ Tue Jun 20 04:05:00 2023 ] 	Training loss: 0.4127.  Training acc: 97.15%.
[ Tue Jun 20 04:05:00 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:05:00 2023 ] Eval epoch: 15
[ Tue Jun 20 04:05:00 2023 ] 	Mean test loss of 625 batches: 1.286552.
[ Tue Jun 20 04:05:00 2023 ] 	Top1: 49.12%
[ Tue Jun 20 04:05:00 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:00 2023 ] Training epoch: 16
[ Tue Jun 20 04:05:02 2023 ] 	Training loss: 0.4192.  Training acc: 97.61%.
[ Tue Jun 20 04:05:02 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:05:02 2023 ] Eval epoch: 16
[ Tue Jun 20 04:05:02 2023 ] 	Mean test loss of 625 batches: 0.416326.
[ Tue Jun 20 04:05:02 2023 ] 	Top1: 96.49%
[ Tue Jun 20 04:05:02 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:02 2023 ] Training epoch: 17
[ Tue Jun 20 04:05:04 2023 ] 	Training loss: 1.5464.  Training acc: 87.59%.
[ Tue Jun 20 04:05:04 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 20 04:05:04 2023 ] Eval epoch: 17
[ Tue Jun 20 04:05:05 2023 ] 	Mean test loss of 625 batches: 2.797327.
[ Tue Jun 20 04:05:05 2023 ] 	Top1: 42.11%
[ Tue Jun 20 04:05:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:05 2023 ] Training epoch: 18
[ Tue Jun 20 04:05:06 2023 ] 	Training loss: 0.7945.  Training acc: 85.94%.
[ Tue Jun 20 04:05:06 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:05:06 2023 ] Eval epoch: 18
[ Tue Jun 20 04:05:07 2023 ] 	Mean test loss of 625 batches: 1.546889.
[ Tue Jun 20 04:05:07 2023 ] 	Top1: 70.18%
[ Tue Jun 20 04:05:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:07 2023 ] Training epoch: 19
[ Tue Jun 20 04:05:09 2023 ] 	Training loss: 0.6218.  Training acc: 86.95%.
[ Tue Jun 20 04:05:09 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:05:09 2023 ] Eval epoch: 19
[ Tue Jun 20 04:05:09 2023 ] 	Mean test loss of 625 batches: 0.711184.
[ Tue Jun 20 04:05:09 2023 ] 	Top1: 80.70%
[ Tue Jun 20 04:05:09 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:09 2023 ] Training epoch: 20
[ Tue Jun 20 04:05:11 2023 ] 	Training loss: 0.5891.  Training acc: 90.62%.
[ Tue Jun 20 04:05:11 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:05:11 2023 ] Eval epoch: 20
[ Tue Jun 20 04:05:11 2023 ] 	Mean test loss of 625 batches: 0.599639.
[ Tue Jun 20 04:05:11 2023 ] 	Top1: 70.18%
[ Tue Jun 20 04:05:11 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:11 2023 ] Training epoch: 21
[ Tue Jun 20 04:05:13 2023 ] 	Training loss: 0.4045.  Training acc: 96.78%.
[ Tue Jun 20 04:05:13 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:05:13 2023 ] Eval epoch: 21
[ Tue Jun 20 04:05:13 2023 ] 	Mean test loss of 625 batches: 0.559269.
[ Tue Jun 20 04:05:13 2023 ] 	Top1: 87.72%
[ Tue Jun 20 04:05:13 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:13 2023 ] Training epoch: 22
[ Tue Jun 20 04:05:15 2023 ] 	Training loss: 0.4792.  Training acc: 94.94%.
[ Tue Jun 20 04:05:15 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Tue Jun 20 04:05:15 2023 ] Eval epoch: 22
[ Tue Jun 20 04:05:15 2023 ] 	Mean test loss of 625 batches: 1.361655.
[ Tue Jun 20 04:05:15 2023 ] 	Top1: 54.39%
[ Tue Jun 20 04:05:15 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:15 2023 ] Training epoch: 23
[ Tue Jun 20 04:05:17 2023 ] 	Training loss: 0.4165.  Training acc: 96.23%.
[ Tue Jun 20 04:05:17 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:05:17 2023 ] Eval epoch: 23
[ Tue Jun 20 04:05:18 2023 ] 	Mean test loss of 625 batches: 0.464516.
[ Tue Jun 20 04:05:18 2023 ] 	Top1: 87.72%
[ Tue Jun 20 04:05:18 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:18 2023 ] Training epoch: 24
[ Tue Jun 20 04:05:19 2023 ] 	Training loss: 0.3679.  Training acc: 98.35%.
[ Tue Jun 20 04:05:19 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:05:19 2023 ] Eval epoch: 24
[ Tue Jun 20 04:05:20 2023 ] 	Mean test loss of 625 batches: 0.670284.
[ Tue Jun 20 04:05:20 2023 ] 	Top1: 78.95%
[ Tue Jun 20 04:05:20 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:20 2023 ] Training epoch: 25
[ Tue Jun 20 04:05:22 2023 ] 	Training loss: 0.3580.  Training acc: 98.53%.
[ Tue Jun 20 04:05:22 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:05:22 2023 ] Eval epoch: 25
[ Tue Jun 20 04:05:22 2023 ] 	Mean test loss of 625 batches: 1.177305.
[ Tue Jun 20 04:05:22 2023 ] 	Top1: 35.09%
[ Tue Jun 20 04:05:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:22 2023 ] Training epoch: 26
[ Tue Jun 20 04:05:24 2023 ] 	Training loss: 0.3440.  Training acc: 99.36%.
[ Tue Jun 20 04:05:24 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:05:24 2023 ] Eval epoch: 26
[ Tue Jun 20 04:05:24 2023 ] 	Mean test loss of 625 batches: 0.737135.
[ Tue Jun 20 04:05:24 2023 ] 	Top1: 49.12%
[ Tue Jun 20 04:05:24 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:24 2023 ] Training epoch: 27
[ Tue Jun 20 04:05:26 2023 ] 	Training loss: 0.3483.  Training acc: 99.26%.
[ Tue Jun 20 04:05:26 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:05:26 2023 ] Eval epoch: 27
[ Tue Jun 20 04:05:26 2023 ] 	Mean test loss of 625 batches: 0.547334.
[ Tue Jun 20 04:05:26 2023 ] 	Top1: 85.96%
[ Tue Jun 20 04:05:26 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:26 2023 ] Training epoch: 28
[ Tue Jun 20 04:05:28 2023 ] 	Training loss: 0.3651.  Training acc: 98.81%.
[ Tue Jun 20 04:05:28 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:05:28 2023 ] Eval epoch: 28
[ Tue Jun 20 04:05:29 2023 ] 	Mean test loss of 625 batches: 0.411198.
[ Tue Jun 20 04:05:29 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:05:29 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:29 2023 ] Training epoch: 29
[ Tue Jun 20 04:05:30 2023 ] 	Training loss: 0.3467.  Training acc: 99.26%.
[ Tue Jun 20 04:05:30 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:05:30 2023 ] Eval epoch: 29
[ Tue Jun 20 04:05:31 2023 ] 	Mean test loss of 625 batches: 0.551693.
[ Tue Jun 20 04:05:31 2023 ] 	Top1: 85.96%
[ Tue Jun 20 04:05:31 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:31 2023 ] Training epoch: 30
[ Tue Jun 20 04:05:33 2023 ] 	Training loss: 0.4158.  Training acc: 96.88%.
[ Tue Jun 20 04:05:33 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:05:33 2023 ] Eval epoch: 30
[ Tue Jun 20 04:05:33 2023 ] 	Mean test loss of 625 batches: 0.412693.
[ Tue Jun 20 04:05:33 2023 ] 	Top1: 92.98%
[ Tue Jun 20 04:05:33 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:33 2023 ] Training epoch: 31
[ Tue Jun 20 04:05:35 2023 ] 	Training loss: 0.3653.  Training acc: 98.25%.
[ Tue Jun 20 04:05:35 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:05:35 2023 ] Eval epoch: 31
[ Tue Jun 20 04:05:35 2023 ] 	Mean test loss of 625 batches: 0.676714.
[ Tue Jun 20 04:05:35 2023 ] 	Top1: 75.44%
[ Tue Jun 20 04:05:35 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:35 2023 ] Training epoch: 32
[ Tue Jun 20 04:05:37 2023 ] 	Training loss: 0.3546.  Training acc: 99.36%.
[ Tue Jun 20 04:05:37 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:05:37 2023 ] Eval epoch: 32
[ Tue Jun 20 04:05:37 2023 ] 	Mean test loss of 625 batches: 0.641900.
[ Tue Jun 20 04:05:37 2023 ] 	Top1: 82.46%
[ Tue Jun 20 04:05:37 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:37 2023 ] Training epoch: 33
[ Tue Jun 20 04:05:39 2023 ] 	Training loss: 0.3489.  Training acc: 98.81%.
[ Tue Jun 20 04:05:39 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:05:39 2023 ] Eval epoch: 33
[ Tue Jun 20 04:05:39 2023 ] 	Mean test loss of 625 batches: 0.381852.
[ Tue Jun 20 04:05:39 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:05:39 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:39 2023 ] Training epoch: 34
[ Tue Jun 20 04:05:41 2023 ] 	Training loss: 1.0474.  Training acc: 80.42%.
[ Tue Jun 20 04:05:41 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:05:41 2023 ] Eval epoch: 34
[ Tue Jun 20 04:05:42 2023 ] 	Mean test loss of 625 batches: 9.190195.
[ Tue Jun 20 04:05:42 2023 ] 	Top1: 57.89%
[ Tue Jun 20 04:05:42 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:42 2023 ] Training epoch: 35
[ Tue Jun 20 04:05:43 2023 ] 	Training loss: 0.5937.  Training acc: 91.08%.
[ Tue Jun 20 04:05:43 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:05:43 2023 ] Eval epoch: 35
[ Tue Jun 20 04:05:44 2023 ] 	Mean test loss of 625 batches: 0.482215.
[ Tue Jun 20 04:05:44 2023 ] 	Top1: 92.98%
[ Tue Jun 20 04:05:44 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:44 2023 ] Training epoch: 36
[ Tue Jun 20 04:05:46 2023 ] 	Training loss: 0.3936.  Training acc: 97.52%.
[ Tue Jun 20 04:05:46 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Tue Jun 20 04:05:46 2023 ] Eval epoch: 36
[ Tue Jun 20 04:05:46 2023 ] 	Mean test loss of 625 batches: 0.372692.
[ Tue Jun 20 04:05:46 2023 ] 	Top1: 96.49%
[ Tue Jun 20 04:05:46 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:46 2023 ] Training epoch: 37
[ Tue Jun 20 04:05:48 2023 ] 	Training loss: 0.3752.  Training acc: 97.52%.
[ Tue Jun 20 04:05:48 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Tue Jun 20 04:05:48 2023 ] Eval epoch: 37
[ Tue Jun 20 04:05:48 2023 ] 	Mean test loss of 625 batches: 0.495931.
[ Tue Jun 20 04:05:48 2023 ] 	Top1: 85.96%
[ Tue Jun 20 04:05:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:48 2023 ] Training epoch: 38
[ Tue Jun 20 04:05:50 2023 ] 	Training loss: 0.3371.  Training acc: 99.54%.
[ Tue Jun 20 04:05:50 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Tue Jun 20 04:05:50 2023 ] Eval epoch: 38
[ Tue Jun 20 04:05:50 2023 ] 	Mean test loss of 625 batches: 0.800933.
[ Tue Jun 20 04:05:50 2023 ] 	Top1: 71.93%
[ Tue Jun 20 04:05:50 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:50 2023 ] Training epoch: 39
[ Tue Jun 20 04:05:52 2023 ] 	Training loss: 0.3160.  Training acc: 99.91%.
[ Tue Jun 20 04:05:52 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:05:52 2023 ] Eval epoch: 39
[ Tue Jun 20 04:05:53 2023 ] 	Mean test loss of 625 batches: 0.876893.
[ Tue Jun 20 04:05:53 2023 ] 	Top1: 40.35%
[ Tue Jun 20 04:05:53 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:53 2023 ] Training epoch: 40
[ Tue Jun 20 04:05:54 2023 ] 	Training loss: 0.3126.  Training acc: 99.91%.
[ Tue Jun 20 04:05:54 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:05:54 2023 ] Eval epoch: 40
[ Tue Jun 20 04:05:55 2023 ] 	Mean test loss of 625 batches: 0.933924.
[ Tue Jun 20 04:05:55 2023 ] 	Top1: 49.12%
[ Tue Jun 20 04:05:55 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:55 2023 ] Training epoch: 41
[ Tue Jun 20 04:05:56 2023 ] 	Training loss: 0.3134.  Training acc: 99.63%.
[ Tue Jun 20 04:05:56 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:05:57 2023 ] Eval epoch: 41
[ Tue Jun 20 04:05:57 2023 ] 	Mean test loss of 625 batches: 0.362431.
[ Tue Jun 20 04:05:57 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:05:57 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:57 2023 ] Training epoch: 42
[ Tue Jun 20 04:05:59 2023 ] 	Training loss: 0.3082.  Training acc: 100.00%.
[ Tue Jun 20 04:05:59 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:05:59 2023 ] Eval epoch: 42
[ Tue Jun 20 04:05:59 2023 ] 	Mean test loss of 625 batches: 0.577831.
[ Tue Jun 20 04:05:59 2023 ] 	Top1: 82.46%
[ Tue Jun 20 04:05:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:05:59 2023 ] Training epoch: 43
[ Tue Jun 20 04:06:01 2023 ] 	Training loss: 0.3101.  Training acc: 99.82%.
[ Tue Jun 20 04:06:01 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:06:01 2023 ] Eval epoch: 43
[ Tue Jun 20 04:06:01 2023 ] 	Mean test loss of 625 batches: 0.562004.
[ Tue Jun 20 04:06:01 2023 ] 	Top1: 80.70%
[ Tue Jun 20 04:06:01 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:01 2023 ] Training epoch: 44
[ Tue Jun 20 04:06:03 2023 ] 	Training loss: 0.3263.  Training acc: 99.26%.
[ Tue Jun 20 04:06:03 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:06:03 2023 ] Eval epoch: 44
[ Tue Jun 20 04:06:03 2023 ] 	Mean test loss of 625 batches: 0.744989.
[ Tue Jun 20 04:06:03 2023 ] 	Top1: 75.44%
[ Tue Jun 20 04:06:03 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:03 2023 ] Training epoch: 45
[ Tue Jun 20 04:06:05 2023 ] 	Training loss: 0.3216.  Training acc: 99.36%.
[ Tue Jun 20 04:06:05 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:06:05 2023 ] Eval epoch: 45
[ Tue Jun 20 04:06:06 2023 ] 	Mean test loss of 625 batches: 0.352013.
[ Tue Jun 20 04:06:06 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:06:06 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:06 2023 ] Training epoch: 46
[ Tue Jun 20 04:06:07 2023 ] 	Training loss: 0.3135.  Training acc: 99.63%.
[ Tue Jun 20 04:06:07 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:06:07 2023 ] Eval epoch: 46
[ Tue Jun 20 04:06:08 2023 ] 	Mean test loss of 625 batches: 0.528902.
[ Tue Jun 20 04:06:08 2023 ] 	Top1: 84.21%
[ Tue Jun 20 04:06:08 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:08 2023 ] Training epoch: 47
[ Tue Jun 20 04:06:10 2023 ] 	Training loss: 0.3194.  Training acc: 100.00%.
[ Tue Jun 20 04:06:10 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:06:10 2023 ] Eval epoch: 47
[ Tue Jun 20 04:06:10 2023 ] 	Mean test loss of 625 batches: 0.960247.
[ Tue Jun 20 04:06:10 2023 ] 	Top1: 43.86%
[ Tue Jun 20 04:06:10 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:10 2023 ] Training epoch: 48
[ Tue Jun 20 04:06:12 2023 ] 	Training loss: 0.3108.  Training acc: 99.82%.
[ Tue Jun 20 04:06:12 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:06:12 2023 ] Eval epoch: 48
[ Tue Jun 20 04:06:12 2023 ] 	Mean test loss of 625 batches: 0.759052.
[ Tue Jun 20 04:06:12 2023 ] 	Top1: 47.37%
[ Tue Jun 20 04:06:12 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:12 2023 ] Training epoch: 49
[ Tue Jun 20 04:06:14 2023 ] 	Training loss: 0.3117.  Training acc: 99.91%.
[ Tue Jun 20 04:06:14 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:06:14 2023 ] Eval epoch: 49
[ Tue Jun 20 04:06:14 2023 ] 	Mean test loss of 625 batches: 0.384255.
[ Tue Jun 20 04:06:14 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:06:14 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:14 2023 ] Training epoch: 50
[ Tue Jun 20 04:06:16 2023 ] 	Training loss: 0.3088.  Training acc: 99.91%.
[ Tue Jun 20 04:06:16 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:06:16 2023 ] Eval epoch: 50
[ Tue Jun 20 04:06:17 2023 ] 	Mean test loss of 625 batches: 0.437214.
[ Tue Jun 20 04:06:17 2023 ] 	Top1: 92.98%
[ Tue Jun 20 04:06:17 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:17 2023 ] Training epoch: 51
[ Tue Jun 20 04:06:18 2023 ] 	Training loss: 0.3061.  Training acc: 99.91%.
[ Tue Jun 20 04:06:18 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:06:18 2023 ] Eval epoch: 51
[ Tue Jun 20 04:06:19 2023 ] 	Mean test loss of 625 batches: 0.321431.
[ Tue Jun 20 04:06:19 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:06:19 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:19 2023 ] Training epoch: 52
[ Tue Jun 20 04:06:21 2023 ] 	Training loss: 0.3488.  Training acc: 98.35%.
[ Tue Jun 20 04:06:21 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:06:21 2023 ] Eval epoch: 52
[ Tue Jun 20 04:06:21 2023 ] 	Mean test loss of 625 batches: 0.359547.
[ Tue Jun 20 04:06:21 2023 ] 	Top1: 96.49%
[ Tue Jun 20 04:06:21 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:21 2023 ] Training epoch: 53
[ Tue Jun 20 04:06:23 2023 ] 	Training loss: 0.3311.  Training acc: 99.17%.
[ Tue Jun 20 04:06:23 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:06:23 2023 ] Eval epoch: 53
[ Tue Jun 20 04:06:23 2023 ] 	Mean test loss of 625 batches: 0.305563.
[ Tue Jun 20 04:06:23 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:06:23 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:23 2023 ] Training epoch: 54
[ Tue Jun 20 04:06:25 2023 ] 	Training loss: 0.3225.  Training acc: 99.63%.
[ Tue Jun 20 04:06:25 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:06:25 2023 ] Eval epoch: 54
[ Tue Jun 20 04:06:25 2023 ] 	Mean test loss of 625 batches: 0.449530.
[ Tue Jun 20 04:06:25 2023 ] 	Top1: 96.49%
[ Tue Jun 20 04:06:25 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:25 2023 ] Training epoch: 55
[ Tue Jun 20 04:06:27 2023 ] 	Training loss: 0.3132.  Training acc: 99.91%.
[ Tue Jun 20 04:06:27 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:06:27 2023 ] Eval epoch: 55
[ Tue Jun 20 04:06:28 2023 ] 	Mean test loss of 625 batches: 0.554034.
[ Tue Jun 20 04:06:28 2023 ] 	Top1: 82.46%
[ Tue Jun 20 04:06:28 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:28 2023 ] Training epoch: 56
[ Tue Jun 20 04:06:29 2023 ] 	Training loss: 0.3089.  Training acc: 99.82%.
[ Tue Jun 20 04:06:29 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:06:29 2023 ] Eval epoch: 56
[ Tue Jun 20 04:06:30 2023 ] 	Mean test loss of 625 batches: 0.459579.
[ Tue Jun 20 04:06:30 2023 ] 	Top1: 94.74%
[ Tue Jun 20 04:06:30 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:30 2023 ] Training epoch: 57
[ Tue Jun 20 04:06:32 2023 ] 	Training loss: 0.3087.  Training acc: 99.82%.
[ Tue Jun 20 04:06:32 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:06:32 2023 ] Eval epoch: 57
[ Tue Jun 20 04:06:32 2023 ] 	Mean test loss of 625 batches: 0.677957.
[ Tue Jun 20 04:06:32 2023 ] 	Top1: 75.44%
[ Tue Jun 20 04:06:32 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:32 2023 ] Training epoch: 58
[ Tue Jun 20 04:06:34 2023 ] 	Training loss: 0.3037.  Training acc: 100.00%.
[ Tue Jun 20 04:06:34 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:06:34 2023 ] Eval epoch: 58
[ Tue Jun 20 04:06:34 2023 ] 	Mean test loss of 625 batches: 0.450685.
[ Tue Jun 20 04:06:34 2023 ] 	Top1: 89.47%
[ Tue Jun 20 04:06:34 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:34 2023 ] Training epoch: 59
[ Tue Jun 20 04:06:36 2023 ] 	Training loss: 0.3045.  Training acc: 99.82%.
[ Tue Jun 20 04:06:36 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:06:36 2023 ] Eval epoch: 59
[ Tue Jun 20 04:06:36 2023 ] 	Mean test loss of 625 batches: 0.767269.
[ Tue Jun 20 04:06:36 2023 ] 	Top1: 49.12%
[ Tue Jun 20 04:06:36 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:36 2023 ] Training epoch: 60
[ Tue Jun 20 04:06:38 2023 ] 	Training loss: 0.3152.  Training acc: 99.17%.
[ Tue Jun 20 04:06:38 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:06:38 2023 ] Eval epoch: 60
[ Tue Jun 20 04:06:38 2023 ] 	Mean test loss of 625 batches: 0.316659.
[ Tue Jun 20 04:06:38 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:06:38 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:38 2023 ] Training epoch: 61
[ Tue Jun 20 04:06:40 2023 ] 	Training loss: 0.4229.  Training acc: 93.57%.
[ Tue Jun 20 04:06:40 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:06:40 2023 ] Eval epoch: 61
[ Tue Jun 20 04:06:41 2023 ] 	Mean test loss of 625 batches: 6.141102.
[ Tue Jun 20 04:06:41 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:06:41 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:41 2023 ] Training epoch: 62
[ Tue Jun 20 04:06:42 2023 ] 	Training loss: 0.3663.  Training acc: 98.81%.
[ Tue Jun 20 04:06:42 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:06:42 2023 ] Eval epoch: 62
[ Tue Jun 20 04:06:43 2023 ] 	Mean test loss of 625 batches: 0.381275.
[ Tue Jun 20 04:06:43 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:06:43 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:43 2023 ] Training epoch: 63
[ Tue Jun 20 04:06:45 2023 ] 	Training loss: 0.3499.  Training acc: 99.08%.
[ Tue Jun 20 04:06:45 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:06:45 2023 ] Eval epoch: 63
[ Tue Jun 20 04:06:45 2023 ] 	Mean test loss of 625 batches: 0.478847.
[ Tue Jun 20 04:06:45 2023 ] 	Top1: 94.74%
[ Tue Jun 20 04:06:45 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:45 2023 ] Training epoch: 64
[ Tue Jun 20 04:06:47 2023 ] 	Training loss: 0.3334.  Training acc: 99.26%.
[ Tue Jun 20 04:06:47 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:06:47 2023 ] Eval epoch: 64
[ Tue Jun 20 04:06:47 2023 ] 	Mean test loss of 625 batches: 0.504981.
[ Tue Jun 20 04:06:47 2023 ] 	Top1: 85.96%
[ Tue Jun 20 04:06:47 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:47 2023 ] Training epoch: 65
[ Tue Jun 20 04:06:49 2023 ] 	Training loss: 0.3226.  Training acc: 99.63%.
[ Tue Jun 20 04:06:49 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:06:49 2023 ] Eval epoch: 65
[ Tue Jun 20 04:06:49 2023 ] 	Mean test loss of 625 batches: 0.723485.
[ Tue Jun 20 04:06:49 2023 ] 	Top1: 73.68%
[ Tue Jun 20 04:06:49 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:49 2023 ] Training epoch: 66
[ Tue Jun 20 04:06:51 2023 ] 	Training loss: 0.3149.  Training acc: 99.82%.
[ Tue Jun 20 04:06:51 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:06:51 2023 ] Eval epoch: 66
[ Tue Jun 20 04:06:51 2023 ] 	Mean test loss of 625 batches: 0.678679.
[ Tue Jun 20 04:06:51 2023 ] 	Top1: 71.93%
[ Tue Jun 20 04:06:51 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:51 2023 ] Training epoch: 67
[ Tue Jun 20 04:06:53 2023 ] 	Training loss: 0.3043.  Training acc: 100.00%.
[ Tue Jun 20 04:06:53 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:06:53 2023 ] Eval epoch: 67
[ Tue Jun 20 04:06:53 2023 ] 	Mean test loss of 625 batches: 0.700447.
[ Tue Jun 20 04:06:53 2023 ] 	Top1: 71.93%
[ Tue Jun 20 04:06:53 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:53 2023 ] Training epoch: 68
[ Tue Jun 20 04:06:55 2023 ] 	Training loss: 0.3042.  Training acc: 100.00%.
[ Tue Jun 20 04:06:55 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:06:55 2023 ] Eval epoch: 68
[ Tue Jun 20 04:06:56 2023 ] 	Mean test loss of 625 batches: 0.601372.
[ Tue Jun 20 04:06:56 2023 ] 	Top1: 78.95%
[ Tue Jun 20 04:06:56 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:56 2023 ] Training epoch: 69
[ Tue Jun 20 04:06:57 2023 ] 	Training loss: 0.3080.  Training acc: 99.82%.
[ Tue Jun 20 04:06:57 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:06:57 2023 ] Eval epoch: 69
[ Tue Jun 20 04:06:58 2023 ] 	Mean test loss of 625 batches: 0.369198.
[ Tue Jun 20 04:06:58 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:06:58 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:06:58 2023 ] Training epoch: 70
[ Tue Jun 20 04:07:00 2023 ] 	Training loss: 0.3102.  Training acc: 99.45%.
[ Tue Jun 20 04:07:00 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:07:00 2023 ] Eval epoch: 70
[ Tue Jun 20 04:07:00 2023 ] 	Mean test loss of 625 batches: 0.344856.
[ Tue Jun 20 04:07:00 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:07:00 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:00 2023 ] Training epoch: 71
[ Tue Jun 20 04:07:02 2023 ] 	Training loss: 0.3093.  Training acc: 99.82%.
[ Tue Jun 20 04:07:02 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:07:02 2023 ] Eval epoch: 71
[ Tue Jun 20 04:07:02 2023 ] 	Mean test loss of 625 batches: 0.485018.
[ Tue Jun 20 04:07:02 2023 ] 	Top1: 85.96%
[ Tue Jun 20 04:07:02 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:02 2023 ] Training epoch: 72
[ Tue Jun 20 04:07:04 2023 ] 	Training loss: 0.3108.  Training acc: 99.72%.
[ Tue Jun 20 04:07:04 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:07:04 2023 ] Eval epoch: 72
[ Tue Jun 20 04:07:04 2023 ] 	Mean test loss of 625 batches: 0.313485.
[ Tue Jun 20 04:07:04 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:07:04 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:04 2023 ] Training epoch: 73
[ Tue Jun 20 04:07:06 2023 ] 	Training loss: 0.3111.  Training acc: 99.45%.
[ Tue Jun 20 04:07:06 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:07:06 2023 ] Eval epoch: 73
[ Tue Jun 20 04:07:06 2023 ] 	Mean test loss of 625 batches: 0.294801.
[ Tue Jun 20 04:07:06 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:07:06 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:06 2023 ] Training epoch: 74
[ Tue Jun 20 04:07:08 2023 ] 	Training loss: 0.3110.  Training acc: 99.54%.
[ Tue Jun 20 04:07:08 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:07:08 2023 ] Eval epoch: 74
[ Tue Jun 20 04:07:09 2023 ] 	Mean test loss of 625 batches: 0.307436.
[ Tue Jun 20 04:07:09 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:07:09 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:09 2023 ] Training epoch: 75
[ Tue Jun 20 04:07:11 2023 ] 	Training loss: 0.3043.  Training acc: 99.72%.
[ Tue Jun 20 04:07:11 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:07:11 2023 ] Eval epoch: 75
[ Tue Jun 20 04:07:11 2023 ] 	Mean test loss of 625 batches: 0.981022.
[ Tue Jun 20 04:07:11 2023 ] 	Top1: 36.84%
[ Tue Jun 20 04:07:11 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:11 2023 ] Training epoch: 76
[ Tue Jun 20 04:07:13 2023 ] 	Training loss: 0.3010.  Training acc: 99.91%.
[ Tue Jun 20 04:07:13 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 20 04:07:13 2023 ] Eval epoch: 76
[ Tue Jun 20 04:07:13 2023 ] 	Mean test loss of 625 batches: 0.313874.
[ Tue Jun 20 04:07:13 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:07:13 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:13 2023 ] Training epoch: 77
[ Tue Jun 20 04:07:15 2023 ] 	Training loss: 0.3076.  Training acc: 99.63%.
[ Tue Jun 20 04:07:15 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Tue Jun 20 04:07:15 2023 ] Eval epoch: 77
[ Tue Jun 20 04:07:15 2023 ] 	Mean test loss of 625 batches: 0.297254.
[ Tue Jun 20 04:07:15 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:07:15 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:15 2023 ] Training epoch: 78
[ Tue Jun 20 04:07:17 2023 ] 	Training loss: 0.3089.  Training acc: 99.45%.
[ Tue Jun 20 04:07:17 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:07:17 2023 ] Eval epoch: 78
[ Tue Jun 20 04:07:17 2023 ] 	Mean test loss of 625 batches: 0.297833.
[ Tue Jun 20 04:07:17 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:07:17 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:17 2023 ] Training epoch: 79
[ Tue Jun 20 04:07:19 2023 ] 	Training loss: 0.3014.  Training acc: 99.91%.
[ Tue Jun 20 04:07:19 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:07:19 2023 ] Eval epoch: 79
[ Tue Jun 20 04:07:20 2023 ] 	Mean test loss of 625 batches: 0.385037.
[ Tue Jun 20 04:07:20 2023 ] 	Top1: 94.74%
[ Tue Jun 20 04:07:20 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:20 2023 ] Training epoch: 80
[ Tue Jun 20 04:07:21 2023 ] 	Training loss: 0.2991.  Training acc: 99.91%.
[ Tue Jun 20 04:07:21 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:07:21 2023 ] Eval epoch: 80
[ Tue Jun 20 04:07:22 2023 ] 	Mean test loss of 625 batches: 0.547559.
[ Tue Jun 20 04:07:22 2023 ] 	Top1: 82.46%
[ Tue Jun 20 04:07:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:22 2023 ] Training epoch: 81
[ Tue Jun 20 04:07:24 2023 ] 	Training loss: 0.3226.  Training acc: 98.71%.
[ Tue Jun 20 04:07:24 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:07:24 2023 ] Eval epoch: 81
[ Tue Jun 20 04:07:24 2023 ] 	Mean test loss of 625 batches: 2.115309.
[ Tue Jun 20 04:07:24 2023 ] 	Top1: 29.82%
[ Tue Jun 20 04:07:24 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:24 2023 ] Training epoch: 82
[ Tue Jun 20 04:07:26 2023 ] 	Training loss: 0.3232.  Training acc: 99.54%.
[ Tue Jun 20 04:07:26 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:07:26 2023 ] Eval epoch: 82
[ Tue Jun 20 04:07:26 2023 ] 	Mean test loss of 625 batches: 0.807658.
[ Tue Jun 20 04:07:26 2023 ] 	Top1: 70.18%
[ Tue Jun 20 04:07:26 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:26 2023 ] Training epoch: 83
[ Tue Jun 20 04:07:28 2023 ] 	Training loss: 0.4590.  Training acc: 93.29%.
[ Tue Jun 20 04:07:28 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:07:28 2023 ] Eval epoch: 83
[ Tue Jun 20 04:07:29 2023 ] 	Mean test loss of 625 batches: 13.531656.
[ Tue Jun 20 04:07:29 2023 ] 	Top1: 29.82%
[ Tue Jun 20 04:07:29 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:29 2023 ] Training epoch: 84
[ Tue Jun 20 04:07:30 2023 ] 	Training loss: 0.6533.  Training acc: 91.08%.
[ Tue Jun 20 04:07:30 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:07:30 2023 ] Eval epoch: 84
[ Tue Jun 20 04:07:31 2023 ] 	Mean test loss of 625 batches: 1709.537646.
[ Tue Jun 20 04:07:31 2023 ] 	Top1: 29.82%
[ Tue Jun 20 04:07:31 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:31 2023 ] Training epoch: 85
[ Tue Jun 20 04:07:33 2023 ] 	Training loss: 1.3758.  Training acc: 78.12%.
[ Tue Jun 20 04:07:33 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 20 04:07:33 2023 ] Eval epoch: 85
[ Tue Jun 20 04:07:33 2023 ] 	Mean test loss of 625 batches: 387.100804.
[ Tue Jun 20 04:07:33 2023 ] 	Top1: 29.82%
[ Tue Jun 20 04:07:33 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:33 2023 ] Training epoch: 86
[ Tue Jun 20 04:07:35 2023 ] 	Training loss: 0.6842.  Training acc: 91.64%.
[ Tue Jun 20 04:07:35 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:07:35 2023 ] Eval epoch: 86
[ Tue Jun 20 04:07:35 2023 ] 	Mean test loss of 625 batches: 1.002076.
[ Tue Jun 20 04:07:35 2023 ] 	Top1: 82.46%
[ Tue Jun 20 04:07:35 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:35 2023 ] Training epoch: 87
[ Tue Jun 20 04:07:37 2023 ] 	Training loss: 0.7769.  Training acc: 89.98%.
[ Tue Jun 20 04:07:37 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:07:37 2023 ] Eval epoch: 87
[ Tue Jun 20 04:07:37 2023 ] 	Mean test loss of 625 batches: 0.807548.
[ Tue Jun 20 04:07:37 2023 ] 	Top1: 82.46%
[ Tue Jun 20 04:07:37 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:37 2023 ] Training epoch: 88
[ Tue Jun 20 04:07:39 2023 ] 	Training loss: 0.4885.  Training acc: 95.13%.
[ Tue Jun 20 04:07:39 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:07:39 2023 ] Eval epoch: 88
[ Tue Jun 20 04:07:39 2023 ] 	Mean test loss of 625 batches: 0.327129.
[ Tue Jun 20 04:07:39 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:07:39 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:39 2023 ] Training epoch: 89
[ Tue Jun 20 04:07:41 2023 ] 	Training loss: 0.3960.  Training acc: 97.43%.
[ Tue Jun 20 04:07:41 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:07:41 2023 ] Eval epoch: 89
[ Tue Jun 20 04:07:41 2023 ] 	Mean test loss of 625 batches: 0.434814.
[ Tue Jun 20 04:07:41 2023 ] 	Top1: 91.23%
[ Tue Jun 20 04:07:41 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:41 2023 ] Training epoch: 90
[ Tue Jun 20 04:07:43 2023 ] 	Training loss: 0.3459.  Training acc: 99.63%.
[ Tue Jun 20 04:07:43 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:07:43 2023 ] Eval epoch: 90
[ Tue Jun 20 04:07:44 2023 ] 	Mean test loss of 625 batches: 0.433652.
[ Tue Jun 20 04:07:44 2023 ] 	Top1: 94.74%
[ Tue Jun 20 04:07:44 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:44 2023 ] Training epoch: 91
[ Tue Jun 20 04:07:45 2023 ] 	Training loss: 0.3265.  Training acc: 99.63%.
[ Tue Jun 20 04:07:45 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 20 04:07:45 2023 ] Eval epoch: 91
[ Tue Jun 20 04:07:46 2023 ] 	Mean test loss of 625 batches: 0.314870.
[ Tue Jun 20 04:07:46 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:07:46 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:46 2023 ] Training epoch: 92
[ Tue Jun 20 04:07:47 2023 ] 	Training loss: 0.3255.  Training acc: 99.26%.
[ Tue Jun 20 04:07:47 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:07:47 2023 ] Eval epoch: 92
[ Tue Jun 20 04:07:48 2023 ] 	Mean test loss of 625 batches: 0.299738.
[ Tue Jun 20 04:07:48 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:07:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:48 2023 ] Training epoch: 93
[ Tue Jun 20 04:07:50 2023 ] 	Training loss: 0.3195.  Training acc: 99.72%.
[ Tue Jun 20 04:07:50 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:07:50 2023 ] Eval epoch: 93
[ Tue Jun 20 04:07:50 2023 ] 	Mean test loss of 625 batches: 0.296591.
[ Tue Jun 20 04:07:50 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:07:50 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:50 2023 ] Training epoch: 94
[ Tue Jun 20 04:07:52 2023 ] 	Training loss: 0.3129.  Training acc: 99.82%.
[ Tue Jun 20 04:07:52 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:07:52 2023 ] Eval epoch: 94
[ Tue Jun 20 04:07:52 2023 ] 	Mean test loss of 625 batches: 0.295621.
[ Tue Jun 20 04:07:52 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:07:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:52 2023 ] Training epoch: 95
[ Tue Jun 20 04:07:54 2023 ] 	Training loss: 0.3135.  Training acc: 99.91%.
[ Tue Jun 20 04:07:54 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:07:54 2023 ] Eval epoch: 95
[ Tue Jun 20 04:07:54 2023 ] 	Mean test loss of 625 batches: 0.296446.
[ Tue Jun 20 04:07:54 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:07:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:54 2023 ] Training epoch: 96
[ Tue Jun 20 04:07:56 2023 ] 	Training loss: 0.3123.  Training acc: 99.82%.
[ Tue Jun 20 04:07:56 2023 ] 	Time consumption: [Data]12%, [Network]88%
[ Tue Jun 20 04:07:56 2023 ] Eval epoch: 96
[ Tue Jun 20 04:07:56 2023 ] 	Mean test loss of 625 batches: 0.295686.
[ Tue Jun 20 04:07:56 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:07:56 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:56 2023 ] Training epoch: 97
[ Tue Jun 20 04:07:58 2023 ] 	Training loss: 0.3096.  Training acc: 100.00%.
[ Tue Jun 20 04:07:58 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:07:58 2023 ] Eval epoch: 97
[ Tue Jun 20 04:07:59 2023 ] 	Mean test loss of 625 batches: 0.294235.
[ Tue Jun 20 04:07:59 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:07:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:07:59 2023 ] Training epoch: 98
[ Tue Jun 20 04:08:00 2023 ] 	Training loss: 0.3104.  Training acc: 99.91%.
[ Tue Jun 20 04:08:00 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:08:00 2023 ] Eval epoch: 98
[ Tue Jun 20 04:08:01 2023 ] 	Mean test loss of 625 batches: 0.294807.
[ Tue Jun 20 04:08:01 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:08:01 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:08:01 2023 ] Training epoch: 99
[ Tue Jun 20 04:08:02 2023 ] 	Training loss: 0.3096.  Training acc: 99.82%.
[ Tue Jun 20 04:08:02 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:08:02 2023 ] Eval epoch: 99
[ Tue Jun 20 04:08:03 2023 ] 	Mean test loss of 625 batches: 0.295049.
[ Tue Jun 20 04:08:03 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:08:03 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:08:03 2023 ] Training epoch: 100
[ Tue Jun 20 04:08:05 2023 ] 	Training loss: 0.3074.  Training acc: 100.00%.
[ Tue Jun 20 04:08:05 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:08:05 2023 ] Eval epoch: 100
[ Tue Jun 20 04:08:05 2023 ] 	Mean test loss of 625 batches: 0.294558.
[ Tue Jun 20 04:08:05 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:08:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:08:05 2023 ] Training epoch: 101
[ Tue Jun 20 04:08:07 2023 ] 	Training loss: 0.3076.  Training acc: 99.91%.
[ Tue Jun 20 04:08:07 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:08:07 2023 ] Eval epoch: 101
[ Tue Jun 20 04:08:07 2023 ] 	Mean test loss of 625 batches: 0.295868.
[ Tue Jun 20 04:08:07 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:08:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:08:07 2023 ] Training epoch: 102
[ Tue Jun 20 04:08:09 2023 ] 	Training loss: 0.3059.  Training acc: 99.72%.
[ Tue Jun 20 04:08:09 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:08:09 2023 ] Eval epoch: 102
[ Tue Jun 20 04:08:09 2023 ] 	Mean test loss of 625 batches: 0.295991.
[ Tue Jun 20 04:08:09 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:08:09 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:08:09 2023 ] Training epoch: 103
[ Tue Jun 20 04:08:11 2023 ] 	Training loss: 0.3049.  Training acc: 100.00%.
[ Tue Jun 20 04:08:11 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:08:11 2023 ] Eval epoch: 103
[ Tue Jun 20 04:08:11 2023 ] 	Mean test loss of 625 batches: 0.295758.
[ Tue Jun 20 04:08:11 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:08:11 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:08:11 2023 ] Training epoch: 104
[ Tue Jun 20 04:08:13 2023 ] 	Training loss: 0.3091.  Training acc: 99.82%.
[ Tue Jun 20 04:08:13 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:08:13 2023 ] Eval epoch: 104
[ Tue Jun 20 04:08:13 2023 ] 	Mean test loss of 625 batches: 0.295168.
[ Tue Jun 20 04:08:13 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:08:13 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:08:13 2023 ] Training epoch: 105
[ Tue Jun 20 04:08:15 2023 ] 	Training loss: 0.3053.  Training acc: 100.00%.
[ Tue Jun 20 04:08:15 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:08:15 2023 ] Eval epoch: 105
[ Tue Jun 20 04:08:16 2023 ] 	Mean test loss of 625 batches: 0.295496.
[ Tue Jun 20 04:08:16 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:08:16 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:08:16 2023 ] Training epoch: 106
[ Tue Jun 20 04:08:17 2023 ] 	Training loss: 0.3067.  Training acc: 100.00%.
[ Tue Jun 20 04:08:17 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:08:17 2023 ] Eval epoch: 106
[ Tue Jun 20 04:08:18 2023 ] 	Mean test loss of 625 batches: 0.295575.
[ Tue Jun 20 04:08:18 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:08:18 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:08:18 2023 ] Training epoch: 107
[ Tue Jun 20 04:08:19 2023 ] 	Training loss: 0.3059.  Training acc: 99.91%.
[ Tue Jun 20 04:08:19 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:08:19 2023 ] Eval epoch: 107
[ Tue Jun 20 04:08:20 2023 ] 	Mean test loss of 625 batches: 0.294941.
[ Tue Jun 20 04:08:20 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:08:20 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:08:20 2023 ] Training epoch: 108
[ Tue Jun 20 04:08:22 2023 ] 	Training loss: 0.3059.  Training acc: 99.91%.
[ Tue Jun 20 04:08:22 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:08:22 2023 ] Eval epoch: 108
[ Tue Jun 20 04:08:22 2023 ] 	Mean test loss of 625 batches: 0.295044.
[ Tue Jun 20 04:08:22 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:08:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:08:22 2023 ] Training epoch: 109
[ Tue Jun 20 04:08:24 2023 ] 	Training loss: 0.3048.  Training acc: 100.00%.
[ Tue Jun 20 04:08:24 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:08:24 2023 ] Eval epoch: 109
[ Tue Jun 20 04:08:24 2023 ] 	Mean test loss of 625 batches: 0.294514.
[ Tue Jun 20 04:08:24 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:08:24 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:08:24 2023 ] Training epoch: 110
[ Tue Jun 20 04:08:26 2023 ] 	Training loss: 0.3051.  Training acc: 99.91%.
[ Tue Jun 20 04:08:26 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:08:26 2023 ] Eval epoch: 110
[ Tue Jun 20 04:08:26 2023 ] 	Mean test loss of 625 batches: 0.294471.
[ Tue Jun 20 04:08:26 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:08:26 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:09:16 2023 ] using warm up, epoch: 5
[ Tue Jun 20 04:09:18 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [90, 100], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 110, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 04:09:18 2023 ] # Parameters: 1538958
[ Tue Jun 20 04:09:18 2023 ] Training epoch: 1
[ Tue Jun 20 04:09:22 2023 ] 	Training loss: 92.1858.  Training acc: 33.73%.
[ Tue Jun 20 04:09:22 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jun 20 04:09:22 2023 ] Eval epoch: 1
[ Tue Jun 20 04:09:23 2023 ] 	Mean test loss of 625 batches: 2809.295557.
[ Tue Jun 20 04:09:23 2023 ] 	Top1: 38.60%
[ Tue Jun 20 04:09:23 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:09:23 2023 ] Training epoch: 2
[ Tue Jun 20 04:09:24 2023 ] 	Training loss: 8.3727.  Training acc: 37.04%.
[ Tue Jun 20 04:09:24 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:09:24 2023 ] Eval epoch: 2
[ Tue Jun 20 04:09:25 2023 ] 	Mean test loss of 625 batches: 31.225703.
[ Tue Jun 20 04:09:25 2023 ] 	Top1: 38.60%
[ Tue Jun 20 04:09:25 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:09:25 2023 ] Training epoch: 3
[ Tue Jun 20 04:09:26 2023 ] 	Training loss: 5.3513.  Training acc: 57.17%.
[ Tue Jun 20 04:09:26 2023 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Jun 20 04:09:26 2023 ] Eval epoch: 3
[ Tue Jun 20 04:09:27 2023 ] 	Mean test loss of 625 batches: 4.339562.
[ Tue Jun 20 04:09:27 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:09:27 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:09:27 2023 ] Training epoch: 4
[ Tue Jun 20 04:09:29 2023 ] 	Training loss: 2.4005.  Training acc: 76.01%.
[ Tue Jun 20 04:09:29 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:09:29 2023 ] Eval epoch: 4
[ Tue Jun 20 04:09:29 2023 ] 	Mean test loss of 625 batches: 2.146508.
[ Tue Jun 20 04:09:29 2023 ] 	Top1: 64.91%
[ Tue Jun 20 04:09:29 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:09:29 2023 ] Training epoch: 5
[ Tue Jun 20 04:09:31 2023 ] 	Training loss: 1.6236.  Training acc: 81.80%.
[ Tue Jun 20 04:09:31 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:09:31 2023 ] Eval epoch: 5
[ Tue Jun 20 04:09:31 2023 ] 	Mean test loss of 625 batches: 0.758874.
[ Tue Jun 20 04:09:31 2023 ] 	Top1: 94.74%
[ Tue Jun 20 04:09:31 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:09:31 2023 ] Training epoch: 6
[ Tue Jun 20 04:09:33 2023 ] 	Training loss: 1.5480.  Training acc: 83.73%.
[ Tue Jun 20 04:09:33 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:09:33 2023 ] Eval epoch: 6
[ Tue Jun 20 04:09:33 2023 ] 	Mean test loss of 625 batches: 2.322934.
[ Tue Jun 20 04:09:33 2023 ] 	Top1: 66.67%
[ Tue Jun 20 04:09:33 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:09:33 2023 ] Training epoch: 7
[ Tue Jun 20 04:09:35 2023 ] 	Training loss: 1.3094.  Training acc: 83.18%.
[ Tue Jun 20 04:09:35 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:09:35 2023 ] Eval epoch: 7
[ Tue Jun 20 04:09:35 2023 ] 	Mean test loss of 625 batches: 1.522596.
[ Tue Jun 20 04:09:35 2023 ] 	Top1: 80.70%
[ Tue Jun 20 04:09:35 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:09:35 2023 ] Training epoch: 8
[ Tue Jun 20 04:09:37 2023 ] 	Training loss: 1.4372.  Training acc: 80.15%.
[ Tue Jun 20 04:09:37 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:09:37 2023 ] Eval epoch: 8
[ Tue Jun 20 04:09:37 2023 ] 	Mean test loss of 625 batches: 1.696142.
[ Tue Jun 20 04:09:37 2023 ] 	Top1: 71.93%
[ Tue Jun 20 04:09:37 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:09:37 2023 ] Training epoch: 9
[ Tue Jun 20 04:09:39 2023 ] 	Training loss: 1.1850.  Training acc: 82.90%.
[ Tue Jun 20 04:09:39 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:09:39 2023 ] Eval epoch: 9
[ Tue Jun 20 04:09:39 2023 ] 	Mean test loss of 625 batches: 0.982996.
[ Tue Jun 20 04:09:39 2023 ] 	Top1: 92.98%
[ Tue Jun 20 04:09:39 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:09:39 2023 ] Training epoch: 10
[ Tue Jun 20 04:09:41 2023 ] 	Training loss: 0.9883.  Training acc: 84.47%.
[ Tue Jun 20 04:09:41 2023 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Jun 20 04:09:41 2023 ] Eval epoch: 10
[ Tue Jun 20 04:09:42 2023 ] 	Mean test loss of 625 batches: 0.662525.
[ Tue Jun 20 04:09:42 2023 ] 	Top1: 94.74%
[ Tue Jun 20 04:09:42 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:09:42 2023 ] Training epoch: 11
[ Tue Jun 20 04:09:43 2023 ] 	Training loss: 0.7756.  Training acc: 88.14%.
[ Tue Jun 20 04:09:43 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:09:43 2023 ] Eval epoch: 11
[ Tue Jun 20 04:09:44 2023 ] 	Mean test loss of 625 batches: 1.084312.
[ Tue Jun 20 04:09:44 2023 ] 	Top1: 78.95%
[ Tue Jun 20 04:09:44 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:09:44 2023 ] Training epoch: 12
[ Tue Jun 20 04:09:45 2023 ] 	Training loss: 0.8028.  Training acc: 91.73%.
[ Tue Jun 20 04:09:45 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:09:45 2023 ] Eval epoch: 12
[ Tue Jun 20 04:09:46 2023 ] 	Mean test loss of 625 batches: 1.182069.
[ Tue Jun 20 04:09:46 2023 ] 	Top1: 68.42%
[ Tue Jun 20 04:09:46 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:09:46 2023 ] Training epoch: 13
[ Tue Jun 20 04:09:48 2023 ] 	Training loss: 0.6646.  Training acc: 88.88%.
[ Tue Jun 20 04:09:48 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:09:48 2023 ] Eval epoch: 13
[ Tue Jun 20 04:09:48 2023 ] 	Mean test loss of 625 batches: 0.448374.
[ Tue Jun 20 04:09:48 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:09:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:09:48 2023 ] Training epoch: 14
[ Tue Jun 20 04:09:50 2023 ] 	Training loss: 0.5311.  Training acc: 92.19%.
[ Tue Jun 20 04:09:50 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:09:50 2023 ] Eval epoch: 14
[ Tue Jun 20 04:09:50 2023 ] 	Mean test loss of 625 batches: 0.478613.
[ Tue Jun 20 04:09:50 2023 ] 	Top1: 91.23%
[ Tue Jun 20 04:09:50 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:09:50 2023 ] Training epoch: 15
[ Tue Jun 20 04:09:52 2023 ] 	Training loss: 0.4843.  Training acc: 94.12%.
[ Tue Jun 20 04:09:52 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:09:52 2023 ] Eval epoch: 15
[ Tue Jun 20 04:09:52 2023 ] 	Mean test loss of 625 batches: 0.396245.
[ Tue Jun 20 04:09:52 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:09:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:09:52 2023 ] Training epoch: 16
[ Tue Jun 20 04:09:54 2023 ] 	Training loss: 0.5890.  Training acc: 92.92%.
[ Tue Jun 20 04:09:54 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:09:54 2023 ] Eval epoch: 16
[ Tue Jun 20 04:09:54 2023 ] 	Mean test loss of 625 batches: 0.399687.
[ Tue Jun 20 04:09:54 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:09:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:09:54 2023 ] Training epoch: 17
[ Tue Jun 20 04:09:56 2023 ] 	Training loss: 0.4688.  Training acc: 95.04%.
[ Tue Jun 20 04:09:56 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:09:56 2023 ] Eval epoch: 17
[ Tue Jun 20 04:09:56 2023 ] 	Mean test loss of 625 batches: 0.459702.
[ Tue Jun 20 04:09:56 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:09:56 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:09:56 2023 ] Training epoch: 18
[ Tue Jun 20 04:09:58 2023 ] 	Training loss: 0.4477.  Training acc: 95.86%.
[ Tue Jun 20 04:09:58 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:09:58 2023 ] Eval epoch: 18
[ Tue Jun 20 04:09:58 2023 ] 	Mean test loss of 625 batches: 0.341623.
[ Tue Jun 20 04:09:58 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:09:58 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:09:58 2023 ] Training epoch: 19
[ Tue Jun 20 04:10:00 2023 ] 	Training loss: 0.3843.  Training acc: 98.53%.
[ Tue Jun 20 04:10:00 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:00 2023 ] Eval epoch: 19
[ Tue Jun 20 04:10:01 2023 ] 	Mean test loss of 625 batches: 0.491760.
[ Tue Jun 20 04:10:01 2023 ] 	Top1: 94.74%
[ Tue Jun 20 04:10:01 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:01 2023 ] Training epoch: 20
[ Tue Jun 20 04:10:02 2023 ] 	Training loss: 1.3279.  Training acc: 87.96%.
[ Tue Jun 20 04:10:02 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:02 2023 ] Eval epoch: 20
[ Tue Jun 20 04:10:03 2023 ] 	Mean test loss of 625 batches: 1.970615.
[ Tue Jun 20 04:10:03 2023 ] 	Top1: 59.65%
[ Tue Jun 20 04:10:03 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:03 2023 ] Training epoch: 21
[ Tue Jun 20 04:10:04 2023 ] 	Training loss: 0.8697.  Training acc: 86.58%.
[ Tue Jun 20 04:10:04 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:04 2023 ] Eval epoch: 21
[ Tue Jun 20 04:10:05 2023 ] 	Mean test loss of 625 batches: 0.660073.
[ Tue Jun 20 04:10:05 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:10:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:05 2023 ] Training epoch: 22
[ Tue Jun 20 04:10:07 2023 ] 	Training loss: 0.5940.  Training acc: 92.00%.
[ Tue Jun 20 04:10:07 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:07 2023 ] Eval epoch: 22
[ Tue Jun 20 04:10:07 2023 ] 	Mean test loss of 625 batches: 0.380785.
[ Tue Jun 20 04:10:07 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:10:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:07 2023 ] Training epoch: 23
[ Tue Jun 20 04:10:09 2023 ] 	Training loss: 0.5744.  Training acc: 91.08%.
[ Tue Jun 20 04:10:09 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:10:09 2023 ] Eval epoch: 23
[ Tue Jun 20 04:10:09 2023 ] 	Mean test loss of 625 batches: 0.915806.
[ Tue Jun 20 04:10:09 2023 ] 	Top1: 61.40%
[ Tue Jun 20 04:10:09 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:09 2023 ] Training epoch: 24
[ Tue Jun 20 04:10:11 2023 ] 	Training loss: 0.4823.  Training acc: 94.94%.
[ Tue Jun 20 04:10:11 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:11 2023 ] Eval epoch: 24
[ Tue Jun 20 04:10:11 2023 ] 	Mean test loss of 625 batches: 0.350418.
[ Tue Jun 20 04:10:11 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:10:11 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:11 2023 ] Training epoch: 25
[ Tue Jun 20 04:10:13 2023 ] 	Training loss: 0.3704.  Training acc: 98.35%.
[ Tue Jun 20 04:10:13 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:13 2023 ] Eval epoch: 25
[ Tue Jun 20 04:10:13 2023 ] 	Mean test loss of 625 batches: 0.445688.
[ Tue Jun 20 04:10:13 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:10:13 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:13 2023 ] Training epoch: 26
[ Tue Jun 20 04:10:15 2023 ] 	Training loss: 0.4061.  Training acc: 96.78%.
[ Tue Jun 20 04:10:15 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:15 2023 ] Eval epoch: 26
[ Tue Jun 20 04:10:16 2023 ] 	Mean test loss of 625 batches: 0.459327.
[ Tue Jun 20 04:10:16 2023 ] 	Top1: 94.74%
[ Tue Jun 20 04:10:16 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:16 2023 ] Training epoch: 27
[ Tue Jun 20 04:10:17 2023 ] 	Training loss: 0.3451.  Training acc: 98.81%.
[ Tue Jun 20 04:10:17 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:10:17 2023 ] Eval epoch: 27
[ Tue Jun 20 04:10:18 2023 ] 	Mean test loss of 625 batches: 0.424419.
[ Tue Jun 20 04:10:18 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:10:18 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:18 2023 ] Training epoch: 28
[ Tue Jun 20 04:10:19 2023 ] 	Training loss: 0.3378.  Training acc: 98.99%.
[ Tue Jun 20 04:10:19 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:19 2023 ] Eval epoch: 28
[ Tue Jun 20 04:10:20 2023 ] 	Mean test loss of 625 batches: 0.349011.
[ Tue Jun 20 04:10:20 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:10:20 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:20 2023 ] Training epoch: 29
[ Tue Jun 20 04:10:22 2023 ] 	Training loss: 0.3250.  Training acc: 99.63%.
[ Tue Jun 20 04:10:22 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:22 2023 ] Eval epoch: 29
[ Tue Jun 20 04:10:22 2023 ] 	Mean test loss of 625 batches: 0.319052.
[ Tue Jun 20 04:10:22 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:10:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:22 2023 ] Training epoch: 30
[ Tue Jun 20 04:10:24 2023 ] 	Training loss: 0.3355.  Training acc: 98.99%.
[ Tue Jun 20 04:10:24 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:24 2023 ] Eval epoch: 30
[ Tue Jun 20 04:10:24 2023 ] 	Mean test loss of 625 batches: 0.400000.
[ Tue Jun 20 04:10:24 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:10:24 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:24 2023 ] Training epoch: 31
[ Tue Jun 20 04:10:26 2023 ] 	Training loss: 0.3175.  Training acc: 99.91%.
[ Tue Jun 20 04:10:26 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:26 2023 ] Eval epoch: 31
[ Tue Jun 20 04:10:26 2023 ] 	Mean test loss of 625 batches: 0.342716.
[ Tue Jun 20 04:10:26 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:10:26 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:26 2023 ] Training epoch: 32
[ Tue Jun 20 04:10:28 2023 ] 	Training loss: 0.3117.  Training acc: 99.91%.
[ Tue Jun 20 04:10:28 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:28 2023 ] Eval epoch: 32
[ Tue Jun 20 04:10:28 2023 ] 	Mean test loss of 625 batches: 0.365125.
[ Tue Jun 20 04:10:28 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:10:28 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:28 2023 ] Training epoch: 33
[ Tue Jun 20 04:10:30 2023 ] 	Training loss: 0.3171.  Training acc: 99.63%.
[ Tue Jun 20 04:10:30 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:10:30 2023 ] Eval epoch: 33
[ Tue Jun 20 04:10:30 2023 ] 	Mean test loss of 625 batches: 0.424119.
[ Tue Jun 20 04:10:30 2023 ] 	Top1: 96.49%
[ Tue Jun 20 04:10:30 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:30 2023 ] Training epoch: 34
[ Tue Jun 20 04:10:32 2023 ] 	Training loss: 0.3160.  Training acc: 99.91%.
[ Tue Jun 20 04:10:32 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:32 2023 ] Eval epoch: 34
[ Tue Jun 20 04:10:33 2023 ] 	Mean test loss of 625 batches: 0.301490.
[ Tue Jun 20 04:10:33 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:10:33 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:33 2023 ] Training epoch: 35
[ Tue Jun 20 04:10:34 2023 ] 	Training loss: 0.3362.  Training acc: 98.90%.
[ Tue Jun 20 04:10:34 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:10:34 2023 ] Eval epoch: 35
[ Tue Jun 20 04:10:35 2023 ] 	Mean test loss of 625 batches: 0.410328.
[ Tue Jun 20 04:10:35 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:10:35 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:35 2023 ] Training epoch: 36
[ Tue Jun 20 04:10:36 2023 ] 	Training loss: 0.3300.  Training acc: 99.36%.
[ Tue Jun 20 04:10:36 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:36 2023 ] Eval epoch: 36
[ Tue Jun 20 04:10:37 2023 ] 	Mean test loss of 625 batches: 0.305891.
[ Tue Jun 20 04:10:37 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:10:37 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:37 2023 ] Training epoch: 37
[ Tue Jun 20 04:10:39 2023 ] 	Training loss: 0.3351.  Training acc: 99.45%.
[ Tue Jun 20 04:10:39 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:39 2023 ] Eval epoch: 37
[ Tue Jun 20 04:10:39 2023 ] 	Mean test loss of 625 batches: 0.303333.
[ Tue Jun 20 04:10:39 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:10:39 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:39 2023 ] Training epoch: 38
[ Tue Jun 20 04:10:41 2023 ] 	Training loss: 0.3320.  Training acc: 99.63%.
[ Tue Jun 20 04:10:41 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:41 2023 ] Eval epoch: 38
[ Tue Jun 20 04:10:41 2023 ] 	Mean test loss of 625 batches: 0.311238.
[ Tue Jun 20 04:10:41 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:10:41 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:41 2023 ] Training epoch: 39
[ Tue Jun 20 04:10:43 2023 ] 	Training loss: 0.3146.  Training acc: 99.91%.
[ Tue Jun 20 04:10:43 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:43 2023 ] Eval epoch: 39
[ Tue Jun 20 04:10:43 2023 ] 	Mean test loss of 625 batches: 0.319811.
[ Tue Jun 20 04:10:43 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:10:43 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:43 2023 ] Training epoch: 40
[ Tue Jun 20 04:10:45 2023 ] 	Training loss: 0.3132.  Training acc: 99.82%.
[ Tue Jun 20 04:10:45 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:45 2023 ] Eval epoch: 40
[ Tue Jun 20 04:10:45 2023 ] 	Mean test loss of 625 batches: 0.364726.
[ Tue Jun 20 04:10:45 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:10:45 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:45 2023 ] Training epoch: 41
[ Tue Jun 20 04:10:47 2023 ] 	Training loss: 0.3218.  Training acc: 99.36%.
[ Tue Jun 20 04:10:47 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:10:47 2023 ] Eval epoch: 41
[ Tue Jun 20 04:10:47 2023 ] 	Mean test loss of 625 batches: 0.374009.
[ Tue Jun 20 04:10:47 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:10:47 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:47 2023 ] Training epoch: 42
[ Tue Jun 20 04:10:49 2023 ] 	Training loss: 0.3133.  Training acc: 99.91%.
[ Tue Jun 20 04:10:49 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:49 2023 ] Eval epoch: 42
[ Tue Jun 20 04:10:50 2023 ] 	Mean test loss of 625 batches: 0.449627.
[ Tue Jun 20 04:10:50 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:10:50 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:50 2023 ] Training epoch: 43
[ Tue Jun 20 04:10:51 2023 ] 	Training loss: 0.3130.  Training acc: 99.91%.
[ Tue Jun 20 04:10:51 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:51 2023 ] Eval epoch: 43
[ Tue Jun 20 04:10:52 2023 ] 	Mean test loss of 625 batches: 0.313116.
[ Tue Jun 20 04:10:52 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:10:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:52 2023 ] Training epoch: 44
[ Tue Jun 20 04:10:53 2023 ] 	Training loss: 0.3173.  Training acc: 99.72%.
[ Tue Jun 20 04:10:53 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:53 2023 ] Eval epoch: 44
[ Tue Jun 20 04:10:54 2023 ] 	Mean test loss of 625 batches: 0.320065.
[ Tue Jun 20 04:10:54 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:10:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:54 2023 ] Training epoch: 45
[ Tue Jun 20 04:10:55 2023 ] 	Training loss: 0.3180.  Training acc: 99.82%.
[ Tue Jun 20 04:10:55 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:10:55 2023 ] Eval epoch: 45
[ Tue Jun 20 04:10:56 2023 ] 	Mean test loss of 625 batches: 0.349474.
[ Tue Jun 20 04:10:56 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:10:56 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:10:56 2023 ] Training epoch: 46
[ Tue Jun 20 04:11:30 2023 ] using warm up, epoch: 5
[ Tue Jun 20 04:11:32 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 60, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [15, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 04:11:32 2023 ] # Parameters: 1538958
[ Tue Jun 20 04:11:32 2023 ] Training epoch: 1
[ Tue Jun 20 04:11:36 2023 ] 	Training loss: 88.9942.  Training acc: 33.64%.
[ Tue Jun 20 04:11:36 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jun 20 04:11:36 2023 ] Eval epoch: 1
[ Tue Jun 20 04:11:37 2023 ] 	Mean test loss of 625 batches: 1118.765601.
[ Tue Jun 20 04:11:37 2023 ] 	Top1: 38.60%
[ Tue Jun 20 04:11:37 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:11:37 2023 ] Training epoch: 2
[ Tue Jun 20 04:11:39 2023 ] 	Training loss: 7.9748.  Training acc: 40.53%.
[ Tue Jun 20 04:11:39 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Tue Jun 20 04:11:39 2023 ] Eval epoch: 2
[ Tue Jun 20 04:11:39 2023 ] 	Mean test loss of 625 batches: 7.321872.
[ Tue Jun 20 04:11:39 2023 ] 	Top1: 36.84%
[ Tue Jun 20 04:11:39 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:11:39 2023 ] Training epoch: 3
[ Tue Jun 20 04:11:41 2023 ] 	Training loss: 5.4279.  Training acc: 53.77%.
[ Tue Jun 20 04:11:41 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Tue Jun 20 04:11:41 2023 ] Eval epoch: 3
[ Tue Jun 20 04:11:41 2023 ] 	Mean test loss of 625 batches: 3.995149.
[ Tue Jun 20 04:11:41 2023 ] 	Top1: 50.88%
[ Tue Jun 20 04:11:41 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:11:41 2023 ] Training epoch: 4
[ Tue Jun 20 04:11:43 2023 ] 	Training loss: 3.0748.  Training acc: 68.47%.
[ Tue Jun 20 04:11:43 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:11:43 2023 ] Eval epoch: 4
[ Tue Jun 20 04:11:43 2023 ] 	Mean test loss of 625 batches: 3.063129.
[ Tue Jun 20 04:11:43 2023 ] 	Top1: 68.42%
[ Tue Jun 20 04:11:43 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:11:43 2023 ] Training epoch: 5
[ Tue Jun 20 04:11:45 2023 ] 	Training loss: 2.5642.  Training acc: 70.77%.
[ Tue Jun 20 04:11:45 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:11:45 2023 ] Eval epoch: 5
[ Tue Jun 20 04:11:45 2023 ] 	Mean test loss of 625 batches: 2.430671.
[ Tue Jun 20 04:11:45 2023 ] 	Top1: 66.67%
[ Tue Jun 20 04:11:45 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:11:45 2023 ] Training epoch: 6
[ Tue Jun 20 04:11:47 2023 ] 	Training loss: 2.3621.  Training acc: 69.76%.
[ Tue Jun 20 04:11:47 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:11:47 2023 ] Eval epoch: 6
[ Tue Jun 20 04:11:48 2023 ] 	Mean test loss of 625 batches: 1.321581.
[ Tue Jun 20 04:11:48 2023 ] 	Top1: 64.91%
[ Tue Jun 20 04:11:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:11:48 2023 ] Training epoch: 7
[ Tue Jun 20 04:11:49 2023 ] 	Training loss: 2.0048.  Training acc: 68.66%.
[ Tue Jun 20 04:11:49 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:11:49 2023 ] Eval epoch: 7
[ Tue Jun 20 04:11:50 2023 ] 	Mean test loss of 625 batches: 1.657408.
[ Tue Jun 20 04:11:50 2023 ] 	Top1: 59.65%
[ Tue Jun 20 04:11:50 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:11:50 2023 ] Training epoch: 8
[ Tue Jun 20 04:11:52 2023 ] 	Training loss: 1.5485.  Training acc: 74.45%.
[ Tue Jun 20 04:11:52 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:11:52 2023 ] Eval epoch: 8
[ Tue Jun 20 04:11:52 2023 ] 	Mean test loss of 625 batches: 0.540409.
[ Tue Jun 20 04:11:52 2023 ] 	Top1: 91.23%
[ Tue Jun 20 04:11:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:11:52 2023 ] Training epoch: 9
[ Tue Jun 20 04:11:54 2023 ] 	Training loss: 1.1891.  Training acc: 78.68%.
[ Tue Jun 20 04:11:54 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:11:54 2023 ] Eval epoch: 9
[ Tue Jun 20 04:11:54 2023 ] 	Mean test loss of 625 batches: 1.092957.
[ Tue Jun 20 04:11:54 2023 ] 	Top1: 84.21%
[ Tue Jun 20 04:11:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:11:54 2023 ] Training epoch: 10
[ Tue Jun 20 04:11:56 2023 ] 	Training loss: 1.2036.  Training acc: 80.61%.
[ Tue Jun 20 04:11:56 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:11:56 2023 ] Eval epoch: 10
[ Tue Jun 20 04:11:56 2023 ] 	Mean test loss of 625 batches: 1.042241.
[ Tue Jun 20 04:11:56 2023 ] 	Top1: 84.21%
[ Tue Jun 20 04:11:56 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:11:56 2023 ] Training epoch: 11
[ Tue Jun 20 04:11:58 2023 ] 	Training loss: 1.0379.  Training acc: 78.40%.
[ Tue Jun 20 04:11:58 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:11:58 2023 ] Eval epoch: 11
[ Tue Jun 20 04:11:59 2023 ] 	Mean test loss of 625 batches: 0.733168.
[ Tue Jun 20 04:11:59 2023 ] 	Top1: 77.19%
[ Tue Jun 20 04:11:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:11:59 2023 ] Training epoch: 12
[ Tue Jun 20 04:12:00 2023 ] 	Training loss: 1.1296.  Training acc: 76.19%.
[ Tue Jun 20 04:12:00 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:12:00 2023 ] Eval epoch: 12
[ Tue Jun 20 04:12:01 2023 ] 	Mean test loss of 625 batches: 1.664493.
[ Tue Jun 20 04:12:01 2023 ] 	Top1: 50.88%
[ Tue Jun 20 04:12:01 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:12:01 2023 ] Training epoch: 13
[ Tue Jun 20 04:12:02 2023 ] 	Training loss: 0.9642.  Training acc: 78.03%.
[ Tue Jun 20 04:12:02 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:12:02 2023 ] Eval epoch: 13
[ Tue Jun 20 04:12:03 2023 ] 	Mean test loss of 625 batches: 2.200606.
[ Tue Jun 20 04:12:03 2023 ] 	Top1: 57.89%
[ Tue Jun 20 04:12:03 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:12:03 2023 ] Training epoch: 14
[ Tue Jun 20 04:12:05 2023 ] 	Training loss: 0.8918.  Training acc: 80.15%.
[ Tue Jun 20 04:12:05 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:12:05 2023 ] Eval epoch: 14
[ Tue Jun 20 04:12:05 2023 ] 	Mean test loss of 625 batches: 1.942102.
[ Tue Jun 20 04:12:05 2023 ] 	Top1: 49.12%
[ Tue Jun 20 04:12:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:12:05 2023 ] Training epoch: 15
[ Tue Jun 20 04:12:07 2023 ] 	Training loss: 0.7263.  Training acc: 80.15%.
[ Tue Jun 20 04:12:07 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:12:07 2023 ] Eval epoch: 15
[ Tue Jun 20 04:12:07 2023 ] 	Mean test loss of 625 batches: 1.518991.
[ Tue Jun 20 04:12:07 2023 ] 	Top1: 47.37%
[ Tue Jun 20 04:12:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:12:07 2023 ] Training epoch: 16
[ Tue Jun 20 04:12:09 2023 ] 	Training loss: 0.6467.  Training acc: 82.54%.
[ Tue Jun 20 04:12:09 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:12:09 2023 ] Eval epoch: 16
[ Tue Jun 20 04:12:09 2023 ] 	Mean test loss of 625 batches: 0.510015.
[ Tue Jun 20 04:12:09 2023 ] 	Top1: 91.23%
[ Tue Jun 20 04:12:09 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:12:09 2023 ] Training epoch: 17
[ Tue Jun 20 04:12:11 2023 ] 	Training loss: 0.5240.  Training acc: 90.53%.
[ Tue Jun 20 04:12:11 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:12:11 2023 ] Eval epoch: 17
[ Tue Jun 20 04:12:11 2023 ] 	Mean test loss of 625 batches: 0.453722.
[ Tue Jun 20 04:12:11 2023 ] 	Top1: 94.74%
[ Tue Jun 20 04:12:11 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:12:11 2023 ] Training epoch: 18
[ Tue Jun 20 04:12:13 2023 ] 	Training loss: 0.5096.  Training acc: 89.89%.
[ Tue Jun 20 04:12:13 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:12:13 2023 ] Eval epoch: 18
[ Tue Jun 20 04:12:13 2023 ] 	Mean test loss of 625 batches: 0.428248.
[ Tue Jun 20 04:12:13 2023 ] 	Top1: 92.98%
[ Tue Jun 20 04:12:13 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:12:13 2023 ] Training epoch: 19
[ Tue Jun 20 04:12:15 2023 ] 	Training loss: 0.4878.  Training acc: 92.19%.
[ Tue Jun 20 04:12:15 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:12:15 2023 ] Eval epoch: 19
[ Tue Jun 20 04:12:16 2023 ] 	Mean test loss of 625 batches: 0.402493.
[ Tue Jun 20 04:12:16 2023 ] 	Top1: 96.49%
[ Tue Jun 20 04:12:16 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:12:16 2023 ] Training epoch: 20
[ Tue Jun 20 04:12:17 2023 ] 	Training loss: 0.4867.  Training acc: 91.82%.
[ Tue Jun 20 04:12:17 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:12:17 2023 ] Eval epoch: 20
[ Tue Jun 20 04:12:18 2023 ] 	Mean test loss of 625 batches: 0.358712.
[ Tue Jun 20 04:12:18 2023 ] 	Top1: 96.49%
[ Tue Jun 20 04:12:18 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:12:18 2023 ] Training epoch: 21
[ Tue Jun 20 04:12:20 2023 ] 	Training loss: 0.4420.  Training acc: 93.29%.
[ Tue Jun 20 04:12:20 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:12:20 2023 ] Eval epoch: 21
[ Tue Jun 20 04:12:20 2023 ] 	Mean test loss of 625 batches: 0.356902.
[ Tue Jun 20 04:12:20 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:12:20 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:12:20 2023 ] Training epoch: 22
[ Tue Jun 20 04:12:22 2023 ] 	Training loss: 0.4395.  Training acc: 94.85%.
[ Tue Jun 20 04:12:22 2023 ] 	Time consumption: [Data]11%, [Network]88%
[ Tue Jun 20 04:12:22 2023 ] Eval epoch: 22
[ Tue Jun 20 04:12:22 2023 ] 	Mean test loss of 625 batches: 0.362537.
[ Tue Jun 20 04:12:22 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:12:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:12:22 2023 ] Training epoch: 23
[ Tue Jun 20 04:12:24 2023 ] 	Training loss: 0.4378.  Training acc: 94.21%.
[ Tue Jun 20 04:12:24 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:12:24 2023 ] Eval epoch: 23
[ Tue Jun 20 04:12:24 2023 ] 	Mean test loss of 625 batches: 0.355545.
[ Tue Jun 20 04:12:24 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:12:24 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:12:24 2023 ] Training epoch: 24
[ Tue Jun 20 04:12:26 2023 ] 	Training loss: 0.4277.  Training acc: 95.40%.
[ Tue Jun 20 04:12:26 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:12:26 2023 ] Eval epoch: 24
[ Tue Jun 20 04:12:26 2023 ] 	Mean test loss of 625 batches: 0.362445.
[ Tue Jun 20 04:12:26 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:12:26 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:12:26 2023 ] Training epoch: 25
[ Tue Jun 20 04:12:28 2023 ] 	Training loss: 0.4149.  Training acc: 95.59%.
[ Tue Jun 20 04:12:28 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:12:28 2023 ] Eval epoch: 25
[ Tue Jun 20 04:12:28 2023 ] 	Mean test loss of 625 batches: 0.343120.
[ Tue Jun 20 04:12:28 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:12:28 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:12:29 2023 ] Training epoch: 26
[ Tue Jun 20 04:12:30 2023 ] 	Training loss: 0.4277.  Training acc: 94.58%.
[ Tue Jun 20 04:12:30 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:12:30 2023 ] Eval epoch: 26
[ Tue Jun 20 04:12:31 2023 ] 	Mean test loss of 625 batches: 0.336883.
[ Tue Jun 20 04:12:31 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:12:31 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:12:31 2023 ] Training epoch: 27
[ Tue Jun 20 04:12:32 2023 ] 	Training loss: 0.4197.  Training acc: 95.04%.
[ Tue Jun 20 04:12:32 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:12:32 2023 ] Eval epoch: 27
[ Tue Jun 20 04:12:33 2023 ] 	Mean test loss of 625 batches: 0.338448.
[ Tue Jun 20 04:12:33 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:12:33 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:12:33 2023 ] Training epoch: 28
[ Tue Jun 20 04:12:35 2023 ] 	Training loss: 0.3977.  Training acc: 96.78%.
[ Tue Jun 20 04:12:35 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:12:35 2023 ] Eval epoch: 28
[ Tue Jun 20 04:12:35 2023 ] 	Mean test loss of 625 batches: 0.337694.
[ Tue Jun 20 04:12:35 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:12:35 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:12:35 2023 ] Training epoch: 29
[ Tue Jun 20 04:12:37 2023 ] 	Training loss: 0.4062.  Training acc: 96.32%.
[ Tue Jun 20 04:12:37 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:12:37 2023 ] Eval epoch: 29
[ Tue Jun 20 04:12:37 2023 ] 	Mean test loss of 625 batches: 0.331887.
[ Tue Jun 20 04:12:37 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:12:37 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:12:37 2023 ] Training epoch: 30
[ Tue Jun 20 04:12:39 2023 ] 	Training loss: 0.3994.  Training acc: 97.24%.
[ Tue Jun 20 04:12:39 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:12:39 2023 ] Eval epoch: 30
[ Tue Jun 20 04:12:39 2023 ] 	Mean test loss of 625 batches: 0.336580.
[ Tue Jun 20 04:12:39 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:12:39 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:01 2023 ] using warm up, epoch: 5
[ Tue Jun 20 04:16:03 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [15, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 04:16:03 2023 ] # Parameters: 1538958
[ Tue Jun 20 04:16:03 2023 ] Training epoch: 1
[ Tue Jun 20 04:16:07 2023 ] 	Training loss: 94.7972.  Training acc: 34.10%.
[ Tue Jun 20 04:16:07 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jun 20 04:16:07 2023 ] Eval epoch: 1
[ Tue Jun 20 04:16:08 2023 ] 	Mean test loss of 625 batches: 832.111853.
[ Tue Jun 20 04:16:08 2023 ] 	Top1: 38.60%
[ Tue Jun 20 04:16:08 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:08 2023 ] Training epoch: 2
[ Tue Jun 20 04:16:10 2023 ] 	Training loss: 8.5803.  Training acc: 37.96%.
[ Tue Jun 20 04:16:10 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:16:10 2023 ] Eval epoch: 2
[ Tue Jun 20 04:16:10 2023 ] 	Mean test loss of 625 batches: 40.465633.
[ Tue Jun 20 04:16:10 2023 ] 	Top1: 38.60%
[ Tue Jun 20 04:16:10 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:10 2023 ] Training epoch: 3
[ Tue Jun 20 04:16:12 2023 ] 	Training loss: 5.2021.  Training acc: 53.40%.
[ Tue Jun 20 04:16:12 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:16:12 2023 ] Eval epoch: 3
[ Tue Jun 20 04:16:12 2023 ] 	Mean test loss of 625 batches: 8.186336.
[ Tue Jun 20 04:16:12 2023 ] 	Top1: 33.33%
[ Tue Jun 20 04:16:12 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:12 2023 ] Training epoch: 4
[ Tue Jun 20 04:16:14 2023 ] 	Training loss: 2.3745.  Training acc: 74.82%.
[ Tue Jun 20 04:16:14 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:16:14 2023 ] Eval epoch: 4
[ Tue Jun 20 04:16:14 2023 ] 	Mean test loss of 625 batches: 1.749000.
[ Tue Jun 20 04:16:14 2023 ] 	Top1: 91.23%
[ Tue Jun 20 04:16:14 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:14 2023 ] Training epoch: 5
[ Tue Jun 20 04:16:16 2023 ] 	Training loss: 4.5611.  Training acc: 63.60%.
[ Tue Jun 20 04:16:16 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:16:16 2023 ] Eval epoch: 5
[ Tue Jun 20 04:16:16 2023 ] 	Mean test loss of 625 batches: 8.961640.
[ Tue Jun 20 04:16:16 2023 ] 	Top1: 38.60%
[ Tue Jun 20 04:16:16 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:16 2023 ] Training epoch: 6
[ Tue Jun 20 04:16:18 2023 ] 	Training loss: 5.6667.  Training acc: 34.01%.
[ Tue Jun 20 04:16:18 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:16:18 2023 ] Eval epoch: 6
[ Tue Jun 20 04:16:19 2023 ] 	Mean test loss of 625 batches: 1.503342.
[ Tue Jun 20 04:16:19 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:16:19 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:19 2023 ] Training epoch: 7
[ Tue Jun 20 04:16:20 2023 ] 	Training loss: 3.6617.  Training acc: 33.73%.
[ Tue Jun 20 04:16:20 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:16:20 2023 ] Eval epoch: 7
[ Tue Jun 20 04:16:21 2023 ] 	Mean test loss of 625 batches: 1.170354.
[ Tue Jun 20 04:16:21 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:16:21 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:21 2023 ] Training epoch: 8
[ Tue Jun 20 04:16:22 2023 ] 	Training loss: 2.9536.  Training acc: 31.62%.
[ Tue Jun 20 04:16:22 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:16:22 2023 ] Eval epoch: 8
[ Tue Jun 20 04:16:23 2023 ] 	Mean test loss of 625 batches: 1.299649.
[ Tue Jun 20 04:16:23 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:16:23 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:23 2023 ] Training epoch: 9
[ Tue Jun 20 04:16:25 2023 ] 	Training loss: 2.3648.  Training acc: 34.83%.
[ Tue Jun 20 04:16:25 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:16:25 2023 ] Eval epoch: 9
[ Tue Jun 20 04:16:25 2023 ] 	Mean test loss of 625 batches: 1.160523.
[ Tue Jun 20 04:16:25 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:16:25 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:25 2023 ] Training epoch: 10
[ Tue Jun 20 04:16:27 2023 ] 	Training loss: 2.0577.  Training acc: 33.82%.
[ Tue Jun 20 04:16:27 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:16:27 2023 ] Eval epoch: 10
[ Tue Jun 20 04:16:27 2023 ] 	Mean test loss of 625 batches: 1.129099.
[ Tue Jun 20 04:16:27 2023 ] 	Top1: 29.82%
[ Tue Jun 20 04:16:27 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:27 2023 ] Training epoch: 11
[ Tue Jun 20 04:16:29 2023 ] 	Training loss: 1.8178.  Training acc: 32.81%.
[ Tue Jun 20 04:16:29 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:16:29 2023 ] Eval epoch: 11
[ Tue Jun 20 04:16:29 2023 ] 	Mean test loss of 625 batches: 1.157282.
[ Tue Jun 20 04:16:29 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:16:29 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:29 2023 ] Training epoch: 12
[ Tue Jun 20 04:16:31 2023 ] 	Training loss: 1.5628.  Training acc: 33.55%.
[ Tue Jun 20 04:16:31 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:16:31 2023 ] Eval epoch: 12
[ Tue Jun 20 04:16:31 2023 ] 	Mean test loss of 625 batches: 1.122136.
[ Tue Jun 20 04:16:31 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:16:31 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:31 2023 ] Training epoch: 13
[ Tue Jun 20 04:16:33 2023 ] 	Training loss: 1.4811.  Training acc: 33.82%.
[ Tue Jun 20 04:16:33 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:16:33 2023 ] Eval epoch: 13
[ Tue Jun 20 04:16:33 2023 ] 	Mean test loss of 625 batches: 1.103598.
[ Tue Jun 20 04:16:33 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:16:33 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:33 2023 ] Training epoch: 14
[ Tue Jun 20 04:16:35 2023 ] 	Training loss: 1.3368.  Training acc: 37.22%.
[ Tue Jun 20 04:16:35 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:16:35 2023 ] Eval epoch: 14
[ Tue Jun 20 04:16:35 2023 ] 	Mean test loss of 625 batches: 1.173075.
[ Tue Jun 20 04:16:35 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:16:35 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:35 2023 ] Training epoch: 15
[ Tue Jun 20 04:16:37 2023 ] 	Training loss: 1.4742.  Training acc: 33.18%.
[ Tue Jun 20 04:16:37 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:16:37 2023 ] Eval epoch: 15
[ Tue Jun 20 04:16:38 2023 ] 	Mean test loss of 625 batches: 1.112608.
[ Tue Jun 20 04:16:38 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:16:38 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:38 2023 ] Training epoch: 16
[ Tue Jun 20 04:16:39 2023 ] 	Training loss: 1.2706.  Training acc: 35.29%.
[ Tue Jun 20 04:16:39 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:16:39 2023 ] Eval epoch: 16
[ Tue Jun 20 04:16:40 2023 ] 	Mean test loss of 625 batches: 1.102732.
[ Tue Jun 20 04:16:40 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:16:40 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:40 2023 ] Training epoch: 17
[ Tue Jun 20 04:16:42 2023 ] 	Training loss: 1.2630.  Training acc: 35.94%.
[ Tue Jun 20 04:16:42 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:16:42 2023 ] Eval epoch: 17
[ Tue Jun 20 04:16:42 2023 ] 	Mean test loss of 625 batches: 1.108794.
[ Tue Jun 20 04:16:42 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:16:42 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:42 2023 ] Training epoch: 18
[ Tue Jun 20 04:16:44 2023 ] 	Training loss: 1.2328.  Training acc: 33.73%.
[ Tue Jun 20 04:16:44 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:16:44 2023 ] Eval epoch: 18
[ Tue Jun 20 04:16:44 2023 ] 	Mean test loss of 625 batches: 1.104001.
[ Tue Jun 20 04:16:44 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:16:44 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:44 2023 ] Training epoch: 19
[ Tue Jun 20 04:16:46 2023 ] 	Training loss: 1.2220.  Training acc: 33.09%.
[ Tue Jun 20 04:16:46 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:16:46 2023 ] Eval epoch: 19
[ Tue Jun 20 04:16:46 2023 ] 	Mean test loss of 625 batches: 1.105116.
[ Tue Jun 20 04:16:46 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:16:46 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:46 2023 ] Training epoch: 20
[ Tue Jun 20 04:16:48 2023 ] 	Training loss: 1.2023.  Training acc: 35.66%.
[ Tue Jun 20 04:16:48 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:16:48 2023 ] Eval epoch: 20
[ Tue Jun 20 04:16:48 2023 ] 	Mean test loss of 625 batches: 1.106558.
[ Tue Jun 20 04:16:48 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:16:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:48 2023 ] Training epoch: 21
[ Tue Jun 20 04:16:50 2023 ] 	Training loss: 1.1790.  Training acc: 37.96%.
[ Tue Jun 20 04:16:50 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:16:50 2023 ] Eval epoch: 21
[ Tue Jun 20 04:16:50 2023 ] 	Mean test loss of 625 batches: 1.106585.
[ Tue Jun 20 04:16:50 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:16:50 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:50 2023 ] Training epoch: 22
[ Tue Jun 20 04:16:52 2023 ] 	Training loss: 1.1805.  Training acc: 36.49%.
[ Tue Jun 20 04:16:52 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:16:52 2023 ] Eval epoch: 22
[ Tue Jun 20 04:16:53 2023 ] 	Mean test loss of 625 batches: 1.106593.
[ Tue Jun 20 04:16:53 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:16:53 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:53 2023 ] Training epoch: 23
[ Tue Jun 20 04:16:54 2023 ] 	Training loss: 1.2208.  Training acc: 31.53%.
[ Tue Jun 20 04:16:54 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:16:54 2023 ] Eval epoch: 23
[ Tue Jun 20 04:16:55 2023 ] 	Mean test loss of 625 batches: 1.106343.
[ Tue Jun 20 04:16:55 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:16:55 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:55 2023 ] Training epoch: 24
[ Tue Jun 20 04:16:57 2023 ] 	Training loss: 1.1824.  Training acc: 35.20%.
[ Tue Jun 20 04:16:57 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:16:57 2023 ] Eval epoch: 24
[ Tue Jun 20 04:16:57 2023 ] 	Mean test loss of 625 batches: 1.106249.
[ Tue Jun 20 04:16:57 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:16:57 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:57 2023 ] Training epoch: 25
[ Tue Jun 20 04:16:59 2023 ] 	Training loss: 1.1787.  Training acc: 36.76%.
[ Tue Jun 20 04:16:59 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:16:59 2023 ] Eval epoch: 25
[ Tue Jun 20 04:16:59 2023 ] 	Mean test loss of 625 batches: 1.106320.
[ Tue Jun 20 04:16:59 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:16:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:16:59 2023 ] Training epoch: 26
[ Tue Jun 20 04:17:01 2023 ] 	Training loss: 1.2061.  Training acc: 33.46%.
[ Tue Jun 20 04:17:01 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:17:01 2023 ] Eval epoch: 26
[ Tue Jun 20 04:17:01 2023 ] 	Mean test loss of 625 batches: 1.106233.
[ Tue Jun 20 04:17:01 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:17:01 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:17:01 2023 ] Training epoch: 27
[ Tue Jun 20 04:17:03 2023 ] 	Training loss: 1.2077.  Training acc: 32.44%.
[ Tue Jun 20 04:17:03 2023 ] 	Time consumption: [Data]10%, [Network]89%
[ Tue Jun 20 04:17:03 2023 ] Eval epoch: 27
[ Tue Jun 20 04:17:03 2023 ] 	Mean test loss of 625 batches: 1.106016.
[ Tue Jun 20 04:17:03 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:17:03 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:17:03 2023 ] Training epoch: 28
[ Tue Jun 20 04:17:05 2023 ] 	Training loss: 1.1747.  Training acc: 35.57%.
[ Tue Jun 20 04:17:05 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:17:05 2023 ] Eval epoch: 28
[ Tue Jun 20 04:17:05 2023 ] 	Mean test loss of 625 batches: 1.105993.
[ Tue Jun 20 04:17:05 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:17:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:17:05 2023 ] Training epoch: 29
[ Tue Jun 20 04:17:07 2023 ] 	Training loss: 1.1746.  Training acc: 36.31%.
[ Tue Jun 20 04:17:07 2023 ] 	Time consumption: [Data]10%, [Network]90%
[ Tue Jun 20 04:17:07 2023 ] Eval epoch: 29
[ Tue Jun 20 04:17:08 2023 ] 	Mean test loss of 625 batches: 1.106117.
[ Tue Jun 20 04:17:08 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:17:08 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:17:08 2023 ] Training epoch: 30
[ Tue Jun 20 04:17:09 2023 ] 	Training loss: 1.1620.  Training acc: 35.94%.
[ Tue Jun 20 04:17:09 2023 ] 	Time consumption: [Data]11%, [Network]89%
[ Tue Jun 20 04:17:09 2023 ] Eval epoch: 30
[ Tue Jun 20 04:17:10 2023 ] 	Mean test loss of 625 batches: 1.106067.
[ Tue Jun 20 04:17:10 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:17:10 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:25:40 2023 ] using warm up, epoch: 5
[ Tue Jun 20 04:25:41 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [15, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 04:25:41 2023 ] # Parameters: 1538958
[ Tue Jun 20 04:25:41 2023 ] Training epoch: 1
[ Tue Jun 20 04:25:45 2023 ] 	Training loss: 87.9586.  Training acc: 34.65%.
[ Tue Jun 20 04:25:45 2023 ] 	Time consumption: [Data]06%, [Network]94%
[ Tue Jun 20 04:25:45 2023 ] Eval epoch: 1
[ Tue Jun 20 04:25:46 2023 ] 	Mean test loss of 625 batches: 203.847009.
[ Tue Jun 20 04:25:46 2023 ] 	Top1: 38.60%
[ Tue Jun 20 04:25:46 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:25:46 2023 ] Training epoch: 2
[ Tue Jun 20 04:25:48 2023 ] 	Training loss: 8.0260.  Training acc: 39.61%.
[ Tue Jun 20 04:25:48 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:25:48 2023 ] Eval epoch: 2
[ Tue Jun 20 04:25:48 2023 ] 	Mean test loss of 625 batches: 4.588953.
[ Tue Jun 20 04:25:48 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:25:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:25:48 2023 ] Training epoch: 3
[ Tue Jun 20 04:25:50 2023 ] 	Training loss: 4.6320.  Training acc: 52.30%.
[ Tue Jun 20 04:25:50 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:25:50 2023 ] Eval epoch: 3
[ Tue Jun 20 04:25:51 2023 ] 	Mean test loss of 625 batches: 1.879528.
[ Tue Jun 20 04:25:51 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:25:51 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:25:51 2023 ] Training epoch: 4
[ Tue Jun 20 04:25:53 2023 ] 	Training loss: 2.7946.  Training acc: 60.85%.
[ Tue Jun 20 04:25:53 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 04:25:53 2023 ] Eval epoch: 4
[ Tue Jun 20 04:25:53 2023 ] 	Mean test loss of 625 batches: 3.787295.
[ Tue Jun 20 04:25:53 2023 ] 	Top1: 33.33%
[ Tue Jun 20 04:25:53 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:25:53 2023 ] Training epoch: 5
[ Tue Jun 20 04:25:55 2023 ] 	Training loss: 2.7443.  Training acc: 56.71%.
[ Tue Jun 20 04:25:55 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:25:55 2023 ] Eval epoch: 5
[ Tue Jun 20 04:25:55 2023 ] 	Mean test loss of 625 batches: 23.108966.
[ Tue Jun 20 04:25:55 2023 ] 	Top1: 38.60%
[ Tue Jun 20 04:25:55 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:25:55 2023 ] Training epoch: 6
[ Tue Jun 20 04:25:57 2023 ] 	Training loss: 2.1714.  Training acc: 59.93%.
[ Tue Jun 20 04:25:57 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:25:57 2023 ] Eval epoch: 6
[ Tue Jun 20 04:25:58 2023 ] 	Mean test loss of 625 batches: 4.343780.
[ Tue Jun 20 04:25:58 2023 ] 	Top1: 52.63%
[ Tue Jun 20 04:25:58 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:25:58 2023 ] Training epoch: 7
[ Tue Jun 20 04:26:00 2023 ] 	Training loss: 1.6237.  Training acc: 61.58%.
[ Tue Jun 20 04:26:00 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 20 04:26:00 2023 ] Eval epoch: 7
[ Tue Jun 20 04:26:00 2023 ] 	Mean test loss of 625 batches: 1.129901.
[ Tue Jun 20 04:26:00 2023 ] 	Top1: 75.44%
[ Tue Jun 20 04:26:00 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:00 2023 ] Training epoch: 8
[ Tue Jun 20 04:26:02 2023 ] 	Training loss: 1.2310.  Training acc: 66.82%.
[ Tue Jun 20 04:26:02 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:26:02 2023 ] Eval epoch: 8
[ Tue Jun 20 04:26:03 2023 ] 	Mean test loss of 625 batches: 5.088612.
[ Tue Jun 20 04:26:03 2023 ] 	Top1: 49.12%
[ Tue Jun 20 04:26:03 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:03 2023 ] Training epoch: 9
[ Tue Jun 20 04:26:04 2023 ] 	Training loss: 1.3471.  Training acc: 65.44%.
[ Tue Jun 20 04:26:04 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:26:04 2023 ] Eval epoch: 9
[ Tue Jun 20 04:26:05 2023 ] 	Mean test loss of 625 batches: 0.789792.
[ Tue Jun 20 04:26:05 2023 ] 	Top1: 70.18%
[ Tue Jun 20 04:26:05 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:05 2023 ] Training epoch: 10
[ Tue Jun 20 04:26:07 2023 ] 	Training loss: 0.8329.  Training acc: 78.77%.
[ Tue Jun 20 04:26:07 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 04:26:07 2023 ] Eval epoch: 10
[ Tue Jun 20 04:26:07 2023 ] 	Mean test loss of 625 batches: 0.856384.
[ Tue Jun 20 04:26:07 2023 ] 	Top1: 66.67%
[ Tue Jun 20 04:26:07 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:07 2023 ] Training epoch: 11
[ Tue Jun 20 04:26:09 2023 ] 	Training loss: 0.8368.  Training acc: 79.04%.
[ Tue Jun 20 04:26:09 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 04:26:09 2023 ] Eval epoch: 11
[ Tue Jun 20 04:26:10 2023 ] 	Mean test loss of 625 batches: 4.133052.
[ Tue Jun 20 04:26:10 2023 ] 	Top1: 49.12%
[ Tue Jun 20 04:26:10 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:10 2023 ] Training epoch: 12
[ Tue Jun 20 04:26:12 2023 ] 	Training loss: 1.2141.  Training acc: 77.57%.
[ Tue Jun 20 04:26:12 2023 ] 	Time consumption: [Data]15%, [Network]84%
[ Tue Jun 20 04:26:12 2023 ] Eval epoch: 12
[ Tue Jun 20 04:26:12 2023 ] 	Mean test loss of 625 batches: 0.510896.
[ Tue Jun 20 04:26:12 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:26:12 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:12 2023 ] Training epoch: 13
[ Tue Jun 20 04:26:14 2023 ] 	Training loss: 1.1552.  Training acc: 79.41%.
[ Tue Jun 20 04:26:14 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 04:26:14 2023 ] Eval epoch: 13
[ Tue Jun 20 04:26:15 2023 ] 	Mean test loss of 625 batches: 1.628804.
[ Tue Jun 20 04:26:15 2023 ] 	Top1: 78.95%
[ Tue Jun 20 04:26:15 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:15 2023 ] Training epoch: 14
[ Tue Jun 20 04:26:17 2023 ] 	Training loss: 0.9779.  Training acc: 76.84%.
[ Tue Jun 20 04:26:17 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 04:26:17 2023 ] Eval epoch: 14
[ Tue Jun 20 04:26:17 2023 ] 	Mean test loss of 625 batches: 1.361665.
[ Tue Jun 20 04:26:17 2023 ] 	Top1: 66.67%
[ Tue Jun 20 04:26:17 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:17 2023 ] Training epoch: 15
[ Tue Jun 20 04:26:19 2023 ] 	Training loss: 0.6799.  Training acc: 82.08%.
[ Tue Jun 20 04:26:19 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 04:26:19 2023 ] Eval epoch: 15
[ Tue Jun 20 04:26:20 2023 ] 	Mean test loss of 625 batches: 1.717866.
[ Tue Jun 20 04:26:20 2023 ] 	Top1: 73.68%
[ Tue Jun 20 04:26:20 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:20 2023 ] Training epoch: 16
[ Tue Jun 20 04:26:22 2023 ] 	Training loss: 0.5566.  Training acc: 90.35%.
[ Tue Jun 20 04:26:22 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 04:26:22 2023 ] Eval epoch: 16
[ Tue Jun 20 04:26:22 2023 ] 	Mean test loss of 625 batches: 0.409162.
[ Tue Jun 20 04:26:22 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:26:22 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:22 2023 ] Training epoch: 17
[ Tue Jun 20 04:26:24 2023 ] 	Training loss: 0.4433.  Training acc: 93.29%.
[ Tue Jun 20 04:26:24 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 04:26:24 2023 ] Eval epoch: 17
[ Tue Jun 20 04:26:25 2023 ] 	Mean test loss of 625 batches: 0.358658.
[ Tue Jun 20 04:26:25 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:26:25 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:25 2023 ] Training epoch: 18
[ Tue Jun 20 04:26:26 2023 ] 	Training loss: 0.4172.  Training acc: 94.76%.
[ Tue Jun 20 04:26:26 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:26:26 2023 ] Eval epoch: 18
[ Tue Jun 20 04:26:27 2023 ] 	Mean test loss of 625 batches: 0.354472.
[ Tue Jun 20 04:26:27 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:26:27 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:27 2023 ] Training epoch: 19
[ Tue Jun 20 04:26:29 2023 ] 	Training loss: 0.3732.  Training acc: 97.70%.
[ Tue Jun 20 04:26:29 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:26:29 2023 ] Eval epoch: 19
[ Tue Jun 20 04:26:29 2023 ] 	Mean test loss of 625 batches: 0.340494.
[ Tue Jun 20 04:26:29 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:26:29 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:29 2023 ] Training epoch: 20
[ Tue Jun 20 04:26:31 2023 ] 	Training loss: 0.3669.  Training acc: 97.61%.
[ Tue Jun 20 04:26:31 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:26:31 2023 ] Eval epoch: 20
[ Tue Jun 20 04:26:32 2023 ] 	Mean test loss of 625 batches: 0.331646.
[ Tue Jun 20 04:26:32 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:26:32 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:32 2023 ] Training epoch: 21
[ Tue Jun 20 04:26:34 2023 ] 	Training loss: 0.3507.  Training acc: 98.25%.
[ Tue Jun 20 04:26:34 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:26:34 2023 ] Eval epoch: 21
[ Tue Jun 20 04:26:34 2023 ] 	Mean test loss of 625 batches: 0.327540.
[ Tue Jun 20 04:26:34 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:26:34 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:34 2023 ] Training epoch: 22
[ Tue Jun 20 04:26:36 2023 ] 	Training loss: 0.3514.  Training acc: 98.16%.
[ Tue Jun 20 04:26:36 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:26:36 2023 ] Eval epoch: 22
[ Tue Jun 20 04:26:36 2023 ] 	Mean test loss of 625 batches: 0.328401.
[ Tue Jun 20 04:26:36 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:26:36 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:36 2023 ] Training epoch: 23
[ Tue Jun 20 04:26:38 2023 ] 	Training loss: 0.3528.  Training acc: 98.35%.
[ Tue Jun 20 04:26:38 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 04:26:38 2023 ] Eval epoch: 23
[ Tue Jun 20 04:26:39 2023 ] 	Mean test loss of 625 batches: 0.325391.
[ Tue Jun 20 04:26:39 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:26:39 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:39 2023 ] Training epoch: 24
[ Tue Jun 20 04:26:41 2023 ] 	Training loss: 0.3585.  Training acc: 98.07%.
[ Tue Jun 20 04:26:41 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 04:26:41 2023 ] Eval epoch: 24
[ Tue Jun 20 04:26:41 2023 ] 	Mean test loss of 625 batches: 0.329990.
[ Tue Jun 20 04:26:41 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:26:41 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:41 2023 ] Training epoch: 25
[ Tue Jun 20 04:26:43 2023 ] 	Training loss: 0.3478.  Training acc: 98.44%.
[ Tue Jun 20 04:26:43 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 04:26:43 2023 ] Eval epoch: 25
[ Tue Jun 20 04:26:44 2023 ] 	Mean test loss of 625 batches: 0.322299.
[ Tue Jun 20 04:26:44 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:26:44 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:44 2023 ] Training epoch: 26
[ Tue Jun 20 04:26:46 2023 ] 	Training loss: 0.3487.  Training acc: 98.16%.
[ Tue Jun 20 04:26:46 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 04:26:46 2023 ] Eval epoch: 26
[ Tue Jun 20 04:26:47 2023 ] 	Mean test loss of 625 batches: 0.323139.
[ Tue Jun 20 04:26:47 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:26:47 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:47 2023 ] Training epoch: 27
[ Tue Jun 20 04:26:48 2023 ] 	Training loss: 0.3437.  Training acc: 98.71%.
[ Tue Jun 20 04:26:48 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 04:26:48 2023 ] Eval epoch: 27
[ Tue Jun 20 04:26:49 2023 ] 	Mean test loss of 625 batches: 0.322815.
[ Tue Jun 20 04:26:49 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:26:49 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:49 2023 ] Training epoch: 28
[ Tue Jun 20 04:26:51 2023 ] 	Training loss: 0.3454.  Training acc: 98.62%.
[ Tue Jun 20 04:26:51 2023 ] 	Time consumption: [Data]17%, [Network]83%
[ Tue Jun 20 04:26:51 2023 ] Eval epoch: 28
[ Tue Jun 20 04:26:51 2023 ] 	Mean test loss of 625 batches: 0.323119.
[ Tue Jun 20 04:26:51 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:26:51 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:51 2023 ] Training epoch: 29
[ Tue Jun 20 04:26:53 2023 ] 	Training loss: 0.3401.  Training acc: 98.90%.
[ Tue Jun 20 04:26:53 2023 ] 	Time consumption: [Data]13%, [Network]87%
[ Tue Jun 20 04:26:53 2023 ] Eval epoch: 29
[ Tue Jun 20 04:26:54 2023 ] 	Mean test loss of 625 batches: 0.320955.
[ Tue Jun 20 04:26:54 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:26:54 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:54 2023 ] Training epoch: 30
[ Tue Jun 20 04:26:56 2023 ] 	Training loss: 0.3488.  Training acc: 98.44%.
[ Tue Jun 20 04:26:56 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 04:26:56 2023 ] Eval epoch: 30
[ Tue Jun 20 04:26:56 2023 ] 	Mean test loss of 625 batches: 0.320604.
[ Tue Jun 20 04:26:56 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:26:56 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:26:57 2023 ] Best accuracy: 0.9824561403508771
[ Tue Jun 20 04:26:57 2023 ] Epoch number: 12
[ Tue Jun 20 04:26:57 2023 ] Model name: results/ec3d_NTU60_CS
[ Tue Jun 20 04:26:57 2023 ] Model total number of params: 1538958
[ Tue Jun 20 04:26:57 2023 ] Weight decay: 0.0005
[ Tue Jun 20 04:26:57 2023 ] Base LR: 0.1
[ Tue Jun 20 04:26:57 2023 ] Batch Size: 64
[ Tue Jun 20 04:26:57 2023 ] Test Batch Size: 64
[ Tue Jun 20 04:26:57 2023 ] seed: 1
[ Tue Jun 20 04:31:17 2023 ] using warm up, epoch: 5
[ Tue Jun 20 04:31:19 2023 ] Parameters:
{'debug': False, 'log_dir': '.', 'model_saved_name': '', 'noise_ratio': 0.5, 'n_desired': 40000, 'num_point': 25, 'num_person': 1, 'num_class': 3, 'dataset': 'ec3d', 'datacase': 'NTU60_CS', 'use_vel': False, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 10, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ec3d.Feeder', 'num_worker': 4, 'balanced_sampling': False, 'random_rot': True, 'repeat': 1, 'weights': None, 'ignore_weights': [], 'n_heads': 3, 'k': 1, 'z_prior_gain': 3, 'graph': 'graph.ec3d.Graph', 'base_lr': 0.1, 'step': [15, 20], 'optimizer': 'Adam', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 30, 'weight_decay': 0.0005, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5, 'lambda_1': 0.0001, 'lambda_2': 0.1, 'half': False, 'amp_opt_level': 1, 'work_dir': 'results/ec3d_NTU60_CS'}

[ Tue Jun 20 04:31:19 2023 ] # Parameters: 1538958
[ Tue Jun 20 04:31:19 2023 ] Training epoch: 1
[ Tue Jun 20 04:31:23 2023 ] 	Training loss: 94.2745.  Training acc: 33.73%.
[ Tue Jun 20 04:31:23 2023 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jun 20 04:31:23 2023 ] Eval epoch: 1
[ Tue Jun 20 04:31:24 2023 ] 	Mean test loss of 625 batches: 1488.178882.
[ Tue Jun 20 04:31:24 2023 ] 	Top1: 38.60%
[ Tue Jun 20 04:31:24 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:31:24 2023 ] Training epoch: 2
[ Tue Jun 20 04:31:26 2023 ] 	Training loss: 8.1431.  Training acc: 37.59%.
[ Tue Jun 20 04:31:26 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 20 04:31:26 2023 ] Eval epoch: 2
[ Tue Jun 20 04:31:26 2023 ] 	Mean test loss of 625 batches: 2.064609.
[ Tue Jun 20 04:31:26 2023 ] 	Top1: 31.58%
[ Tue Jun 20 04:31:26 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:31:26 2023 ] Training epoch: 3
[ Tue Jun 20 04:31:28 2023 ] 	Training loss: 5.1589.  Training acc: 50.55%.
[ Tue Jun 20 04:31:28 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:31:28 2023 ] Eval epoch: 3
[ Tue Jun 20 04:31:29 2023 ] 	Mean test loss of 625 batches: 2.358512.
[ Tue Jun 20 04:31:29 2023 ] 	Top1: 24.56%
[ Tue Jun 20 04:31:29 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:31:29 2023 ] Training epoch: 4
[ Tue Jun 20 04:31:31 2023 ] 	Training loss: 3.0255.  Training acc: 69.30%.
[ Tue Jun 20 04:31:31 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:31:31 2023 ] Eval epoch: 4
[ Tue Jun 20 04:31:31 2023 ] 	Mean test loss of 625 batches: 9.626069.
[ Tue Jun 20 04:31:31 2023 ] 	Top1: 38.60%
[ Tue Jun 20 04:31:31 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:31:31 2023 ] Training epoch: 5
[ Tue Jun 20 04:31:33 2023 ] 	Training loss: 2.6608.  Training acc: 61.76%.
[ Tue Jun 20 04:31:33 2023 ] 	Time consumption: [Data]18%, [Network]82%
[ Tue Jun 20 04:31:33 2023 ] Eval epoch: 5
[ Tue Jun 20 04:31:34 2023 ] 	Mean test loss of 625 batches: 4.018153.
[ Tue Jun 20 04:31:34 2023 ] 	Top1: 29.82%
[ Tue Jun 20 04:31:34 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:31:34 2023 ] Training epoch: 6
[ Tue Jun 20 04:31:35 2023 ] 	Training loss: 2.2680.  Training acc: 61.12%.
[ Tue Jun 20 04:31:35 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:31:35 2023 ] Eval epoch: 6
[ Tue Jun 20 04:31:36 2023 ] 	Mean test loss of 625 batches: 14.845348.
[ Tue Jun 20 04:31:36 2023 ] 	Top1: 38.60%
[ Tue Jun 20 04:31:36 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:31:36 2023 ] Training epoch: 7
[ Tue Jun 20 04:31:38 2023 ] 	Training loss: 1.7820.  Training acc: 67.28%.
[ Tue Jun 20 04:31:38 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 04:31:38 2023 ] Eval epoch: 7
[ Tue Jun 20 04:31:38 2023 ] 	Mean test loss of 625 batches: 3.670178.
[ Tue Jun 20 04:31:38 2023 ] 	Top1: 40.35%
[ Tue Jun 20 04:31:38 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:31:38 2023 ] Training epoch: 8
[ Tue Jun 20 04:31:40 2023 ] 	Training loss: 2.1388.  Training acc: 67.19%.
[ Tue Jun 20 04:31:40 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:31:40 2023 ] Eval epoch: 8
[ Tue Jun 20 04:31:41 2023 ] 	Mean test loss of 625 batches: 2.485728.
[ Tue Jun 20 04:31:41 2023 ] 	Top1: 33.33%
[ Tue Jun 20 04:31:41 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:31:41 2023 ] Training epoch: 9
[ Tue Jun 20 04:31:42 2023 ] 	Training loss: 1.3142.  Training acc: 74.54%.
[ Tue Jun 20 04:31:42 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:31:42 2023 ] Eval epoch: 9
[ Tue Jun 20 04:31:43 2023 ] 	Mean test loss of 625 batches: 4.780332.
[ Tue Jun 20 04:31:43 2023 ] 	Top1: 29.82%
[ Tue Jun 20 04:31:43 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:31:43 2023 ] Training epoch: 10
[ Tue Jun 20 04:31:45 2023 ] 	Training loss: 1.4892.  Training acc: 72.06%.
[ Tue Jun 20 04:31:45 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 04:31:45 2023 ] Eval epoch: 10
[ Tue Jun 20 04:31:45 2023 ] 	Mean test loss of 625 batches: 1.082076.
[ Tue Jun 20 04:31:45 2023 ] 	Top1: 78.95%
[ Tue Jun 20 04:31:45 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:31:45 2023 ] Training epoch: 11
[ Tue Jun 20 04:31:47 2023 ] 	Training loss: 1.4490.  Training acc: 73.81%.
[ Tue Jun 20 04:31:47 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 04:31:47 2023 ] Eval epoch: 11
[ Tue Jun 20 04:31:48 2023 ] 	Mean test loss of 625 batches: 0.715537.
[ Tue Jun 20 04:31:48 2023 ] 	Top1: 92.98%
[ Tue Jun 20 04:31:48 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:31:48 2023 ] Training epoch: 12
[ Tue Jun 20 04:31:50 2023 ] 	Training loss: 1.1716.  Training acc: 75.55%.
[ Tue Jun 20 04:31:50 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 04:31:50 2023 ] Eval epoch: 12
[ Tue Jun 20 04:31:50 2023 ] 	Mean test loss of 625 batches: 0.875222.
[ Tue Jun 20 04:31:50 2023 ] 	Top1: 80.70%
[ Tue Jun 20 04:31:50 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:31:50 2023 ] Training epoch: 13
[ Tue Jun 20 04:31:52 2023 ] 	Training loss: 1.0774.  Training acc: 77.30%.
[ Tue Jun 20 04:31:52 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:31:52 2023 ] Eval epoch: 13
[ Tue Jun 20 04:31:52 2023 ] 	Mean test loss of 625 batches: 1.102828.
[ Tue Jun 20 04:31:52 2023 ] 	Top1: 68.42%
[ Tue Jun 20 04:31:52 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:31:52 2023 ] Training epoch: 14
[ Tue Jun 20 04:31:54 2023 ] 	Training loss: 0.6753.  Training acc: 87.59%.
[ Tue Jun 20 04:31:54 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 20 04:31:54 2023 ] Eval epoch: 14
[ Tue Jun 20 04:31:55 2023 ] 	Mean test loss of 625 batches: 1.241117.
[ Tue Jun 20 04:31:55 2023 ] 	Top1: 68.42%
[ Tue Jun 20 04:31:55 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:31:55 2023 ] Training epoch: 15
[ Tue Jun 20 04:31:57 2023 ] 	Training loss: 0.5058.  Training acc: 91.08%.
[ Tue Jun 20 04:31:57 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 04:31:57 2023 ] Eval epoch: 15
[ Tue Jun 20 04:31:57 2023 ] 	Mean test loss of 625 batches: 0.651539.
[ Tue Jun 20 04:31:57 2023 ] 	Top1: 82.46%
[ Tue Jun 20 04:31:57 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:31:57 2023 ] Training epoch: 16
[ Tue Jun 20 04:31:59 2023 ] 	Training loss: 0.5171.  Training acc: 94.03%.
[ Tue Jun 20 04:31:59 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:31:59 2023 ] Eval epoch: 16
[ Tue Jun 20 04:31:59 2023 ] 	Mean test loss of 625 batches: 0.365705.
[ Tue Jun 20 04:31:59 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:31:59 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:31:59 2023 ] Training epoch: 17
[ Tue Jun 20 04:32:01 2023 ] 	Training loss: 0.4278.  Training acc: 95.50%.
[ Tue Jun 20 04:32:01 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:32:01 2023 ] Eval epoch: 17
[ Tue Jun 20 04:32:02 2023 ] 	Mean test loss of 625 batches: 0.334574.
[ Tue Jun 20 04:32:02 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:32:02 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:32:02 2023 ] Training epoch: 18
[ Tue Jun 20 04:32:04 2023 ] 	Training loss: 0.3967.  Training acc: 96.32%.
[ Tue Jun 20 04:32:04 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:32:04 2023 ] Eval epoch: 18
[ Tue Jun 20 04:32:04 2023 ] 	Mean test loss of 625 batches: 0.327872.
[ Tue Jun 20 04:32:04 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:32:04 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:32:04 2023 ] Training epoch: 19
[ Tue Jun 20 04:32:06 2023 ] 	Training loss: 0.3906.  Training acc: 96.69%.
[ Tue Jun 20 04:32:06 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 20 04:32:06 2023 ] Eval epoch: 19
[ Tue Jun 20 04:32:06 2023 ] 	Mean test loss of 625 batches: 0.332070.
[ Tue Jun 20 04:32:06 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:32:06 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:32:06 2023 ] Training epoch: 20
[ Tue Jun 20 04:32:08 2023 ] 	Training loss: 0.3773.  Training acc: 97.98%.
[ Tue Jun 20 04:32:08 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:32:08 2023 ] Eval epoch: 20
[ Tue Jun 20 04:32:09 2023 ] 	Mean test loss of 625 batches: 0.331047.
[ Tue Jun 20 04:32:09 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:32:09 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:32:09 2023 ] Training epoch: 21
[ Tue Jun 20 04:32:11 2023 ] 	Training loss: 0.3685.  Training acc: 97.89%.
[ Tue Jun 20 04:32:11 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 04:32:11 2023 ] Eval epoch: 21
[ Tue Jun 20 04:32:11 2023 ] 	Mean test loss of 625 batches: 0.325097.
[ Tue Jun 20 04:32:11 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:32:11 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:32:11 2023 ] Training epoch: 22
[ Tue Jun 20 04:32:13 2023 ] 	Training loss: 0.3703.  Training acc: 98.16%.
[ Tue Jun 20 04:32:13 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 04:32:13 2023 ] Eval epoch: 22
[ Tue Jun 20 04:32:13 2023 ] 	Mean test loss of 625 batches: 0.325670.
[ Tue Jun 20 04:32:13 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:32:13 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:32:13 2023 ] Training epoch: 23
[ Tue Jun 20 04:32:15 2023 ] 	Training loss: 0.3630.  Training acc: 98.81%.
[ Tue Jun 20 04:32:15 2023 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Jun 20 04:32:15 2023 ] Eval epoch: 23
[ Tue Jun 20 04:32:16 2023 ] 	Mean test loss of 625 batches: 0.323121.
[ Tue Jun 20 04:32:16 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:32:16 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:32:16 2023 ] Training epoch: 24
[ Tue Jun 20 04:32:18 2023 ] 	Training loss: 0.3651.  Training acc: 98.07%.
[ Tue Jun 20 04:32:18 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 04:32:18 2023 ] Eval epoch: 24
[ Tue Jun 20 04:32:18 2023 ] 	Mean test loss of 625 batches: 0.328014.
[ Tue Jun 20 04:32:18 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:32:18 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:32:18 2023 ] Training epoch: 25
[ Tue Jun 20 04:32:20 2023 ] 	Training loss: 0.3623.  Training acc: 97.70%.
[ Tue Jun 20 04:32:20 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 04:32:20 2023 ] Eval epoch: 25
[ Tue Jun 20 04:32:20 2023 ] 	Mean test loss of 625 batches: 0.324179.
[ Tue Jun 20 04:32:20 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:32:20 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:32:20 2023 ] Training epoch: 26
[ Tue Jun 20 04:32:22 2023 ] 	Training loss: 0.3539.  Training acc: 98.81%.
[ Tue Jun 20 04:32:22 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 04:32:22 2023 ] Eval epoch: 26
[ Tue Jun 20 04:32:23 2023 ] 	Mean test loss of 625 batches: 0.322643.
[ Tue Jun 20 04:32:23 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:32:23 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:32:23 2023 ] Training epoch: 27
[ Tue Jun 20 04:32:25 2023 ] 	Training loss: 0.3566.  Training acc: 98.16%.
[ Tue Jun 20 04:32:25 2023 ] 	Time consumption: [Data]16%, [Network]84%
[ Tue Jun 20 04:32:25 2023 ] Eval epoch: 27
[ Tue Jun 20 04:32:25 2023 ] 	Mean test loss of 625 batches: 0.321565.
[ Tue Jun 20 04:32:25 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:32:25 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:32:25 2023 ] Training epoch: 28
[ Tue Jun 20 04:32:27 2023 ] 	Training loss: 0.3578.  Training acc: 98.71%.
[ Tue Jun 20 04:32:27 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 04:32:27 2023 ] Eval epoch: 28
[ Tue Jun 20 04:32:27 2023 ] 	Mean test loss of 625 batches: 0.321402.
[ Tue Jun 20 04:32:27 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:32:27 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:32:27 2023 ] Training epoch: 29
[ Tue Jun 20 04:32:29 2023 ] 	Training loss: 0.3611.  Training acc: 98.16%.
[ Tue Jun 20 04:32:29 2023 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Jun 20 04:32:29 2023 ] Eval epoch: 29
[ Tue Jun 20 04:32:30 2023 ] 	Mean test loss of 625 batches: 0.321466.
[ Tue Jun 20 04:32:30 2023 ] 	Top1: 100.00%
[ Tue Jun 20 04:32:30 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:32:30 2023 ] Training epoch: 30
[ Tue Jun 20 04:32:32 2023 ] 	Training loss: 0.3559.  Training acc: 98.07%.
[ Tue Jun 20 04:32:32 2023 ] 	Time consumption: [Data]15%, [Network]85%
[ Tue Jun 20 04:32:32 2023 ] Eval epoch: 30
[ Tue Jun 20 04:32:32 2023 ] 	Mean test loss of 625 batches: 0.323172.
[ Tue Jun 20 04:32:32 2023 ] 	Top1: 98.25%
[ Tue Jun 20 04:32:32 2023 ] 	Top5: 100.00%
[ Tue Jun 20 04:32:33 2023 ] Best accuracy: 1.0
[ Tue Jun 20 04:32:33 2023 ] Epoch number: 18
[ Tue Jun 20 04:32:33 2023 ] Model name: results/ec3d_NTU60_CS
[ Tue Jun 20 04:32:33 2023 ] Model total number of params: 1538958
[ Tue Jun 20 04:32:33 2023 ] Weight decay: 0.0005
[ Tue Jun 20 04:32:33 2023 ] Base LR: 0.1
[ Tue Jun 20 04:32:33 2023 ] Batch Size: 64
[ Tue Jun 20 04:32:33 2023 ] Test Batch Size: 64
[ Tue Jun 20 04:32:33 2023 ] seed: 1
